{"chunk_id": "NIST.FIPS.203::c00000", "doc_id": "NIST.FIPS.203", "start_page": 1, "end_page": 4, "text": "FIPS 203\n\nFederal Information Processing Standards Publication\n\nModule-Lattice-Based Key-Encapsulation Mechanism Standard\n\nCategory: Computer Security Subcategory: Cryptography\n\nInformation Technology Laboratory National Institute of Standards and Technology Gaithersburg, MD 20899-8900\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.FIPS.203\n\nPublished August 13, 2024\n\nU.S. Department of Commerce Gina M. Raimondo, Secretary\n\n0 National Institute of Standards and Technology Laurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology\n\nCheck for updates\n\nForeword\n\nThe Federal Information Processing Standards (FIPS) Publication Series of the National Institute of Standards and Technology is the official series of publications relating to standards and guidelines developed under 15 U.S.C. 278g-3, and issued by the Secretary of Commerce under 40 U.S.C. 11331. Comments concerning this Federal Information Processing Standard publication are welcomed and should be submitted using the contact information in the “Inquiries and Comments” clause of the announcement section.\n\nKevin M. Stine, Director Information Technology Laboratory\n\nAbstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography.\n\nFederal Information Processing Standards Publication 203\n\nPublished: August 13, 2024 Effective: August 13, 2024\n\nAnnouncing the Module-Lattice-Based Key-Encapsulation Mechanism Standard\n\nFederal Information Processing Standards (FIPS) publications are developed by the National Institute of Standards and Technology (NIST) under 15 U.S.C. 278g-3 and issued by the Secretary of Commerce under 40 U.S.C. 11331. 1. Name of Standard. Module-Lattice-Based Key-Encapsulation Mechanism Standard (FIPS 203). 2. Category of Standard. Computer Security. Subcategory. Cryptography. 3. Explanation. A cryptographic key (or simply “key”) is represented in a computer as a string of bits. A shared secret key is a cryptographic key that is computed jointly by two parties (e.g., Alice and Bob) using a set of algorithms. Under certain conditions, these algorithms ensure that both parties will produce the same key and that this key is secret from adversaries. Such a shared secret key can then be used with symmetric-key cryptographic algorithms (specified in other NIST standards) to perform tasks such as encryption and authentication of digital information. This standard specifies a set of algorithms for establishing a shared secret key. While there are many methods for establishing a shared secret key, the particular method described in this standard is a key-encapsulation mechanism (KEM). In a KEM, the computation of the shared secret key begins with Alice generating a decapsu- lation key and an encapsulation key. Alice keeps the decapsulation key private and makes the encapsulation key available to Bob. Bob then uses Alice’s encapsulation key to generate one copy of a shared secret key along with an associated ciphertext.", "char_len": 3979, "approx_tokens": 994}
{"chunk_id": "NIST.FIPS.203::c00001", "doc_id": "NIST.FIPS.203", "start_page": 4, "end_page": 5, "text": "digital information. This standard specifies a set of algorithms for establishing a shared secret key. While there are many methods for establishing a shared secret key, the particular method described in this standard is a key-encapsulation mechanism (KEM). In a KEM, the computation of the shared secret key begins with Alice generating a decapsu- lation key and an encapsulation key. Alice keeps the decapsulation key private and makes the encapsulation key available to Bob. Bob then uses Alice’s encapsulation key to generate one copy of a shared secret key along with an associated ciphertext. Bob then sends the ciphertext to Alice. Finally, Alice uses the ciphertext from Bob along with Alice’s private decapsulation key to compute another copy of the shared secret key. The security of the particular KEM specified in this standard is related to the computational difficulty of solving certain systems of noisy linear equations, specifically the Module Learn- ing With Errors (MLWE) problem. At present, it is believed that this particular method of establishing a shared secret key is secure, even against adversaries who possess a quantum computer. In the future, additional KEMs may be specified and approved in FIPS publications or in NIST Special Publications. 4. Approving Authority. Secretary of Commerce. 5. Maintenance Agency. Department of Commerce, National Institute of Standards and Tech- nology, Information Technology Laboratory (ITL).\n\ni\n\n6. Applicability. Federal Information Processing Standards apply to information systems used or operated by federal agencies or by a contractor of an agency or other organization on behalf of an agency. They do not apply to national security systems as defined in 44 U.S.C. 3552. This standard, or other FIPS or NIST Special Publications that specify alternative mechanisms, shall be used wherever the establishment of a shared secret key (or shared secret from which keying material can be generated) is required for federal applications, including the use of such a key with symmetric-key cryptographic algorithms, in accordance with applicable Office of Management and Budget and agency policies. The adoption and use of this standard are available to private and commercial organizations. 7. Implementations. A key-encapsulation mechanism may be implemented in software, firmware, hardware, or any combination thereof. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, different procedures that produce the correct output for every input are permitted. NIST will develop a validation program to test implementations for conformance to the algorithms in this standard. Information about validation programs is available at https: //csrc.nist.gov/projects/cmvp. Example values will be available at https://csrc.nist.gov/proj ects/cryptographic-standards-and-guidelines/example-values. 8. Other Approved Security Functions. Implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government-sensitive information. Approved cryptographic algorithms and techniques include those that are either: (a) Specified in a Federal Information Processing Standards (FIPS) publication, (b) Adopted in a FIPS or NIST recommendation, or (c) Specified in the list of approved security functions in SP 800-140C. 9. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with all federal laws and regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 10. Patents.", "char_len": 3935, "approx_tokens": 983}
{"chunk_id": "NIST.FIPS.203::c00002", "doc_id": "NIST.FIPS.203", "start_page": 5, "end_page": 6, "text": "ndards (FIPS) publication, (b) Adopted in a FIPS or NIST recommendation, or (c) Specified in the list of approved security functions in SP 800-140C. 9. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with all federal laws and regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 10. Patents. NIST has entered into two patent license agreements to facilitate the adoption of NIST’s announced selection of the PQC key-encapsulation mechanism CRYSTALS-KYBER. NIST and the licensing parties share a desire, in the public interest, the licensed patents be freely available to be practiced by any implementer of the ML-KEM algorithm as published by NIST. ML-KEM is the name given to the algorithm in this standard derived from CRYSTALS-KYBER. For a summary and extracts from the license, please see https://csrc.nist.gov/csrc/media/P rojects/post-quantum-cryptography/documents/selected-algos-2022/nist-pqc-license-sum mary-and-excerpts.pdf. Implementation of the algorithm specified in the standard may be covered by U.S. and foreign patents of which NIST is not aware.\n\nii\n\n11. Implementation Schedule. This standard becomes effective immediately upon final publica- tion. 12. Specifications. Federal Information Processing Standards (FIPS) 203, Module-Lattice-Based Key-Encapsulation Mechanism Standard (affixed). 13. Qualifications. In applications, the security guarantees of a KEM only hold under certain conditions (see SP 800-227 [1]). One such condition is the secrecy of several values, including the randomness used by the two parties, the decapsulation key, and the shared secret key itself. Users shall, therefore, guard against the disclosure of these values. While it is the intent of this standard to specify general requirements for implementing ML-KEM algorithms, conformance to this standard does not ensure that a particular imple- mentation is secure. It is the responsibility of the implementer to ensure that any module that implements a key establishment capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The re- sponsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. NIST will continue to follow developments in the analysis of the ML-KEM algorithm. As with its other cryptographic algorithm standards, NIST will formally reevaluate this standard every five years. Both this standard and possible threats that reduce the security provided through the use of this standard will undergo review by NIST as appropriate, taking into account newly available analysis and technology. In addition, the awareness of any breakthrough in technology or any mathematical weakness of the algorithm will cause NIST to reevaluate this standard and provide necessary revisions. 14. Waiver Procedure. The Federal Information Security Management Act (FISMA) does not allow for waivers to Federal Information Processing Standards (FIPS) that are made mandatory by the Secretary of Commerce. 15. Where to Obtain Copies of the Standard. This publication is available by accessing https: //csrc.nist.gov/publications. Other computer security publications are available at the same website. 16. How to Cite This Publication. NIST has assigned NIST FIPS 203 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Module-Lattice-Based Key- Encapsulation Mechanism Standard.", "char_len": 3983, "approx_tokens": 995}
{"chunk_id": "NIST.FIPS.203::c00003", "doc_id": "NIST.FIPS.203", "start_page": 6, "end_page": 9, "text": "g Standards (FIPS) that are made mandatory by the Secretary of Commerce. 15. Where to Obtain Copies of the Standard. This publication is available by accessing https: //csrc.nist.gov/publications. Other computer security publications are available at the same website. 16. How to Cite This Publication. NIST has assigned NIST FIPS 203 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Module-Lattice-Based Key- Encapsulation Mechanism Standard. (Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) NIST FIPS 203. https://doi.org/10.6028/NIST.FIPS.203 17. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-203-comments@nist.gov.\n\niii\n\nFederal Information Processing Standards Publication 203\n\nSpecification for the Module-Lattice-Based Key-Encapsulation Mechanism Standard\n\nTable of Contents\n\n1 Introduction 1 1.1 Purpose and Scope 1 1.2 Context 1\n\n2 Terms, Acronyms, and Notation 2 2.1 Terms and Definitions 2 2.2 Acronyms 4 2.3 Mathematical Symbols 5 2.4 Interpreting the Pseudocode 6 2.4.1 Data Types 7 2.4.2 Loop Syntax 7 2.4.3 Arithmetic With Arrays of Integers 7 2.4.4 Representations of Algebraic Objects 8 2.4.5 Arithmetic With Polynomials and NTT Representations 9 2.4.6 Matrices and Vectors 9 2.4.7 Arithmetic With Matrices and Vectors 10 2.4.8 Applying Algorithms to Arrays, Examples 11\n\n3 Overview of the ML-KEM Scheme 12 3.1 Key-Encapsulation Mechanisms 12 3.2 The ML-KEM Scheme 13 3.3 Requirements for ML-KEM Implementations 15\n\n4 Auxiliary Algorithms 18 4.1 Cryptographic Functions 18 4.2 General Algorithms 20 4.2.1 Conversion and Compression Algorithms 20 4.2.2 Sampling Algorithms 22 4.3 The Number-Theoretic Transform 24\n\niv\n\n4.3.1 Multiplication in the NTT Domain 27\n\n5 The K-PKE Component Scheme 28 5.1 K-PKE Key Generation 28 5.2 K-PKE Encryption 29 5.3 K-PKE Decryption 31\n\n6 Main Internal Algorithms 32 6.1 Internal Key Generation 32 6.2 Internal Encapsulation 32 6.3 Internal Decapsulation 33\n\n7 The ML-KEM Key-Encapsulation Mechanism 35 7.1 ML-KEM Key Generation 35 7.2 ML-KEM Encapsulation 36 7.3 ML-KEM Decapsulation 37\n\n8 Parameter Sets 39\n\nReferences 41\n\nAppendix A — Precomputed Values for the NTT 44\n\nAppendix B — SampleNTT Loop Bounds 46\n\nAppendix C — Differences From the CRYSTALS-KYBER Submission 47 C.1 Differences Between CRYSTALS-KYBER and FIPS 203 Initial Public Draft 47 C.2 Changes From FIPS 203 Initial Public Draft 47\n\nv\n\nList of Tables\n\nTable 1 Decapsulation failure rates for ML-KEM 15 Table 2 Approved parameter sets for ML-KEM 39 Table 3 Sizes (in bytes) of keys and ciphertexts of ML-KEM 39 Table 4 While-loop limits and probabilities of occurrence for SampleNTT 46\n\nList of Figures\n\nFigure 1 A simple view of key establishment using a KEM 12\n\nList of Algorithms Algorithm 1 ForExample() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Algorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) . . . . . . . . . . . . . 19 Algorithm 3 BitsToBytes(b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Algorithm 4 BytesToBits(B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Algorithm 5 ByteEncoded(F ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Algorithm 6 ByteDecoded(B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Algorithm 7 SampleNTT(B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 8 SamplePolyCBDη(B) . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 9 NTT(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Algorithm 10 NTT−1(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Algorithm 11 MultiplyNTTs(f, g)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . 27 Algorithm 12 BaseCaseMultiply(a0, a1, b0, b1, γ) . . . . . . . . . . . . . . . . . .", "char_len": 3986, "approx_tokens": 996}
{"chunk_id": "NIST.FIPS.203::c00004", "doc_id": "NIST.FIPS.203", "start_page": 9, "end_page": 10, "text": "Algorithm 6 ByteDecoded(B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Algorithm 7 SampleNTT(B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 8 SamplePolyCBDη(B) . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 9 NTT(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Algorithm 10 NTT−1(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Algorithm 11 MultiplyNTTs(f, g)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . 27 Algorithm 12 BaseCaseMultiply(a0, a1, b0, b1, γ) . . . . . . . . . . . . . . . . . . 27 Algorithm 13 K-PKE.KeyGen(d) . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 14 K-PKE.Encrypt(ekPKE, m, r) . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 15 K-PKE.Decrypt(dkPKE, c) . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 16 ML-KEM.KeyGen_internal(d, z) . . . . . . . . . . . . . . . . . . . . 32 Algorithm 17 ML-KEM.Encaps_internal(ek, m) . . . . . . . . . . . . . . . . . . . 33 Algorithm 18 ML-KEM.Decaps_internal(dk, c) . . . . . . . . . . . . . . . . . . . . 34 Algorithm 19 ML-KEM.KeyGen() . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 20 ML-KEM.Encaps(ek) . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 21 ML-KEM.Decaps(dk, c) . . . . . . . . . . . . . . . . . . . . . . . . 38\n\nvi\n\n1. Introduction\n\n1.1 Purpose and Scope This standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment Schemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation for Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3]. The key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the CRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization project. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C. This standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs in applications, see SP 800-227 [1]. This standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government.\n\n1.2 Context Over the past several years, there has been steady progress toward building quantum computers. If large-scale quantum computers are realized, the security of many commonly used public-key cryptosystems will be at risk. This would include key-establishment schemes and digital signature schemes whose security depends on the difficulty of solving the integer factorization and discrete logarithm problems (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantum-resistant public-key cryptographic algorithms. A total of 82 candidate algorithms were submitted to NIST for consideration.", "char_len": 3956, "approx_tokens": 989}
{"chunk_id": "NIST.FIPS.203::c00005", "doc_id": "NIST.FIPS.203", "start_page": 10, "end_page": 11, "text": "If large-scale quantum computers are realized, the security of many commonly used public-key cryptosystems will be at risk. This would include key-establishment schemes and digital signature schemes whose security depends on the difficulty of solving the integer factorization and discrete logarithm problems (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantum-resistant public-key cryptographic algorithms. A total of 82 candidate algorithms were submitted to NIST for consideration. After three rounds of evaluation and analysis, NIST selected the first four algorithms for standardization. These algorithms are intended to protect sensitive U.S. Government information well into the foreseeable future, including after the advent of cryptographically-relevant quantum computers. This standard specifies a variant of the selected algorithm CRYSTALS-KYBER, a lattice-based key-encapsulation mechanism (KEM) designed by Peter Schwabe, Roberto Avanzi, Joppe Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John Schanck, Gregor Seiler, Damien Stehlé, and Jintai Ding [4]. Throughout this standard, the KEM specified here will be referred to as ML-KEM, as it is based on the Module Learning With Errors assumption.\n\n2. Terms, Acronyms, and Notation\n\n2.1 Terms and Definitions approved FIPS-approved and/or NIST-recommended. An algorithm or technique that is either 1) specified in a FIPS or NIST recommendation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security functions. (KEM) ciphertext A bit string that is produced by encapsulation and used as an input to decapsulation. cryptographic The set of hardware, software, and/or firmware that implements ap- module proved cryptographic functions (including key generation) that are con- tained within the cryptographic boundary of the module. decapsulation The process of applying the Decaps algorithm of a KEM. This algorithm accepts a KEM ciphertext and the decapsulation key as input and pro- duces a shared secret key as output. decapsulation key A cryptographic key produced by a KEM during key generation and used during the decapsulation process. The decapsulation key must be kept private and must be destroyed after it is no longer needed. (See Section 3.3.) decryption key A cryptographic key that is used with a PKE in order to decrypt cipher- texts into plaintexts. The decryption key must be kept private and must be destroyed after it is no longer needed. destroy An action applied to a key or other piece of secret data. After a piece of secret data is destroyed, no information about its value can be re- covered. encapsulation The process of applying the Encaps algorithm of a KEM. This algorithm accepts the encapsulation key as input, requires private randomness, and produces a shared secret key and an associated ciphertext as out- put. encapsulation key A cryptographic key produced by a KEM during key generation and used during the encapsulation process. The encapsulation key can be made public. (See Section 3.3.) encryption key A cryptographic key that is used with a PKE in order to encrypt plaintexts into ciphertexts. The encryption key can be made public. equivalent process Two processes are equivalent if the same output is produced when the same values are input to each process (either as input parameters, as values made available during the process, or both). fresh random value An output that was produced by a random bit generator and has not been previously used.", "char_len": 3629, "approx_tokens": 907}
{"chunk_id": "NIST.FIPS.203::c00006", "doc_id": "NIST.FIPS.203", "start_page": 11, "end_page": 13, "text": "by a KEM during key generation and used during the encapsulation process. The encapsulation key can be made public. (See Section 3.3.) encryption key A cryptographic key that is used with a PKE in order to encrypt plaintexts into ciphertexts. The encryption key can be made public. equivalent process Two processes are equivalent if the same output is produced when the same values are input to each process (either as input parameters, as values made available during the process, or both). fresh random value An output that was produced by a random bit generator and has not been previously used.\n\nhash function A function on bit strings in which the length of the output is fixed. Approved hash functions (such as those specified in FIPS 180 [5] and FIPS 202 [6]) are designed to satisfy the following properties: 1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 2. (Collision-resistant) It is computationally infeasible to find any two distinct inputs that map to the same output. input checking Examination of a potential input to an algorithm for the purpose of determining whether it conforms to certain requirements. key A bit string that is used in conjunction with a cryptographic algorithm, such as the encapsulation and decapsulation keys (of a KEM), the shared secret key (produced by a KEM), and the encryption and decryption keys (of a PKE). (See Section 3.3.) key-encapsulation A set of three cryptographic algorithms (KeyGen, Encaps, and Decaps) mechanism (KEM) that can be used by two parties to establish a shared secret key over a public channel. key establishment A procedure that results in secret keying material that is shared among different parties. key pair A set of two keys with the property that one key can be made public while the other key must be kept private. In this standard, this could refer to either the (encapsulation key, decapsulation key) key pair of a KEM or the (encryption key, decryption key) key pair of a PKE. little-endian The property of a byte string having its bytes positioned in order of increasing significance. In particular, the leftmost (first) byte is the least significant, and the rightmost (last) byte is the most significant. The term “little-endian” may also be applied in the same manner to bit strings (e.g., the 8-bit string 11010001 corresponds to the byte 20 + 21 + 23 + 27 = 139). party An individual person, organization, device, or process. In this specifica- tion, there are two parties (e.g., Party A and Party B, or Alice and Bob) who jointly perform the key establishment process using a KEM. pseudorandom A process (or data produced by a process) is said to be pseudorandom when the outcome is deterministic yet also appears random as long as the internal action of the process is hidden from observation. For cryptographic purposes, “effectively random” means “computationally indistinguishable from random within the limits of the intended security strength.” public channel A communication channel between two parties. Such a channel can be observed and possibly also corrupted by third parties.\n\npublic-key A set of three cryptographic algorithms (KeyGen, Encrypt, and Decrypt) encryption scheme that can be used by two parties to send secret data over a public channel. (PKE) Also known as an asymmetric encryption scheme. shared secret A secret value that has been computed during a key-establishment scheme, is known by both participants, and is used as input to a key- derivation method to produce keying material. shared secret key A shared secret that can be used directly as a cryptographic key in symmetric-key cryptography. It does not require additional key deriva- tion. The shared secret key must be kept private and must be destroyed when no longer needed. security category A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST (see [7]).", "char_len": 3950, "approx_tokens": 987}
{"chunk_id": "NIST.FIPS.203::c00007", "doc_id": "NIST.FIPS.203", "start_page": 13, "end_page": 15, "text": "ption scheme. shared secret A secret value that has been computed during a key-establishment scheme, is known by both participants, and is used as input to a key- derivation method to produce keying material. shared secret key A shared secret that can be used directly as a cryptographic key in symmetric-key cryptography. It does not require additional key deriva- tion. The shared secret key must be kept private and must be destroyed when no longer needed. security category A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST (see [7]). security strength A number associated with the amount of work (i.e., the number of op- erations) that is required to break a cryptographic algorithm or system. shall Used to indicate a requirement of this standard. should Used to indicate a strong recommendation but not a requirement of this standard. Ignoring the recommendation could lead to undesirable results.\n\n2.2 Acronyms AES Advanced Encryption Standard CBD Centered Binomial Distribution FIPS Federal Information Processing Standard KEM Key-Encapsulation Mechanism LWE Learning with Errors MLWE Module Learning with Errors NIST National Institute of Standards and Technology NISTIR NIST Interagency or Internal Report NTT Number-Theoretic Transform PKE Public-Key Encryption PQC Post-Quantum Cryptography PRF Pseudorandom Function RBG Random Bit Generator SHA Secure Hash Algorithm\n\nSHAKE Secure Hash Algorithm KECCAK SP Special Publication XOF Extendable-Output Function\n\n2.3 Mathematical Symbols n Denotes the integer 256 throughout this document. q Denotes the prime integer 3329 = 28 ⋅ 13 + 1 throughout this document. ζ Denotes the integer 17, which is a primitive n-th root of unity modulo q. B The set {0, 1, ... , 255} of unsigned 8-bit integers (bytes). Q The set of rational numbers. Z The set of integers. Zm The ring of integers modulo m (i.e., the set {0, 1, ... , m − 1} equipped with the operations of addition and multiplication modulo m.) Zn The set of n-tuples over Z equipped with Z -module structure. As a data m type, this is the set of m m length-n arrays whose entries are in Zm . Rq The ring Zq [X]/(Xn + 1) consisting of polynomials of the form f = f0 + f1X + ⋯ + f255X255, where fj ∈ Zq for all j. The ring operations are addi- tion and multiplication modulo Xn + 1. Tq The image of Rq under the number-theoretic transform. Its elements are called “NTT representations” of polynomials in Rq . (See Section 4.3.) Dη(Rq ) A certain distribution of polynomials in Rq with small coefficients, from which noise is sampled. The distribution is parameterized by η ∈ {2, 3}. (See Section 4.2.2.) S ∗ If S is a set, this denotes the set of finite-length tuples (or arrays) of elements from the set S, including the empty tuple (or empty array). S k If S is a set, this denotes the set of k-tuples (or length-k arrays) of elements from the set S. fj The coefficient of Xj of a polynomial f = f0 + f1X + ⋯ + f255X255 ∈ Rq .\n\nf The element of Tq that is equal to the NTT representation of a polynomial f ∈ Rq . (See Sections 2.4.4 and 4.3.) vT, AT The transpose of a row or column vector v. In general, the transpose of a matrix A.\n\n∘ Denotes linear-algebraic composition with coefficients in Rq or Tq (e.g., A ∘ v denotes the vector resulting from applying matrix A to vector v). (See Section 2.4.7.) ×Tq Denotes the operation on coefficient arrays that implements product in the ring Tq . (See Sections 2.4.5 and 4.3.1.) A‖B The concatenation of two arrays or bit strings A and B. B[i] The entry at index i in the array B. All arrays have indices that begin at zero. B[k ∶ m] The subarray (B[k], B[k + 1], ... , B[m − 1]) of the array B. |B| If B is a number, this denotes the absolute value of B. If B is an array, this denotes its length. ⌈x⌉ The ceiling of x (i.e., the smallest integer greater than or equal to x). ⌊x⌋ The floor of x (i.e., the largest integer less than or equal to x).", "char_len": 3966, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.203::c00008", "doc_id": "NIST.FIPS.203", "start_page": 15, "end_page": 16, "text": "2.4.7.) ×Tq Denotes the operation on coefficient arrays that implements product in the ring Tq . (See Sections 2.4.5 and 4.3.1.) A‖B The concatenation of two arrays or bit strings A and B. B[i] The entry at index i in the array B. All arrays have indices that begin at zero. B[k ∶ m] The subarray (B[k], B[k + 1], ... , B[m − 1]) of the array B. |B| If B is a number, this denotes the absolute value of B. If B is an array, this denotes its length. ⌈x⌉ The ceiling of x (i.e., the smallest integer greater than or equal to x). ⌊x⌋ The floor of x (i.e., the largest integer less than or equal to x). ⌈x⌋ The rounding of x to the nearest integer. If x = y + 1/2 for some y ∈ Z, then ⌈x⌋ = y + 1. ∶= Denotes that the left-hand side is defined to be the expression on the right- hand side. r mod m The unique integer r′ in {0, 1, ... , m − 1} such that m divides r − r′ . BitRev7 (r) Bit reversal of a seven-bit integer r. Specifically, if r = r0 + 2r1 + 4r2 + ⋯ + 64r6 with ri ∈ {0, 1}, then BitRev7 (r) = r6 + 2r5 + 4r4 + ⋯ + 64r0. s ← x In pseudocode, this notation means that the variable s is assigned the value of the expression x. s $ Bl In pseudocode, this notation means that the variable s is assigned the value − ← of an array of l random bytes. The bytes must be freshly generated using randomness from an approved RBG. (See Section 3.3.) ⊥ A symbol indicating failure or the lack of output from an algorithm.\n\n2.4 Interpreting the Pseudocode This section outlines the conventions of the pseudocode used to describe the algorithms in this standard. All algorithms are understood to have access to two global integer constants: n = 256 and q = 3329. There are also five global integer variables: k, η1, η2, du, and dv. All other variables are local. The five global variables are set to particular values when a parameter set is selected (see Section 8). When algorithms in this specification invoke other algorithms as subroutines, all arguments (i.e., inputs) are passed by value. In other words, a copy of the inputs is created, and the subroutine is invoked with the copy. There is no “passing by reference.” Pseudocode assignments are performed using the symbol “←.” For example, the statement z ← y means that the variable z is assigned the value of variable y. Pseudocode comparisons\n\nare performed via the symbol “==.” For example, the expression x == w is a boolean value that is TRUE if and only if the variables x and w have the same value. In regular text (i.e., outside of the pseudocode), a different convention is applied. There, the “=” symbol is used both for assigning values and for comparisons, in keeping with standard mathematical notation. When emphasis is needed, assignments will be made with “∶=” instead. Variables will always have a valid value that is appropriate to their data type, with two exceptions: 1. The outputs of a random bit generator (RBG) have the byte array data type but are also allowed to have the special value NULL. This value indicates that randomness generation failed. This can only occur in ML-KEM.KeyGen and ML-KEM.Encaps. 2. The outputs of ML-KEM.KeyGen and ML-KEM.Encaps have the byte array data type but are also allowed to have the special value ⊥. When ML-KEM.KeyGen or ML-KEM.Encaps return the value ⊥, this indicates that the algorithm failed due to a failure of randomness generation.\n\n2.4.1 Data Types For variables that represent the input or output of an algorithm, the data type (e.g., bit, byte, array of bits) will be explicitly described at the start of the algorithm. For most local variables in the pseudocode, the data type is easily deduced from context. For all other variables, the data type will be declared in a comment. In a single algorithm, the data type of a variable is determined the first time that the variable is used and will not be changed. Variable names can and will be reused across different algorithms, including with different data types.", "char_len": 3938, "approx_tokens": 984}
{"chunk_id": "NIST.FIPS.203::c00009", "doc_id": "NIST.FIPS.203", "start_page": 16, "end_page": 18, "text": "s generation.\n\n2.4.1 Data Types For variables that represent the input or output of an algorithm, the data type (e.g., bit, byte, array of bits) will be explicitly described at the start of the algorithm. For most local variables in the pseudocode, the data type is easily deduced from context. For all other variables, the data type will be declared in a comment. In a single algorithm, the data type of a variable is determined the first time that the variable is used and will not be changed. Variable names can and will be reused across different algorithms, including with different data types. In addition to standard atomic data types (e.g., bits, bytes) and data structures (e.g., arrays), integers modulo m (i.e., elements of Zm ) will also be used as an abstract data type. It is implicit that reduction modulo m takes place whenever an assignment is made to a variable in Zm . For example, for z ∈ Zm and integers x and y, the statement\n\nz ← x + y (2.1)\n\nmeans that z is assigned the value x + y mod m. The pseudocode is agnostic regarding how an integer modulo m is represented in actual implementations or how modular reduction is computed.\n\n2.4.2 Loop Syntax The pseudocode will make use of both “while” and “for” loops. The “while” syntax is selfexplanatory. In the case of “for” loops, the syntax will be in the style of the programming language C. Two simple examples are given in Algorithm 1. The standard mathematical expression (e.g., ∑n (i + 3)) will be used for simple summations instead of a “for” loop. i←1\n\n2.4.3 Arithmetic With Arrays of Integers This standard makes extensive use of arrays of integers modulo m (i.e., elements of Zl ). In a typical case, the relevant values are m = q = 3329 and l = n = 256. Arithmetic with m arrays in\n\nAlgorithm 1 ForExample() Performs two simple “for” loops. 1: for (i ← 0; i < 10; i ++) 2: A[i] ← i ▷ A is an integer array of length 10 3: end for ▷ A now has the value (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) 4: j ← 0 5: for (k ← 256; k > 1; k ← k/2) 6: B[j] ← k ▷ B is an integer array of length 8 7: j ← j + 1 8: end for ▷ B now has the value (256, 128, 64, 32, 16, 8, 4, 2)\n\nZl will be done as follows. Let a ∈ Z and X, Y ∈ Zl . The statements m m m Z ← a ⋅ X (2.2) W ← X + Y (2.3)\n\nwill result in two arrays Z, W ∈ Zl , with the property that Z[i] = a ⋅ X[i] and W [i] = X[i] + Y [i] for all . Multiplication of arrays m l which i in Zm will only be meaningful when m = q and l = n = 256, in case it corresponds to multiplication in a particular ring. This operation will be described in (2.8).\n\n2.4.4 Representations of Algebraic Objects An essential operation in ML-KEM is the number-theoretic transform (NTT), which maps a polynomial f in a certain ring Rq to its “NTT representation” f in an isomorphic ring Tq . The rings Rq and Tq and the NTT are discussed in detail in Section 4.3. This standard will represent elements of Rq and Tq in pseudocode using arrays of integers modulo q as follows. An element f of Rq is a polynomial of the form\n\nf = f0 + f1X + ⋯ + f255X255 ∈ Rq (2.4)\n\nand will be represented in pseudocode by the array\n\n(f0, f1, ... , f255) ∈ Z256, (2.5) q whose entries contain the coefficients of f. Overloading notation, the array in (2.5) will also be denoted by f. The i-th entry of the array f will thus contain the i-th coefficient of the polynomial f (i.e., f[i] = fi ). An element (sometimes called “NTT representation”) ĝ of Tq is a tuple of 128 polynomials, each of degree at most one. Specifically,\n\ng = (g0,0 + g0,1 X, g1,0 + g1,1 X, ... , g127,0 + g127,1X) ∈ Tq . (2.6)\n\nSuch an algebraic object will be represented in pseudocode by the array\n\n(g0,0 , g0,1 , g1,0 , g1,1 , ... , g127,0, g127,1) ∈ Z256 . (2.7) q Overloading notation, the array in (2.7) will also be denoted by g. In this case, the mapping between array entries and coefficients is g[2i] = gi,0 and g[2i + 1] = gi,1 for i ∈ {0, 1, ... , 127}.", "char_len": 3902, "approx_tokens": 975}
{"chunk_id": "NIST.FIPS.203::c00010", "doc_id": "NIST.FIPS.203", "start_page": 17, "end_page": 19, "text": "th coefficient of the polynomial f (i.e., f[i] = fi ). An element (sometimes called “NTT representation”) ĝ of Tq is a tuple of 128 polynomials, each of degree at most one. Specifically,\n\ng = (g0,0 + g0,1 X, g1,0 + g1,1 X, ... , g127,0 + g127,1X) ∈ Tq . (2.6)\n\nSuch an algebraic object will be represented in pseudocode by the array\n\n(g0,0 , g0,1 , g1,0 , g1,1 , ... , g127,0, g127,1) ∈ Z256 . (2.7) q Overloading notation, the array in (2.7) will also be denoted by g. In this case, the mapping between array entries and coefficients is g[2i] = gi,0 and g[2i + 1] = gi,1 for i ∈ {0, 1, ... , 127}.\n\nConverting between a polynomial f ∈ Rq and its NTT representation f ∈ Tq will be done via the algorithms NTT (Algorithm 9) and NTT−1 (Algorithm 10). These algorithms act on arrays of coefficients, as described above, and satisfy f = NTT(f) and f = NTT−1(f).\n\n2.4.5 Arithmetic With Polynomials and NTT Representations The algebraic operations of addition and scalar multiplication in Rq and Tq are done coordinatewise. For example, if a ∈ Zq and f ∈ Rq , the i-th coefficient of the polynomial a ⋅ f ∈ Rq is equal to a ⋅ fi mod q. In pseudocode, elements of both Rq and Tq are represented by coefficient arrays (i.e., elements of Z256). The algebraic operations of addition and scalar multiplication are thus performed by q addition and scalar multiplication of the corresponding coefficient arrays, as in (2.3) and (2.2). For example, the addition of two NTT representations in pseudocode is performed by a statement of the form h ← f + g, where h, f, g ∈ Z256 are coefficient arrays. q The algebraic operations of multiplication in Rq and Tq are treated as follows. For efficiency reasons, multiplication in Rq will not be used. The algebraic meaning of multiplication in Tq is discussed in Section 4.3.1. In pseudocode, it will be performed by the algorithm MultiplyNTTs (Algorithm 11). Specifically, if f, g ∈ Z256 are a pair of arrays (each representing the NTT of some polynomial), then q\n\nh ← f ×Tq g means h ← MultiplyNTTs(f, g) . (2.8)\n\nThe result is an array h ∈ Z256. q\n\n2.4.6 Matrices and Vectors In addition to arrays of integers modulo q, the pseudocode will also make use of arrays whose entries are themselves elements of Z256. For example, an element v ∈ (Z256)3 will be a length- q q three array whose entries v[0], v[1], and v[2] are themselves elements of Z256 (i.e., arrays). One can think of each of these entries as representing a polynomial in so q Rq that v itself represents an element of the module R3. q When arrays are used to represent matrices and vectors whose entries are elements of Rq , they will be denoted with bold letters (e.g., v for vectors and A for matrices). When arrays are used to represent matrices and vectors whose entries are elements of Tq , they will be denoted with a “hat” (e.g., v̂ and A). Unless an explicit transpose operation is performed, it is understood that vectors are column vectors. One can then view vectors as the special case of matrices with only one column. Converting between matrices over Rq and matrices over Tq will be done coordinate-wise. For\n\nexample, if v ∈ (Z256)k, then the statement q v ← NTT(v) (2.9)\n\nwill result in v ∈ (Z256)k such that v[i]̂ = NTT(v[i]) for all i. This involves running NTT a total of k times. q\n\n2.4.7 Arithmetic With Matrices and Vectors The following describes how to perform arithmetic with matrices over Rq and Tq with vectors as a special case. Addition and scalar multiplication are performed coordinate-wise, so the addition of matrices over Rq and Tq is straightforward. In the case of Tq , scalar multiplication is done via (2.8). For example, if f ∈ Z256 and u, v ∈ (Z256)k, then q q\n\nw ← f ⋅ u (2.10) z ← u + v (2.11)", "char_len": 3730, "approx_tokens": 932}
{"chunk_id": "NIST.FIPS.203::c00011", "doc_id": "NIST.FIPS.203", "start_page": 19, "end_page": 20, "text": "∈ (Z256)k, then the statement q v ← NTT(v) (2.9)\n\nwill result in v ∈ (Z256)k such that v[i]̂ = NTT(v[i]) for all i. This involves running NTT a total of k times. q\n\n2.4.7 Arithmetic With Matrices and Vectors The following describes how to perform arithmetic with matrices over Rq and Tq with vectors as a special case. Addition and scalar multiplication are performed coordinate-wise, so the addition of matrices over Rq and Tq is straightforward. In the case of Tq , scalar multiplication is done via (2.8). For example, if f ∈ Z256 and u, v ∈ (Z256)k, then q q\n\nw ← f ⋅ u (2.10) z ← u + v (2.11)\n\nwill result in w, z ∈ (Z256)k satisfying w[i] = f × u[i] and z[i] = u[i] + v[i] for all i. Here, the multiplication and q Tq addition of individual entries are performed using the appropriate arithmetic for coefficient arrays of elements of Tq (i.e., as in (2.3)). It will also be necessary to multiply matrices with entries in Tq , which is done by using standard matrix multiplication with the base-case multiplication (i.e., multiplication of individual entries) being multiplication in Tq . If A and B are two matrices with entries in Tq , their matrix product will be denoted A ∘ B. Some example pseudocode statements involving matrix multiplication are given in (2.12), (2.13), and (2.14). In these examples, A is a k × k matrix, while û and v̂ are vectors of length k. All three of these objects are represented in pseudocode by arrays: a k × k array for A and length-k arrays for û and v̂. The entries of A, û, and v̂ are elements of Z256. In and , the pseudocode statement on the left produces a new length- vector q (2.12) (2.13) k whose entries are specified on the right. In (2.14), the pseudocode statement on the left computes a dot product. The result is in the base ring (i.e., Tq ) and is represented by an element z of Z256. q\n\nk−1 w ← A ∘ u w[i] = ∑ A[i, j] ×Tq u[j] (2.12) j=0 k−1 y ← A⊺ ∘ u y[i] = ∑ A[j, i] ×Tq u[j] (2.13) j=0 k−1 z ← u⊺ ∘ v z = ∑ u[j] ×Tq v[j] (2.14) j=0 The multiplication ×Tq of individual entries above is performed using MultiplyNTTs, as described in (2.8).\n\n2.4.8 Applying Algorithms to Arrays, Examples In the previous examples, arithmetic over Zm was extended to arithmetic with arrays over Zm and then further extended to arithmetic with matrices whose entries are themselves arrays over Zm . Similarly, algorithms defined with a given data type as input will be applied to arrays and matrices over that data type. When the pseudocode invokes such an algorithm on an array or matrix input, it is implied that the algorithm is invoked repeatedly and applied to each entry of the input. For example, consider the function Compressd ∶ Zq → Z2d defined in Section 4. It can be invoked on an array input F ∈ Z256 with the statement q K ← Compressd(F ) . (2.15)\n\nThe result will be an array K ∈ Z256 such that K[i] = Compress (F [i]) for every i ∈ {0, 1, ... , 255}. The computation (2.15) 2d d involves running the Compress algorithm 256 times. For a second example, consider the algorithm NTT defined in Section 4.3. It takes an array f ∈ Z256 (representing an element of R ) as input and outputs another array f ∈ Z256 (representing q q q an element of T ). If the NTT algorithm is invoked on a vector s ∈ (Z256)k (representing an q q element of Rk) with the pseudocode statement q s ← NTT(s) , (2.16)\n\nthe result is a vector s ∈ (Z256)k such that s[i] = NTT(s[i]) for all i ∈ {0, 1, ... , k − 1}. The vector q ŝ represents an element of T k. The computation (2.16) involves running the NTT algorithm k times. q For a third example, consider line 2 of K-PKE.Encrypt in Section 5.2:\n\nt ← ByteDecode12(ekPKE[0 ∶ 384k]) . (2.17)", "char_len": 3669, "approx_tokens": 917}
{"chunk_id": "NIST.FIPS.203::c00012", "doc_id": "NIST.FIPS.203", "start_page": 20, "end_page": 22, "text": "array f ∈ Z256 (representing an element of R ) as input and outputs another array f ∈ Z256 (representing q q q an element of T ). If the NTT algorithm is invoked on a vector s ∈ (Z256)k (representing an q q element of Rk) with the pseudocode statement q s ← NTT(s) , (2.16)\n\nthe result is a vector s ∈ (Z256)k such that s[i] = NTT(s[i]) for all i ∈ {0, 1, ... , k − 1}. The vector q ŝ represents an element of T k. The computation (2.16) involves running the NTT algorithm k times. q For a third example, consider line 2 of K-PKE.Encrypt in Section 5.2:\n\nt ← ByteDecode12(ekPKE[0 ∶ 384k]) . (2.17)\n\nByteDecode12 is defined to receive a byte array of length 32 ⋅ 12 = 384 as input and produce an integer array in Z256 as output. The computation (2.17) is run on the first 384k bytes of q byte array ekPKE and results in t ∈ (Z256)k. ByteDecode will thus be applied k times, once for each subarray q , and will result 12 256 ekPKE[384 ⋅ j, 384 ⋅ (j + 1)] in an integer array t[j] ∈ Zq such that t[j] = ByteDecode12(ekPKE[384 ⋅ j, 384 ⋅ (j + 1)]) for each j from 0 to k − 1.\n\n3. Overview of the ML-KEM Scheme\n\nThis section gives a high-level overview of the ML-KEM scheme.\n\n3.1 Key-Encapsulation Mechanisms The following is a high-level overview of key-encapsulation mechanisms (KEMs). For details, see SP 800-227 [1]. A KEM is a cryptographic scheme that, under certain conditions, can be used to establish a shared secret key between two communicating parties. This shared secret key can then be used for symmetric-key cryptography. A KEM consists of three algorithms and a collection of parameter sets. The three algorithms are: 1. A probabilistic key generation algorithm denoted by KeyGen 2. A probabilistic ”encapsulation” algorithm denoted by Encaps 3. A deterministic ”decapsulation” algorithm denoted by Decaps The collection of parameter sets is used to select a trade-off between security and efficiency. Each parameter set in the collection is a list of specific (typically numerical) values, one for each parameter required by the three algorithms. Alice Bob\n\nKeyGen\n\ndecapsulation key encapsulation key\n\nDecaps ciphertext Encaps\n\nAlice’s copy of the Bob’s copy of the shared secret key shared secret key K′ K\n\nFigure 1. A simple view of key establishment using a KEM\n\nIn the typical application, a KEM is used to establish a shared secret key between two parties (here referred to as Alice and Bob) as described in Figure 1. Alice begins by running KeyGen in order to generate a (public) encapsulation key and a (private) decapsulation key. Upon obtaining Alice’s encapsulation key, Bob runs the Encaps algorithm, which produces Bob’s copy K of the shared secret key along with an associated ciphertext. Bob sends the ciphertext to Alice, and Alice completes the process by running the Decaps algorithm using her decapsulation key and the ciphertext. This final step produces Alice’s copy K′ of the shared secret key. After completing this process, Alice and Bob would like to conclude that their outputs satisfy K′ = K and that this value is a secure, random, shared secret key. However, these properties only hold if certain important conditions are satisfied, as discussed in SP 800-227 [1].\n\n3.2 The ML-KEM Scheme ML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was initially described in [8]. The following is a brief and informal description of the computational assumption underlying ML-KEM and how the ML-KEM scheme is constructed.", "char_len": 3485, "approx_tokens": 871}
{"chunk_id": "NIST.FIPS.203::c00013", "doc_id": "NIST.FIPS.203", "start_page": 22, "end_page": 23, "text": "Alice’s copy K′ of the shared secret key. After completing this process, Alice and Bob would like to conclude that their outputs satisfy K′ = K and that this value is a secure, random, shared secret key. However, these properties only hold if certain important conditions are satisfied, as discussed in SP 800-227 [1].\n\n3.2 The ML-KEM Scheme ML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was initially described in [8]. The following is a brief and informal description of the computational assumption underlying ML-KEM and how the ML-KEM scheme is constructed.\n\nThe computational assumption. The security of ML-KEM is based on the presumed hardness of the so-called Module Learning with Errors (MLWE) problem [9], which is a generalization of the Learning With Errors (LWE) problem introduced by Regev in 2005 [10]. The hardness of the MLWE problem is itself based on the presumed hardness of certain computational problems in module lattices [9]. This motivates the name of the scheme ML-KEM. In the LWE problem, the input is a set of random “noisy” linear equations in some secret variables x ∈ Zn, and the task is to recover x. The noise in the equations is such that standard algorithms q (e.g., Gaussian elimination) are intractable. The LWE problem naturally lends itself to cryptographic applications. For example, if x is interpreted as a secret key, then one can encrypt a one-bit plaintext value by sampling either an approximately correct linear equation (if the plaintext is zero) or a far-from-correct linear equation (if the plaintext is one). Plausibly, only a party in possession of x can distinguish these two cases. Encryption can then be delegated to another party by publishing a large collection of noisy linear equations, which can be combined appropriately by the encrypting party. The result is an asymmetric encryption scheme. The MLWE problem is similar to the LWE problem. An important difference is that, in MLWE, Zn q is replaced by a certain module Rk, which is constructed by taking the k-fold Cartesian product of a certain polynomial ring Rq . Inqparticular, the secret in the MLWE problem is an element x of the module Rk. The ring R is discussed in detail in Section 4.3. q q\n\nThe ML-KEM construction. At a high level, the construction of the scheme ML-KEM proceeds in two steps. First, the ideas discussed previously are used to construct a public-key encryption (PKE) scheme from the MLWE problem. Second, this PKE scheme is converted into a key-encapsulation mechanism using the so-called Fujisaki-Okamoto (FO) transform [11, 12]. Due to certain properties of the FO transform, the resulting KEM provides security in a significantly more general attack model than the PKE scheme. As a result, ML-KEM is believed to satisfy so-called IND-CCA2 security [1, 4, 13, 14].\n\nThe specification of the ML-KEM algorithms in this standard will follow the same pattern. Specifically, this standard will first describe a public-key encryption scheme called K-PKE (in Section 5) and then use the algorithms of K-PKE as subroutines when describing the algorithms of ML-KEM (in Sections 6 and 7). The cryptographic transformation from K-PKE to ML-KEM is crucial for achieving IND-CCA2 security. The scheme K-PKE is not IND-CCA2-secure and shall not be used as a stand-alone scheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability.", "char_len": 3934, "approx_tokens": 983}
{"chunk_id": "NIST.FIPS.203::c00014", "doc_id": "NIST.FIPS.203", "start_page": 23, "end_page": 24, "text": "cheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability. ML-KEM also comes with a proof of asymptotic theoretical security in a certain heuristic model [4]. Each of the parameter sets of ML-KEM comes with an associated security strength that was estimated based on current cryptanalysis (see Section 8 for details).\n\nParameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329.\n\nDecapsulation failures. Provided that all inputs are well-formed and randomness generation is successful, the key establishment procedure of ML-KEM will never explicitly fail, meaning that both ML-KEM.Encaps and ML-KEM.Decaps will each output a 256-bit value. Moreover, if no corruption or interference is present, the two 256-bit values produced by ML-KEM.Encaps and ML-KEM.Decaps will be equal with overwhelming probability (i.e., K′ will equal K in the process described in Figure 1). The event that K′ ≠ K under these conditions is called a decapsulation\n\nfailure. Formally, the decapsulation failure probability is defined to be the probability (conditioned on no RGB failures) that the process\n\n1. (ek, dk) ← ML-KEM.KeyGen() (3.1) 2. (c, K) ← ML-KEM.Encaps(ek) (3.2) 3. K′ ← ML-KEM.Decaps (dk, c) (3.3)\n\nresults in K′ ≠ K. The probability is taken over uniformly random seeds d, z (sampled in ML-KEM.KeyGen) and m (sampled in ML-KEM.Encaps) and under the heuristic assumption that hash functions and XOFs behave like uniformly random functions. The decapsulation failure rates for ML-KEM are listed in Table 1. For details, see Theorem 1 in [8] and the scripts in [15].\n\nTable 1. Decapsulation failure rates for ML-KEM\n\nParameter set Decapsulation failure rate ML-KEM-512 2−138.8 ML-KEM-768 2−164.8 ML-KEM-1024 2−174.8\n\nTerminology for keys. A KEM involves three different types of keys: encapsulation keys, decapsulation keys, and shared secret keys. ML-KEM is built on top of the component public-key encryption scheme K-PKE, which has two additional key types: encryption keys and decryption keys. In the literature, encapsulation keys and encryption keys are sometimes referred to as “public keys,” while decapsulation keys and decryption keys are sometimes referred to as “pri- vate keys.” In order to reduce confusion, this standard will not use the terms “public key” or “private key.” Instead, keys will be referred to only using the more specific terms, i.e., one of “encapsulation key”, “decapsulation key”, “encryption key”, “decryption key”, and “shared secret key”.", "char_len": 3903, "approx_tokens": 975}
{"chunk_id": "NIST.FIPS.203::c00015", "doc_id": "NIST.FIPS.203", "start_page": 24, "end_page": 25, "text": "e component public-key encryption scheme K-PKE, which has two additional key types: encryption keys and decryption keys. In the literature, encapsulation keys and encryption keys are sometimes referred to as “public keys,” while decapsulation keys and decryption keys are sometimes referred to as “pri- vate keys.” In order to reduce confusion, this standard will not use the terms “public key” or “private key.” Instead, keys will be referred to only using the more specific terms, i.e., one of “encapsulation key”, “decapsulation key”, “encryption key”, “decryption key”, and “shared secret key”.\n\n3.3 Requirements for ML-KEM Implementations This section describes several requirements for cryptographic modules that implement ML-KEM. Implementation requirements specific to particular algorithms will be described in later sections. Additional requirements, including requirements for using ML-KEM in specific applications, are given in SP 800-227 [1]. While conforming implementations must adhere to all of these requirements, adherence does not guarantee that the result will be secure (see Point 13 in the announcement).\n\nK-PKE is only a component. The public-key encryption scheme K-PKE described in Section 5 shall not be used as a stand-alone cryptographic scheme. Instead, the algorithms that comprise K-PKE may only be used as subroutines in the algorithms of ML-KEM. In particular, the algorithms K-PKE.KeyGen (Algorithm 13), K-PKE.Encrypt (Algorithm 14), and K-PKE.Decrypt (Algorithm 15) are not approved for use as a public-key encryption scheme.\n\nControlled access to internal functions. The key-encapsulation mechanism ML-KEM makes use of internal, “derandomized” functions ML-KEM.KeyGen_internal, ML-KEM.Encaps_internal, and ML-KEM.Decaps_internal, specified in Section 6. The interfaces for these functions should not be made available to applications other than for testing purposes. In particular, the sampling of random values required for key generation (as specified in ML-KEM.KeyGen) and encapsulation (as specified in ML-KEM.Encaps) shall be performed by the cryptographic module.\n\nEquivalent implementations. For every algorithm that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, the specified algorithm may be replaced with a different procedure that produces the correct output for every input (where “input” includes the specified input as well as all parameter values and all randomness).\n\nApproved usage of the shared secret key. If randomness generation is successful, the values K and K′ returned by ML-KEM.Encaps and ML-KEM.Decaps, respectively, are always 256-bit values. Under appropriate conditions (see Sections 3.1 and 3.2, and SP 800-227 [1]), these values match (i.e., K′ = K) and can be used directly as a shared secret key for symmetric cryptography. If further key derivation is needed, the final symmetric keys shall be derived from this 256-bit shared secret key in an approved manner, as specified in SP 800-108 and SP 800-56C [16, 17]. As discussed in Section 3.2, ML-KEM is an IND-CCA2-secure KEM. However, a combined KEM that includes ML-KEM as a component might not meet IND-CCA2 security. Implementers should assess the security of any procedure in which the key derivation methods of SP 800-56C are applied to ML-KEM in combination with another key establishment procedure. More guidance regarding combined KEMs is given in SP 800-227 [1].", "char_len": 3505, "approx_tokens": 876}
{"chunk_id": "NIST.FIPS.203::c00016", "doc_id": "NIST.FIPS.203", "start_page": 25, "end_page": 27, "text": "If further key derivation is needed, the final symmetric keys shall be derived from this 256-bit shared secret key in an approved manner, as specified in SP 800-108 and SP 800-56C [16, 17]. As discussed in Section 3.2, ML-KEM is an IND-CCA2-secure KEM. However, a combined KEM that includes ML-KEM as a component might not meet IND-CCA2 security. Implementers should assess the security of any procedure in which the key derivation methods of SP 800-56C are applied to ML-KEM in combination with another key establishment procedure. More guidance regarding combined KEMs is given in SP 800-227 [1].\n\nRandomness generation. Two algorithms in this standard require the generation of randomness as an internal step: ML-KEM.KeyGen and ML-KEM.Encaps. In pseudocode, this randomness generation is denoted by a statement of the form m $ B32. A fresh string of random bytes ← − must be generated for every such invocation. These random bytes shall be generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [18, 19, 20]. Moreover, this RBG shall have a security strength of at least 128 bits for ML-KEM-512, at least 192 bits for ML-KEM-768, and at least 256 bits for ML-KEM-1024.\n\nInput checking. The algorithms ML-KEM.Encaps and ML-KEM.Decaps require input checking. Implementers shall ensure that ML-KEM.Encaps and ML-KEM.Decaps are only executed on inputs that have been checked, as described in Section 7.\n\nDestruction of intermediate values. Data used in intermediate computation steps of KEM algorithms could be used by an adversary to compromise security. Therefore, implementers shall ensure that intermediate data is destroyed as soon as it is no longer needed. In particular, for ML-KEM.KeyGen, ML-KEM.Encaps, and ML-KEM.Decaps, only the designated output can be retained in memory after the algorithm terminates. All other data shall be destroyed prior to\n\nthe algorithm terminating. There are two exceptions to this rule: 1. The seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal. As this seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a decapsulation key (see SP 800-227 [1]). 2. The matrix A generated in steps 3-7 of K-PKE.KeyGen (as a subroutine of ML-KEM.KeyGen) can be stored so that it need not be recomputed in later operations (e.g., ML-KEM.Decaps). The same matrix A is also generated in steps 4-8 of K-PKE.Encrypt (as a subroutine of ML-KEM.Encaps or ML-KEM.Decaps); it can also then be stored. In either case, the matrix A is data that is easily computed from the public encapsulation key and thus does not require any special protections.\n\nNo floating-point arithmetic. Implementations of ML-KEM shall not use floating-point arithmetic, as rounding errors in floating-point operations may lead to incorrect results in some cases. In all pseudocode in this standard in which division is performed (e.g., x/y) and y may not divide x, either ⌊x/y⌋, ⌈x/y⌉, or ⌈x/y⌋ is used. All of these can be computed without floating-point arithmetic, as ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative integers x and positive integers y.\n\n4. Auxiliary Algorithms\n\n4.1 Cryptographic Functions The algorithms specified in this publication require the use of several cryptographic functions. Each function shall be instantiated by means of an approved hash function or an approved eXtendable-Output Function (XOF), as prescribed below. The relevant hash functions and XOFs are described in detail in FIPS 202 [6]. They will be used as follows. SHA3-256 and SHA3-512 are hash functions with one variable-length input and one fixed-length output. In this standard, invocations of these functions on an input M will be denoted by SHA3-256(M) and SHA3-512(M), respectively. The inputs and outputs for both SHA3-256 and SHA3-512 are always byte arrays.", "char_len": 3964, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.203::c00017", "doc_id": "NIST.FIPS.203", "start_page": 27, "end_page": 28, "text": "the use of several cryptographic functions. Each function shall be instantiated by means of an approved hash function or an approved eXtendable-Output Function (XOF), as prescribed below. The relevant hash functions and XOFs are described in detail in FIPS 202 [6]. They will be used as follows. SHA3-256 and SHA3-512 are hash functions with one variable-length input and one fixed-length output. In this standard, invocations of these functions on an input M will be denoted by SHA3-256(M) and SHA3-512(M), respectively. The inputs and outputs for both SHA3-256 and SHA3-512 are always byte arrays. SHAKE128 and SHAKE256 are XOFs with one variable-length input and one variable-length output. This standard will adhere to the following conventions [6]: • The inputs and outputs for both SHAKE128 and SHAKE256 are always byte arrays. • When invoking SHAKE128 or SHAKE256, desired output length is always specified in bits. For example, the expression r ∶= SHAKE128(M , 8 ⋅ 64) (4.1) implies that M is an array of bytes and that r is an array of 64 bytes. The aforementioned functions play several different roles in the algorithms specified in this standard and will only be invoked using the wrapper functions defined below. Importantly, these wrappers will avoid any potential “byte array” versus “bit-length” confusion by only working with bytes and byte array lengths.\n\nPseudorandom function (PRF). The function PRF takes a parameter η ∈ {2, 3}, one 32-byte input, and one 1-byte input. It produces one (64 ⋅ η)-byte output. It will be denoted by\n\nPRF ∶ {2, 3} × B32 × B → B64η , (4.2)\n\nand it shall be instantiated as\n\nPRFη(s, b) ∶= SHAKE256(s‖b, 8 ⋅ 64 ⋅ η) , (4.3)\n\nwhere η ∈ {2, 3}, s ∈ B32, and b ∈ B. Note that η is only used to specify the desired output length and not to perform domain separation.\n\nHash functions. The specification will also make use of three hash functions H, J and G, which are defined as follows. The functions H and J each take one variable-length input and produce one 32-byte output. They will be denoted by H ∶ B∗ → B32 and J ∶ B∗ → B32, respectively, and shall be instantiated as\n\nH(s) ∶= SHA3-256(s) and J(s) ∶= SHAKE256(s, 8 ⋅ 32) (4.4)\n\nwhere s ∈ B∗. The function G takes one variable-length input and produces two 32-byte outputs. It will be denoted by G ∶ B∗ → B32 × B32. The two outputs of G will be denoted by (a, b) ← G(c), where a, b ∈ B32, c ∈ B∗, and G(c) = a‖b. The function G shall be instantiated as\n\nG(c) ∶= SHA3-512(c) . (4.5)\n\neXtendable-Output Function (XOF). This standard uses a XOF wrapper defined in terms of the incremental API for SHAKE128 in SP 800-185 [21]. This SHAKE128 API consists of three functions: • ctx ← SHAKE128.Init() Initializes a XOF “context” ctx. • ctx ← SHAKE128.Absorb(ctx, str) Injects data to be used in the “absorbing” phase of SHAKE128 and updates the context accordingly. • (ctx, B) ← SHAKE128.Squeeze(ctx, 8 ⋅ z) Extracts z output bytes produced during the “squeezing” phase of SHAKE128 and updates the context accordingly. While the above functions are constructed using the Keccak-f permutation rather than the XOF SHAKE128 directly, they are defined so that a single SHAKE128 call of the form\n\noutput ← SHAKE128(str1‖ ... ‖strm , 8b1 + ... + 8bl) (4.6)\n\nis equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are multiples of the SHAKE128 block length.\n\nAlgorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results", "char_len": 3986, "approx_tokens": 996}
{"chunk_id": "NIST.FIPS.203::c00018", "doc_id": "NIST.FIPS.203", "start_page": 28, "end_page": 30, "text": "rithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results\n\nIn this standard, the incremental API for SHAKE128 will only be invoked through a wrapper XOF,\n\nwhich is defined as follows. 1. XOF.Init() = SHAKE128.Init(). 2. XOF.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str). 3. XOF.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8 ⋅ l). Note that XOF.Squeeze requires the input length to be specified in bytes. This is consistent with the convention that all wrapper functions treat inputs and outputs as byte arrays and measure the lengths of all such arrays in terms of bytes.\n\n4.2 General Algorithms This section specifies a number of algorithms that will be used as subroutines in ML-KEM.\n\n4.2.1 Conversion and Compression Algorithms This section specifies several algorithms for converting between bit arrays, byte arrays, and arrays of integers modulo m. It also specifies a certain operation for compressing integers modulo q, and the corresponding decompression operation.\n\nAlgorithm 3 BitsToBytes(b) Converts a bit array (of a length that is a multiple of eight) into an array of bytes. Input: bit array b ∈ {0, 1}8⋅l. Output: byte array B ∈ Bl. 1: B ← (0, ... , 0) 2: for (i ← 0; i < 8l; i ++) 3: B [⌊i/8⌋] ← B [⌊i/8⌋] + b[i] ⋅ 2i mod 8 4: end for 5: return B\n\nAlgorithm 4 BytesToBits(B) Performs the inverse of BitsToBytes, converting a byte array into a bit array. Input: byte array B ∈ Bl. Output: bit array b ∈ {0, 1}8⋅l. 1: C ← B ▷ copy B into array C ∈ Bl 2: for (i ← 0; i < l; i ++) 3: for (j ← 0; j < 8; j ++) 4: b[8i + j] ← C[i] mod 2 5: C[i] ← ⌊C[i]/2⌋ 6: end for 7: end for 8: return b\n\nConverting between bits and bytes. The algorithms BitsToBytes (Algorithm 3) and BytesToBits (Algorithm 4) convert between bit arrays and byte arrays. The inputs to BitsToBytes and the outputs of BytesToBits are bit arrays, with each segment of eight bits representing a byte in little-endian order. As an example, the 8-bit string 11010001 corresponds to the byte 20 + 21 + 23 + 27 = 139.\n\nCompression and decompression. Recall that q = 3329, and that the bit length of q is 12. For d < 12, define\n\nCompressd ∶ Zq ⟶ Z2d (4.7) x ⟼ ⌈(2d/q) ⋅ x⌋ mod 2d . Decompressd ∶ Z2d ⟶ Zq (4.8) y ⟼ ⌈(q/2d) ⋅ y⌋ .\n\nThe input and output types of these functions are integers modulo m (see Section 2.4.1). Division and rounding in the computation of these functions are performed in the set of rational numbers. Floating-point computations shall not be used. The Compress and Decompress algorithms satisfy two important properties. First, decompression followed by compression preserves the input. That is, Compressd(Decompressd(y)) = y for all y ∈ Z2d and all d < 12. Second, if d is large (i.e., close to 12), compression followed by decompression does not significantly alter the value.\n\nEncoding and decoding. The algorithms ByteEncode (Algorithm 5) and ByteDecode (Algorithm 6) will be used for conversion between integers modulo m and bytes. The algorithm ByteEncode converts an array of n = 256 integers modulo m into a corresponding array of bytes. ByteDecode performs the inverse operation, converting an array of bytes into an array of integers modulo m. Specifying the modulus m is done as described below. For the following description, it is convenient to view ByteDecode and ByteEncode as converting between integers and bits. The conversion between bits and bytes is straightforward and done using BitsToBytes and BytesToBits.", "char_len": 3962, "approx_tokens": 990}
{"chunk_id": "NIST.FIPS.203::c00019", "doc_id": "NIST.FIPS.203", "start_page": 30, "end_page": 31, "text": "lgorithm 5) and ByteDecode (Algorithm 6) will be used for conversion between integers modulo m and bytes. The algorithm ByteEncode converts an array of n = 256 integers modulo m into a corresponding array of bytes. ByteDecode performs the inverse operation, converting an array of bytes into an array of integers modulo m. Specifying the modulus m is done as described below. For the following description, it is convenient to view ByteDecode and ByteEncode as converting between integers and bits. The conversion between bits and bytes is straightforward and done using BitsToBytes and BytesToBits. The valid range of values for the parameter d is 1 ≤ d ≤ 12. Bit arrays are divided into d-bit segments. The operations are performed in two different ways, depending on the value of d: • For d satisfying 1 ≤ d ≤ 11, the conversion is one-to-one. ByteDecoded converts each d-bit segment of its input into one integer modulo 2d, while ByteEncoded performs the inverse operation. • For d = 12, ByteDecode12 produces integers modulo q as output, while ByteEncode12 receives integers modulo q as input. Specifically, ByteDecode12 converts each 12-bit segment of its input into an integer modulo 212 = 4096 and then reduces the result modulo q. This is no longer a one-to-one operation. Indeed, some 12-bit segments could correspond to an integer greater than q − 1 = 3328 but less than 4096. However, this cannot occur for arrays produced by ByteEncode12. These aspects of ByteDecode12 and\n\nByteEncode12 will be important when considering checking of the ML-KEM encapsulation key in Section 7.\n\nAlgorithm 5 ByteEncoded(F ) Encodes an array of d-bit integers into a byte array for 1 ≤ d ≤ 12. Input: integer array F ∈ Z256, where m = 2d if d < 12, and m = q if d = 12. m Output: byte array B ∈ B32d. 1: for (i ← 0; i < 256; i ++) 2: a ← F [i] ++) ▷ a ∈ Zm 3: for (j ← 0; j < d; j 4: b[i ⋅ d + j] ← a mod 2 ▷ b ∈ {0, 1}256⋅d 5: a ← (a − b[i ⋅ d + j])/2 ▷ note a − b[i ⋅ d + j] is always even 6: end for 7: end for 8: B ← BitsToBytes(b) 9: return B\n\nAlgorithm 6 ByteDecoded(B) Decodes a byte array into an array of d-bit integers for 1 ≤ d ≤ 12. Input: byte array B ∈ B32d. Output: integer array F ∈ Z256, where m = 2d if d < 12 and m = q if d = 12. m 1: b ← BytesToBits(B) 2: for (i ← 0; i < 256; i ++) 3: F [i] ← ∑d−1 b[i ⋅ d + j] ⋅ 2j mod m 4: end for j←0 5: return F\n\n4.2.2 Sampling Algorithms The algorithms of ML-KEM require two sampling subroutines that are specified in Algorithms 7 and 8. Both of these algorithms can be used to convert a stream of uniformly random bytes into a sample from some desired distribution. In this standard, these algorithms will be invoked with a stream of pseudorandom bytes as the input. It follows that the output will then be a sample from a distribution that is computationally indistinguishable from the desired distribution.\n\nUniform sampling of NTT representations. The algorithm SampleNTT (Algorithm 7) converts a seed together with two indexing bytes into a polynomial in the NTT domain. If the seed is uniformly random, the resulting polynomial will be drawn from a distribution that is computationally indistinguishable from the uniform distribution on Tq . The output of SampleNTT is an array in Z256 that contains the coefficients of the sampled element of T (see Section 2.4.4). See Appendixq q B for a note on (optionally) safely bounding the algorithm’s while-loop iterations.", "char_len": 3424, "approx_tokens": 856}
{"chunk_id": "NIST.FIPS.203::c00020", "doc_id": "NIST.FIPS.203", "start_page": 31, "end_page": 33, "text": "hable from the desired distribution.\n\nUniform sampling of NTT representations. The algorithm SampleNTT (Algorithm 7) converts a seed together with two indexing bytes into a polynomial in the NTT domain. If the seed is uniformly random, the resulting polynomial will be drawn from a distribution that is computationally indistinguishable from the uniform distribution on Tq . The output of SampleNTT is an array in Z256 that contains the coefficients of the sampled element of T (see Section 2.4.4). See Appendixq q B for a note on (optionally) safely bounding the algorithm’s while-loop iterations.\n\nAlgorithm 7 SampleNTT(B) Takes a 32-byte seed and two indices as input and outputs a pseudorandom element of Tq . Input: byte array B ∈ B34. ▷ a 32-byte seed along with two indices Output: array a ∈ Z256. ▷ the coefficients of the NTT of a polynomial q 1: ctx ← XOF.Init() 2: ctx ← XOF.Absorb(ctx, B) ▷ input the given byte array into XOF 3: j ← 0 4: while j < 256 do 5: (ctx, C) ← XOF.Squeeze(ctx, 3) ▷ get a fresh 3-byte array C from XOF 6: d1 ← C[0] + 256 ⋅ (C[1] mod 16) ▷ 0 ≤ d1 < 212 7: d2 ← ⌊C[1]/16⌋ + 16 ⋅ C[2] ▷ 0 ≤ d2 < 212 8: if d1 < q then 256 9: a[j] ← d1 ▷ a ∈ Zq 10: j ← j + 1 11: end if 12: if d2 < q and j < 256 then 13: a[j] ← d2 14: j ← j + 1 15: end if 16: end while 17: return â\n\nSampling from the centered binomial distribution. ML-KEM makes use of a special distribution Dη(Rq ) of polynomials in Rq with small coefficients. Such polynomials are sometimes referred to as “errors” or “noise.” The distribution is parameterized by an integer η ∈ {2, 3}. To sample a polynomial from Dη(Rq ), each of its coefficients is independently sampled from a certain centered binomial distribution (CBD) on Zq . The algorithm SamplePolyCBD (Algorithm 8) samples the coefficient array of a polynomial f ∈ Rq according to the distribution Dη(Rq ), provided that\n\nAlgorithm 8 SamplePolyCBDη(B) Takes a seed as input and outputs a pseudorandom sample from the distribution Dη(Rq ). Input: byte array B ∈ B64η . Output: array f ∈ Z256. ▷ the coefficients of the sampled polynomial q 1: b ← BytesToBits(B) 2: for (i ← 0; i < 256; i ++) 3: x ← ∑η−1 b[2iη + j] ▷ 0 ≤ x ≤ η j←0 4: y ← ∑η−1 b[2iη + η + j] ▷ 0 ≤ y ≤ η j←0 5: f[i] ← x − y mod q ▷ 0 ≤ f[i] ≤ η or q − η ≤ f[i] ≤ q − 1 6: end for 7: return f\n\nits input is a stream of uniformly random bytes.\n\n4.3 The Number-Theoretic Transform The Number-Theoretic Transform (NTT) can be viewed as a specialized, exact version of the discrete Fourier transform. In the case of ML-KEM, the NTT is used to improve the efficiency of multiplication in the ring Rq . Recall that Rq is the ring Zq [X]/(Xn + 1) of polynomials of the form f = f0 + f1X + ⋯ + f255X255 (where fj ∈ Zq for all j), with the ring operations defined by arithmetic modulo Xn + 1. The ring Rq is isomorphic to another ring Tq , which is a direct sum of 128 quadratic extensions of Zq . The NTT is a computationally efficient isomorphism between these two rings. When a polynomial f ∈ Rq is input, the NTT outputs an element f ∶= NTT(f) of the ring Tq , where f is called the “NTT representation” of f. The isomorphism property implies that\n\nf ×Rq g = NTT−1(f ×Tq g), (4.9)\n\nwhere ×Rq and ×Tq denote multiplication in Rq and Tq , respectively. Moreover, since Tq is a product of 128 rings that each consist of polynomials of degree at most one, the operation ×Tq is much more efficient than the operation ×Rq . For these reasons, the NTT is considered to be an integral part of ML-KEM and not merely an optimization. As the rings Rq and Tq have a vector space structure over Zq , the most natural abstract data type to represent elements from either of these rings is Zn. For this reason, the choice of data q structure for the inputs and outputs of NTT and NTT−1 are length-n arrays of integers modulo q. These arrays are understood to represent elements of Tq or Rq , respectively (see Section 2.4.4).", "char_len": 3919, "approx_tokens": 979}
{"chunk_id": "NIST.FIPS.203::c00021", "doc_id": "NIST.FIPS.203", "start_page": 33, "end_page": 35, "text": "st of polynomials of degree at most one, the operation ×Tq is much more efficient than the operation ×Rq . For these reasons, the NTT is considered to be an integral part of ML-KEM and not merely an optimization. As the rings Rq and Tq have a vector space structure over Zq , the most natural abstract data type to represent elements from either of these rings is Zn. For this reason, the choice of data q structure for the inputs and outputs of NTT and NTT−1 are length-n arrays of integers modulo q. These arrays are understood to represent elements of Tq or Rq , respectively (see Section 2.4.4). Algorithms 9 and 10 describe an efficient means of computing NTT and NTT−1 in place. However, to clarify the distinction between the algebraic objects before and after the conversion, the algorithms are written with explicit inputs and outputs. This is consistent with this standard’s convention that all inputs are passed by copy.\n\nThe mathematical structure of the NTT. In ML-KEM, q is the prime 3329 = 28 ⋅ 13 + 1, and n = 256. There are 128 primitive 256-th roots of unity and no primitive 512-th roots of unity in Zq . Note that ζ = 17 ∈ Zq is a primitive 256-th root of unity modulo q. Thus, ζ 128 ≡ −1. Define BitRev7 (i) to be the integer represented by bit-reversing the unsigned 7-bit value that corresponds to the input integer i ∈ {0, ... , 127}. The polynomial X256 + 1 factors into 128 polynomials of degree 2 modulo q as follows:\n\nX256 + 1 = ∏ (X2 − ζ 2BitRev7(i)+1) . (4.10) i=0\n\nTherefore, Rq ∶= Zq [X]/(X256 + 1) is isomorphic to a direct sum of 128 quadratic extension\n\nfields of Zq , denoted Tq . Specifically, this ring has the structure\n\nTq ∶= ⨁ Zq [X]/ (X2 − ζ 2BitRev7(i)+1) . (4.11) i=0\n\nThus, the NTT representation f ∈ Tq of a polynomial f ∈ Rq is the vector that consists of the corresponding residues of degree at most one:\n\nf ∶= (f mod (X2 − ζ 2BitRev7(0)+1), ... , f mod (X2 − ζ 2BitRev7(127)+1)) . (4.12)\n\nAs discussed in Section 2.4.4, the algorithms in this standard represent f as an array of 256 integers modulo q. Specifically,\n\nf mod (X2 − ζ 2BitRev7(i)+1) = f[2i] + f[2i + 1]X, (4.13)\n\nfor i from 0 to 127.\n\nThe ML-KEM NTT algorithms. An algorithm for the ML-KEM NTT is described in Algorithm 9. An algorithm for the inverse operation (NTT−1) is described in Algorithm 10. These two algorithms will be used to transform elements of Rq to elements of Tq (using NTT) and vice versa (using NTT−1). In addition, as discussed in Section 2.4.8, these algorithms represent the coordinate- wise transformation of structures over those rings. Specifically, they map matrices/vectors with entries in Rq to matrices/vectors with entries in Tq (using NTT) and vice versa (using NTT−1). The values ζ BitRev7(i) mod q for i = 1, ... , 127 used in line 5 of Algorithm 9 and line 5 of Algorithm 10 may be precomputed into an array. This array is given in Appendix A.\n\nAlgorithm 9 NTT(f) Computes the NTT representation f of the given polynomial f ∈ Rq . Input: array f ∈ Z256. ▷ the coefficients of the input polynomial q Output: array f ∈ Z256. ▷ the coefficients of the NTT of the input polynomial q 1: f ← f ▷ will compute in place on a copy of input array 2: i ← 1 3: for (len ← 128; len ≥ 2; len ← len/2) 4: for (start ← 0; start < 256; start ← start + 2 ⋅ len) 5: zeta ← ζ BitRev7(i) mod q 6: i ← i + 1 7: for (j ← start; j < start + len; j ++) 8: t ← zeta ⋅ f[j + len] ▷ steps 8-10 done modulo q 9: f[j + len] ← f[j] − t 10: f[j] ← f[j] + t 11: end for 12: end for 13: end for 14: return f", "char_len": 3519, "approx_tokens": 879}
{"chunk_id": "NIST.FIPS.203::c00022", "doc_id": "NIST.FIPS.203", "start_page": 35, "end_page": 37, "text": "e NTT representation f of the given polynomial f ∈ Rq . Input: array f ∈ Z256. ▷ the coefficients of the input polynomial q Output: array f ∈ Z256. ▷ the coefficients of the NTT of the input polynomial q 1: f ← f ▷ will compute in place on a copy of input array 2: i ← 1 3: for (len ← 128; len ≥ 2; len ← len/2) 4: for (start ← 0; start < 256; start ← start + 2 ⋅ len) 5: zeta ← ζ BitRev7(i) mod q 6: i ← i + 1 7: for (j ← start; j < start + len; j ++) 8: t ← zeta ⋅ f[j + len] ▷ steps 8-10 done modulo q 9: f[j + len] ← f[j] − t 10: f[j] ← f[j] + t 11: end for 12: end for 13: end for 14: return f\n\nAlgorithm 10 NTT−1(f) Computes the polynomial f ∈ Rq that corresponds to the given NTT representation f ∈ Tq . Input: array f ∈ Z256. ▷ the coefficients of input NTT representation q Output: array f ∈ Z256. ▷ the coefficients of the inverse NTT of the input q 1: f ← f ▷ will compute in place on a copy of input array 2: i ← 127 3: for (len ← 2; len ≤ 128; len ← 2 ⋅ len) 4: for (start ← 0; start < 256; start ← start + 2 ⋅ len) 5: zeta ← ζ BitRev7(i) mod q 6: i ← i − 1 7: for (j ← start; j < start + len; j ++) 8: t ← f[j] 9: f[j] ← t + f[j + len] ▷ steps 9-10 done modulo q 10: f[j + len] ← zeta ⋅ (f[j + len] − t) 11: end for 12: end for 13: end for 14: f ← f ⋅ 3303 mod q ▷ multiply every entry by 3303 ≡ 128−1 mod q 15: return f\n\n4.3.1 Multiplication in the NTT Domain The addition and scalar multiplication of elements of Tq can be done using the corresponding coordinate-wise arithmetic operations on the coefficient arrays (see Section 2.4.5). This section describes how to do the remaining ring operation (i.e., multiplication in Tq ).\n\nRecall from (4.12) that f ∈ Tq is a vector of 128 degree-one residues modulo quadratic polynomials. Algebraically, multiplication in the ring Tq consists of independent multiplication in each of the 128 coordinates with respect to the quadratic modulus of that coordinate. Specifically, the i-th coordinate in Tq of the product h = f ×Tq ĝ is determined by the calculation\n\nh[2i] + h[2i + 1]X = (f[2i] + f[2i + 1]X)(g[2i] + g[2i + 1]X) mod (X2 − ζ 2BitRev7(i)+1). (4.14)\n\nAlgorithm 11 MultiplyNTTs(f, g) Computes the product (in the ring Tq ) of two NTT representations. Input: Two arrays f ∈ Z256 and g ∈ Z256. ▷ the coefficients of two NTT representations q q Output: An array h ∈ Z256. ▷ the coefficients of the product of the inputs q 1: for (i ← 0; i < 128; i ++) 2: (h[2i], h[2i + 1]) ← BaseCaseMultiply(f[2i], f[2i + 1], g[2i], g[2i + 1], ζ 2BitRev7(i)+1) 3: end for 4: return h\n\nThus, one can compute the product of two elements of Tq using the algorithm MultiplyNTTs (Algorithm 11), which uses BaseCaseMultiply (Algorithm 12) as a subroutine. The values ζ 2BitRev7(i)+1 used in Algorithm 11 may be precomputed and stored in an array (see Appendix A). MultiplyNTTs also enables linear-algebraic arithmetic with matrices and vectors whose entries are in Tq (see Section 2.4.7).\n\nAlgorithm 12 BaseCaseMultiply(a0, a1, b0, b1, γ) Computes the product of two degree-one polynomials with respect to a quadratic modulus. Input: a0, a1, b0, b1 ∈ Zq . ▷ the coefficients of a0 + a1X and b0 + b1X Input: γ ∈ Zq . ▷ the modulus is X2 − γ Output: c0, c1 ∈ Zq . ▷ the coefficients of the product of the two polynomials 1: c0 ← a0 ⋅ b0 + a1 ⋅ b1 ⋅ γ ▷ steps 1-2 done modulo q 2: c1 ← a0 ⋅ b1 + a1 ⋅ b0 3: return (c0, c1)\n\n5. The K-PKE Component Scheme\n\nThis section describes the component scheme K-PKE. As discussed in Section 3.3, K-PKE is not approved for use in a stand-alone fashion. It serves only as a collection of subroutines for use in the algorithms of the approved scheme ML-KEM, as described in Section 7. K-PKE consists of three algorithms: 1. Key generation (K-PKE.KeyGen) 2. Encryption (K-PKE.Encrypt) 3. Decryption (K-PKE.Decrypt) When K-PKE is instantiated as part of ML-KEM, K-PKE inherits the parameter set selected for ML-KEM. Each parameter set specifies numerical values for each parameter.", "char_len": 3955, "approx_tokens": 988}
{"chunk_id": "NIST.FIPS.203::c00023", "doc_id": "NIST.FIPS.203", "start_page": 36, "end_page": 38, "text": "0, c1)\n\n5. The K-PKE Component Scheme\n\nThis section describes the component scheme K-PKE. As discussed in Section 3.3, K-PKE is not approved for use in a stand-alone fashion. It serves only as a collection of subroutines for use in the algorithms of the approved scheme ML-KEM, as described in Section 7. K-PKE consists of three algorithms: 1. Key generation (K-PKE.KeyGen) 2. Encryption (K-PKE.Encrypt) 3. Decryption (K-PKE.Decrypt) When K-PKE is instantiated as part of ML-KEM, K-PKE inherits the parameter set selected for ML-KEM. Each parameter set specifies numerical values for each parameter. While n is always 256 and q is always 3329, the values of the remaining parameters k, η1, η2, du, and dv vary among the three parameter sets. Parameters and parameter sets are described in Section 8. The algorithms in this section do not perform any input checking because they are only invoked as subroutines of the main ML-KEM algorithms. The algorithms of ML-KEM themselves do perform input checking as needed. Each of the algorithms of K-PKE is accompanied by a brief, informal description in text. For simplicity, this description is written in terms of vectors and matrices whose entries are elements of Rq . In the actual algorithm, most of the computations occur in the NTT domain in order to improve the efficiency of multiplication. The relevant vectors and matrices will then have entries in Tq . Linear-algebraic arithmetic with such vectors and matrices (e.g., line 18 of K-PKE.KeyGen) is performed as described in Sections 2.4.7 and 4.3.1. The encryption and decryption keys of K-PKE are also stored in the NTT form.\n\n5.1 K-PKE Key Generation The key generation algorithm K-PKE.KeyGen of K-PKE (Algorithm 13) receives a seed as input and outputs an encryption key ekPKE and a decryption key dkPKE. As is typically the case for public-key encryption, the encryption key can be made public, while the decryption key and the randomness must remain private. Indeed, the encryption key of K-PKE will serve as the encapsulation key of ML-KEM (see ML-KEM.KeyGen below) and can thus be made public. Meanwhile, the decryption key and seed of K-PKE.KeyGen must remain private as they can be used to perform decapsulation in ML-KEM. The matrix A generated in steps 3-7 of K-PKE.KeyGen can be stored, as specified in Section 3.3. This allows later operations to use A directly rather than re-expanding it from the public seed ρ.\n\nInformal description. The decryption key of K-PKE.KeyGen is a length-k vector s of elements of Rq (i.e., s ∈ Rk). Roughly speaking, s is a set of secret variables, while the encryption key is a collection of q “noisy” linear equations (A, As + e) in the secret variables s. The rows of the matrix A form the equation coefficients. This matrix is generated pseudorandomly using XOF with only a seed stored in the encryption key. The secret s and the “noise” e are sampled from\n\nAlgorithm 13 K-PKE.KeyGen(d) Uses randomness to generate an encryption key and a corresponding decryption key. Input: randomness d ∈ B32. Output: encryption key ekPKE ∈ B384k+32 . Output: decryption key dkPKE ∈ B384k . 1: (ρ, σ) ← G(d‖k) ▷ expand 32+1 bytes to two pseudorandom 32-byte seeds1 2: N ← 0 3: for (i ← 0; i < k; i ++) ▷ generate matrix A∈ (Z256)k×k 4: for (j ← 0; j < k; j ++) q 5: A[i, j] ← SampleNTT(ρ‖j‖i) ▷ j and i are bytes 33 and 34 of the input 6: end for 7: end for 8: for (i ← 0; i < k; i ++) ▷ generate s ∈ (Z256)k q 9: s[i] ← SamplePolyCBD (PRFη (σ, N )) ▷ s[i] ∈ Z256 sampled from CBD 10: N ← N + 1 η1 1 q 11: end for 12: for (i ← 0; i < k; i ++) ▷ generate e ∈ (Z256)k q 13: e[i] ← SamplePolyCBD (PRFη (σ, N )) ▷ e[i] ∈ Z256 sampled from CBD 14: N ← N + 1 η1 1 q 15: end for 16: s ← NTT(s) ▷ run NTT k times (once for each coordinate of s) 17: e ← NTT(e) ▷ run NTT k times 18: t ← A ∘ s +̂ ê ▷ noisy linear system in NTT domain 19: ekPKE ← ByteEncode12(t)‖ρ ▷ run ByteEncode12 k times, then append A-seed 20: dkPKE ← ByteEncode12(s)̂ ▷ run ByteEncode12 k times 21: r", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.FIPS.203::c00024", "doc_id": "NIST.FIPS.203", "start_page": 38, "end_page": 39, "text": "r (i ← 0; i < k; i ++) ▷ generate s ∈ (Z256)k q 9: s[i] ← SamplePolyCBD (PRFη (σ, N )) ▷ s[i] ∈ Z256 sampled from CBD 10: N ← N + 1 η1 1 q 11: end for 12: for (i ← 0; i < k; i ++) ▷ generate e ∈ (Z256)k q 13: e[i] ← SamplePolyCBD (PRFη (σ, N )) ▷ e[i] ∈ Z256 sampled from CBD 14: N ← N + 1 η1 1 q 15: end for 16: s ← NTT(s) ▷ run NTT k times (once for each coordinate of s) 17: e ← NTT(e) ▷ run NTT k times 18: t ← A ∘ s +̂ ê ▷ noisy linear system in NTT domain 19: ekPKE ← ByteEncode12(t)‖ρ ▷ run ByteEncode12 k times, then append A-seed 20: dkPKE ← ByteEncode12(s)̂ ▷ run ByteEncode12 k times 21: return (ekPKE, dkPKE)\n\ncentered binomial distributions using randomness expanded from another seed σ via PRF. Once A, s, and e are generated, the computation of the final part t = As + e of the encryption key takes place. The results are appropriately encoded into byte arrays and output. In K-PKE.KeyGen, the choice of parameter set affects the length of the secret s (via the parameter k) and, as a consequence, the sizes of the noise vector e and the pseudorandom matrix A. The choice of parameter set also affects the noise distribution (via the parameter η1) used to sample the entries of s and e.\n\n5.2 K-PKE Encryption The encryption algorithm K-PKE.Encrypt of K-PKE (Algorithm 14) takes an encryption key ekPKE, a 32-byte plaintext m, and randomness r as input and produces a single output: a ciphertext c. 1Byte 33 of the input to G is the module dimension k ∈ {2, 3, 4} ⊂ B. This is included to establish domain separation between the three parameter sets. For implementations that use the seed in place of the private key, this ensures that the expansion will produce an unrelated key if the seed is mistakenly expanded using a parameter set other than the originally intended one.\n\nThe matrix A generated in steps 4-8 of K-PKE.Encrypt can be stored, as specified in Section 3.3. This allows later operations to use A directly rather than re-expanding it from the public seed ρ.\n\nAlgorithm 14 K-PKE.Encrypt(ekPKE, m, r) Uses the encryption key to encrypt a plaintext message using the randomness r. Input: encryption key ekPKE ∈ B384k+32 . Input: message m ∈ B32. Input: randomness r ∈ B32. Output: ciphertext c ∈ B32(duk+dv). 1: N ← 0 2: t ← ByteDecode (ekPKE[0 ∶ 384k]) ▷ run ByteDecode k times to decode t ∈ (Z256)k ρ ← ek [384k ∶12 12 q 3: PKE 384k + 32] ▷ extract 32-byte seed from ekPKE 4: for (i ← 0; i < k; i ++) ▷ re-generate matrix A ∈ (Z256)k×k sampled in Alg. 13 5: for (j ← 0; j < k; j ++) q 6: A[i, j] ← SampleNTT(ρ‖j‖i) ▷ j and i are bytes 33 and 34 of the input 7: end for 8: end for 9: for (i ← 0; i < k; i ++) ▷ generate y ∈ (Z256)k q 10: y[i] ← SamplePolyCBD (PRFη (r, N )) ▷ y[i] ∈ Z256 sampled from CBD 11: N ← N + 1 η1 1 q 12: end for 13: for (i ← 0; i < k; i ++) ▷ generate e ∈ (Z256)k 1 q 14: e1 [i] ← SamplePolyCBD (PRFη (r, N )) ▷ e1 [i] ∈ Z256 sampled from CBD 15: N ← N + 1 η2 2 q 16: end for 17: e2 ← SamplePolyCBD (PRFη (r, N )) ▷ sample e2 ∈ Z256 from CBD y ← NTT(y) η2 2 ▷ run q 18: NTT k times 19: u ← NTT−1(A⊺ ∘ y) + e1 ▷ run NTT−1 k times 20: μ ← Decompress1(ByteDecode1(m)) 21: v ← NTT−1(t⊺ ∘ y) + e2 + μ ▷ encode plaintext m into polynomial v 22: c1 ← ByteEncodedu (Compressdu (u)) ▷ run ByteEncodedu and Compressdu k times 23: c2 ← ByteEncodedv (Compressdv (v)) 24: return c ← (c1‖c2)\n\nInformal description. The algorithm K-PKE.Encrypt begins by extracting the vector t and the seed from the encryption key. The seed is then expanded to re-generate the matrix A in the same manner as was done in K-PKE.KeyGen. If t and A are derived correctly from an encryption key produced by K-PKE.KeyGen, then they are equal to their corresponding values in K-PKE.KeyGen. Recall from the description of key generation that the pair (A, t = As + e) can be thought of as a system of noisy linear equations in the secret variables s. One can generate an additional noisy linear equation in the same secret variables — without knowing s — by picking a random linear", "char_len": 3995, "approx_tokens": 998}
{"chunk_id": "NIST.FIPS.203::c00025", "doc_id": "NIST.FIPS.203", "start_page": 39, "end_page": 41, "text": "acting the vector t and the seed from the encryption key. The seed is then expanded to re-generate the matrix A in the same manner as was done in K-PKE.KeyGen. If t and A are derived correctly from an encryption key produced by K-PKE.KeyGen, then they are equal to their corresponding values in K-PKE.KeyGen. Recall from the description of key generation that the pair (A, t = As + e) can be thought of as a system of noisy linear equations in the secret variables s. One can generate an additional noisy linear equation in the same secret variables — without knowing s — by picking a random linear\n\ncombination of the noisy equations in the system (A, t). One can then encode information in the “constant term” (i.e., the entry that is a linear combination of entries of t) of such a combined equation. This information can then be deciphered by a party in possession of s. For example, one could encode a single bit by deciding whether or not to significantly alter the constant term, thus making either a nearly correct equation that corresponds to the decrypted bit value of 0 or a far-from-correct equation that corresponds to the decrypted bit value of 1. In the case of K-PKE, the constant term is a polynomial with 256 coefficients, so one can encode more information: one bit in each coefficient. To this end, K-PKE.Encrypt proceeds by generating a vector y ∈ Rk and noise terms e ∈ Rk and , all of which are sampled from the centered binomial q 1 q e2 ∈ Rq PRF r distribution using pseudoran- domness expanded via from the input randomness . One then computes the “new noisy equation,” which is (up to some details) (A⊺y + e1, t⊺y + e2). An appropriate encoding μ of the input message m is then added to the latter term in the pair. Finally, the resulting pair (u, v) is compressed, serialized into a byte array, and output as the ciphertext.\n\n5.3 K-PKE Decryption The decryption algorithm K-PKE.Decrypt of K-PKE (Algorithm 15) takes a decryption key dkPKE and a ciphertext c as input, requires no randomness, and outputs a plaintext m.\n\nInformal description. The algorithm K-PKE.Decrypt begins by recovering a pair (u′ , v′ ) from the ciphertext c (see the description of K-PKE.Encrypt). Here, one can think of u′ as the coefficients of the equation and v′ as the constant term. The decryption key dkPKE contains the vector of secret variables s. The decryption algorithm can thus use the decryption key to compute the true constant term v = s⊺u′ and calculate v′ − v. The decryption algorithm ends by decoding the plaintext message m from v′ − v and outputting m.\n\nAlgorithm 15 K-PKE.Decrypt(dkPKE, c) Uses the decryption key to decrypt a ciphertext. Input: decryption key dkPKE ∈ B384k . Input: ciphertext c ∈ B32(duk+dv). Output: message m ∈ B32. 1: c1 ← c[0 ∶ 32duk] 2: c2 ← c[32duk ∶ 32(duk + dv)] 3: u′ ← Decompressdu (ByteDecodedu (c1)) ▷ run Decompressdu and ByteDecodedu k times 4: v′ ← Decompressdv (ByteDecodedv (c2)) 5: s ← ByteDecode12(dkPKE) ▷ run ByteDecode12 k times 6: w ← v′ − NTT−1(s⊺ ∘ NTT(u′ )) ▷ run NTT k times; run NTT−1 once 7: m ← ByteEncode1(Compress1(w)) ▷ decode plaintext m from polynomial v 8: return m\n\n6. Main Internal Algorithms\n\nThis section specifies three algorithms: ML-KEM.KeyGen_internal, ML-KEM.Encaps_internal, and ML-KEM.Decaps_internal. These three algorithms are all deterministic, meaning that their output is completely determined by their input. No randomness is sampled inside of these algorithms. These three algorithms will be used to construct ML-KEM in Section 7. The algorithms in this section make use of the parameters n, q, k, du, and dv. The subroutines they invoke additionally make use of the parameters η1 and η2. While n is always 256 and q is always 3329, the remaining parameters vary among the possible parameter sets (see Section 8). The interfaces specified in this section will be used to test ML-KEM implementations through the Cryptographic Algorithm Validation Program (CAVP).", "char_len": 3958, "approx_tokens": 989}
{"chunk_id": "NIST.FIPS.203::c00026", "doc_id": "NIST.FIPS.203", "start_page": 41, "end_page": 42, "text": "tput is completely determined by their input. No randomness is sampled inside of these algorithms. These three algorithms will be used to construct ML-KEM in Section 7. The algorithms in this section make use of the parameters n, q, k, du, and dv. The subroutines they invoke additionally make use of the parameters η1 and η2. While n is always 256 and q is always 3329, the remaining parameters vary among the possible parameter sets (see Section 8). The interfaces specified in this section will be used to test ML-KEM implementations through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to re-expand a key from a seed (see Section 3.3), including when obtaining assurance of private key possession via regeneration. As prescribed in Section 3.3, the interfaces specified in this section should not be made available to applications other than for testing purposes, and the random seeds (as specified in ML-KEM.KeyGen and ML-KEM.Encaps in Section 7) shall be generated by the cryptographic module.\n\n6.1 Internal Key Generation The algorithm ML-KEM.KeyGen_internal (Algorithm 16) accepts two random seeds as input, and produces an encapsulation key and a decapsulation key.\n\nInformal description. The core subroutine of ML-KEM.KeyGen_internal is the key generation algorithm of K-PKE (Algorithm 13). The encapsulation key is simply the encryption key of K-PKE. The decapsulation key consists of the decryption key of K-PKE, the encapsulation key, a hash of the encapsulation key, and a random 32-byte value. This random value will be used in the ”implicit rejection” mechanism of the internal decapsulation algorithm (Algorithm 18).\n\nAlgorithm 16 ML-KEM.KeyGen_internal(d, z) Uses randomness to generate an encapsulation key and a corresponding decapsulation key. Input: randomness d ∈ B32. Input: randomness z ∈ B32. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . 1: (ekPKE, dkPKE) ← K-PKE.KeyGen(d) ▷ run key generation for K-PKE 2: ek ← ekPKE ▷ KEM encaps key is just the PKE encryption key 3: dk ← (dkPKE‖ek‖H(ek)‖z) ▷ KEM decaps key includes PKE decryption key 4: return (ek, dk)\n\n6.2 Internal Encapsulation The algorithm ML-KEM.Encaps_internal (Algorithm 17) accepts an encapsulation key and a random byte array as input and outputs a ciphertext and a shared key.\n\nAlgorithm 17 ML-KEM.Encaps_internal(ek, m) Uses the encapsulation key and randomness to generate a key and an associated ciphertext. Input: encapsulation key ek ∈ B384k+32 . Input: randomness m ∈ B32. Output: shared secret key K ∈ B32. Output: ciphertext c ∈ B32(duk+dv). 1: (K, r) ← G(m‖H(ek)) ▷ derive shared secret key K and randomness r 2: c ← K-PKE.Encrypt(ek, m, r) ▷ encrypt m using K-PKE with randomness r 3: return (K, c)\n\nInformal description. The core subroutine of ML-KEM.Encaps_internal is the encryption algorithm of K-PKE, which is used to encrypt a random value m into a ciphertext c. A copy of the shared secret key K and the randomness used during encryption are derived from m and the encapsulation key ek via hashing. Specifically, H is applied to ek, and the result is concatenated with m and then hashed using G. Finally, the algorithm outputs the shared secret key K and the ciphertext c.\n\n6.3 Internal Decapsulation The algorithm ML-KEM.Decaps_internal (Algorithm 18) accepts a decapsulation key and a ciphertext as input, does not use any randomness, and outputs a shared secret key.", "char_len": 3488, "approx_tokens": 872}
{"chunk_id": "NIST.FIPS.203::c00027", "doc_id": "NIST.FIPS.203", "start_page": 42, "end_page": 44, "text": "ryption algorithm of K-PKE, which is used to encrypt a random value m into a ciphertext c. A copy of the shared secret key K and the randomness used during encryption are derived from m and the encapsulation key ek via hashing. Specifically, H is applied to ek, and the result is concatenated with m and then hashed using G. Finally, the algorithm outputs the shared secret key K and the ciphertext c.\n\n6.3 Internal Decapsulation The algorithm ML-KEM.Decaps_internal (Algorithm 18) accepts a decapsulation key and a ciphertext as input, does not use any randomness, and outputs a shared secret key.\n\nInformal description. The algorithm ML-KEM.Decaps_internal begins by parsing out the components of the decapsulation key dk of ML-KEM. These components are an (encryption key, decryption key) pair for K-PKE, a hash value h, and a random value z. The decryption key of K-PKE is then used to decrypt the input ciphertext c to get a plaintext m′ . The decapsulation algorithm then re-encrypts m′ and computes a candidate shared secret key K′ in the same manner as should have been done in encapsulation. Specifically, K′ and the encryption randomness r′ are computed by hashing m′ and the encryption key of K-PKE, and a ciphertext c′ is generated by encrypting m′ using randomness r′ . Finally, decapsulation checks whether the resulting ciphertext c′ matches the provided ciphertext c. If it does not, the algorithm performs an “implicit rejection”: the value of K′ is changed to a hash of c together with the random value z stored in the ML-KEM secret key (see the discussion of decapsulation failures in Section 3.2). In either case, decapsulation outputs the resulting shared secret key K′ . The “implicit reject” flag computed in step 9 (by comparing c and c′ ) is a secret piece of intermediate data. As specified in the requirements in Section 3.3, this flag shall be destroyed prior to ML-KEM.Decaps_internal terminating. In particular, returning the value of the flag as an output in any form is not permitted.\n\nAlgorithm 18 ML-KEM.Decaps_internal(dk, c) Uses the decapsulation key to produce a shared secret key from a ciphertext. Input: decapsulation key dk ∈ B768k+96 . Input: ciphertext c ∈ B32(duk+dv). Output: shared secret key K ∈ B32. 1: dkPKE ← dk[0 ∶ 384k] ▷ extract (from KEM decaps key) the PKE decryption key 2: ekPKE ← dk[384k ∶ 768k + 32] ▷ extract PKE encryption key 3: h ← dk[768k + 32 ∶ 768k + 64] ▷ extract hash of PKE encryption key 4: z ← dk[768k + 64 ∶ 768k + 96] ▷ extract implicit rejection value 5: m′ ′←′K-PKE.Decrypt(dkPKE, c) ▷ decrypt ciphertext 6: (K , r ) ← G(m′ ‖h)̄ 7: K ← J(z‖c) 8: c′ ← K-PKE.Encrypt(ekPKE, m′ , r′ ) ▷ re-encrypt using the derived randomness r′ 9: if c ≠ c′ then 10: K′ ← K ▷ if ciphertexts do not match, “implicitly reject” 11: end if 12: return K′\n\n7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme: 1. Key generation (ML-KEM.KeyGen) 2. Encapsulation (ML-KEM.Encaps) 3. Decapsulation (ML-KEM.Decaps) To instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.", "char_len": 3919, "approx_tokens": 979}
{"chunk_id": "NIST.FIPS.203::c00028", "doc_id": "NIST.FIPS.203", "start_page": 44, "end_page": 45, "text": "meter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation The key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key. While the encapsulation key can be made public, the decapsulation key shall remain private. The seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a decapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)\n\nSecure key establishment depends on the use of key pairs that have been properly generated via ML-KEM.KeyGen. If the owner of a KEM key pair did not generate the key pair but instead received it from a trusted third party or other source, the owner may optionally perform certain\n\nchecks on the key pair. While these checks can detect certain corruptions, they do not guarantee that the key pair was properly generated.\n\nKey pair check. To check a candidate key pair1 (ek, dk), perform the following checks: 1. (Seed consistency) If a seed (d, z) is available, run ML-KEM.KeyGen_internal(d, z), and verify that the output is equal to (ek, dk). 2. (Encapsulation key check) Check ek as specified in Section 7.2. 3. (Decapsulation key check) Check dk as specified in Section 7.3. 4. (Pair-wise consistency) Perform the following steps: i. Generate an array of 32 random bytes by performing m $ B32. ← − ii. Perform (K, c) ← ML-KEM.Encaps_internal(ek, m). iii. Perform K′ ← ML-KEM.Decaps_internal(dk, c). iv. Reject unless K == K′ . It is important to note that this checking process does not guarantee that the key pair is a properly produced output of ML-KEM.KeyGen.\n\n7.2 ML-KEM Encapsulation The encapsulation algorithm ML-KEM.Encaps of ML-KEM (Algorithm 20) accepts an encapsulation key as input, generates randomness internally, and outputs a ciphertext and a shared key. This algorithm requires input checking, as specified below.\n\nEncapsulation key check. To check a candidate encapsulation key ek, perform the following: 1. (Type check) If ek is not an array of bytes of length 384k + 32 for the value of k specified by the relevant parameter set, then input checking failed. 2. (Modulus check) Perform the computation\n\ntest ← ByteEncode12(ByteDecode12(ek[0 ∶ 384k])) (7.1)", "char_len": 3503, "approx_tokens": 875}
{"chunk_id": "NIST.FIPS.203::c00029", "doc_id": "NIST.FIPS.203", "start_page": 45, "end_page": 48, "text": "capsulation The encapsulation algorithm ML-KEM.Encaps of ML-KEM (Algorithm 20) accepts an encapsulation key as input, generates randomness internally, and outputs a ciphertext and a shared key. This algorithm requires input checking, as specified below.\n\nEncapsulation key check. To check a candidate encapsulation key ek, perform the following: 1. (Type check) If ek is not an array of bytes of length 384k + 32 for the value of k specified by the relevant parameter set, then input checking failed. 2. (Modulus check) Perform the computation\n\ntest ← ByteEncode12(ByteDecode12(ek[0 ∶ 384k])) (7.1)\n\n(see Section 4.2.1). If test ≠ ek[0 ∶ 384k], then input checking failed. This check ensures that the integers encoded in the public key are in the valid range [0, q − 1]. If both checks pass, then ML-KEM.Encaps can be run with input ek ∶= ek. It is important to note that this checking process does not guarantee that ek is a properly produced output of ML-KEM.KeyGen. ML-KEM.Encaps shall not be run with an encapsulation key that has not been checked as above. However, checking of the encapsulation key need not be performed by the encapsulating party,\n\n1In discussions of input checking, the “low overline” in the notation indicates that the input has not yet been checked (e.g., ek has not yet been checked, while ek has passed the check).\n\nnor with every execution of ML-KEM.Encaps. Instead, assurance that these checks have been performed can be acquired through other means (see SP 800-227 [1]).\n\nAlgorithm 20 ML-KEM.Encaps(ek) Uses the encapsulation key to generate a shared secret key and an associated ciphertext. Checked input: encapsulation key ek ∈ B384k+32 . Output: shared secret key K ∈ B32. Output: ciphertext c ∈ B32(duk+dv). m $ B32 ▷ m is 32 random bytes (see Section 3.3) ← 1: − 2: if m == NULL then 3: return ⊥ ▷ return an error indication if random bit generation failed 4: end if 5: (K, c) ← ML-KEM.Encaps_internal(ek, m) ▷ run internal encapsulation algorithm 6: return (K, c)\n\n7.3 ML-KEM Decapsulation The decapsulation algorithm ML-KEM.Decaps of ML-KEM (Algorithm 21) accepts a decapsulation key and an ML-KEM ciphertext as input, does not use any randomness, and outputs a shared secret. This algorithm requires input checking, as specified below.\n\nDecapsulation input check. To check a candidate decapsulation key dk and ciphertext c, perform the following checks: 1. (Ciphertext type check) If c is not a byte array of length 32(duk + dv) for the values of du, dv, and k specified by the relevant parameter set, then input checking has failed. 2. (Decapsulation key type check) If dk is not a byte array of length 768k + 96 for the value of k specified by the relevant parameter set, then input checking has failed. 3. (Hash check) Perform the computation\n\ntest ← H(dk[384k ∶ 768k + 32])) . (7.2)\n\nIf test ≠ dk[768k + 32 ∶ 768k + 64], then input checking has failed. If all of the above checks pass, then ML-KEM.Decaps can be run with inputs dk ∶= dk and c ∶= c. It is important to note that this checking process does not guarantee that dk is a properly produced output of ML-KEM.KeyGen, nor that c is a properly produced output of ML-KEM.Encaps. ML-KEM.Decaps shall not be run with a decapsulation key or a ciphertext unless both have been checked. However, checking of the decapsulation key need not be performed by the decapsulating party, nor with every execution of ML-KEM.Decaps. Instead, assurance that this check has been performed can be acquired through other means (see SP 800-227 [1]). Ciphertext checking shall be performed with every execution of ML-KEM.Decaps.\n\nAlgorithm 21 ML-KEM.Decaps(dk, c) Uses the decapsulation key to produce a shared secret key from a ciphertext. Checked input: decapsulation key dk ∈ B768k+96 . Checked input: ciphertext c ∈ B32(duk+dv). Output: shared secret key K ∈ B32. 1: K′ ← ML-KEM.Decaps_internal(dk, c) ▷ run internal decapsulation algorithm 2: return K′\n\n8. Parameter Sets", "char_len": 3954, "approx_tokens": 988}
{"chunk_id": "NIST.FIPS.203::c00030", "doc_id": "NIST.FIPS.203", "start_page": 46, "end_page": 49, "text": "apsulating party, nor with every execution of ML-KEM.Decaps. Instead, assurance that this check has been performed can be acquired through other means (see SP 800-227 [1]). Ciphertext checking shall be performed with every execution of ML-KEM.Decaps.\n\nAlgorithm 21 ML-KEM.Decaps(dk, c) Uses the decapsulation key to produce a shared secret key from a ciphertext. Checked input: decapsulation key dk ∈ B768k+96 . Checked input: ciphertext c ∈ B32(duk+dv). Output: shared secret key K ∈ B32. 1: K′ ← ML-KEM.Decaps_internal(dk, c) ▷ run internal decapsulation algorithm 2: return K′\n\n8. Parameter Sets\n\nML-KEM is equipped with three parameter sets, each of the which comprises five individual parameters: k, η1, η2, du, and dv. There are also two constants: n = 256 and q = 3329. The following is a brief and informal description of the roles played by the variable parameters in the algorithms of K-PKE and ML-KEM. See Section 5 for details. • The parameter k determines the dimensions of the matrix A that appears in K-PKE.KeyGen and K-PKE.Encrypt. It also determines the dimensions of vectors s and e in K-PKE.KeyGen and the dimensions of vectors y and e1 in K-PKE.Encrypt. • The parameter η1 is required to specify the distribution for generating the vectors s and e in K-PKE.KeyGen and the vector y in K-PKE.Encrypt. • The parameter η2 is required to specify the distribution for generating the vectors e1 and e2 in K-PKE.Encrypt. • The parameters du and dv serve as parameters and inputs for the functions Compress, Decompress, ByteEncode, and ByteDecode in K-PKE.Encrypt and K-PKE.Decrypt. This standard approves the parameter sets given in Table 2. Each parameter set is associated with a required security strength for randomness generation (see Section 3.3). The sizes of the ML-KEM keys and ciphertexts for each parameter set are summarized in Table 3.\n\nTable 2. Approved parameter sets for ML-KEM\n\nn q k η1 η2 du dv required RBG strength (bits) ML-KEM-512 256 3329 2 3 2 10 4 128 ML-KEM-768 256 3329 3 2 2 10 4 192 ML-KEM-1024 256 3329 4 2 2 11 5 256\n\nTable 3. Sizes (in bytes) of keys and ciphertexts of ML-KEM\n\nencapsulation key decapsulation key ciphertext shared secret key ML-KEM-512 800 1632 768 32 ML-KEM-768 1184 2400 1088 32 ML-KEM-1024 1568 3168 1568 32\n\nA parameter set name can also be said to denote a (parameter-free) KEM. Specifically, ML-KEM-x can be used to denote the parameter-free KEM that results from instantiating the scheme ML-KEM with the parameter set ML-KEM-x. The three parameter sets included in Table 2 were designed to meet certain security strength categories defined by NIST in its original Call for Proposals [4, 22]. These security strength categories are explained further in SP 800-57, Part 1 [7]. Using this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each ML-KEM parameter set is claimed to be at least as secure as a generic\n\nblock cipher with a prescribed key size or a generic hash function with a prescribed output length. More precisely, it is claimed that the computational resources needed to break ML-KEM are greater than or equal to the computational resources needed to break the block cipher or hash function when those computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models are discussed in [23]. Concretely, ML-KEM-512 is claimed to be in security category 1, ML-KEM-768 is claimed to be in security category 3, and ML-KEM-1024 is claimed to be in security category 5. For additional discussion of the security strength of MLWE-based cryptosystems, see [4].", "char_len": 3776, "approx_tokens": 944}
{"chunk_id": "NIST.FIPS.203::c00031", "doc_id": "NIST.FIPS.203", "start_page": 49, "end_page": 50, "text": "s needed to break the block cipher or hash function when those computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models are discussed in [23]. Concretely, ML-KEM-512 is claimed to be in security category 1, ML-KEM-768 is claimed to be in security category 3, and ML-KEM-1024 is claimed to be in security category 5. For additional discussion of the security strength of MLWE-based cryptosystems, see [4].\n\nSelecting an appropriate parameter set. When initially establishing cryptographic protections for data, the strongest possible parameter set should be used. This has a number of advantages, including reducing the likelihood of costly transitions to higher-security parameter sets in the future. At the same time, it should be noted that some parameter sets might have adverse performance effects for the relevant application (e.g., the algorithm may be unacceptably slow, or objects such as keys or ciphertexts may be unacceptably large). NIST recommends using ML-KEM-768 as the default parameter set, as it provides a large security margin at a reasonable performance cost. In cases where this is impractical or even higher security is required, other parameter sets may be used.\n\nReferences\n\n[1] National Institute of Standards and Technology (2024) Recommendations for key- encapsulation mechanisms, (National Institute of Standards and Technology, Gaithers- burg, MD), NIST Special Publication (SP) 800-227. [Forthcoming; will be available at https://csrc.nist.gov/publications]. [2] Barker EB, Chen L, Roginsky AL, Vassilev A, Davis R (2018) Recommendation for pair-wise key-establishment schemes using discrete logarithm cryptography (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56A Revi- sion 3. https://doi.org/10.6028/NIST.SP.800-56Ar3. [3] Barker EB, Chen L, Roginsky AL, Vassilev A, Davis R, Simon S (2019) Recommendation for pair-wise key-establishment using integer factorization cryptography (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56B Revision 2. https://doi.org/10.6028/NIST.SP.800-56Br2. [4] Avanzi R, Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2020) CRYSTALS-Kyber algorithm specifications and supporting documentation, Third-round submission to the NIST’s post-quantum cryptography standardization process. Available at https://csrc.nist.gov/Projects/post-quantum-cryptography/post-quantum-cry ptography-standardization/round-3-submissions. [5] National Institute of Standards and Technology (2015) Secure hash standard (SHS), (U.S. Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) 180-4. https://doi.org/10.6028/NIST.FIPS.180-4. [6] National Institute of Standards and Technology (2015) SHA-3 standard: Permutation-based hash and extendable-output functions, (U.S. Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) 202. https://doi.org/10.6028/ NIST.FIPS.202. [7] Barker EB (2020) Recommendation for key management: Part 1 - General, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev. 5 [or as amended]. https://doi.org/10.6028/NIST.SP.800-57pt1r5. [8] Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2018) CRYSTALS-Kyber: A CCA-secure module-lattice-based KEM. 2018 IEEE European Symposium on Security and Privacy (EuroS&P), pp 353–367. https://doi.org/10.1109/Euro SP.2018.00032. [9] Langlois A, Stehlé D (2015) Worst-case to average-case reductions for module lattices. Designs, Codes and Cryptography 75(3):565–599. https://doi.org/10.1007/s10623-014-9 938-4.", "char_len": 3971, "approx_tokens": 992}
{"chunk_id": "NIST.FIPS.203::c00032", "doc_id": "NIST.FIPS.203", "start_page": 50, "end_page": 51, "text": "ogy, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev. 5 [or as amended]. https://doi.org/10.6028/NIST.SP.800-57pt1r5. [8] Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2018) CRYSTALS-Kyber: A CCA-secure module-lattice-based KEM. 2018 IEEE European Symposium on Security and Privacy (EuroS&P), pp 353–367. https://doi.org/10.1109/Euro SP.2018.00032. [9] Langlois A, Stehlé D (2015) Worst-case to average-case reductions for module lattices. Designs, Codes and Cryptography 75(3):565–599. https://doi.org/10.1007/s10623-014-9 938-4. [10] Regev O (2005) On lattices, learning with errors, random linear codes, and cryptography. Proceedings of the Thirty-Seventh Annual ACM Symposium on Theory of Computing STOC ’05 (Association for Computing Machinery, New York, NY, USA), pp 84––93. https://doi.org/ 10.1145/1060590.1060603.\n\n[11] Fujisaki E, Okamoto T (2013) Secure integration of asymmetric and symmetric encryption schemes. Journal of Cryptology 26:80–101. https://doi.org/10.1007/s00145-011-9114-1. [12] Hofheinz D, Hövelmanns K, Kiltz E (2017) A modular analysis of the Fujisaki-Okamoto trans- formation. Theory of Cryptography, eds Kalai Y, Reyzin L (Springer International Publishing, Cham), pp 341–371. https://doi.org/10.1007/978-3-319-70500-2_12. [13] Katz J, Lindell Y (2020) Introduction to Modern Cryptography (Chapman & Hall/CRC), 3rd Ed. [14] Almeida JB, Olmos SA, Barbosa M, Barthe G, Dupressoir F, Grégoire B, Laporte V, Léchenet JC, Low C, Oliveira T, Pacheco H, Quaresma M, Schwabe P, Strub PY (2024) Formally verifying Ky- ber episode V: Machine-checked IND-CCA security and correctness of ML-KEM in EasyCrypt, Cryptology ePrint Archive, Paper 2024/843. Available at https://eprint.iacr.org/2024/843. [15] Ducas L, Schanck J (2021) Security estimation scripts for Kyber and Dilithium, Github reposi- tory. Available at https://github.com/pq-crystals/security-estimates. [16] Chen L (2022) Recommendation for key derivation using pseudorandom functions, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-108r1-upd1, Includes updates as of February 2, 2024. https://doi.org/10.6028/NIST.SP. 800-108r1-upd1. [17] Barker EB, Chen L, Davis R (2020) Recommendation for key-derivation methods in key- establishment schemes (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56C Revision 2. https://doi.org/10.6028/NIST.SP.800-56C r2. [18] Barker EB, Kelsey JM (2015) Recommendation for random number generation using deter- ministic random bit generators, (National Institute of Standards and Technology, Gaithers- burg, MD), NIST Special Publication (SP) 800-90A, Rev. 1. https://doi.org/10.6028/NIST.SP. 800-90Ar1. [19] Sönmez Turan M, Barker EB, Kelsey JM, McKay KA, Baish ML, Boyle M (2018) Recom- mendation for the entropy sources used for random bit generation, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90B. https://doi.org/10.6028/NIST.SP.800-90B. [20] Barker E, Kelsey J, McKay K, Roginsky A, Turan MS (2024) Recommendation for random bit generator (RBG) constructions, (National Institute of Standards and Technology, Gaithers- burg, MD), NIST Special Publication (SP) 800-90C 4pd. https://doi.org/10.6028/NIST.SP.80 0-90C.4pd. [21] Kelsey J, Chang S, Perlner R (2016) SHA-3 Derived Functions: cSHAKE, KMAC, TupleHash and ParallelHash, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-185 [or as amended]. https://doi.org/10.6028/NIST.SP.800-1 85. [22] National Institute of Standards and Technology (2016) Submission requirements and eval- uation criteria for the post-quantum cryptography standardization process. Available at https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-f or-proposals-final-dec-2016.pdf.", "char_len": 3952, "approx_tokens": 988}
{"chunk_id": "NIST.FIPS.203::c00033", "doc_id": "NIST.FIPS.203", "start_page": 51, "end_page": 55, "text": "6028/NIST.SP.80 0-90C.4pd. [21] Kelsey J, Chang S, Perlner R (2016) SHA-3 Derived Functions: cSHAKE, KMAC, TupleHash and ParallelHash, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-185 [or as amended]. https://doi.org/10.6028/NIST.SP.800-1 85. [22] National Institute of Standards and Technology (2016) Submission requirements and eval- uation criteria for the post-quantum cryptography standardization process. Available at https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-f or-proposals-final-dec-2016.pdf.\n\n[23] Alagic G, Apon D, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Smith-Tone D (2022) Status report on the third round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8413. https://doi.org/10.6028/NIST.IR.8413-upd1. [24] CRYSTALS-Kyber submission team (2023) “Discussion about Kyber’s tweaked FO transform”, PQC-Forum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/W FRDl8DqYQ4. [25] CRYSTALS-Kyber submission team (2023) “Kyber decisions, part 2: FO transform”, PQC- Forum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/C0D3W 1KoINY/m/99kIvydoAwAJ.\n\nAppendix A — Precomputed Values for the NTT\n\nThe following 128 numbers are the values of ζ BitRev7(i) mod q for i ∈ {0, ... , 127}. These numbers are used in Algorithms 9 and 10. { 1 1729 2580 3289 2642 630 1897 848\n\n1062 1919 193 797 2786 3260 569 1746\n\n296 2447 1339 1476 3046 56 2240 1333\n\n1426 2094 535 2882 2393 2879 1974 821\n\n289 331 3253 1756 1197 2304 2277 2055\n\n650 1977 2513 632 2865 33 1320 1915\n\n2319 1435 807 452 1438 2868 1534 2402\n\n2647 2617 1481 648 2474 3110 1227 910\n\n17 2761 583 2649 1637 723 2288 1100\n\n1409 2662 3281 233 756 2156 3015 3050\n\n1703 1651 2789 1789 1847 952 1461 2687\n\n939 2308 2437 2388 733 2337 268 641\n\n1584 2298 2037 3220 375 2549 2090 1645\n\n1063 319 2773 757 2099 561 2466 2594\n\n2804 1092 403 1026 1143 2150 2775 886\n\n1722 1212 1874 1029 2110 2935 885 2154 }\n\nWhen implementing Algorithm 11, the values ζ 2BitRev7(i)+1 mod q need to be computed. The following array contains these values for i ∈ {0, ... , 127}: { 17 -17 2761 -2761 583 -583 2649 -2649\n\n1637 -1637 723 -723 2288 -2288 1100 -1100\n\n1409 -1409 2662 -2662 3281 -3281 233 -233\n\n756 -756 2156 -2156 3015 -3015 3050 -3050\n\n1703 -1703 1651 -1651 2789 -2789 1789 -1789\n\n1847 -1847 952 -952 1461 -1461 2687 -2687\n\n939 -939 2308 -2308 2437 -2437 2388 -2388\n\n733 -733 2337 -2337 268 -268 641 -641\n\n1584 -1584 2298 -2298 2037 -2037 3220 -3220\n\n375 -375 2549 -2549 2090 -2090 1645 -1645\n\n1063 -1063 319 -319 2773 -2773 757 -757\n\n2099 -2099 561 -561 2466 -2466 2594 -2594\n\n2804 -2804 1092 -1092 403 -403 1026 -1026\n\n1143 -1143 2150 -2150 2775 -2775 886 -886\n\n1722 -1722 1212 -1212 1874 -1874 1029 -1029\n\n2110 -2110 2935 -2935 885 -885 2154 -2154 }\n\nAppendix B — SampleNTT Loop Bounds\n\nIn SampleNTT (Algorithm 7), the algorithm repeatedly generates byte arrays from the XOF to create an element of Tq . If a generated byte array value is out of bounds for a coefficient of Tq , the algorithm tries again until all 256 coefficients are created. On average, this while loop will resolve within a reasonable number of iterations. However, there may be cases in which the generated byte arrays are consistently out of bounds and the algorithm may run for a higher number of iterations. Implementations should not bound this loop, if at all possible. An incorrect limit will cause interoperability errors, and the chances for SampleNTT to iterate longer become exponentially rare. If an implementation does bound the number of iterations of SampleNTT, it shall not use a limit lower than those presented in Table 4.", "char_len": 3896, "approx_tokens": 974}
{"chunk_id": "NIST.FIPS.203::c00034", "doc_id": "NIST.FIPS.203", "start_page": 55, "end_page": 56, "text": "ll 256 coefficients are created. On average, this while loop will resolve within a reasonable number of iterations. However, there may be cases in which the generated byte arrays are consistently out of bounds and the algorithm may run for a higher number of iterations. Implementations should not bound this loop, if at all possible. An incorrect limit will cause interoperability errors, and the chances for SampleNTT to iterate longer become exponentially rare. If an implementation does bound the number of iterations of SampleNTT, it shall not use a limit lower than those presented in Table 4. The calculated probability of SampleNTT exceeding the limit is included and calculated under standard assumptions about the output distributions of XOFs and hash functions.\n\nTable 4. While-loop limits and probabilities of occurrence for SampleNTT\n\nNumber of iterations Probability of reaching limit 280 2−261\n\nIf a limit is used and the number of iterations exceeds the limit, then the algorithm shall destroy all intermediate results. If a return value or exception is produced, it shall be the same value for any execution in which the maximum number of iterations is exceeded.\n\nAppendix C — Differences From the CRYSTALS-Kyber Submission\n\nThis appendix lists the differences between CRYSTALS-KYBER (as described in [4]) and the ML-KEM scheme (specified in this document) that result in differing input-output behavior of the main algorithms (i.e., KeyGen, Encaps, Decaps). Since a conforming implementation need only match the input-output behavior of these three algorithms (see “Implementations” and Section 3.3 below), the list does not include any of the numerous differences in how the main algorithms actually produce outputs from inputs (e.g., via different computational steps or different subroutines), nor any differences in presentation between this standard and [4].\n\nC.1 Differences Between CRYSTALS-Kyber and FIPS 203 Initial Public Draft • In the third-round specification [4], the shared secret key was treated as a variable-length value whose length depended on how it would be used in the relevant application. In this specification, the length of the shared secret key is fixed to 256 bits. It can be used directly in applications as a symmetric key, or symmetric keys can be derived from it, as specified in Section 3.3. • The ML-KEM.Encaps and ML-KEM.Decaps algorithms in this specification use a different variant of the Fujisaki-Okamoto transform (see [24, 25]) than the third-round specifica- tion [4]. Specifically, ML-KEM.Encaps no longer includes a hash of the ciphertext in the derivation of the shared secret, and ML-KEM.Decaps has been adjusted to match this change. • In the third-round specification [4], the initial randomness m in the ML-KEM.Encaps algo- rithm was first hashed before being used. Specifically, between lines 1 and 2 in Algorithm 20, there was an additional step that performed the operation m ← H(m). The purpose of this step was to safeguard against the use of flawed randomness generation processes. As this standard requires the use of NIST-approved randomness generation, this step is unnecessary and is not performed in ML-KEM. • This specification includes explicit input checking steps that were not part of the third-round specification [4]. For example, ML-KEM.Encaps requires that the byte array containing the encapsulation key correctly decodes to an array of integers modulo q without any modular reductions.", "char_len": 3475, "approx_tokens": 868}
{"chunk_id": "NIST.FIPS.203::c00035", "doc_id": "NIST.FIPS.203", "start_page": 56, "end_page": 56, "text": "rithm 20, there was an additional step that performed the operation m ← H(m). The purpose of this step was to safeguard against the use of flawed randomness generation processes. As this standard requires the use of NIST-approved randomness generation, this step is unnecessary and is not performed in ML-KEM. • This specification includes explicit input checking steps that were not part of the third-round specification [4]. For example, ML-KEM.Encaps requires that the byte array containing the encapsulation key correctly decodes to an array of integers modulo q without any modular reductions.\n\nC.2 Changes From FIPS 203 Initial Public Draft The differences between CRYSTALS-KYBER and ML-KEM as described in Appendix C were included in the initial public draft (ipd) of FIPS 203, which was posted on August 24, 2023. Based on comments submitted on the draft ML-KEM, domain separation was added to K-PKE.KeyGen to prevent the misuse of keys generated to target one security level from being used for a different security level when saving a key as a seed. Additionally, FIPS 203 ipd had inadvertently swapped the indices of matrix A in K-PKE.KeyGen and K-PKE.Encrypt. This was changed back in the final version of ML-KEM to match CRYSTALS-KYBER.", "char_len": 1249, "approx_tokens": 312}
{"chunk_id": "NIST.FIPS.204::c00000", "doc_id": "NIST.FIPS.204", "start_page": 1, "end_page": 4, "text": "FIPS 204\n\nFederal Information Processing Standards Publication\n\nModule-Lattice-Based Digital Signature Standard\n\nCategory: Computer Security Subcategory: Cryptography\n\nInformation Technology Laboratory National Institute of Standards and Technology Gaithersburg, MD 20899-8900\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.FIPS.204\n\nPublished August 13, 2024\n\nU.S. Department of Commerce Gina M. Raimondo, Secretary\n\n0 National Institute of Standards and Technology Laurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology\n\nCheck for updates\n\nForeword\n\nThe Federal Information Processing Standards Publication Series of the National Institute of Standards and Technology is the official series of publications relating to standards and guidelines developed under 15 U.S.C. 278g-3, and issued by the Secretary of Commerce under 40 U.S.C. 11331. Comments concerning this Federal Information Processing Standard publication are welcomed and should be submitted using the contact information in the “Inquiries and comments” clause of the announcement section.\n\nKevin M. Stine, Director Information Technology Laboratory\n\nAbstract Digital signatures are used to detect unauthorized modifications to data and to authenticate the identity of the signatory. In addition, the recipient of signed data can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. This standard specifies ML-DSA, a set of algorithms that can be used to generate and verify digital signatures. ML-DSA is believed to be secure, even against adversaries in possession of a large-scale quantum computer.\n\nKeywords: cryptography; digital signatures; Federal Information Processing Standards; lattice; postquantum; public-key cryptography.\n\nFederal Information Processing Standards Publication 204\n\nPublished: August 13, 2024 Effective: August 13, 2024\n\nAnnouncing the Module-Lattice-Based Digital Signature Standard\n\nFederal Information Processing Standards (FIPS) publications are developed by the National Institute of Standards and Technology (NIST) under 15 U.S.C. 278g-3 and issued by the Secretary of Commerce under 40 U.S.C. 11331.\n\n1. Name of Standard. Module-Lattice-Based Digital Signature Standard (FIPS 204).\n\n2. Category of Standard. Computer Security. Subcategory. Cryptography.\n\n3. Explanation. This standard specifies ML-DSA, a lattice-based digital signature algorithm for applications that require a digital signature rather than a written signature. Additional digital signature schemes are specified and approved in other NIST Special Publications and FIPS publications (e.g., FIPS 186-5 [1]). A digital signature is represented in a computer as a string of bits and computed using a set of rules and parameters that allow the identity of the signatory and the integrity of the data to be verified. Digital signatures may be generated on both stored and transmitted data. Signature generation uses a private key to generate a digital signature. Signature verification uses a public key that corresponds to but is not the same as the private key. Each signatory possesses a key-pair composed of a private key and a corresponding public key. Public keys may be known by the public, but private keys must be kept secret. Anyone can verify the signature by employing the signatory’s public key. Only the user who possesses the private key can generate a signature that can be verified by the corresponding public key. The digital signature is provided to the intended verifier along with the signed data. The verifying entity verifies the signature by using the claimed signatory’s public key. Similar procedures may be used to generate and verify signatures for both stored and transmitted data.", "char_len": 3942, "approx_tokens": 985}
{"chunk_id": "NIST.FIPS.204::c00001", "doc_id": "NIST.FIPS.204", "start_page": 4, "end_page": 5, "text": "a private key and a corresponding public key. Public keys may be known by the public, but private keys must be kept secret. Anyone can verify the signature by employing the signatory’s public key. Only the user who possesses the private key can generate a signature that can be verified by the corresponding public key. The digital signature is provided to the intended verifier along with the signed data. The verifying entity verifies the signature by using the claimed signatory’s public key. Similar procedures may be used to generate and verify signatures for both stored and transmitted data. This standard specifies several parameter sets for ML-DSA that are approved for use. Additional parameter sets may be specified and approved in future NIST Special Publications.\n\n4. Approving Authority. Secretary of Commerce.\n\n5. Maintenance Agency. Department of Commerce, National Institute of Standards and Technology, Information Technology Laboratory (ITL).\n\n6. Applicability. This standard is applicable to all federal departments and agencies for the protection of sensitive unclassified information that is not subject to section 2315 of Title 10, United States Code, or section 3502 (2) of Title 44, United States Code. Either this standard, FIPS 205, FIPS 186-5, or NIST Special Publication 800-208 shall be used in designing and implementing public-key-based signature systems that federal departments and agencies operate or that are operated for them under contract. In the future, additional digital signature schemes may be specified and approved in FIPS or NIST Special Publications. The adoption and use of this standard are available to private and commercial organizations. i\n\n7. Applications. A digital signature algorithm allows an entity to authenticate the integrity of signed data and the identity of the signatory. The recipient of a signed message can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. A digital signature algorithm is intended for use in electronic mail, electronic funds transfer, electronic data interchange, software distribution, data storage, and other applications that require data integrity assurance and data origin authentication. 8. Implementations. A digital signature algorithm may be implemented in software, firmware, hardware, or any combination thereof. NIST will develop a validation program to test implementations for conformance to the algorithm in this standard. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, different procedures that produce the correct output for every input are permitted. Information about validation programs is available at https://csrc.nist.gov/projects/cmvp. Examples for digital signature algorithms are available at https://csrc.nist.gov/projects/cryptographic-standards -and-guidelines/example-values. Agencies are advised that digital signature key pairs shall not be used for other purposes. 9. Other Approved Security Functions. Digital signature implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government- sensitive information. Approved cryptographic algorithms and techniques include those that are either: a. Specified in a Federal Information Processing Standards (FIPS) publication, b. Adopted in a FIPS or NIST recommendation, or c. Specified in the list of approved security functions in SP 800-140C. 10. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls.", "char_len": 3860, "approx_tokens": 965}
{"chunk_id": "NIST.FIPS.204::c00002", "doc_id": "NIST.FIPS.204", "start_page": 5, "end_page": 7, "text": "Functions. Digital signature implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government- sensitive information. Approved cryptographic algorithms and techniques include those that are either: a. Specified in a Federal Information Processing Standards (FIPS) publication, b. Adopted in a FIPS or NIST recommendation, or c. Specified in the list of approved security functions in SP 800-140C. 10. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with these federal regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 11. Patents. The algorithm in this standard may be covered by U.S. or foreign patents. 12. Implementation Schedule. This standard becomes effective immediately upon final publication. 13. Specifications. Federal Information Processing Standards (FIPS) 204, Module-Lattice-Based Digital Signature Standard (affixed). 14. Qualifications. The security of a digital signature system depends on maintaining the secrecy of the signatory’s private keys. Signatories shall, therefore, guard against the disclosure of their private keys. While it is the intent of this standard to specify general security requirements for generating digital signatures, conformance to this standard does not ensure that a particular implementation is secure. It is the responsibility of an implementer to ensure that any module that implements a digital signature capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The responsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. ii\n\nSince a standard of this nature must be flexible enough to adapt to advancements and innovations in science and technology, this standard will be reviewed every five years in order to assess its adequacy.\n\n15. Waiver Procedure. The Federal Information Security Management Act (FISMA) does not allow for waivers to Federal Information Processing Standards (FIPS) that are made mandatory by the Secretary of Commerce.\n\n16. Where to Obtain Copies of the Standard. This publication is available by accessing https://csrc.nist. gov/publications. Other computer security publications are available at the same website.\n\n17. How to Cite This Publication. NIST has assigned NIST FIPS 204 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Module-Lattice-Based Digital Signa- ture Standard. (Department of Commerce, Washington, D.C.), Federal Information Pro- cessing Standards Publication (FIPS) NIST FIPS 204. https://doi.org/10.6028/NIST.FIPS.204\n\n18. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-204- comments@nist.gov.\n\niii\n\nFederal Information Processing Standards Publication 204\n\nSpecification for the Module-Lattice-Based Digital Signature Standard\n\nTable of Contents\n\n1 Introduction 1 1.1 Purpose and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1", "char_len": 3698, "approx_tokens": 924}
{"chunk_id": "NIST.FIPS.204::c00003", "doc_id": "NIST.FIPS.204", "start_page": 6, "end_page": 8, "text": "Federal Information Pro- cessing Standards Publication (FIPS) NIST FIPS 204. https://doi.org/10.6028/NIST.FIPS.204\n\n18. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-204- comments@nist.gov.\n\niii\n\nFederal Information Processing Standards Publication 204\n\nSpecification for the Module-Lattice-Based Digital Signature Standard\n\nTable of Contents\n\n1 Introduction 1 1.1 Purpose and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n\n2 Glossary of Terms, Acronyms, and Symbols 2 2.1 Terms and Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2.2 Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.3 Mathematical Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.4 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.4.1 Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.4.2 Vectors and Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.5 NTT Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n\n3 Overview of the ML-DSA Signature Scheme 9 3.1 Security Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2 Computational Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.3 ML-DSA Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.4 Hedged and Deterministic Signing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.5 Use of Digital Signatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.6 Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.6.1 Randomness Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.6.2 Public-Key and Signature Length Checks . . . . . . . . . . . . . . . . . . . . . 12 3.6.3 Intermediate Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.6.4 No Floating-Point Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.7 Use of Symmetric Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n4 Parameter Sets 15\n\n5 External Functions 17 5.1 ML-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5.2 ML-DSA Signing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5.3 ML-DSA Verifying . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 iv\n\n5.4 Pre-Hash ML-DSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 5.4.1 HashML-DSA Signing and Verifying . . . . . . . . . . . . . . . . . . . . . . . . 19 6 Internal Functions 22 6.1 ML-DSA Key Generation (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 6.2 ML-DSA Signing (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6.3 ML-DSA Verifying (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n7 Auxiliary Functions 28 7.1 Conversion Between Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52", "char_len": 3966, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.204::c00004", "doc_id": "NIST.FIPS.204", "start_page": 8, "end_page": 9, "text": "28 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52\n\nAppendix D — Differences from the CRYSTALS-DILITHIUM Submission 54 D.1 Differences Between Version 3.1 and the Round 3 Version of CRYSTALS-DILITHIUM . . 54 D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft 54 D.3 Changes From FIPS 204 Initial Public Draft . . . . . . . . . . . . . . . . . . . . . . . . 54\n\nv\n\nList of Tables\n\nTable 1 ML-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Table 2 Sizes (in bytes) of keys and signatures of ML-DSA . . . . . . . . . . . . . . . . . . 16 Table 3 While loop and XOF output limits for a 2−256 or less probability of failure . . . . . 52\n\nList of Algorithms Algorithm 1 ML-DSA.KeyGen() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Algorithm 2 ML-DSA.Sign(sk, M, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 3 ML-DSA.Verify(pk, M, σ, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 4 HashML-DSA.Sign(sk, M, ctx, PH) . . . . . . . . . . . . . . . . . . . . . . 20 Algorithm 5 HashML-DSA.Verify(pk, M, σ, ctx, PH) . . . . . . . . . . . . . . . . . . . . 21 Algorithm 6 ML-DSA.KeyGen_internal(ξ) . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 7 ML-DSA.Sign_internal(sk, M′, rnd) . . . . . . . . . . . . . . . . . . . . . . 25 Algorithm 8 ML-DSA.Verify_internal(pk, M′, σ) . . . . . . . . . . . . . . . . . . . . . . 27 Algorithm 9 IntegerToBits(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 10 BitsToInteger(y, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 11 IntegerToBytes(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 12 BitsToBytes(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 13 BytesToBits(z) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 14 CoeffFromThreeBytes(b0, b1, b2) . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 15 CoeffFromHalfByte(b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 16 SimpleBitPack(w, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 17 BitPack(w, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 18 SimpleBitUnpack(v, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 19 BitUnpack(v, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 20 HintBitPack(h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 21 HintBitUnpack(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 22 pkEncode(ρ, t1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 23 pkDecode(pk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 24 skEncode(ρ, K, tr, s1, s2, t0) . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 25 skDecode(sk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 26 sigEncode(c, z, h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 27 sigDecode(σ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 28 w1Encode(w1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 29 SampleInBall(ρ) . . . .", "char_len": 3999, "approx_tokens": 999}
{"chunk_id": "NIST.FIPS.204::c00005", "doc_id": "NIST.FIPS.204", "start_page": 9, "end_page": 11, "text": "(pk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 24 skEncode(ρ, K, tr, s1, s2, t0) . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 25 skDecode(sk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 26 sigEncode(c, z, h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 27 sigDecode(σ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 28 w1Encode(w1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 29 SampleInBall(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Algorithm 30 RejNTTPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 31 RejBoundedPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 32 ExpandA(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 33 ExpandS(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 34 ExpandMask(ρ, μ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 35 Power2Round(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 36 Decompose(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 37 HighBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 38 LowBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\nvi\n\nAlgorithm 39 MakeHint(z, r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 Algorithm 40 UseHint(h, r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 Algorithm 41 NTT(w) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 Algorithm 42 NTT−1(w)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Algorithm 43 BitRev8(m) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Algorithm 44 AddNTT(a,̂ b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 Algorithm 45 MultiplyNTT(a,̂ b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 Algorithm 46 AddVectorNTT(v,̂ w)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 Algorithm 47 ScalarVectorNTT(c,̂ v)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 Algorithm 48 MatrixVectorNTT(M, v)̂ . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 Algorithm 49 MontgomeryReduce(a) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n\nvii\n\n1. Introduction\n\n1.1 Purpose and Scope This standard defines a digital signature scheme, which includes a method for digital signature generation that can be used for the protection of binary data (commonly called a “message”) and a method for the verification and validation of those digital signatures. NIST Special Publication (SP) 800-175B [2], Guideline for Using Cryptographic Standards in the Federal Government: Cryptographic Mechanisms, includes a general discussion of digital signatures. This standard specifies the mathematical steps that need to be performed for key generation, signature generation, and signature verification. In order for digital signatures to be valid, additional assurances are required, such as assurance of identity and of private key possession. SP 800-89, Recommendation for Obtaining Assurances for Digital Signature Applications [3], specifies the required assurances and the methods for obtaining them. The digital signature scheme approved in this standard is the Module-Lattice-Based Digital Signature Algorithm (ML-DSA), which is based on the Module Learning With Errors problem [4]. ML-DSA is believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer.", "char_len": 3864, "approx_tokens": 966}
{"chunk_id": "NIST.FIPS.204::c00006", "doc_id": "NIST.FIPS.204", "start_page": 11, "end_page": 12, "text": "for digital signatures to be valid, additional assurances are required, such as assurance of identity and of private key possession. SP 800-89, Recommendation for Obtaining Assurances for Digital Signature Applications [3], specifies the required assurances and the methods for obtaining them. The digital signature scheme approved in this standard is the Module-Lattice-Based Digital Signature Algorithm (ML-DSA), which is based on the Module Learning With Errors problem [4]. ML-DSA is believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. In particular, ML-DSA is believed to be strongly unforgeable, which implies that the scheme can be used to detect unauthorized modifications to data and to authenticate the identity of the signatory (one bound to the possession of the private-key). In addition, a signature generated by this scheme can be used as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. The latter property is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. This standard gives algorithms for ML-DSA key generation, signature generation, and signature verification (Section 5), and for supporting algorithms used by them (Section 7). ML-DSA is standardized with three possible parameter sets, each of which corresponds to a different security strength. Section 4 describes the global parameters used by these algorithms and enumerates the parameter sets for ML-DSA that are approved by this standard. ML-DSA can be used in place of other digital signature schemes specified in NIST FIPS and Special Publications (e.g., FIPS 186-5, Digital Signature Standard (DSS) [1]).\n\n1.2 Context Over the past several years, there has been steady progress toward building quantum computers. The security of many commonly used public-key cryptosystems will be at risk if large-scale quantum computers are ever realized. This would include key-establishment schemes and digital signatures that are based on integer factorization and discrete logarithms (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantumresistant public-key cryptographic algorithms for standardization. A total of 82 candidate algorithms were submitted to NIST for consideration. After three rounds of evaluation and analysis, NIST selected the first four algorithms for standardization. ML-DSA is derived from one of the selected schemes, CRYSTALS-DILITHIUM [5, 6], and is intended to protect sensitive U.S. Government information well into the foreseeable future, including after the advent of cryptographically relevant quantum computers. For the differences between ML-DSA and CRYSTALS- DILITHIUM, see Appendix D.\n\n2. Glossary of Terms, Acronyms, and Symbols\n\n2.1 Terms and Definitions\n\napproved FIPS-approved and/or NIST-recommended. An algorithm or technique that is either 1) specified in a FIPS or NIST recommendation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security functions.\n\nassurance of Confidence that an entity possesses a private key and any associated keying possession material.\n\nasymmetric Cryptography that uses two separate keys to exchange data — one to encrypt cryptography or digitally sign the data and one to decrypt the data or verify the digital signature. Also known as public-key cryptography.\n\nbit string An ordered sequence of zeros and ones.\n\nbyte An integer from the set {0, 1, 2, ..., 255}.\n\nbyte string An ordered sequence of bytes.", "char_len": 3676, "approx_tokens": 919}
{"chunk_id": "NIST.FIPS.204::c00007", "doc_id": "NIST.FIPS.204", "start_page": 12, "end_page": 13, "text": "dation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security functions.\n\nassurance of Confidence that an entity possesses a private key and any associated keying possession material.\n\nasymmetric Cryptography that uses two separate keys to exchange data — one to encrypt cryptography or digitally sign the data and one to decrypt the data or verify the digital signature. Also known as public-key cryptography.\n\nbit string An ordered sequence of zeros and ones.\n\nbyte An integer from the set {0, 1, 2, ..., 255}.\n\nbyte string An ordered sequence of bytes.\n\ncertificate A set of data that uniquely identifies a public key that has a corresponding private key and an owner that is authorized to use the key pair. The certificate contains the owner’s public key and possibly other information and is digitally signed by a certification authority (i.e., a trusted party), thereby binding the public key to the owner.\n\ncertification authority The entity in a public-key infrastructure (PKI) that is responsible for issuing (CA) certificates and exacting compliance with a PKI policy.\n\nclaimed signatory From the verifier’s perspective, the claimed signatory is the entity that pur- portedly generated a digital signature.\n\ndestroy An action applied to a key or a piece of secret data. After a key or a piece of secret data is destroyed, no information about its value can be recovered.\n\ndigital signature The result of a cryptographic transformation of data that, when properly implemented, provides a mechanism to verify origin authenticity and data integrity and to enforce signatory non-repudiation.\n\nentity An individual person, organization, device, or process. Used interchangeably with party.\n\nequivalent process Two processes are equivalent if the same output is produced when the same values are input to each process (either as input parameters, as values made available during the process, or both).\n\neXtendable-Output A function on bit strings in which the output can be extended to any desired Function (XOF) length. Approved XOFs (e.g., those specified in FIPS 202 [7]) are designed to satisfy the following properties as long as the specified output length is sufficiently long to prevent trivial attacks:\n\n1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 2. (Collision-resistant) It is computationally infeasible to find any two dis- tinct inputs that map to the same output.\n\nfresh random value A previously unused output of a random bit generator.\n\nhash function A function on bit strings in which the length of the output is fixed. Approved hash functions (such as those specified in FIPS 180 [8] and FIPS 202 [7]) are designed to satisfy the following properties: 1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 2. (Collision-resistant) It is computationally infeasible to find any two dis- tinct inputs that map to the same output.\n\nhash value See message digest.\n\nkey A parameter used in conjunction with a cryptographic algorithm that deter- mines its operation. Examples of cryptographic algorithms applicable to this standard include: 1. The computation of a digital signature from data 2. The verification of a digital signature\n\nkey pair A public key and its corresponding private key.\n\nlittle-endian The property of a byte string having its bytes positioned in order of increasing significance. In particular, the leftmost (first) byte is the least significant, and the rightmost (last) byte is the most significant. The term “little-endian” may also be applied in the same manner to bit strings (e.g., the 8-bit string 11010001 corresponds to the byte 20 + 21 + 23 + 27 = 139).\n\nmessage The data that is signed. Also known as signed data during the signature verification and validation process.\n\nmessage digest The result of applying a hash function to a message. Also known as a hash value.", "char_len": 3976, "approx_tokens": 994}
{"chunk_id": "NIST.FIPS.204::c00008", "doc_id": "NIST.FIPS.204", "start_page": 13, "end_page": 14, "text": "dian The property of a byte string having its bytes positioned in order of increasing significance. In particular, the leftmost (first) byte is the least significant, and the rightmost (last) byte is the most significant. The term “little-endian” may also be applied in the same manner to bit strings (e.g., the 8-bit string 11010001 corresponds to the byte 20 + 21 + 23 + 27 = 139).\n\nmessage The data that is signed. Also known as signed data during the signature verification and validation process.\n\nmessage digest The result of applying a hash function to a message. Also known as a hash value.\n\nnon-repudiation A service that is used to provide assurance of the integrity and origin of data in such a way that the integrity and origin can be verified and validated by a third party as having originated from a specific entity in possession of the private key (i.e., the signatory).\n\nowner A key pair owner is the entity authorized to use the private key of a key pair.\n\nparty An individual person, organization, device, or process. Used interchangeably with entity.\n\npublic-key A framework that is established to issue, maintain, and revoke public key infrastructure (PKI) certificates.\n\nprivate key A cryptographic key that is used with an asymmetric (public-key) cryptographic algorithm. The private key is uniquely associated with the owner and is not made public. The private key is used to compute a digital signature that may be verified using the corresponding public key.\n\npseudorandom A process or data produced by a process is said to be pseudorandom when the outcome is deterministic yet also effectively random as long as the internal action of the process is hidden from observation. For cryptographic purposes, “effectively random” means “computationally indistinguishable from random within the limits of the intended security strength.”\n\npublic key A cryptographic key that is used with an asymmetric (public-key) cryptographic algorithm and is associated with a private key. The public key is associated with an owner and may be made public. In the case of digital signatures, the public key is used to verify a digital signature that was generated using the corresponding private key.\n\nsecurity category A number associated with the security strength of a post-quantum crypto- graphic algorithm, as specified by NIST (see [9, Sect. 5.6]).\n\nsecurity strength A number associated with the amount of work (i.e., the number of operations) that is required to break a cryptographic algorithm or system.\n\nseed A bit string used as input to a pseudorandom process.\n\nshall Used to indicate a requirement of this standard.\n\nshould Used to indicate a strong recommendation but not a requirement of this standard. Ignoring the recommendation could lead to undesirable results.\n\nsignatory The entity that generates a digital signature on data using a private key.\n\nsignature generation The process of using a digital signature algorithm and a private key to generate a digital signature on data.\n\nsignature validation The mathematical verification of the digital signature along with obtaining the appropriate assurances (e.g., public-key validity, private-key possession, etc.).\n\nsignature verification The process of using a digital signature algorithm and a public key to verify a digital signature on data.\n\nsigned data The data or message upon which a digital signature has been computed. Also see message.\n\ntrusted third party An entity other than the key pair owner and the verifier that is trusted by the (TTP) owner, the verifier, or both. Sometimes shortened to “trusted party.”\n\nverifier The entity that verifies the authenticity of a digital signature using the public key of the signatory.", "char_len": 3713, "approx_tokens": 928}
{"chunk_id": "NIST.FIPS.204::c00009", "doc_id": "NIST.FIPS.204", "start_page": 14, "end_page": 16, "text": "riate assurances (e.g., public-key validity, private-key possession, etc.).\n\nsignature verification The process of using a digital signature algorithm and a public key to verify a digital signature on data.\n\nsigned data The data or message upon which a digital signature has been computed. Also see message.\n\ntrusted third party An entity other than the key pair owner and the verifier that is trusted by the (TTP) owner, the verifier, or both. Sometimes shortened to “trusted party.”\n\nverifier The entity that verifies the authenticity of a digital signature using the public key of the signatory.\n\n2.2 Acronyms AES Advanced Encryption Standard API Application Programming Interface DER Distinguished Encoding Rules FIPS Federal Information Processing Standard ML-DSA Module-Lattice-Based Digital Signature Algorithm MLWE Module Learning With Errors NIST National Institute of Standards and Technology NIST IR NIST Interagency or Internal Report NTT Number Theoretic Transform OID Object Identifier PQC Post-Quantum Cryptography RBG Random Bit Generator SHA Secure Hash Algorithm SHAKE Secure Hash Algorithm KECCAK SP Special Publication SUF-CMA Strongly existentially UnForgeable under Chosen Message Attack XOF eXtendable-Output Function\n\n2.3 Mathematical Symbols The following symbols and mathematical expressions are used in this standard.\n\nq The prime number q = 223 − 213 + 1 = 8380417. B The set {0, 1, ... , 255} of integers represented by a byte. N The set of natural numbers {1, 2, 3, ...}. Z The ring of integers. Zm The ring of integers modulo m whose set of elements is {0, 1, ... , m − 1}. Zn The set of n-tuples over Zm equipped with the Z-module structure. m R The ring of single-variable polynomials over Z modulo X256 + 1, also denoted by Z[X]/(X256 + 1). Rm The ring of single-variable polynomials over Zm modulo X256 + 1, also denoted by Zm[X]/(X256 + 1).\n\nBτ The set of all polynomials p = ∑255 piXi in Rq that are such that exactly τ of the coefficients of p are from the seti=0 , and all other coefficients are zero. (See Section 7.3.) i {−1, 1} Π Used to denote a direct product of two or more rings, where addition and multipli- cation are performed componentwise. Tq The ring Π255 Zq. j=0 A × B Cartesian product of two sets A, B. [a, b] For two integers a ≤ b, [a, b] denotes the set of integers {a, a + 1, ... , b}. bitlen a The bit length of a positive integer a. The bit length of a is the number of digits that would appear in a base-2 representation of a, where the most significant digit in the representation is assumed to be a 1 (e.g., bitlen 32 = 6 and bitlen 31 = 5).1 BitRev8(r) Bit reversal of an 8-bit integer r. If r = r0 + 2r1 + 4r2 + ... + 128r7 with ri ∈ {0, 1}, then BitRev8(r) = r7 + 2r6 + 4r5 + ... + 128r0. 0x Prefix to an integer written in hexadecimal representation. log2 x The base 2 logarithm of x. For example, log2(16) = 4. mod If α is a positive integer and m ∈ Z or m ∈ Zα, then m mod α denotes the unique element m′ ∈ Z in the range 0 ≤ m′ < α such that m and m′ are congruent modulo α. mod± If α is a positive integer and m ∈ Z or m ∈ Zα, then m mod±α denotes the unique element m′ ∈ Z in the range −⌈α/2⌉ < m′ ≤ ⌊α/2⌋ such that m and m′ are congruent modulo α. ⌊x⌋ The largest integer less than or equal to the real number x, called the floor of x. For example, ⌊2.1⌋ = 2, and ⌊4⌋ = 4. ⌈x⌉ The least integer greater than or equal to the real number x, called the ceiling of x. For example, ⌈5⌉ = 5 and ⌈5.3⌉ = 6. ‖⋅‖∞ The infinity norm. For an element w ∈ Z, ‖w‖∞ = |w|, the absolute value of w. For an element w ∈ Zq,‖w‖∞ = ∣w mod±q∣ . For an element w of R or Rq, ‖w‖∞ = max0≤i<256 ‖wi‖∞ . For a length-m vector w with entries from R or Rq, ‖w‖∞ = max0≤i<m ‖w[i]‖∞ . a! The factorial quantity 1 ⋅ 2 ⋅ 3 ⋅ ... ⋅ a. The value 0! is defined as 1. (a) For a ≥ b, the quantity a!/(b!(a − b)!). b s ← x In pseudocode, this notation means that the variable s is assigned the value of the expression x.", "char_len": 3957, "approx_tokens": 989}
{"chunk_id": "NIST.FIPS.204::c00010", "doc_id": "NIST.FIPS.204", "start_page": 16, "end_page": 18, "text": "st integer greater than or equal to the real number x, called the ceiling of x. For example, ⌈5⌉ = 5 and ⌈5.3⌉ = 6. ‖⋅‖∞ The infinity norm. For an element w ∈ Z, ‖w‖∞ = |w|, the absolute value of w. For an element w ∈ Zq,‖w‖∞ = ∣w mod±q∣ . For an element w of R or Rq, ‖w‖∞ = max0≤i<256 ‖wi‖∞ . For a length-m vector w with entries from R or Rq, ‖w‖∞ = max0≤i<m ‖w[i]‖∞ . a! The factorial quantity 1 ⋅ 2 ⋅ 3 ⋅ ... ⋅ a. The value 0! is defined as 1. (a) For a ≥ b, the quantity a!/(b!(a − b)!). b s ← x In pseudocode, this notation means that the variable s is assigned the value of the expression x. s ← Bl In pseudocode, this notation means that the variable s is assigned the value of an array of l random bytes. The bytes must be generated using randomness from an approved RBG. See Section 3.6.1. 1In this specification, bitlen a is only ever called with a small finite number of values for a, so it may be helpful to precompute bitlen a for these values and hard code the results, rather than computing them on the fly.\n\nx ∈ S ← y Type casting. The variable x is assigned a value in a set S that is constructed from the value of an expression y in a possibly different set T. The set T and the mapping from T to S are not explicitly specified, but they should be obvious from the context in which this statement appears.\n\n[[a < b]] A Boolean predicate. A comparison operator inside double square brackets [[a < b]] denotes that the expression should be evaluated as a Boolean. Booleans can also be interpreted as elements of Z2 with 1 denoting true and 0 denoting false.\n\n⟨⟨f(x)⟩⟩ A temporary variable that stores the output of a computation f(x) so that it can be used many times without needing to be recomputed. This is equivalent to defining a temporary variable y ← f(x). Naming the variable ⟨⟨f(x)⟩⟩ makes the pseudocode less cluttered.\n\na||b Concatenation of two bit or byte strings a and b.\n\na ∘ b Multiplication of a and b in the ring Tq.\n\na ⋅ b or ab Multiplication in any of the rings Z, Zm, R, or Rm.\n\na + b Addition of a and b.\n\na/b Division of integers. When this notation is used, a and b are always integers. If b cannot be assumed to divide a, then either ⌊a/b⌋ or ⌈a/b⌉ is used.\n\n⊥ Blank symbol that indicates failure or the lack of an output from an algorithm.\n\n2.4 Notation 2.4.1 Rings Elements of the rings Z, Zq, Z2, R, and Rq are denoted by italicized lowercase letters (e.g., w). Elements of the ring Tq are length-256 arrays of elements of Zq, and they are denoted by italicized letters with a hat symbol (e.g., ŵ). The addition and multiplication of elements of Tq are performed entry-wise. Thus, the ith entry of the product of two elements û and v̂ of Tq is u[i] ⋅ v[i] ∈ Zq. The multiplication operation in Tq is denoted by the symbol ∘ (see Section 2.3). When a product a ⋅ b or a sum a + b is written and either a or b is a congruence class modulo m (i.e., if either a or b is an element of Zm or Rm), then the product or sum is also understood to be a congruence class modulo m (i.e., an element of Zm or Rm). Likewise, an element of R or Z may be “typecast” to an element of Rm or Zm, respectively, and may be used as the input of a function specified to act on an element of Rm or Zm, respectively. In both cases, the element itself or its coefficients are mapped from Z to Zm by taking the unique congruence class modulo m that contains the integer. The coefficients of an element w of R or Rm are denoted by wi so that w = w0 + w1X + ... + w255X255. If w is in R (respectively, Rm) and t is in Z (respectively, Zd), then w(t) denotes the polynomial w = w0 + w1X + ... + w255X255 evaluated at X = t.\n\n2.4.2 Vectors and Matrices Vectors with elements in R or Rm are denoted by bold lowercase letters (e.g., v). Matrices with elements in R or Rm are denoted by bold uppercase letters (e.g., A).\n\nIf S is a ring and v is a length-L vector over S, then the entries in the vector v are expressed as\n\nv[0], v[1], ... , v[L − 1].", "char_len": 3962, "approx_tokens": 990}
{"chunk_id": "NIST.FIPS.204::c00011", "doc_id": "NIST.FIPS.204", "start_page": 17, "end_page": 19, "text": "hat contains the integer. The coefficients of an element w of R or Rm are denoted by wi so that w = w0 + w1X + ... + w255X255. If w is in R (respectively, Rm) and t is in Z (respectively, Zd), then w(t) denotes the polynomial w = w0 + w1X + ... + w255X255 evaluated at X = t.\n\n2.4.2 Vectors and Matrices Vectors with elements in R or Rm are denoted by bold lowercase letters (e.g., v). Matrices with elements in R or Rm are denoted by bold uppercase letters (e.g., A).\n\nIf S is a ring and v is a length-L vector over S, then the entries in the vector v are expressed as\n\nv[0], v[1], ... , v[L − 1].\n\nThe entries of a K × L matrix A over S are denoted as A[i, j], where 0 ≤ i < K and 0 ≤ j < L. The set of all length-L vectors over S is denoted by SL. The set of all K × L matrices over S is denoted by SK×L . A length-L vector can also be treated as an L × 1 matrix.\n\n2.5 NTT Representation The Number Theoretic Transform (NTT) is a specific isomorphism between the rings Rq and Tq. Let ζ = 1753 ∈ Zq, which is a 512th root of unity. If w ∈ Rq, then\n\nNTT(w) = (w(ζ0), w(ζ1), ... , w(ζ255)) ∈ Tq, (2.1)\n\nwhere ζi = w(ζ2BitRev8(i)+1) mod q. See Section 7.5 for an implementation discussion for NTT and NTT−1. The motivation for using NTT is that multiplication is considerably faster in the ring Tq. Since NTT is an isomorphism, for any a, b ∈ Rq, NTT(ab) = NTT(a) ∘ NTT(b). (2.2)\n\nIf A is a matrix with entries from Rq, then NTT(A) denotes the matrix computed via the entry-wise application of NTT to A. The symbol ∘ is also used to denote the matrix multiplication of matrices with entries in Tq. Thus, NTT(AB) = NTT(A) ∘ NTT(B). Explicit algorithms for linear algebra over Tq are given in Section 7.6.\n\n3. Overview of the ML-DSA Signature Scheme\n\nML-DSA is a digital signature scheme based on CRYSTALS-DILITHIUM [6]. It consists of three main algorithms: ML-DSA.KeyGen (Algorithm 1), ML-DSA.Sign (Algorithm 2), and ML-DSA.Verify (Algorithm 3). The ML-DSA scheme uses the Fiat-Shamir With Aborts construction [10, 11] and bears the most resemblance to the schemes proposed in [12, 13]. This document also defines a closely related but domain-separated signature scheme, HashML-DSA, which differs from ML-DSA in that it includes an additional pre-hashing step before signing. It consists of three main algorithms: ML-DSA.KeyGen (Algorithm 1), which is the same key generation algorithm used for ML-DSA; HashML-DSA.Sign (Algorithm 4); and HashML-DSA.Verify (Algorithm 5).\n\n3.1 Security Properties ML-DSA is designed to be strongly existentially unforgeable under chosen message attack (SUF-CMA). That is, it is expected that even if an adversary can get the honest party to sign arbitrary messages, the adversary cannot create any additional valid signatures based on the signer’s public key, including on messages for which the signer has already provided a signature. Beyond unforgeability, ML-DSA is designed to satisfy additional security properties described in [14].\n\n3.2 Computational Assumptions Security for lattice-based digital signature schemes is typically related to the Learning With Errors (LWE) problem and the short integer solution (SIS) problem. The LWE problem [15] is to recover a vector s ∈ Zn given a set of random “noisy” linear equations2 satisfied by . The SIS problem is to find a non-zero q s solution t ∈ Zn for a given linear system over Zq of the form At = 0 such that ‖t‖ is small. For appropriate q ∞ choices of parameters, these problems are intractable for the best known techniques, including Gaussian elimination. When the module Zn in LWE and SIS is replaced by a module over a ring larger than Zq (e.g., Rq), the resulting problems q are called Module Learning With Errors (MLWE) [4] and Module Short Integer Solution (MSIS). The security of ML-DSA is based on the MLWE problem over Rq and a nonstandard variant of MSIS called SelfTargetMSIS [16].", "char_len": 3885, "approx_tokens": 971}
{"chunk_id": "NIST.FIPS.204::c00012", "doc_id": "NIST.FIPS.204", "start_page": 19, "end_page": 20, "text": "roblem is to find a non-zero q s solution t ∈ Zn for a given linear system over Zq of the form At = 0 such that ‖t‖ is small. For appropriate q ∞ choices of parameters, these problems are intractable for the best known techniques, including Gaussian elimination. When the module Zn in LWE and SIS is replaced by a module over a ring larger than Zq (e.g., Rq), the resulting problems q are called Module Learning With Errors (MLWE) [4] and Module Short Integer Solution (MSIS). The security of ML-DSA is based on the MLWE problem over Rq and a nonstandard variant of MSIS called SelfTargetMSIS [16].\n\n3.3 ML-DSA Construction ML-DSA is a Schnorr-like signature with several optimizations. The Schnorr signature scheme applies the Fiat-Shamir heuristic to an interactive protocol between a verifier who knows g (the generator of a group in which discrete logs are believed to be difficult) and the value y = gx and a prover who knows g and x. The interactive protocol, where the prover demonstrates knowledge of x to the verifier, consists of three steps:\n\n1. Commitment: The prover generates a random positive integer r that is less than the order of g and commits to its value by sending gr to the verifier.\n\n2. Challenge: The verifier sends a random positive integer c that is less than the order of g to the prover.\n\n2Specifically, the LWE problem is to solve a system of equations of the form As + e = b, where A and b are given and e is not given but known to be small.\n\n3. Response: The prover returns s = r − cx reduced modulo the order of g, and the verifier checks whether gs ⋅ yc = gr.\n\nThis protocol is made noninteractive and turned into a signature scheme by replacing the verifier’s random choice of c in step 2 with a deterministic process that pseudorandomly derives c from a hash of the commitment gr concatenated with the message to be signed. For this signature scheme, y is the public key, and x is the private key. The basic idea of ML-DSA and similar lattice signature schemes is to build a signature scheme from an analogous interactive protocol, where a prover who knows matrices A ∈ ZK×L , S1 ∈ ZL×n, and K×n with small coefficients (for and ) demonstrates knowledge of q q S2 ∈ Zq K×n S1 S2 these matrices to a verifier who knows A and T ∈ Zq = AS1 + S2. Such an interactive protocol would proceed as follows:\n\n1. Commitment: The prover generates y ∈ ZL with small coefficients and commits to its value by sending w = Ay + y to the verifier, q K Approx 2 where y2 ∈ Zq is a vector with small coefficients. 2. Challenge: The verifier sends a vector c ∈ Zn with small coefficients to the prover. q 3. Response: The prover returns z = y + S1c, and the verifier checks that z has small coefficients and that Az − Tc ≈ wApprox.\n\nAs written, the above protocol has a security flaw: the response z will be biased in a direction related to the private value S1. Likewise r = wApprox − Az + Tc = y2 + S2c is biased in a direction related to the private value S2. However, this flaw can be corrected when converting the interactive protocol into a signature scheme. As with Schnorr signatures, the signer derives the challenge by a pseudorandom process from a hash of the commitment concatenated with the message. To correct the bias, the signer applies rejection sampling to z; if coefficients of z fall outside of a specified range, the signing process is aborted, and the signer starts over from a new value of y. Likewise, similar rejection sampling must also be applied to r. These checks are analogous to those done at Line 23 of Algorithm 7. In the simplified Fiat-Shamir With Aborts signature, the public key is (A, T), and the private key is (S1, S2). In the ML-DSA standard, a number of tweaks and modifications are added to this basic framework for security or efficiency reasons:", "char_len": 3805, "approx_tokens": 951}
{"chunk_id": "NIST.FIPS.204::c00013", "doc_id": "NIST.FIPS.204", "start_page": 20, "end_page": 21, "text": "ed with the message. To correct the bias, the signer applies rejection sampling to z; if coefficients of z fall outside of a specified range, the signing process is aborted, and the signer starts over from a new value of y. Likewise, similar rejection sampling must also be applied to r. These checks are analogous to those done at Line 23 of Algorithm 7. In the simplified Fiat-Shamir With Aborts signature, the public key is (A, T), and the private key is (S1, S2). In the ML-DSA standard, a number of tweaks and modifications are added to this basic framework for security or efficiency reasons:\n\n• To reduce key and signature size and to use fast NTT-based polynomial multiplication, ML-DSA uses module-structured matrices. Relative to the basic scheme described above, it replaces dimension-n × n blocks of matrices and dimension-n blocks of vectors with polynomials in the ring Rq. Thus, instead of A ∈ ZK×L , T ∈ ZK×n, S ∈ ZL×n, S ∈ ZK×n, y ∈ ZL, c ∈ Zn, ML-DSA q q 1 q 2 q q q has A ∈ Rk×l, t ∈ Rk, s ∈ Rl, s ∈ Rk, y ∈ Rl, c ∈ R , where l = L/n and k = K/n. q q 1 q 2 q q q • To further reduce the size of the public key, the matrix A is pseudorandomly derived from a 256-bit public seed ρ, which is included in the ML-DSA public key in place of A.\n\n• For a still further reduction in public key size, the ML-DSA public key substitutes a compressed value t1 for t, which drops the d low-order bits of each coefficient.\n\n• To obtain beyond unforgeability (BUFF) properties noted in [14], ML-DSA does not directly sign the message M but rather signs a message representative μ that is obtained by hashing the concatenation of a hash of the public key and M.\n\n• To reduce signature size, rather than including the commitment wApprox = Ay+y2 in the signature, the ML-DSA signature uses a rounded version of w = Ay as a commitment w1 and includes only the hash c of w1||μ.\n\n• To ensure that w1 can be reconstructed by the verifier from z and the compressed value t1, the signature must also include a hint h ∈ Rk computed by the signer using the signer’s private key. • Additionally, to ensure correctness, a second stage of rejection sampling must be included (Line 28 of Algorithm 7)\n\nIn this document, the abbreviations ML-DSA-44, ML-DSA-65, and ML-DSA-87 are used to refer to ML-DSA with the parameter choices given in Table 1. In these abbreviations, the numerical suffix refers to the dimension of the matrix A. For example, in ML-DSA-65, the matrix A is a 6 × 5 matrix over Rq.\n\n3.4 Hedged and Deterministic Signing For ML-DSA to be secure, the signer’s commitment value y must not be used to sign more than one message, and it must not be easily guessed by an attacker. This requires randomness. In principle, the randomness leading to y can be produced either with the use of fresh randomness at signing time or pseudorandomly from the message being signed and a precomputed random value included in the signer’s private key. By default, this standard specifies the signing algorithm to use both types of randomness. This is referred to as the “hedged” variant of the signing procedure. The use of fresh randomness during signing helps mitigate side-channel attacks, while the use of precomputed randomness protects against the possibility that there may be flaws in the random number generator used by the signer at signing time. This document also permits a fully deterministic variant of the signing procedure in case the signer has no access to a fresh source of randomness at signing time. However, the lack of randomness in the deterministic variant makes the risk of side-channel attacks (particularly fault attacks) more difficult to mitigate. Therefore, this variant should not be used on platforms where side-channel attacks are a concern and where they cannot be otherwise mitigated. Only implementing the hedged variant (i.e., without the deterministic variant) is sufficient to guarantee interoperability.", "char_len": 3930, "approx_tokens": 982}
{"chunk_id": "NIST.FIPS.204::c00014", "doc_id": "NIST.FIPS.204", "start_page": 21, "end_page": 22, "text": "gning time. This document also permits a fully deterministic variant of the signing procedure in case the signer has no access to a fresh source of randomness at signing time. However, the lack of randomness in the deterministic variant makes the risk of side-channel attacks (particularly fault attacks) more difficult to mitigate. Therefore, this variant should not be used on platforms where side-channel attacks are a concern and where they cannot be otherwise mitigated. Only implementing the hedged variant (i.e., without the deterministic variant) is sufficient to guarantee interoperability. The same verification algorithm will work to verify signatures produced by either variant, so implementing the deterministic variant in addition to the hedged variant does not enhance interoperability. The hedged and deterministic signing procedure differ only at line 5 of Algorithm 2 and line 5 of Algorithm 4.\n\n3.5 Use of Digital Signatures Secure key management is an essential requirement for the use of digital signatures. This is contextdependent and involves more than the key generation, signing, and signature verification algorithms in this document. Guidance for key management is provided in the SP 800-57 series [9, 17, 18]. Digital signatures are most useful when bound to an identity. Binding a public key to an identity requires proof of possession of the private key. In the PKI context, issuing certificates involves assurances of identity and proof of possession. When a public-key certificate is not available, users of digital signatures should determine whether a public key needs to be bound to an identity. Methods for obtaining assurances of identity and proof of possession are provided in [3].\n\n3.6 Additional Requirements This section describes several required assurances when implementing ML-DSA. These are in addition to the considerations in Section 3.5.\n\n3.6.1 Randomness Generation Algorithm 1, implementing key generation for ML-DSA, uses an RBG to generate the 256-bit random seed ξ. The seed ξ shall be a fresh (i.e., not previously used) random value generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [19, 20, 21]. Moreover, the RBG used shall have a security strength of at least 192 bits for ML-DSA-65 and 256 bits for ML-DSA-87. For ML-DSA-44, the RBG should have a security strength of at least 192 bits and shall have a security strength of at least 128 bits. If an approved RBG with at least 128 bits of security but less than 192 bits of security is used, then the claimed security strength of ML-DSA-44 is reduced from category 2 to category 1. Additionally, the value rnd is generated using an RBG in the default “hedged” variants of Algorithms 2 and 4 for ML-DSA and HashML-DSA signing, respectively. While this value should ideally be generated by an approved RBG, other methods for generating fresh random values may be used. The primary purpose of rnd is to facilitate countermeasures to side-channel attacks and fault attacks on deterministic signatures, such as [22, 23, 24].3 For this purpose, even a weak RBG may be preferable to the fully deterministic variants of Algorithms 2 and 4.\n\n3.6.2 Public-Key and Signature Length Checks Algorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard. Failing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability.", "char_len": 3794, "approx_tokens": 948}
{"chunk_id": "NIST.FIPS.204::c00015", "doc_id": "NIST.FIPS.204", "start_page": 22, "end_page": 23, "text": "ey and Signature Length Checks Algorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard. Failing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability.\n\n3.6.3 Intermediate Values The data used internally by the key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or the verification of signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of ML-DSA shall ensure that any potentially sensitive intermediate data is destroyed as soon as it is no longer needed. Two particular cases in which implementations may refrain from destroying intermediate data are:\n\n1. The seed ξ generated in step 1 of ML-DSA.KeyGen can be stored for the purpose of later expansion\n\n3In addition, when signing is deterministic, there is leakage through timing side channels of information about the message but not the private key). If the signer does not want to reveal the message being signed, hedged signatures should be used (see Section 3.2 in [6]).\n\nusing ML-DSA.KeyGen_internal. As the seed can be used to compute the private key, it is sensitive data and shall be treated with the same safeguards as a private key.\n\n2. The matrix A generated in step 3 of ML-DSA.KeyGen_internal can be stored so that it need not be recomputed in later operations. Likewise, the matrix A generated in step 5 of the verification algorithm ML-DSA.Verify_internal can also be stored. In either case, the matrix A is data that is easily computed from the public key and does not require any special protections.\n\nIn certain situations (e.g., deterministic signing and the verification of confidential messages and signatures), additional care must be taken to protect implementations against side-channel attacks or fault attacks. A cryptographic device may leak critical information through side channels, which allows internal data or keying material to be extracted without breaking the cryptographic primitives.\n\n3.6.4 No Floating-Point Arithmetic Implementations of ML-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. Either ⌊x/y⌋ or ⌈x/y⌉ is used in all pseudocode in this standard in which division is performed (e.g., x/y), and y may not divide x. Both of these can be computed without floating-point arithmetic, as ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative integers x and positive integers y. If y is a power of two, it may be more efficient to use bit shift operations than integer division.", "char_len": 3560, "approx_tokens": 890}
{"chunk_id": "NIST.FIPS.204::c00016", "doc_id": "NIST.FIPS.204", "start_page": 23, "end_page": 25, "text": "Arithmetic Implementations of ML-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. Either ⌊x/y⌋ or ⌈x/y⌉ is used in all pseudocode in this standard in which division is performed (e.g., x/y), and y may not divide x. Both of these can be computed without floating-point arithmetic, as ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative integers x and positive integers y. If y is a power of two, it may be more efficient to use bit shift operations than integer division.\n\n3.7 Use of Symmetric Cryptography This standard makes use of the functions SHAKE256 and SHAKE128, as defined in FIPS 202 [7]. While FIPS 202 specifies these functions as inputting and outputting bit strings, most implementations treat inputs and outputs as byte strings. This standard will always call these functions with an output length of a multiple of eight bits and treat the output of these functions as a byte string, which will be the same byte string that would result from taking the bit string expected from a literal reading of FIPS 202 and processing it with BitsToBytes. However, to allow the signing of messages that are not a whole number of bytes, this document will overload SHAKE256 so that its input may be a bit string but will usually be a byte string. The following equivalence will hold for any byte string str and integer l ≥ 1:\n\nSHAKE256(str, 8l) = SHAKE256(BytesToBits(str), 8l).\n\nIn addition to using a mostly byte-oriented variant of the API defined in FIPS 202 for SHAKE256 and SHAKE128, this standard sometimes makes use of the incremental API defined in SP 800-185 [25]. This API consists of three functions for each variant of SHAKE. These functions can be used to absorb a sequence of arbitrary-length strings and squeeze a sequence of arbitrary-length strings. These functions perform buffering to handle any incomplete data blocks while absorbing or squeezing. For example, for SHAKE256:\n\n• ctx ← SHAKE256.Init() Initializes a hash function context.\n\n• ctx ← SHAKE256.Absorb(ctx, str) Injects data to be used in the absorbing phase of SHAKE256 and updates context ctx.\n\n• (ctx, out) ← SHAKE256.Squeeze(ctx, 8l) Extracts l output bytes produced during the squeezing phase of SHAKE256 and updates context ctx.\n\nWhile the above functions are specified in terms of the Keccak-f permutation rather than the eXtendable- Output Function (XOF), SHAKE256, they are defined so that any series of commands of the following form:\n\n1. ctx ← SHAKE256.Init()\n\n2. For i = 1 to m: ctx ← SHAKE256.Absorb(ctx, stri)\n\n3. For j = 1 to k: (ctx, outj) ← SHAKE256.Squeeze(ctx, 8bj)\n\n4. output ← out1|| ... ||outk\n\nwill yield the same output as a single SHAKE256 call:\n\noutput ← SHAKE256(str1|| ... ||strm, 8b1 + ... + 8bk).\n\nThis equivalence holds whether or not |stri| and bj are multiples of the SHAKE256 block length.\n\nSince all outputs of SHAKE128 and SHAKE256 in this document give a whole number of bytes, the wrapper functions H and G are defined as follows:\n\n1. H(str, l) = SHAKE256(str, 8l)\n\n2. G(str, l) = SHAKE128(str, 8l)\n\n3. H.Init() = SHAKE256.Init()\n\n4. G.Init() = SHAKE128.Init()\n\n5. H.Absorb(ctx, str) = SHAKE256.Absorb(ctx, str)\n\n6. G.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str)\n\n7. H.Squeeze(ctx, l) = SHAKE256.Squeeze(ctx, 8l)\n\n8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it should be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to relate bits, bytes, and words.\n\n4. Parameter Sets\n\nTable 1. ML-DSA parameter sets", "char_len": 3901, "approx_tokens": 975}
{"chunk_id": "NIST.FIPS.204::c00017", "doc_id": "NIST.FIPS.204", "start_page": 24, "end_page": 27, "text": "x, str)\n\n7. H.Squeeze(ctx, l) = SHAKE256.Squeeze(ctx, 8l)\n\n8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it should be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to relate bits, bytes, and words.\n\n4. Parameter Sets\n\nTable 1. ML-DSA parameter sets\n\nParameters Values assigned by each parameter set (see Sections 6.1 and 6.2 of this document) ML-DSA-44 ML-DSA-65 ML-DSA-87 q - modulus [see §6.1] 8380417 8380417 8380417 ζ - a 512th root of unity in Zq [see §7.5] 1753 1753 1753 d - # of dropped bits from t [see §6.1] 13 13 13 τ - # of ±1’s in polynomial c [see §6.2] 39 49 60 λ - collision strength of c [see §6.2] 128 192 256\n\nγ γ1 - coefficient range of y [see §6.2] 217 219 219 2 - low-order rounding range [see §6.2] (q − 1)/88 (q − 1)/32 (q − 1)/32 (k, l) - dimensions of A [see §6.1] (4,4) (6,5) (8,7) η - private key range [see §6.1] 2 4 2 β = τ ⋅ η [see §6.2] 78 196 120 ω - max # of 1’s in the hint h [see §6.2] 80 55 75 Challenge entropy log (256) + τ [see §6.2] 192 225 257 Repetitions (see 2 τ explanation below) 4.25 5.1 3.85 Claimed security strength Category 2 Category 3 Category 5\n\nThree ML-DSA parameter sets are included in Table 1. Each parameter set assigns values for all of the parameters used in the ML-DSA algorithms for key generation, signing, and verification. For informational purposes, some parameters used in the analysis of these algorithms are also included in the table. In particular, “repetitions” refers to the expected number of repetitions of the main loop in the signing algorithm from eq. 5 in [5]. The names of the parameter sets are of the form “ML-DSA-kl,” where (k, l) are the dimensions of the matrix A. These parameter sets were designed to meet certain security strength categories defined by NIST in its original Call for Proposals [26]. These security strength categories are explained further in SP 800-57, Part 1 [9]. Using this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each ML-DSA parameter set is claimed to be at least as secure as a generic block cipher with a prescribed key size or a generic hash function with a prescribed output length. More precisely, it is claimed that the computational resources needed to break ML-DSA are greater than or equal to the computational resources needed to break the block cipher or hash function when these computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models are discussed in [27]. Concretely, the parameter set ML-DSA-44 is claimed to be in security strength category 2, ML-DSA-65 is claimed to be in category 3, and ML-DSA-87 is claimed to be in category 5 [6]. For additional discussion of the security strength of MLWE-based cryptosystems, see [28]. The sizes of keys and signatures that correspond to each parameter set are given in Table 2. Certain optimizations are possible when storing ML-DSA public and private keys. If additional space is available, one can precompute and store A to speed up signing and verifying. Alternatively, if one wants to reduce\n\nthe space needed for the private key, one can store only the 32-byte seed ξ, which is sufficient to generate the other parts of the private key. For additional details, see Section 3.1 in [6].\n\nTable 2. Sizes (in bytes) of keys and signatures of ML-DSA\n\nPrivate Key Public Key Signature Size ML-DSA-44 2560 1312 2420 ML-DSA-65 4032 1952 3309 ML-DSA-87 4896 2592 4627\n\n5. External Functions", "char_len": 3965, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.204::c00018", "doc_id": "NIST.FIPS.204", "start_page": 25, "end_page": 28, "text": "timizations are possible when storing ML-DSA public and private keys. If additional space is available, one can precompute and store A to speed up signing and verifying. Alternatively, if one wants to reduce\n\nthe space needed for the private key, one can store only the 32-byte seed ξ, which is sufficient to generate the other parts of the private key. For additional details, see Section 3.1 in [6].\n\nTable 2. Sizes (in bytes) of keys and signatures of ML-DSA\n\nPrivate Key Public Key Signature Size ML-DSA-44 2560 1312 2420 ML-DSA-65 4032 1952 3309 ML-DSA-87 4896 2592 4627\n\n5. External Functions\n\nThe signing, verifying, and key generation functions can be split into “external” and “internal” components to simplify APIs and Cryptographic Algorithm Validation Program (CAVP) testing. The external components generate randomness and perform various checks before calling their internal counterparts. The internal components are deterministic and can assume that the external components did not encounter error conditions. The distinction between external and internal functions also simplifies the presentation of algorithms for signing and verification by grouping the operations that are shared between ML-DSA.Sign and HashML-DSA.Sign in ML-DSA.Sign_internal and grouping the operations that are shared between ML-DSA.Verify and HashML-DSA.Verify in ML-DSA.Verify_internal.\n\n5.1 ML-DSA Key Generation The key generation algorithm ML-DSA.KeyGen takes no input and outputs a public key and a private key, which are both encoded as byte strings. The algorithm uses an approved RBG to generate a 256-bit (32-byte) random seed ξ that is given as input to ML-DSA.KeyGen_internal (Algorithm 6), which produces the public and private keys.\n\nAlgorithm 1 ML-DSA.KeyGen() Generates a public-private key pair. Output: Public key pk ∈ B32+32k(bitlen (q−1)−d) and private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk). 1: ξ ← B32 ▷ choose random seed 2: if ξ = NULL then 3: return ⊥ ▷ return an error indication if random bit generation failed 4: end if 5: return ML-DSA.KeyGen_internal (ξ)\n\n5.2 ML-DSA Signing The signing algorithm ML-DSA.Sign (Algorithm 2) takes a private key, a message, and a context string as input4. It outputs a signature that is encoded as a byte string. For the default “hedged” version of ML-DSA signing, the algorithm (at line 5) uses an approved RBG to generate a 256-bit (32-byte) random seed rnd. If the deterministic variant is desired, then rnd is set to the fixed zero string {0}32. The value rnd, the private key, and the encoded message are input to ML-DSA.Sign_internal (Algorithm 7), which produces the signature.\n\n4By default, the context is the empty string, though applications may specify the use of a non-empty context string.\n\nAlgorithm 2 ML-DSA.Sign(sk, M, ctx) Generates an ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes). Output: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: M′ ← BytesToBits(IntegerToBytes(0, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx) ∥ M 11: σ ← ML-DSA.Sign_internal(sk, M′ , rnd) 12: return σ", "char_len": 3455, "approx_tokens": 863}
{"chunk_id": "NIST.FIPS.204::c00019", "doc_id": "NIST.FIPS.204", "start_page": 28, "end_page": 29, "text": "2+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes). Output: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: M′ ← BytesToBits(IntegerToBytes(0, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx) ∥ M 11: σ ← ML-DSA.Sign_internal(sk, M′ , rnd) 12: return σ\n\n5.3 ML-DSA Verifying The verification algorithm ML-DSA.Verify (Algorithm 3) takes a public key, a message, a signature, and a context string as input. The public key, signature, and context string are all encoded as byte strings, while the message is a bit string. ML-DSA.Verify outputs a Boolean value that is true if the signature is valid with respect to the message and the public key and false if the signature is invalid. The verification is accomplished by calling ML-DSA.Verify_internal (Algorithm 8) with the public key, the encoded message, and the signature.\n\nAlgorithm 3 ML-DSA.Verify(pk, M, σ, ctx) Verifies a signature σ for a message M. Input: Public key pk ∈ B32+32k(bitlen (q−1)−d), message M ∈ {0, 1}∗, signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k, context string ctx (a byte string of 255 or fewer bytes). Output: Boolean. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: M′ ← BytesToBits(IntegerToBytes(0, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx) ∥ M 6: return ML-DSA.Verify_internal(pk, M′ , σ)\n\n5.4 Pre-Hash ML-DSA For some cryptographic modules that generate ML-DSA signatures, hashing the message in step 6 of ML-DSA.Sign_internal may result in unacceptable performance if the message M is large. For example,\n\nthe platform may require hardware support for hashing to achieve acceptable performance but lack hardware support for SHAKE256 specifically. For some use cases, this may be addressed by signing a digest of the message along with some domain separation information rather than signing the message directly. This version of ML-DSA is known as “pre-hash” ML-DSA or HashML-DSA . In general, the “pure” ML-DSA version is preferred. While key generation for HashML-DSA is the same as for ML-DSA, it is not the same for the signing algorithm HashML-DSA.Sign or the verification algorithm HashML-DSA.Verify. Like ML-DSA, the signing algorithm of HashML-DSA takes the content to be signed, the private key, and a context as input, as well as a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string, though applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a ML-DSA signature or a pre-hash HashML-DSA signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash. 5 While a single key pair may be used for both ML-DSA and HashML-DSA signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or by the application with which the signature is being used. If the default “hedged” variant of is used, the 32-byte random value rnd shall be generated by the cryptographic module that generates the signature (i.e., that runs ML-DSA.Sign_internal). However, all other steps of signing may be performed outside of the cryptographic module that generates the signature.", "char_len": 3807, "approx_tokens": 951}
{"chunk_id": "NIST.FIPS.204::c00020", "doc_id": "NIST.FIPS.204", "start_page": 29, "end_page": 30, "text": "for both ML-DSA and HashML-DSA signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or by the application with which the signature is being used. If the default “hedged” variant of is used, the 32-byte random value rnd shall be generated by the cryptographic module that generates the signature (i.e., that runs ML-DSA.Sign_internal). However, all other steps of signing may be performed outside of the cryptographic module that generates the signature. In the case of pre-hashing, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that generates the signature. If the content to be signed is large, hashing of the content is often performed at the application level. For example, in the Cryptographic Message Syntax [29], a digest of the content may be computed, and that digest is signed along with other attributes. If the content is not hashed at the application level, the pre-hash version of ML-DSA signing may be used. In order to maintain the same level of security strength when the content is hashed at the application level or using HashML-DSA , the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180 [8] or FIPS 202 [7]) that provides at least λ bits of classical security strength against both collision and second preimage attacks [7, Table 4].6 The verification of a signature that is created in this way will require the verify function to generate a digest from the message in the same way to be used as input for the verification function.\n\n5.4.1 HashML-DSA Signing and Verifying In the HashML-DSA version, the message input to ML-DSA.Sign_internal is the result of applying either a hash function or a XOF to the content to be signed. The output of the hash function or XOF is prepended by a one-byte domain separator, one byte that indicates the length of the context string, the context string, and the distinguished encoding rules (DER) encoding of the hash function or XOF’s OID. The domain separator has a value of one for “pre-hash” signing. The DER encoding of the OID includes the tag and length.\n\n5In the case of a XOF this would also include the length of the output from the XOF. 6Obtaining at least λ bits of classical security strength against collision attacks requires that the digest to be signed be at least 2λ bits in length.\n\nAlgorithm 4 shows the DER encodings of the OIDs for SHA-256, SHA-512, and SHAKE128. However, it may be used with other hash functions or XOFs.\n\nAlgorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ", "char_len": 3959, "approx_tokens": 989}
{"chunk_id": "NIST.FIPS.204::c00021", "doc_id": "NIST.FIPS.204", "start_page": 30, "end_page": 32, "text": "HA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ\n\nAlgorithm 5 presents the signature verification for HashML-DSA . This function constructs M′ in the same way as Algorithm 4 and passes the resulting M′ to Algorithm ML-DSA.Verify_internal for verification. As with the pre-hash signature generation, M′ may be constructed outside of the cryptographic module that performs ML-DSA.Verify_internal. However, in the case of HashML-DSA , the hash or XOF of the content must be computed within a FIPS 140-validated cryptographic module, which may be a different cryptographic module than the one that performs ML-DSA.Verify_internal. As noted in Section 5.4, the identifier associated with the signature should indicate whether ML-DSA or\n\nthe pre-hash version HashML-DSA of signature verification should be used, as well as the hash function or XOF to be used to compute the pre-hash. A non-empty context string should be used in verification if one is specified either in the signature’s identifier or by the application with which the signature is being used.\n\nAlgorithm 5 HashML-DSA.Verify(pk, M , σ, ctx, PH) Verifies a pre-hash HashML-DSA signature. Input: Public key pk ∈ B32+32k(bitlen (q−1)−d), message M ∈ {0, 1}∗, signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: Boolean. 1: if |ctx| > 255 then 2: return false 3: end if 4: 5: switch PH do 6: case SHA-256: 7: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 8: PHM ← SHA256(M) 9: case SHA-512: 10: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 11: PHM ← SHA512(M) 12: case SHAKE128: 13: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 14: PHM ← SHAKE128(M, 256) 15: case ... 16: ... 17: end switch 18: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) 19: return ML-DSA.Verify_internal(pk, M′ , σ)\n\n6. Internal Functions\n\nThis section describes the functions for ML-DSA key generation, signature generation, and signature verification. Where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of ML-DSA implementations is performed through the CAVP. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 5 provides guidance on the interfaces to be made available to applications.7\n\n6.1 ML-DSA Key Generation (Internal) The internal key generation algorithm ML-DSA.KeyGen_internal takes a 32-byte random seed as input and outputs a public key and a private key that are both encoded as byte strings. The seed ξ is expanded as needed using an XOF (i.e., a byte-variant of SHAKE256) denoted by H to produce other random values.8 In particular:", "char_len": 3649, "approx_tokens": 912}
{"chunk_id": "NIST.FIPS.204::c00022", "doc_id": "NIST.FIPS.204", "start_page": 32, "end_page": 33, "text": "made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 5 provides guidance on the interfaces to be made available to applications.7\n\n6.1 ML-DSA Key Generation (Internal) The internal key generation algorithm ML-DSA.KeyGen_internal takes a 32-byte random seed as input and outputs a public key and a private key that are both encoded as byte strings. The seed ξ is expanded as needed using an XOF (i.e., a byte-variant of SHAKE256) denoted by H to produce other random values.8 In particular:\n\n• A 32-byte public random seed ρ. Using this seed, a polynomial matrix A ∈ Rk×l is pseudorandomly q sampled9 from Rk×l. q • A 64-byte private random seed ρ′. Using this seed, the polynomial vectors s1 ∈ Rl and s ∈ Rk are pseudorandomly sampled from the subset of polynomial vectors whose q 2 q coordinate polynomials have short coefficients (i.e., in the range [−η, η]). • A 32-byte private random seed K for use during signing.\n\nThe core cryptographic operation computes the public value\n\nt = As1 + s2.\n\nThe vector t together with the matrix A may be considered an expanded form of the public key. The vector t is compressed in the actual public key by dropping the d least significant bits from each coefficient, thus producing the polynomial vector t1. This compression is an optimization for performance, not security. The low-order bits of t can be reconstructed from a small number of signatures and, therefore, need not be regarded as secret. The ML-DSA public key pk is a byte encoding of the public random seed ρ and the compressed polynomial vector t1. The ML-DSA private key sk is a byte encoding of the public random seed ρ, a private random seed K for use during signing, a 64-byte hash tr of the public key for use during signing, the secret polynomial 7In some cases, it is permissible to modify the format of the private key in these interfaces (see Sections 4 and 3.6.3.) 8Single-byte encodings of the parameters k and l are included in the XOF input for domain separation. For implementations that use the seed in place of the private key, this ensures that the expansion will produce an unrelated key if the seed is mistakenly expanded using a parameter set other than the one originally intended. 9More precisely, since only the NTT form of A, A ∈ T k×l = NTT(A) is needed in subsequent calculations, the q code actually computes Â as a pseudorandom sample over T k×l, and the sampling of A = NTT−1(A)̂ is only implicit (i.e., it could be computed but is not). q\n\nvectors s1 and s2, and a polynomial vector t0 encoding the d least significant bits of each coefficient of the uncompressed public-key polynomial t.\n\nAlgorithm 6 ML-DSA.KeyGen_internal(ξ) Generates a public-private key pair from a seed. Input: Seed ξ ∈ B32 Output: Public key pk ∈ B32+32k(bitlen (q−1)−d) and private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk). 1: (ρ, ρ′ , K) ∈ B32 × B64 × B32 ← H(ξ||IntegerToBytes(k, 1)||IntegerToBytes(l, 1), 128) 2: ▷ expand seed 3: A ← ExpandA(ρ) ▷ A is generated and stored in NTT representation as A 4: (s1, s2) ← ExpandS(ρ′ ) 5: t ← NTT−1 (A ∘ NTT(s1)) + s2 ▷ compute t = As1 + s2 6: (t1, t0) ← Power2Round(t) ▷ compress t 7: ▷ PowerTwoRound is applied componentwise (see explanatory text in Section 7.4) 8: pk ← pkEncode(ρ, t1) 9: tr ← H(pk, 64) 10: sk ← skEncode(ρ, K, tr, s1, s2, t0) ▷ K and tr are for use in signing 11: return (pk, sk)", "char_len": 3467, "approx_tokens": 866}
{"chunk_id": "NIST.FIPS.204::c00023", "doc_id": "NIST.FIPS.204", "start_page": 33, "end_page": 34, "text": "32k(bitlen (q−1)−d) and private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk). 1: (ρ, ρ′ , K) ∈ B32 × B64 × B32 ← H(ξ||IntegerToBytes(k, 1)||IntegerToBytes(l, 1), 128) 2: ▷ expand seed 3: A ← ExpandA(ρ) ▷ A is generated and stored in NTT representation as A 4: (s1, s2) ← ExpandS(ρ′ ) 5: t ← NTT−1 (A ∘ NTT(s1)) + s2 ▷ compute t = As1 + s2 6: (t1, t0) ← Power2Round(t) ▷ compress t 7: ▷ PowerTwoRound is applied componentwise (see explanatory text in Section 7.4) 8: pk ← pkEncode(ρ, t1) 9: tr ← H(pk, 64) 10: sk ← skEncode(ρ, K, tr, s1, s2, t0) ▷ K and tr are for use in signing 11: return (pk, sk)\n\n6.2 ML-DSA Signing (Internal) ML-DSA.Sign_internal (Algorithm 7) outputs a signature encoded as a byte string. It takes a private key sk encoded as a byte string, a formatted message M′ encoded as a bit string, and a 32-byte string rnd as input. There are two ways that a signing algorithm can use ML-DSA.Sign_internal: “hedged” and “deterministic.” The default “hedged” variants of ML-DSA.Sign and HashML-DSA.Sign use a fresh random value for rnd, while the optional deterministic variants use the constant byte string {0}32 (see Section 3). In both variants, the signer first extracts the following from the private key: the public random seed ρ, the 32-byte private random seed K, the 64-byte hash of the public key tr, the secret polynomial vectors s1 and s2, and the polynomial vector t0 encoding the d least significant bits of each coefficient of the uncompressed public-key polynomial t. ρ is then expanded to the same matrix A as in key generation. Before the message M is signed, it is concatenated with the public-key hash tr and hashed down to a 64-byte message representative μ using H. The signer produces an additional 64-byte seed ρ′′ for private randomness during each signing operation. ρ′′ is computed as ρ′′ ← H(K||rnd||μ, 64). In the default hedged variant, rnd is the output of an RBG, while in the deterministic variant, rnd is a 32-byte string that consists entirely of zeros. This is the only difference between the deterministic and hedged variant of ML-DSA.Sign. The main part of the signing algorithm consists of a rejection sampling loop in which each iteration of the loop either produces a valid signature or an invalid signature whose release would leak information about the private key. The loop is repeated until a valid signature is produced, which can then be encoded as a byte string and output.10 The rejection sampling loop follows the Fiat-Shamir With Aborts paradigm [10]\n\n10Implementations may limit the number of iterations in this loop to not exceed a finite maximum value. If this\n\nand (aside from the rejection step) is similar in structure to Schnorr signatures [30] (e.g., EdDSA [31]). The signer first produces a “commitment” w1 and then pseudorandomly derives a “challenge” c from w1 and the message representative μ. Finally, the signer computes a response z. In more detail, the main computations involved in the rejection sampling loop are as follows:\n\n• Using the ExpandMask function (Algorithm 34), the seed ρ′′, and a counter κ, a polynomial vector y ∈ Rl is pseudorandomly sampled from the subset of polynomial vectors whose coefficients are q moderately short (i.e., in the range [−γ1 + 1, γ1]).\n\n• From y, the signer computes the commitment w1 by computing w = Ay and then rounding to a nearby multiple of 2γ2 using HighBits (Algorithm 37).\n\n• w1 and μ are concatenated and hashed to produce the commitment hash c. This uses the function w1Encode (Algorithm 28). The byte string c is used to pseudorandomly sample a polynomial c ∈ Rq that has coefficients in {−1, 0, 1} and Hamming weight τ. The sampling is done with the function SampleInBall (Algorithm 29).11\n\n• The signer computes the response z = y + cs1 and performs various validity checks. If any of the checks fails, the signer will continue the rejection sampling loop.", "char_len": 3889, "approx_tokens": 972}
{"chunk_id": "NIST.FIPS.204::c00024", "doc_id": "NIST.FIPS.204", "start_page": 34, "end_page": 35, "text": "ommitment w1 by computing w = Ay and then rounding to a nearby multiple of 2γ2 using HighBits (Algorithm 37).\n\n• w1 and μ are concatenated and hashed to produce the commitment hash c. This uses the function w1Encode (Algorithm 28). The byte string c is used to pseudorandomly sample a polynomial c ∈ Rq that has coefficients in {−1, 0, 1} and Hamming weight τ. The sampling is done with the function SampleInBall (Algorithm 29).11\n\n• The signer computes the response z = y + cs1 and performs various validity checks. If any of the checks fails, the signer will continue the rejection sampling loop.\n\n• If the checks pass, the signer can compute a hint polynomial h, which will allow the verifier to reconstruct w1 using the compressed public key along with the other components of the signature. This uses the function MakeHint (Algorithm 39). The signer will then output the final signature, which is a byte encoding of the commitment hash c, the response z, and the hint h.\n\nIn addition, there is an alternative way of implementing the validity checks on z and the computation of h, which is described in Section 5.1 of [6]. This method may also be used in implementations of ML-DSA. In Algorithm 7, variables are sometimes used to store products to avoid recomputing them later in the signing algorithm. These precomputed products are denoted in the pseudocode by a pair of double angle brackets enclosing the variables being multiplied (e.g., ⟨⟨cs1⟩⟩).\n\noption is used and the maximum number of iterations is exceeded without producing a valid signature, the signing algorithm shall return a constant that represents an error and no other output, destroying the results of the unsuccessful signing attempts. See Appendix C. 11The length of c is determined by the desired security with respect to the “message-bound signatures” property described in [14]. Here, a length of λ/4 bytes or equivalently 2λ bits is required for λ bits of classical security.\n\nAlgorithm 7 ML-DSA.Sign_internal(sk, M′ , rnd) Deterministic algorithm to generate a signature for a formatted message M′ . Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), formatted message M′ ∈ {0, 1}∗, and per message randomness or dummy variable rnd ∈ B32. Output: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: (ρ, K, tr, s1, s2, t0) ← skDecode(sk) 2: s1 ← NTT(s1) 3: s2 ← NTT(s2) 4: t0 ← NTT(t0) 5: A ← ExpandA(ρ) ▷ A is generated and stored in NTT representation as A 6: μ ← H(BytesToBits(tr)||M ′ , 64) ▷ message representative that may optionally be computed in a different cryptographic module 7: ρ′′ ← H(K||rnd||μ, 64) ▷ compute private random seed 8: κ ← 0 ▷ initialize counter κ 9: (z, h) ← ⊥ 10: while (z, h) = ⊥ do ▷ rejection sampling loop 11: y ∈ Rl ← ExpandMask(ρ′′ , κ) q 12: w ← NTT−1 (A ∘ NTT(y)) 13: w1 ← HighBits(w) ▷ signer’s commitment 14: ▷ HighBits is applied componentwise (see explanatory text in Section 7.4) 15: c ← H(μ||w1Encode(w1), λ/4) ▷ commitment hash 16: c ∈ Rq ← SampleInBall(c)̃ ▷ verifier’s challenge 17: c ← NTT(c) 18: ⟨⟨cs1⟩⟩ ← NTT−1 (c ∘̂ s1) 19: ⟨⟨cs2⟩⟩ ← NTT−1 (c ∘̂ s2) 20: z ← y + ⟨⟨cs1⟩⟩ ▷ signer’s response 21: r0 ← LowBits(w − ⟨⟨cs2⟩⟩) 22: ▷ LowBits is applied componentwise (see explanatory text in Section 7.4) 23: if ||z||∞ ≥ γ1 − β or ||r0||∞ ≥ γ2 − β then (z, h) ← ⊥ ▷ validity checks 24: else 25: ⟨⟨ct0⟩⟩ ← NTT−1 (c ∘̂ t0) 26: h ← MakeHint(−⟨⟨ct0⟩⟩, w − ⟨⟨cs2⟩⟩ + ⟨⟨ct0⟩⟩) ▷ Signer’s hint 27: ▷ MakeHint is applied componentwise (see explanatory text in Section 7.4) 28: if ||⟨⟨ct0⟩⟩||∞ ≥ γ2 or the number of 1’s in h is greater than ω, then (z, h) ← ⊥ 29: end if 30: end if 31: κ ← κ + l ▷ increment counter 32: end while 33: σ ← sigEncode(c, z̃ mod±q, h) 34: return σ\n\n6.3 ML-DSA Verifying (Internal) The algorithm ML-DSA.Verify_internal (Algorithm 8) takes a public key pk encoded as a byte string, a message M encoded as a bit string, and a signature σ encoded as a byte string as input. No randomness is", "char_len": 3938, "approx_tokens": 984}
{"chunk_id": "NIST.FIPS.204::c00025", "doc_id": "NIST.FIPS.204", "start_page": 35, "end_page": 37, "text": "−1 (c ∘̂ t0) 26: h ← MakeHint(−⟨⟨ct0⟩⟩, w − ⟨⟨cs2⟩⟩ + ⟨⟨ct0⟩⟩) ▷ Signer’s hint 27: ▷ MakeHint is applied componentwise (see explanatory text in Section 7.4) 28: if ||⟨⟨ct0⟩⟩||∞ ≥ γ2 or the number of 1’s in h is greater than ω, then (z, h) ← ⊥ 29: end if 30: end if 31: κ ← κ + l ▷ increment counter 32: end while 33: σ ← sigEncode(c, z̃ mod±q, h) 34: return σ\n\n6.3 ML-DSA Verifying (Internal) The algorithm ML-DSA.Verify_internal (Algorithm 8) takes a public key pk encoded as a byte string, a message M encoded as a bit string, and a signature σ encoded as a byte string as input. No randomness is\n\nrequired for ML-DSA.Verify_internal. It produces a Boolean value (i.e., a value that is true if the signature is valid with respect to the message and public key and false if the signature is invalid) as output. Algorithm 8 specifies the lengths of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA.Verify_internal can accept inputs for σ or pk of any other length, it shall return false whenever the length of either of these inputs differs from its specified length. The verifier first extracts the public random seed ρ and the compressed polynomial vector t1 from the public key pk and then extracts the signer’s commitment hash c, response z, and hint h from the signature σ. The verifier may find that the hint was not properly byte-encoded, denoted by the symbol “⊥,” in which case the verification algorithm will immediately return false to indicate that the signature is invalid. Assuming that the signature is successfully extracted from its byte encoding, the verifier pseudorandomly derives A from ρ, as is done in key generation and signing, and creates a message representative μ by hashing the concatenation of tr (i.e., the hash of the public key pk) and the message M. The verifier then attempts to reconstruct the signer’s commitment (i.e., the polynomial vector w1) from the public key pk and the signature σ. In ML-DSA.Sign_internal, w1 is computed by rounding w = Ay. In ML-DSA.Verify_internal, the reconstructed value of w1 is called w′ since it may have been computed in a different way if the signature is invalid. This w′ is computed 1 1 through the following process:\n\n• Derive the challenge polynomial c from the signer’s commitment hash c, just as similarly is done in ML-DSA.Sign_internal.\n\n• Use the signer’s response z to compute\n\nw′ = Az − ct1 ⋅ 2d. Approx Assuming the signature was computed correctly, as in ML-DSA.Sign_internal, it follows that\n\nw = Ay = Az − ct + cs2 ≈ w′ = Az − ct1 ⋅ 2d Approx\n\nbecause c and s2 have small coefficients, and t1 ⋅ 2d ≈ t .\n\n• Use the signer’s hint h to obtain w′ from w′ . 1 Approx\n\nFinally, the verifier checks that the signer’s response z and the signer’s hint h are valid and that the reconstructed w′ is consistent with the signer’s commitment hash c. More precisely, the verifier checks that all of the 1 coefficients of z are sufficiently small (i.e., in′the range (−(γ1 − β), γ1 − β)), h contains no more than ω nonzero coefficients, and c matches the hash c of the message representative μ concatenated with w′ (represented as a byte string). If all of these checks succeed, then ML-DSA.Verify_internal returns true. 1 Otherwise, it returns false.\n\nAlgorithm 8 ML-DSA.Verify_internal(pk, M′ , σ) Internal function to verify a signature σ for a formatted message M′ . Input: Public key pk ∈ B32+32k(bitlen (q−1)−d) and message M′ ∈ {0, 1}∗. Input: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k.", "char_len": 3538, "approx_tokens": 884}
{"chunk_id": "NIST.FIPS.204::c00026", "doc_id": "NIST.FIPS.204", "start_page": 36, "end_page": 39, "text": "f the 1 coefficients of z are sufficiently small (i.e., in′the range (−(γ1 − β), γ1 − β)), h contains no more than ω nonzero coefficients, and c matches the hash c of the message representative μ concatenated with w′ (represented as a byte string). If all of these checks succeed, then ML-DSA.Verify_internal returns true. 1 Otherwise, it returns false.\n\nAlgorithm 8 ML-DSA.Verify_internal(pk, M′ , σ) Internal function to verify a signature σ for a formatted message M′ . Input: Public key pk ∈ B32+32k(bitlen (q−1)−d) and message M′ ∈ {0, 1}∗. Input: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. Output: Boolean 1: (ρ, t1) ← pkDecode(pk) 2: (c, z, h) ← sigDecode(σ) ▷ signer’s commitment hash c, response z, and hint h 3: if h = ⊥ then return false ▷ hint was not properly encoded 4: end if 5: A ← ExpandA(ρ) ▷ A is generated and stored in NTT representation as A 6: tr ← H(pk, 64) 7: μ ← (H(BytesToBits(tr)||M ′ , 64)) ▷ message representative that may optionally be computed in a different cryptographic module 8: c ∈ Rq ← SampleInBall(c)̃ ▷ compute verifier’s challenge from c 9: w′ ← NTT−1 (A ∘ NTT(z) − NTT(c) ∘ NTT(t ⋅ 2d)) ▷ w′ = Az − ct ⋅ 2d Approx 1 Approx 1 10: w′ ← UseHint(h, w′ ) ▷ reconstruction of signer’s commitment 1 ▷ Approx 11: UseHint is applied componentwise (see explanatory text in Section 7.4) 12: c′ ← H(μ||w1Encode(w′ ), λ/4) ▷ hash it; this should match c return [[ ||z|| < γ − 1 ′ 13: ∞ 1 β]] and [[c = c ]]\n\n7. Auxiliary Functions\n\nThis section provides pseudocode for subroutines utilized by ML-DSA, including functions for data-type conversions, arithmetic, and sampling.\n\n7.1 Conversion Between Data Types While the primary data type in ML-DSA is a byte string, other data types are used as well. The goal in this section is to construct procedures for translating between the various algebraic objects defined in Section 2.3. Algorithms 9–13 are intermediate procedures for converting between bit strings, byte strings, and integers.\n\nAlgorithm 9 IntegerToBits(x, α) Computes a base-2 representation of x mod 2α using little-endian order. Input: A nonnegative integer x and a positive integer α. Output: A bit string y of length α. 1: x′ ← x 2: for i from 0 to α − 1 do 3: y[i] ← x′ mod 2 4: x′ ← ⌊x′ /2⌋ 5: end for 6: return y\n\nAlgorithm 10 BitsToInteger(y, α) Computes the integer value expressed by a bit string using little-endian order. Input: A positive integer α and a bit string y of length α. Output: A nonnegative integer x. 1: x ← 0 2: for i from 1 to α do 3: x ← 2x + y[α − i] 4: end for 5: return x\n\nAlgorithm 11 IntegerToBytes(x, α) Computes a base-256 representation of x mod 256α using little-endian order. Input: A nonnegative integer x and a positive integer α. Output: A byte string y of length α. 1: x′ ← x 2: for i from 0 to α − 1 do 3: y[i] ← x′ mod 256 4: x′ ← ⌊x′ /256⌋ 5: end for 6: return y\n\nAlgorithm 12 BitsToBytes(y) Converts a bit string into a byte string using little-endian order. Input: A bit string y of length α. Output: A byte string z of length ⌈α/8⌉. 1: z ∈ B⌈α/8⌉ ← 0⌈α/8⌉ 2: for i from 0 to α − 1 do 3: z [⌊i/8⌋] ← z [⌊i/8⌋] + y[i] ⋅ 2i mod 8 4: end for 5: return z\n\nAlgorithm 13 BytesToBits(z) Converts a byte string into a bit string using little-endian order. Input: A byte string z of length α. Output: A bit string y of length 8α. 1: z′ ← z 2: for i from 0 to α − 1 do 3: for j from 0 to 7 do ▷ convert the byte z[i] into 8 bits 4: y[8i + j] ← z′ [i] mod 2 5: z′ [i] ← ⌊z′ [i]/2⌋ 6: end for 7: end for 8: return y\n\nAlgorithms 14 and 15 translate byte strings into coefficients of polynomials in R. CoeffFromThreeBytes uses a 3-byte string to either generate an element of {0, 1, ... , q − 1} or return the blank symbol ⊥. CoeffFromHalfByte uses an element of {0, 1, ... , 15} to either generate an element of {−η, −η+1, ... , η} or return ⊥. These two procedures will be used in the uniform sampling algorithms RejNTTPoly and RejBoundedPoly, which are discussed in Section 7.3.", "char_len": 3961, "approx_tokens": 990}
{"chunk_id": "NIST.FIPS.204::c00027", "doc_id": "NIST.FIPS.204", "start_page": 39, "end_page": 41, "text": "rom 0 to 7 do ▷ convert the byte z[i] into 8 bits 4: y[8i + j] ← z′ [i] mod 2 5: z′ [i] ← ⌊z′ [i]/2⌋ 6: end for 7: end for 8: return y\n\nAlgorithms 14 and 15 translate byte strings into coefficients of polynomials in R. CoeffFromThreeBytes uses a 3-byte string to either generate an element of {0, 1, ... , q − 1} or return the blank symbol ⊥. CoeffFromHalfByte uses an element of {0, 1, ... , 15} to either generate an element of {−η, −η+1, ... , η} or return ⊥. These two procedures will be used in the uniform sampling algorithms RejNTTPoly and RejBoundedPoly, which are discussed in Section 7.3.\n\nAlgorithm 14 CoeffFromThreeBytes(b0, b1, b2) Generates an element of {0, 1, 2, ... , q − 1} ∪ {⊥}. Input: Bytes b0, b1, b2. Output: An integer modulo q or ⊥. 1: b′ ← b2 2 ′ 2: if b2 > 127 then 3: b′ ← b′ − 128 ▷ set the top bit of b′ to zero end 2 2 2 4: if 5: z ← 216 ⋅ b′ + 28 ⋅ b1 + b0 ▷ 0 ≤ z ≤ 223 − 1 if z < q 2 6: then return z ▷ rejection sampling 7: else return ⊥ 8: end if\n\nAlgorithm 15 CoeffFromHalfByte(b) Let η ∈ {2, 4}. Generates an element of {−η, −η + 1, ... , η} ∪ {⊥}. Input: Integer b ∈ {0, 1, ... , 15}. Output: An integer between −η and η, or ⊥. 1: if η = 2 and b < 15 then return 2 − (b mod 5) ▷ rejection sampling from {−2, ... , 2} 2: else 3: if η = 4 and b < 9 then return 4 − b ▷ rejection sampling from {−4, ... , 4} 4: else return ⊥ 5: end if 6: end if\n\nAlgorithms 16–19 efficiently translate an element w ∈ R into a byte string and vice versa under the assumption that the coefficients of w are in a restricted range. SimpleBitPack assumes that wi ∈ [0, b] for some positive integer b and packs w into a byte string of length 32 ⋅ bitlen b. BitPack allows for the more general restriction wi ∈ [−a, b]. The BitPack algorithm works by merely subtracting w from the polynomial ∑255 bXi. i=0\n\nAlgorithm 16 SimpleBitPack(w, b) Encodes a polynomial w into a byte string. Input: b ∈ N and w ∈ R such that the coefficients of w are all in [0, b]. Output: A byte string of length 32 ⋅ bitlen b. 1: z ← () ▷ set z to the empty bit string 2: for i from 0 to 255 do 3: endz ← z||IntegerToBits(wi , bitlen b) 4: for 5: return BitsToBytes(z)\n\nAlgorithm 17 BitPack(w, a, b) Encodes a polynomial w into a byte string. Input: a, b ∈ N and w ∈ R such that the coefficients of w are all in [−a, b]. Output: A byte string of length 32 ⋅ bitlen (a + b). 1: z ← () ▷ set z to the empty bit string 2: for i from 0 to 255 do 3: endz ← z||IntegerToBits(b − wi , bitlen (a + b)) 4: for 5: return BitsToBytes(z)\n\nSimpleBitUnpack and BitUnpack are used to decode the byte strings produced by the above functions. For some choices of a and b, there exist malformed byte strings that will cause SimpleBitUnpack and BitUnpack to output polynomials whose coefficients are not in the ranges [0, b] and [−a, b], respectively. This can be a concern when running SimpleBitUnpack and BitUnpack on inputs that may come from an untrusted source.\n\nAlgorithm 18 SimpleBitUnpack(v, b) Reverses the procedure SimpleBitPack. Input: b ∈ N and a byte string v of length 32 ⋅ bitlen b. Output: A polynomial w ∈ R with coefficients in [0, 2c − 1], where c = bitlen b. When b + 1 is a power of 2, the coefficients are in [0, b]. 1: c ← bitlen b 2: z ← BytesToBits(v) 3: for i from 0 to 255 do 4: endwi ← BitsToInteger((z[ic], z[ic + 1], ... z[ic + c − 1]), c) 5: for 6: return w\n\nAlgorithm 19 BitUnpack(v, a, b) Reverses the procedure BitPack. Input: a, b ∈ N and a byte string v of length 32 ⋅ bitlen (a + b). Output: A polynomial w ∈ R with coefficients in [b − 2c + 1, b], where c = bitlen (a + b). When a + b + 1 is a power of 2, the coefficients are in [−a, b]. 1: c ← bitlen (a + b) 2: z ← BytesToBits(v) 3: for i from 0 to 255 do 4: endwi ← b − BitsToInteger((z[ic], z[ic + 1], ... z[ic + c − 1]), c) 5: for 6: return w", "char_len": 3807, "approx_tokens": 951}
{"chunk_id": "NIST.FIPS.204::c00028", "doc_id": "NIST.FIPS.204", "start_page": 41, "end_page": 43, "text": "1: c ← bitlen b 2: z ← BytesToBits(v) 3: for i from 0 to 255 do 4: endwi ← BitsToInteger((z[ic], z[ic + 1], ... z[ic + c − 1]), c) 5: for 6: return w\n\nAlgorithm 19 BitUnpack(v, a, b) Reverses the procedure BitPack. Input: a, b ∈ N and a byte string v of length 32 ⋅ bitlen (a + b). Output: A polynomial w ∈ R with coefficients in [b − 2c + 1, b], where c = bitlen (a + b). When a + b + 1 is a power of 2, the coefficients are in [−a, b]. 1: c ← bitlen (a + b) 2: z ← BytesToBits(v) 3: for i from 0 to 255 do 4: endwi ← b − BitsToInteger((z[ic], z[ic + 1], ... z[ic + c − 1]), c) 5: for 6: return w\n\nAlgorithms 20 and 21 carry out byte-string-to-polynomial conversions for polynomials with sparse binary coefficients. In particular, the signing and verification algorithms (Sections 6.2 and 6.3) make use of a “hint,” which is a vector of polynomials h ∈ Rk such that the total number of coefficients in h[0], h[1], ... , h[k−1] that are equal to is no more than . 2 1 ω This constraint enables encoding and decoding procedures that are more efficient (although more complex) than BitPack and BitUnpack. HintBitPack (h) outputs a byte string y of length ω + k. The last k bytes of y contain information about how many nonzero coefficients are present in each of the polynomials h[0], h[1], ... , h[k − 1], and the first ω bytes of y contain information about exactly where those nonzero terms occur. HintBitUnpack reverses the procedure performed by HintBitPack and recovers the vector h.\n\nAlgorithm 20 HintBitPack(h) Encodes a polynomial vector h with binary coefficients into a byte string. Input: A polynomial vector h ∈ Rk such that the polynomials h[0], h[1],...,h[k − 1] have collectively at most ω nonzero 2 coefficients. Output: A byte string y of length ω + k that encodes h as described above. 1: y ∈ Bω+k ← 0ω+k 2: Index ← 0 ▷ Index for writing the first ω bytes of y 3: for i from 0 to k − 1 do ▷ look at h[i] 4: for j from 0 to 255 do 5: if h[i]j ≠ 0 then 6: y[Index] ← j ▷ store the locations of the nonzero coefficients in h[i] 7: Index ← Index + 1 8: end if 9: end for 10: y[ω + i] ← Index ▷ after processing h[i], store the value of Index 11: end for 12: return y\n\nAlgorithm 21 HintBitUnpack(y) Reverses the procedure HintBitPack. Input: A byte string y of length ω + k that encodes h as described above. Output: A polynomial vector h ∈ Rk or ⊥. 1: h ∈ Rk ← 0k Index 2 2: ← 0 ▷ Index for reading the first ω bytes of y 3: for i from 0 to k − 1 do ▷ reconstruct h[i] 4: if y[ω + i] < Index or y[ω + i] > ω then return ⊥ ▷ malformed input 5: end if 6: First ← Index 7: while Index < y[ω + i] do ▷ y[ω + i] says how far one can advance Index 8: if Index > First then 9: if y[Index − 1] ≥ y[Index] then return ⊥ ▷ malformed input 10: end if 11: end if 12: h[i]y[Index] ← 1 ▷ y[Index] says which coefficient in h[i] should be 1 13: Index ← Index + 1 14: end while 15: end for 16: for i from Index to ω − 1 do ▷ read any leftover bytes in the first ω bytes of y 17: if y[i] ≠ 0 then return ⊥ ▷ malformed input 18: end if 19: end for 20: return h\n\n7.2 Encodings of ML-DSA Keys and Signatures Algorithms 22–27 translate keys and signatures for ML-DSA into byte strings. These procedures take certain sequences of algebraic objects, encode them consecutively into byte strings, and perform the respective decoding procedures. First, pkEncode and pkDecode translate ML-DSA public keys into byte strings and vice versa. When verifying a signature, pkDecode might be run on an input that comes from an untrusted source. Thus, care is required when using SimpleBitUnpack. As used here, SimpleBitUnpack always returns values in the correct range.\n\nAlgorithm 22 pkEncode(ρ, t1) Encodes a public key for ML-DSA into a byte string. Input:ρ ∈ B32, t1 ∈ Rk with coefficients in [0, 2bitlen (q−1)−d − 1]. Output: Public key pk ∈ B32+32k(bitlen (q−1)−d). 1: pk ← ρ 2: for i from 0 to k − 1 do 3: endpk ← pk || SimpleBitPack (t1[i], 2bitlen (q−1)−d − 1) 4: for 5: return pk", "char_len": 3967, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.204::c00029", "doc_id": "NIST.FIPS.204", "start_page": 43, "end_page": 45, "text": "te ML-DSA public keys into byte strings and vice versa. When verifying a signature, pkDecode might be run on an input that comes from an untrusted source. Thus, care is required when using SimpleBitUnpack. As used here, SimpleBitUnpack always returns values in the correct range.\n\nAlgorithm 22 pkEncode(ρ, t1) Encodes a public key for ML-DSA into a byte string. Input:ρ ∈ B32, t1 ∈ Rk with coefficients in [0, 2bitlen (q−1)−d − 1]. Output: Public key pk ∈ B32+32k(bitlen (q−1)−d). 1: pk ← ρ 2: for i from 0 to k − 1 do 3: endpk ← pk || SimpleBitPack (t1[i], 2bitlen (q−1)−d − 1) 4: for 5: return pk\n\nAlgorithm 23 pkDecode(pk) Reverses the procedure pkEncode. Input: Public key pk ∈ B32+32k(bitlen (q−1)−d). Output: ρ ∈ B32, t1 ∈ Rk with coefficients in [0, 2bitlen (q−1)−d − 1]. 1: (ρ, z0, ... , zk−1 ) ∈ B32 × (B32(bitlen (q−1)−d))k ← pk 2: for i from 0 to k − 1 do 3: endt1[i] ← SimpleBitUnpack(zi , 2bitlen (q−1)−d − 1) ▷ This is always in the correct range 4: for 5: return (ρ, t1)\n\nNext, skEncode and skDecode translate ML-DSA secret keys into byte strings and vice versa. Note that there exist malformed inputs that can cause skDecode to return values that are not in the correct range. Hence, skDecode should only be run on inputs that come from trusted sources.\n\nAlgorithm 24 skEncode(ρ, K, tr, s1, s2, t0) Encodes a secret key for ML-DSA into a byte string. Input: ρ ∈ B32, K ∈ B32, tr ∈ B64, s1 ∈ Rl with coefficients in [−η, η], s2 ∈ Rk with coefficients in [−η, η], t0 ∈ Rk with coefficients in [−2d−1 + 1, 2d−1]. Output: Private key sk ∈ B32+32+64+32⋅((k+l)⋅bitlen (2η)+dk). 1: sk ← ρ||K||tr 2: for i from 0 to l − 1 do 3: endsk ← sk || BitPack (s1[i], η, η) 4: for 5: for i from 0 to k − 1 do 6: endsk ← sk || BitPack (s2[i], η, η) 7: for 8: for i from 0 to k − 1 do 9: endsk ← sk || BitPack (t0[i], 2d−1 − 1, 2d−1) 10: for 11: return sk\n\nAlgorithm 25 skDecode(sk) Reverses the procedure skEncode. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk). Output: ρ ∈ B32, K ∈ B32, tr ∈ B64, s1 ∈ Rl, s2 ∈ Rk, t0 ∈ Rk with coefficients in [−2d−1 + 1, 2d−1]. 1: (ρ, K, tr, y0, ... , yl−1, z0, ... , zk−1 , w0, ... , wk−1 ) ∈ B32 × B32 × B64 × (B32⋅bitlen (2η))l × (B32⋅bitlen (2η))k × (B32d)k ← sk 2: for i from 0 to l − 1 do 3: ends1[i] ← BitUnpack(yi , η, η) ▷ this may lie outside [−η, η] if input is malformed 4: for 5: for i from 0 to k − 1 do 6: ends2[i] ← BitUnpack(zi , η, η) ▷ this may lie outside [−η, η] if input is malformed 7: for 8: for i from 0 to k − 1 do 9: endt0[i] ← BitUnpack(wi , 2d−1 − 1, 2d−1) ▷ this is always in the correct range 10: for 11: return (ρ, K, tr, s1, s2, t0)\n\nNext, sigEncode and sigDecode translate ML-DSA signatures into byte strings and vice versa. When verifying a signature, sigDecode might take input that comes from an untrusted source. Thus, care is required when using BitUnpack. As used here, BitUnpack always returns values in the correct range.\n\nAlgorithm 26 sigEncode(c, z, h) Encodes a signature into a byte string. Input: c ∈ Bλ/4, z ∈ Rl with coefficients in [−γ1 + 1, γ1], h ∈ Rk. Output: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 2 1: σ ← c̃ 2: for i from 0 to l − 1 do 3: endσ ← σ || BitPack (z[i], γ1 − 1, γ1) 4: for 5: σ ← σ || HintBitPack (h) 6: return σ\n\nAlgorithm 27 sigDecode(σ) Reverses the procedure sigEncode. Input: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. Output: c ∈ Bλ/4, z ∈ Rl with coefficients in [−γ1 + 1, γ1], h ∈ Rk, or ⊥. 1: (c, x̃0, ... , xl−1, y) ∈ Bλ/4 × (B32⋅(1+bitlen (γ1−1)))l × Bω+k ← σ 2: for i from 0 to l − 1 do 3: endz[i] ← BitUnpack(xi , γ1 − 1, γ1) ▷ this is in the correct range, as γ1 is a power of 2 4: for 5: h ← HintBitUnpack(y) 6: return (c, z, h)\n\nw1Encode is a specific subroutine used in ML-DSA.Sign. The procedure w1Encode encodes a polynomial vector w1 into a string of bytes so that it can be processed by the function H.", "char_len": 3850, "approx_tokens": 962}
{"chunk_id": "NIST.FIPS.204::c00030", "doc_id": "NIST.FIPS.204", "start_page": 45, "end_page": 47, "text": "gDecode(σ) Reverses the procedure sigEncode. Input: Signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. Output: c ∈ Bλ/4, z ∈ Rl with coefficients in [−γ1 + 1, γ1], h ∈ Rk, or ⊥. 1: (c, x̃0, ... , xl−1, y) ∈ Bλ/4 × (B32⋅(1+bitlen (γ1−1)))l × Bω+k ← σ 2: for i from 0 to l − 1 do 3: endz[i] ← BitUnpack(xi , γ1 − 1, γ1) ▷ this is in the correct range, as γ1 is a power of 2 4: for 5: h ← HintBitUnpack(y) 6: return (c, z, h)\n\nw1Encode is a specific subroutine used in ML-DSA.Sign. The procedure w1Encode encodes a polynomial vector w1 into a string of bytes so that it can be processed by the function H.\n\nAlgorithm 28 w1Encode(w1) Encodes a polynomial vector w1 into a byte string. Input: w1 ∈ Rk whose polynomial coordinates have coefficients in [0, (q − 1)/(2γ2) − 1]. Output: A byte string representation w1 ∈ B32k⋅bitlen ((q−1)/(2γ2)−1). 1: w̃1 ← () 2: for i from 0 to k − 1 do 3: endw̃1 ← w̃1 || SimpleBitPack (w1[i], (q − 1)/(2γ2) − 1) 4: for 5: return w̃1\n\n7.3 Pseudorandom Sampling This section specifies various algorithms for generating algebraic objects pseudorandomly from a seed ρ, where ρ is a byte string whose length varies depending on the algorithm. The first procedure to be defined is SampleInBall. As in Section 2.3, Bτ denotes the set of all polynomials c ∈ R such that\n\n• Each coefficient of c is either −1, 0, or 1, and\n\n• Exactly τ of the coefficients of c are nonzero.\n\nSampleInBall pseudorandomly generates an element of Bτ using the XOF of a seed ρ. The procedure is based on the Fisher-Yates shuffle. H is applied to ρ, and the first 8 bytes of the output are used to choose the signs of the nonzero entries of c.12 Subsequent bytes are used to choose the positions of those nonzero entries.\n\nAlgorithm 29 SampleInBall(ρ) Samples a polynomial c ∈ R with coefficients from {−1, 0, 1} and Hamming weight τ ≤ 64. Input: A seed ρ ∈ Bλ/4 Output: A polynomial c in R. 1: c ← 0 2: ctx ← H.Init() 3: ctx ← H.Absorb(ctx, ρ) 4: (ctx, s) ← H.Squeeze(ctx, 8) 5: h ← BytesToBits(s) ▷ h is a bit string of length 64 6: for i from 256 − τ to 255 do 7: (ctx, j) ← H.Squeeze(ctx, 1) 8: while j > i do ▷ rejection sampling in {0, ... , i} 9: (ctx, j) ← H.Squeeze(ctx, 1) 10: end while ▷ j is a pseudorandom byte that is ≤ i 11: ci ← cj 12: endcj ← (−1)h[i+τ−256] 13: for 14: return c\n\nAlgorithms 30–34 are the pseudorandom procedures RejNTTPoly, RejBoundedPoly, ExpandA, ExpandS, and ExpandMask. Each generates elements of R or Tq under different input and output conditions. RejNTTPoly and ExpandA make use of the more efficient XOF G, whereas the other three procedures use the XOF H. The procedure ExpandMask (Algorithm 34) generates a polynomial vector y in Rk that disguises the secret key in the ML-DSA.Sign_internal procedure (Algorithm 7). In addition to the seed ρ, ExpandMask also accepts an integer input μ that is incorporated into the pseudorandom procedure that generates s.\n\n12The parameter τ is always less than or equal to 64, and thus 8 bytes are sufficient to choose the signs for all τ nonzero entries of c.\n\nAlgorithm 30 RejNTTPoly(ρ) Samples a polynomial ∈ Tq . Input: A seed ρ ∈ B34. Output: An element a ∈ Tq . 1: j ← 0 2: ctx ← G.Init() 3: ctx ← G.Absorb(ctx, ρ) 4: while j < 256 do 5: (ctx, s) ← G.Squeeze(ctx, 3) 6: a[j] ← CoeffFromThreeBytes(s[0], s[1], s[2]) 7: if a[j] ≠ ⊥ then 8: j ← j + 1 9: end if 10: end while 11: return â\n\nAlgorithm 31 RejBoundedPoly(ρ) Samples an element a ∈ R with coefficients in [−η, η] computed via rejection sampling from ρ. Input: A seed ρ ∈ B66. Output: A polynomial a ∈ R. 1: j ← 0 2: ctx ← H.Init() 3: ctx ← H.Absorb(ctx, ρ) 4: while j < 256 do 5: z ← H.Squeeze(ctx, 1) 6: z0 ← CoeffFromHalfByte(z mod 16) 7: z1 ← CoeffFromHalfByte(⌊z/16⌋) 8: if z0 ≠ ⊥ then 9: aj ← z0 10: j ← j + 1 11: end if 12: if z1 ≠ ⊥ and j < 256 then 13: aj ← z1 14: j ← j + 1 15: end if 16: end while 17: return a", "char_len": 3857, "approx_tokens": 964}
{"chunk_id": "NIST.FIPS.204::c00031", "doc_id": "NIST.FIPS.204", "start_page": 47, "end_page": 49, "text": "ffFromThreeBytes(s[0], s[1], s[2]) 7: if a[j] ≠ ⊥ then 8: j ← j + 1 9: end if 10: end while 11: return â\n\nAlgorithm 31 RejBoundedPoly(ρ) Samples an element a ∈ R with coefficients in [−η, η] computed via rejection sampling from ρ. Input: A seed ρ ∈ B66. Output: A polynomial a ∈ R. 1: j ← 0 2: ctx ← H.Init() 3: ctx ← H.Absorb(ctx, ρ) 4: while j < 256 do 5: z ← H.Squeeze(ctx, 1) 6: z0 ← CoeffFromHalfByte(z mod 16) 7: z1 ← CoeffFromHalfByte(⌊z/16⌋) 8: if z0 ≠ ⊥ then 9: aj ← z0 10: j ← j + 1 11: end if 12: if z1 ≠ ⊥ and j < 256 then 13: aj ← z1 14: j ← j + 1 15: end if 16: end while 17: return a\n\nAlgorithm 32 ExpandA(ρ) Samples a k × l matrix A of elements of Tq . Input: A seed ρ ∈ B32. Output: Matrix A ∈ (Tq )k×l. 1: for r from 0 to k − 1 do 2: for s from 0 to l − 1 do 3: ρ′ ← ρ||IntegerToBytes(s, 1)||IntegerToBytes(r, 1) 4: A[r, s] ← RejNTTPoly(ρ′ ) ▷ seed ρ′ depends on s and r 5: end for 6: end for 7: return A\n\nAlgorithm 33 ExpandS(ρ) Samples vectors s1 ∈ Rl and s2 ∈ Rk, each with polynomial coordinates whose coefficients are in the interval [−η, η]. Input: A seed ρ ∈ B64. Output: Vectors s1, s2 of polynomials in R. 1: for r from 0 to l − 1 do 2: ends1 [r] ← RejBoundedPoly(ρ||IntegerToBytes(r, 2)) ▷ seed depends on r 3: for 4: for r from 0 to k − 1 do 5: ends2 [r] ← RejBoundedPoly(ρ||IntegerToBytes(r + l, 2)) ▷ seed depends on r + l 6: for 7: return (s1 , s2 )\n\nAlgorithm 34 ExpandMask(ρ, μ) Samples a vector y ∈ Rl such that each polynomial y[r] has coefficients between −γ1 + 1 and γ1. Input: A seed ρ ∈ B64 and a nonnegative integer μ. Output: Vector y ∈ Rl. 1: c ← 1 + bitlen (γ1 − 1) ▷ γ1 is always a power of 2 2: for r from 0 to l − 1 do 3: ρ′ ← ρ||IntegerToBytes(μ + r, 2) 4: v ← H(ρ′ , 32c) ▷ seed depends on μ + r 5: endy[r] ← BitUnpack(v, γ1 − 1, γ1) 6: for 7: return y\n\n7.4 High-Order and Low-Order Bits and Hints This specification uses the auxiliary functions Power2Round, Decompose, HighBits, LowBits, MakeHint, and UseHint and explicitly defines these functions, where r ∈ Zq, r1, r0 ∈ Z, and h is a Boolean (or equivalently an element of Z2). However, this specification also uses these functions where r, z ∈ Rk, q r1, r0 ∈ Rk, and h ∈ Rk. In this case, the functions are applied coefficientwise to the polynomials in the vectors. In particular: 2\n\n• For r ∈ Rk, define (r , r ) ∈ (Rk)2 = Power2Round(r) so that: q 1 0 ((r1[i])j, (r0[i])j) = Power2Round((r[i])j).\n\n• For r ∈ Rk, define (r , r ) ∈ (Rk)2 = Decompose(r) so that: q 1 0 ((r1[i])j, (r0[i])j) = Decompose((r[i])j).\n\n• For r ∈ Rk, define r = HighBits (r) so that: q 1 (r1[i])j = HighBits((r[i])j).\n\n• For r ∈ Rk, define r = LowBits(r) so that: q 0 (r0[i])j = LowBits((r[i])j).\n\n• For z, r ∈ Rk, define h ∈ Rk = MakeHint(z, r) so that: q 2 (h[i])j = MakeHint((z[i])j, (r[i])j).\n\n• For h ∈ Rk and r ∈ Rk, define r ∈ Rk = UseHint(h, r) so that: 2 q 1 r1[i]j = UseHint((h[i])j, (r[i])j).\n\nThese algorithms are used to support the key compression optimization of ML-DSA. They involve dropping the d low-order bits of each coefficient of the polynomial vector t from the public key using the function Power2Round. However, in order to make this optimization work, additional information called a “hint” needs to be provided in the signature to allow the verifier to reconstruct enough of the information in the dropped public-key bits to verify the signature. Hints are created during signing and used during verification by the functions MakeHint and UseHint, respectively. In the verification of a valid signature, the hint allows the verifier to recover w1 ∈ Rk, which represents w ∈ Rk rounded to a nearby multiple of . The signer directly obtains using the function , q is α = 2γ2 w1 HighBits and the part rounded off (i.e., r0) obtained by LowBits. r0 is used by the signer in the rejection sampling procedure.", "char_len": 3809, "approx_tokens": 952}
{"chunk_id": "NIST.FIPS.204::c00032", "doc_id": "NIST.FIPS.204", "start_page": 49, "end_page": 52, "text": "ovided in the signature to allow the verifier to reconstruct enough of the information in the dropped public-key bits to verify the signature. Hints are created during signing and used during verification by the functions MakeHint and UseHint, respectively. In the verification of a valid signature, the hint allows the verifier to recover w1 ∈ Rk, which represents w ∈ Rk rounded to a nearby multiple of . The signer directly obtains using the function , q is α = 2γ2 w1 HighBits and the part rounded off (i.e., r0) obtained by LowBits. r0 is used by the signer in the rejection sampling procedure. Power2Round decomposes an input r ∈ Zq into integers that represent the high- and low-order bits of r mod q in the straightforward bitwise way, r mod q = r1 ⋅ 2d + r0, where r0 = (r mod q) mod±2d and r1 = (r mod q − r0)/2d. However, for the purpose of computations related to hints, this method of decomposing r has the undesirable property that when r is close to q − 1 or 0, a small rounding error in r can cause r1 to change by more than 1, even accounting for wrap-around. In contrast to other unequal pairs of values of r1 ⋅ 2d and r′ ⋅ 2d, the distance (modq) between ⌊q/2d⌋ ⋅ 2d and 0 may be very small.\n\nTo avoid this problem, this specification defines Decompose, which is similar to Power2Round except:\n\n• r is generally decomposed as r mod q = r1 ⋅ α + r0, where α = 2γ2 is a divisor of q − 1.\n\n• If the straightforward rounding procedure would return (r1 = (q − 1)/α, r0 ∈ [−(α/2) + 1, α/2]), Decompose instead returns (r1 = 0, r0 − 1).\n\nThe functions HighBits and LowBits — which only return r1 and r0, respectively — and MakeHint and UseHint use Decompose. For additional discussion of the mathematical properties of these functions that are relevant to the correctness and security of ML-DSA, see Section 2.4 in [6].\n\nAlgorithm 35 Power2Round(r) Decomposes r into (r1, r0) such that r ≡ r12d + r0 mod q. Input: r ∈ Zq . Output: Integers (r1, r0). 1: r+ ← r mod q 2: r0 ← r+ mod±2d 3: return ((r+ − r0)/2d, r0)\n\nAlgorithm 36 Decompose(r) Decomposes r into (r1, r0) such that r ≡ r1(2γ2) + r0 mod q. Input: r ∈ Zq . Output: Integers (r1, r0). 1: r+ ← r mod q 2: r0 ← r+ mod±(2γ2) 3: if r+ − r0 = q − 1 then 4: r1 ← 0 5: r0 ← r0 − 1 6: else r1 ← (r+ − r0)/(2γ2) 7: end if 8: return (r1, r0)\n\nAlgorithm 37 HighBits(r) Returns r1 from the output of Decompose (r). Input: r ∈ Zq . Output: Integer r1. 1: (r1, r0) ← Decompose(r) 2: return r1\n\nAlgorithm 38 LowBits(r) Returns r0 from the output of Decompose (r). Input: r ∈ Zq . Output: Integer r0. 1: (r1, r0) ← Decompose(r) 2: return r0\n\nAlgorithm 39 MakeHint(z, r) Computes hint bit indicating whether adding z to r alters the high bits of r. Input: z, r ∈ Zq . Output: Boolean. 1: r1 ← HighBits(r) 2: v1 ← HighBits(r + z) 3: return [[r1 ≠ v1]]\n\nAlgorithm 40 UseHint(h, r) Returns the high bits of r adjusted according to hint h. Input: Boolean h, r ∈ Zq . Output: r1 ∈ Z with 0 ≤ r1 ≤ q−1. 2γ2 1: m ← (q − 1)/(2γ2) 2: (r1, r0) ← Decompose(r) 3: if h = 1 and r0 > 0 return (r1 + 1) mod m 4: if h = 1 and r0 ≤ 0 return (r1 − 1) mod m 5: return r1\n\n7.5 NTT and NTT−1\n\nThe following algorithms implement the NTT and its inverse (NTT−1), which is important for efficiency. There are other optimizations that are not included in this standard. In particular, mod q and mod±q are expensive operations whose use can be minimized by using Montgomery Multiplication (see Appendix A). An element of Rq is a polynomial in Zq[X]/(X256 + 1), and an element of Tq is a tuple in Π255 Zq. The j=0 NTT algorithm takes a polynomial w ∈ Rq as input and returns w ∈ Tq. NTT−1 takes w ∈ Tq as input and returns w such that ŵ = NTT(w). This document always distinguishes between elements of Rq and elements of Tq. However, the natural data structure for both of these sets is as an integer array of size 256. This would allow the NTT and NTT−1 algorithms to perform computation in place on an integer array passed by reference.", "char_len": 3965, "approx_tokens": 991}
{"chunk_id": "NIST.FIPS.204::c00033", "doc_id": "NIST.FIPS.204", "start_page": 52, "end_page": 55, "text": "an be minimized by using Montgomery Multiplication (see Appendix A). An element of Rq is a polynomial in Zq[X]/(X256 + 1), and an element of Tq is a tuple in Π255 Zq. The j=0 NTT algorithm takes a polynomial w ∈ Rq as input and returns w ∈ Tq. NTT−1 takes w ∈ Tq as input and returns w such that ŵ = NTT(w). This document always distinguishes between elements of Rq and elements of Tq. However, the natural data structure for both of these sets is as an integer array of size 256. This would allow the NTT and NTT−1 algorithms to perform computation in place on an integer array passed by reference. That optimization is not included in this document. In Section 2.5, ζ = 1753 ∈ Zq, which is a 512th root of unity modulo q. On input w ∈ Rq, the algorithm outputs NTT(w) = (w(ζ0), w(ζ1), ... , w(ζ255)) ∈ Tq, (7.1) where ζi = w(ζ2BitRev8(i)+1) mod q. The values ζBitRev8(k) mod q for k = 1, ... , 255 used in line 10 of Algorithms 41 and 42 are pre-computed into an array zetas[1..255]. The table of zetas is given in Appendix B. If Montgomery Multiplication is used (see Appendix A), then the zetas array would typically be stored in Montgomery form. NTT and NTT−1 use BitRev8, which reverses the order of bits in an 8-bit integer.\n\nAlgorithm 41 NTT(w) Computes the NTT. Input: Polynomial w(X) = ∑255 wjXj ∈ Rq . j=0 Output: w = (w[0], ... , w[255]) ∈ Tq . 1: for j from 0 to 255 do 2: endw[j] ← wj 3: for 4: m ← 0 5: len ← 128 6: while len ≥ 1 do 7: start ← 0 8: while start < 256 do 9: m ← m + 1 10: z ← zetas[m] ▷ z ← ζBitRev8(m) mod q 11: for j from start to start + len − 1 do 12: t ← (z ⋅ w[j + len]) mod q 13: w[j + len] ← (w[j] − t) mod q 14: w[j] ← (w[j] + t) mod q 15: end for 16: start ← start + 2 ⋅ len 17: end while 18: len ← ⌊len/2⌋ 19: end while 20: return ŵ\n\nAlgorithm 42 NTT−1 (w)̂ Computes the inverse of the NTT. Input: w = (w[0], ... , w[255]) ∈ Tq . Output: Polynomial w(X) = ∑255 wjXj ∈ Rq . j=0 1: for j from 0 to 255 do 2: endwj ← w[j] 3: for 4: m ← 256 5: len ← 1 6: while len < 256 do 7: start ← 0 8: while start < 256 do 9: m ← m − 1 10: z ← −zetas[m] ▷ z ← −ζBitRev8(m) mod q 11: for j from start to start + len − 1 do 12: t ← wj 13: wj ← (t + wj+len) mod q 14: wj+len ← (t − wj+len) mod q 15: endwj+len ← (z ⋅ wj+len) mod q 16: for 17: start ← start + 2 ⋅ len 18: end while 19: len ← 2 ⋅ len 20: end while 21: f ← 8347681 ▷ f = 256−1 mod q 22: for j from 0 to 255 do 23: endwj ← (f ⋅ wj) mod q 24: for 25: return w\n\nAlgorithm 43 BitRev8 (m) Transforms a byte by reversing the order of bits in its 8-bit binary expansion. Input: A byte m ∈ [0, 255]. Output: A byte r ∈ [0, 255]. 1: b ← IntegerToBits(m, 8) 2: brev ∈ {0, 1}8 ← (0, ... , 0) 3: for i from 0 to 7 do 4: endbrev [i] ← b [7 − i] 5: for 6: r ← BitsToInteger(brev, 8) 7: return r\n\n7.6 Arithmetic Under NTT The NTT converts elements of the ring Rq (where addition and multiplication are denoted by + and ⋅, respectively) into elements of the ring Tq (where addition and multiplication are denoted by + and ∘, respectively). This section gives explicit algorithms for linear algebra over the ring Tq. The ring Tq is defined to be the direct product ring Π255Zq. Thus, an element a ∈ Tq is an array of length 256, and its elements are denoted by a[0], a[1], ... , i=0 a[255] ∈ Zq.\n\nAlgorithm 44 AddNTT(a,̂ b) Computes the sum a + b of two elements a, b ∈ Tq . Input: a,̂ b ∈ Tq . Output: c ∈ Tq . 1: for i from 0 to 255 do 2: c[i] ← a[i] + b[i] 3: end for 4: return c\n\nAlgorithm 45 MultiplyNTT(a,̂ b) Computes the product a ∘̂ b of two elements a,̂ b ∈ Tq . Input: a,̂ b ∈ Tq . Output: c ∈ Tq . 1: for i from 0 to 255 do 2: c[i] ← a[i] ⋅ b[i] 3: end for 4: return c\n\nAlgorithm 46 AddVectorNTT(v,̂ w)̂ Computes the sum v + w of two vectors v, w over Tq . Input: l ∈ N, v ∈ T l, w ∈ T l. q q Output: u ∈ T l. q 1: for i from 0 to l − 1 do 2: u[i] ← AddNTT(v[i], w[i]) 3: end for 4: return û", "char_len": 3872, "approx_tokens": 968}
{"chunk_id": "NIST.FIPS.204::c00034", "doc_id": "NIST.FIPS.204", "start_page": 55, "end_page": 57, "text": "m 44 AddNTT(a,̂ b) Computes the sum a + b of two elements a, b ∈ Tq . Input: a,̂ b ∈ Tq . Output: c ∈ Tq . 1: for i from 0 to 255 do 2: c[i] ← a[i] + b[i] 3: end for 4: return c\n\nAlgorithm 45 MultiplyNTT(a,̂ b) Computes the product a ∘̂ b of two elements a,̂ b ∈ Tq . Input: a,̂ b ∈ Tq . Output: c ∈ Tq . 1: for i from 0 to 255 do 2: c[i] ← a[i] ⋅ b[i] 3: end for 4: return c\n\nAlgorithm 46 AddVectorNTT(v,̂ w)̂ Computes the sum v + w of two vectors v, w over Tq . Input: l ∈ N, v ∈ T l, w ∈ T l. q q Output: u ∈ T l. q 1: for i from 0 to l − 1 do 2: u[i] ← AddNTT(v[i], w[i]) 3: end for 4: return û\n\nAlgorithm 47 ScalarVectorNTT(c,̂ v)̂ Computes the product c ∘̂ v̂ of a scalar c and a vector v̂ over Tq . Input: c ∈ Tq , l ∈ N, v ∈ T l. q Output: w ∈ T l. q 1: for i from 0 to l − 1 do 2: w[i] ← MultiplyNTT(c, v[i]) 3: end for 4: return ŵ\n\nAlgorithm 48 MatrixVectorNTT(M, v)̂ Computes the product M ∘ v̂ of a matrix M and a vector v̂ over Tq . Input: k, l ∈ N, M ∈ T k×l, v ∈ T l. q q Output: w ∈ T k. q 1: w ← 0k 2: for i from 0 to k − 1 do 3: for j from 0 to l − 1 do 4: w[i] ← AddNTT(w[i], MultiplyNTT(M[i, j], v[j])) 5: end for 6: end for 7: return ŵ\n\nReferences\n\n[1] National Institute of Standards and Technology (2023) Digital signature standard (DSS), (U.S. Depart- ment of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) 186-5. https://doi.org/10.6028/NIST.FIPS.186-5.\n\n[2] Barker E (2020) Guideline for using cryptographic standards in the federal government: Cryptographic mechanisms, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-175B, Rev. 1 [or as amended]. https://doi.org/10.6028/NIST.SP.800-175Br1.\n\n[3] Barker E (2006) Recommendation for obtaining assurances for digital signature applications, National Institute of Standards and Technology, Gaithersburg, MD. NIST Special Publication (SP) 800-89 [or as amended]. https://doi.org/10.6028/NIST.SP.800-89.\n\n[4] Langlois A, Stehlé D (2015) Worst-case to average-case reductions for module lattices. Designs, Codes and Cryptography 75(3):565–599. https://doi.org/10.1007/s10623-014-9938-4.\n\n[5] Bai S, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schwabe P, Seiler G, Stehlé D (2020) CRYSTALS- Dilithium: Algorithm specifications and supporting documentation, Submission to the NIST’s post- quantum cryptography standardization process. Available at https://csrc.nist.gov/Projects/post-qua ntum-cryptography/post-quantum-cryptography-standardization/round-3-submissions.\n\n[6] Bai S, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schwabe P, Seiler G, Stehlé D (2021) CRYSTALS- Dilithium: Algorithm specifications and supporting documentation (Version 3.1). Available at https: //pq-crystals.org/dilithium/data/dilithium-specification-round3-20210208.pdf.\n\n[7] National Institute of Standards and Technology (2015) SHA-3 standard: Permutation-based hash and extendable-output functions, (U.S. Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) 202. https://doi.org/10.6028/NIST.FIPS.202.\n\n[8] National Institute of Standards and Technology (2015) Secure hash standard (SHS), (U.S. Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) 180-4. https://doi.org/10.6028/NIST.FIPS.180-4.\n\n[9] Barker E (2020) Recommendation for key management: Part 1 - general, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev. 5 [or as amended]. https://doi.org/10.6028/NIST.SP.800-57pt1r5.\n\n[10] Lyubashevsky V (2009) Fiat-Shamir with aborts: Applications to lattice and factoring-based signa- tures. Advances in Cryptology – ASIACRYPT 2009, ed Matsui M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 598–616. https://doi.org/10.1007/978-3-642-10366-7_35.", "char_len": 3866, "approx_tokens": 966}
{"chunk_id": "NIST.FIPS.204::c00035", "doc_id": "NIST.FIPS.204", "start_page": 57, "end_page": 58, "text": "rds Publication (FIPS) 180-4. https://doi.org/10.6028/NIST.FIPS.180-4.\n\n[9] Barker E (2020) Recommendation for key management: Part 1 - general, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev. 5 [or as amended]. https://doi.org/10.6028/NIST.SP.800-57pt1r5.\n\n[10] Lyubashevsky V (2009) Fiat-Shamir with aborts: Applications to lattice and factoring-based signa- tures. Advances in Cryptology – ASIACRYPT 2009, ed Matsui M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 598–616. https://doi.org/10.1007/978-3-642-10366-7_35.\n\n[11] Lyubashevsky V (2012) Lattice signatures without trapdoors. EUROCRYPT (Springer), Lecture Notes in Computer Science, Vol. 7237, pp 738–755. https://doi.org/10.1007/978-3-642-29011-4_43.\n\n[12] Güneysu T, Lyubashevsky V, Pöppelmann T (2012) Practical lattice-based cryptography: A signature scheme for embedded systems. CHES (Springer), Vol. 7428, pp 530–547. https://doi.org/10.1007/97 8-3-642-33027-8_31.\n\n[13] Bai S, Galbraith SD (2014) An improved compression technique for signatures based on learning with errors. Topics in Cryptology – CT-RSA 2014, ed Benaloh J (Springer International Publishing, Cham), pp 28–47. https://doi.org/10.1007/978-3-319-04852-9_2.\n\n[14] Cremers C, Düzlü S, Fiedler R, Janson C, Fischlin M (2021) BUFFing signature schemes beyond unforgeability and the case of post-quantum signatures. 2021 IEEE Symposium on Security and Privacy (SP) (IEEE Computer Society, Los Alamitos, CA, USA), pp 1696–1714. https://doi.org/10.110 9/SP40001.2021.00093.\n\n[15] Regev O (2005) On lattices, learning with errors, random linear codes, and cryptography. Proceedings of the Thirty-Seventh Annual ACM Symposium on Theory of Computing STOC ’05 (Association for Computing Machinery, New York, NY, USA), p 84–93. https://doi.org/10.1145/1060590.1060603.\n\n[16] Kiltz E, Lyubashevsky V, Schaffner C (2018) A concrete treatment of Fiat-Shamir signatures in the quantum random-oracle model. Advances in Cryptology – EUROCRYPT 2018, eds Nielsen JB, Rijmen V (Springer International Publishing, Cham), pp 552–586. https://doi.org/10.1007/978-3-319-78372 -7_18.\n\n[17] Barker E, Barker W (2019) Recommendation for key management: Part 2 - best practices for key management organizations, National Institute of Standards and Technology, Gaithersburg, MD. NIST Special Publication (SP) 800-57 Part 2, Rev. 1. https://doi.org/10.6028/NIST.SP.800-57pt2r1.\n\n[18] Barker E, Dang Q (2019) Recommendation for key management: Part 3 - application-specific key management guidance, National Institute of Standards and Technology, Gaithersburg, MD. NIST Special Publication (SP) 800-57 Part 3, Rev. 1. http://doi.org/10.6028/NIST.SP.800-57pt3r1.\n\n[19] Barker E, Kelsey J (2015) Recommendation for random number generation using deterministic random bit generators, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90A, Rev. 1. https://doi.org/10.6028/NIST.SP.800-90Ar1.\n\n[20] Sönmez Turan M, Barker E, Kelsey J, McKay K, Baish M, Boyle M (2018) Recommendation for the entropy sources used for random bit generation, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90B. https://doi.org/10.6028/NIST.SP.800-90B.\n\n[21] Barker E, Kelsey J, McKay K, Roginsky A, Turan MS (2024) Recommendation for random bit generator (RBG) constructions, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90C 4pd. https://doi.org/10.6028/NIST.SP.800-90C.4pd.\n\n[22] Bruinderink LG, Pessl P (2018) Differential fault attacks on deterministic lattice signatures. IACR Transactions on Cryptographic Hardware and Embedded Systems (3):21–43. https://doi.org/10.131 54/tches.v2018.i3.21-43.", "char_len": 3818, "approx_tokens": 954}
{"chunk_id": "NIST.FIPS.204::c00036", "doc_id": "NIST.FIPS.204", "start_page": 58, "end_page": 60, "text": "ersburg, MD), NIST Special Publication (SP) 800-90B. https://doi.org/10.6028/NIST.SP.800-90B.\n\n[21] Barker E, Kelsey J, McKay K, Roginsky A, Turan MS (2024) Recommendation for random bit generator (RBG) constructions, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90C 4pd. https://doi.org/10.6028/NIST.SP.800-90C.4pd.\n\n[22] Bruinderink LG, Pessl P (2018) Differential fault attacks on deterministic lattice signatures. IACR Transactions on Cryptographic Hardware and Embedded Systems (3):21–43. https://doi.org/10.131 54/tches.v2018.i3.21-43.\n\n[23] Poddebniak D, Somorovsky J, Schinzel S, Lochter M, Rösler P (2018) Attacking deterministic signature schemes using fault attacks. 2018 IEEE European Symposium on Security and Privacy (EuroS&P) (IEEE), pp 338–352. https://doi.org/10.1109/EuroSP.2018.00031.\n\n[24] Samwel N, Batina L, Bertoni G, Daemen J, Susella R (2018) Breaking ed25519 in wolfssl. Topics in Cryptology–CT-RSA 2018: The Cryptographers’ Track at the RSA Conference 2018, San Francisco, CA, USA, April 16-20, 2018, Proceedings (Springer), pp 1–20. https://doi.org/10.1007/978-3-319-76953 -0_1.\n\n[25] Kelsey J, Chang S, Perlner R (2016) SHA-3 Derived Functions: cSHAKE, KMAC, TupleHash and Parallel- Hash, (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-185 [or as amended]. https://doi.org/10.6028/NIST.SP.800-185.\n\n[26] National Institute of Standards and Technology (2016) Submission requirements and evaluation criteria for the post-quantum cryptography standardization process. Available at https://csrc.nist.go\n\nv/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-201 6.pdf.\n\n[27] Alagic G, Apon D, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Smith-Tone D (2022) Status report on the third round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8413. https://doi.org/10.6028/NIST.IR.8413-upd1.\n\n[28] Avanzi R, Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2020) CRYSTALS-Kyber algorithm specifications and supporting documentation, 3rd Round submission to the NIST’s post-quantum cryptography standardization process. Available at https://csrc.nist.gov/Projects/post-quantum-cryptography/post-quantum-cryptography-standar dization/round-3-submissions.\n\n[29] Housley R (2009) Cryptographic Message Syntax (CMS), Internet Engineering Task Force (IETF) request for comments (RFC) 5652, https://doi.org/10.17487/RFC5652.\n\n[30] Schnorr C (1990) Efficient identification and signatures for smart cards. Advances in Cryptology — CRYPTO’ 89 Proceedings, ed Brassard G (Springer New York, New York, NY), pp 239–252. https: //doi.org/10.1007/0-387-34805-0_22.\n\n[31] Josefsson S, Liusvaara I (2017) Edwards-Curve Digital Signature Algorithm (EdDSA), RFC 8032. https: //doi.org/10.17487/RFC8032.\n\n[32] Lyubashevsky V (2021) Round 3 Official Comment: CRYSTALS-DILITHIUM. Available at https://groups .google.com/a/list.nist.gov/g/pqc-forum/c/BjfjRMIdnhM/m/W7kkVOFDBAAJ.\n\n[33] Hamburg M (2024) Dilithium hint unpacking. Available at https://groups.google.com/a/list.nist.gov/ g/pqc-forum/c/TQo-qFbBO1A/m/YcYKjMblAAAJ.\n\n[34] Mattsson (on behalf of Sönke Jendral) JP (2024) Dilithium hint unpacking. Available at https://grou ps.google.com/a/list.nist.gov/g/pqc-forum/c/TQo-qFbBO1A/m/sLjseYlSAwAJ.\n\n[35] Lee S (2024) Updates for FIPS 203. Available at https://groups.google.com/a/list.nist.gov/g/pqc-for um/c/Rb0nFvfFTEQ/m/lw-k7tVdBQAJ.\n\nAppendix A — Montgomery Multiplication", "char_len": 3761, "approx_tokens": 940}
{"chunk_id": "NIST.FIPS.204::c00037", "doc_id": "NIST.FIPS.204", "start_page": 59, "end_page": 61, "text": "ilable at https://groups .google.com/a/list.nist.gov/g/pqc-forum/c/BjfjRMIdnhM/m/W7kkVOFDBAAJ.\n\n[33] Hamburg M (2024) Dilithium hint unpacking. Available at https://groups.google.com/a/list.nist.gov/ g/pqc-forum/c/TQo-qFbBO1A/m/YcYKjMblAAAJ.\n\n[34] Mattsson (on behalf of Sönke Jendral) JP (2024) Dilithium hint unpacking. Available at https://grou ps.google.com/a/list.nist.gov/g/pqc-forum/c/TQo-qFbBO1A/m/sLjseYlSAwAJ.\n\n[35] Lee S (2024) Updates for FIPS 203. Available at https://groups.google.com/a/list.nist.gov/g/pqc-for um/c/Rb0nFvfFTEQ/m/lw-k7tVdBQAJ.\n\nAppendix A — Montgomery Multiplication\n\nThis document uses modular multiplications of the form a ⋅ b modulo q. This is an expensive operation that is often sped up in practice through the use of Montgomery Multiplication. If a is an integer modulo q, then its Montgomery form with multiplier 232 is r ≡ a ⋅ 232 mod q. 13 Suppose that two integers u and v modulo q are in Montgomery form. Their product modulo q is c = u ⋅ v ⋅ 2−32, which is also in Montgomery form. If the integer product of u and v does not overflow a 64-bit signed integer, then one can compute c by first performing the integer multiplication u ⋅ v and then “reducing” the product by multiplying by 2−32 modulo q. This last operation can be done efficiently as follows. The MontgomeryReduce function takes an integer a with absolute value at most 231q as input. It returns an integer r such that r = a ⋅ 2−32 mod q. The output is in Montgomery form with multiplier 232 mod q. An implementation would typically input a 64-bit input and return a 32-bit output. The “modulo 232” operation simply extracts the 32 least significant bits of a 64-bit value. The value (a − t ⋅ q) on line 3 is an integer divisible by 232. Therefore, the division consists of simply taking the most significant 32 bits of a 64-bit value. Extracting the four low- or high-order bytes is often done using typecasting.\n\nAlgorithm 49 MontgomeryReduce(a) Computes a ⋅ 2−32 mod q. Input: Integer a with −231q ≤ a ≤ 231q. Output: r ≡ a ⋅ 2−32 mod q. 1: QINV ← 58728449 ▷ the inverse of q modulo 232 2: t ← ((a mod 232) ⋅ QINV) mod 232 3: r ← (a − t ⋅ q)/232 4: return r\n\nWith this algorithm, the modular product of a and b is c = MontgomeryReduce(a ⋅ b), where a, b, and c are in Montgomery form. The return value of the algorithm is not necessarily less than q in absolute value, but it is less than 2q in absolute value. This is not a concern in practice since the objective of Montgomery Multiplication is to efficiently work with modular values that fit in a 32-bit register. If necessary, the result can be normalized to an integer in (−q, q) using a comparison and an integer addition. Converting an integer modulo q to Montgomery form by multiplying by 232 modulo q is an expensive operation. When a sequence of modular operations is to be performed, the operands are converted once to Montgomery form. The operations are then performed, and the factor 232 is extracted from the final result.\n\n13This section does not distinguish between different versions of the “ mod ” operator. There are three such versions of “x = a modulo q”: i) x ∈ [0, q − 1]; ii) x ∈ [−⌈q/2⌉, ⌊q/2⌋] ; iii) x ∈ [−q + 1, q − 1]. The last version corresponds to the ‵‵%′′ operator in most programming languages.\n\nAppendix B — Zetas Array\n\nThe values ζBitRev8(k) mod q for k = 1, ... , 255 used in the NTT Algorithms 41 and 42 may be pre-computed and stored in an array zetas[1..255]. This table of zetas is given below.", "char_len": 3498, "approx_tokens": 874}
{"chunk_id": "NIST.FIPS.204::c00038", "doc_id": "NIST.FIPS.204", "start_page": 60, "end_page": 62, "text": "ry form. The operations are then performed, and the factor 232 is extracted from the final result.\n\n13This section does not distinguish between different versions of the “ mod ” operator. There are three such versions of “x = a modulo q”: i) x ∈ [0, q − 1]; ii) x ∈ [−⌈q/2⌉, ⌊q/2⌋] ; iii) x ∈ [−q + 1, q − 1]. The last version corresponds to the ‵‵%′′ operator in most programming languages.\n\nAppendix B — Zetas Array\n\nThe values ζBitRev8(k) mod q for k = 1, ... , 255 used in the NTT Algorithms 41 and 42 may be pre-computed and stored in an array zetas[1..255]. This table of zetas is given below. zetas[0..255] = { 0, 4808194, 3765607, 3761513, 5178923, 5496691, 5234739, 5178987, 7778734, 3542485, 2682288, 2129892, 3764867, 7375178, 557458, 7159240, 5010068, 4317364, 2663378, 6705802, 4855975, 7946292, 676590, 7044481, 5152541, 1714295, 2453983, 1460718, 7737789, 4795319, 2815639, 2283733, 3602218, 3182878, 2740543, 4793971, 5269599, 2101410, 3704823, 1159875, 394148, 928749, 1095468, 4874037, 2071829, 4361428, 3241972, 2156050, 3415069, 1759347, 7562881, 4805951, 3756790, 6444618, 6663429, 4430364, 5483103, 3192354, 556856, 3870317, 2917338, 1853806, 3345963, 1858416, 3073009, 1277625, 5744944, 3852015, 4183372, 5157610, 5258977, 8106357, 2508980, 2028118, 1937570, 4564692, 2811291, 5396636, 7270901, 4158088, 1528066, 482649, 1148858, 5418153, 7814814, 169688, 2462444, 5046034, 4213992, 4892034, 1987814, 5183169, 1736313, 235407, 5130263, 3258457, 5801164, 1787943, 5989328, 6125690, 3482206, 4197502, 7080401, 6018354, 7062739, 2461387, 3035980, 621164, 3901472, 7153756, 2925816, 3374250, 1356448, 5604662, 2683270, 5601629, 4912752, 2312838, 7727142, 7921254, 348812, 8052569, 1011223, 6026202, 4561790, 6458164, 6143691, 1744507, 1753, 6444997, 5720892, 6924527, 2660408, 6600190, 8321269, 2772600, 1182243, 87208, 636927, 4415111, 4423672, 6084020, 5095502, 4663471, 8352605, 822541, 1009365, 5926272, 6400920, 1596822, 4423473, 4620952, 6695264, 4969849, 2678278, 4611469, 4829411, 635956, 8129971, 5925040, 4234153, 6607829, 2192938, 6653329, 2387513, 4768667, 8111961, 5199961, 3747250, 2296099, 1239911, 4541938, 3195676, 2642980, 1254190, 8368000, 2998219, 141835, 8291116, 2513018, 7025525, 613238, 7070156, 6161950, 7921677, 6458423, 4040196, 4908348, 2039144, 6500539, 7561656, 6201452, 6757063, 2105286, 6006015, 6346610, 586241, 7200804, 527981, 5637006, 6903432, 1994046, 2491325, 6987258, 507927, 7192532, 7655613, 6545891, 5346675, 8041997, 2647994, 3009748, 5767564, 4148469, 749577, 4357667, 3980599, 2569011, 6764887, 1723229, 1665318, 2028038, 1163598, 5011144, 3994671, 8368538, 7009900, 3020393, 3363542, 214880, 545376, 7609976, 3105558, 7277073, 508145, 7826699, 860144, 3430436, 140244, 6866265, 6195333, 3123762, 2358373, 6187330, 5365997, 6663603, 2926054, 7987710, 8077412, 3531229, 4405932, 4606686, 1900052, 7598542, 1054478, 7648983 }\n\nAppendix C — Loop Bounds\n\nThere are four algorithms in this standard with loops that iterate an indeterminate number of times, though the expected number of iterations is a small constant in each case. Three of the four algorithms involve sampling from the output of an XOF, where the amount of output required from the XOF is proportional to the number of iterations that are performed. Implementations should not bound the number of iterations in these loops or the amount of output that is extracted from the XOFs when executing these functions.14 If an implementation bounds the number of iterations or the number of bytes that may be extracted from the XOF, it shall not use a limit lower than those presented in Table 3. The limits yield a probability of approximately 2−256 (or less) of being reached in a correct implementation of this standard. The probability is calculated under standard assumptions about the output distributions of XOFs and hash functions.\n\nTable 3. While loop and XOF output limits for a 2−256 or less probability of failure", "char_len": 3944, "approx_tokens": 986}
{"chunk_id": "NIST.FIPS.204::c00039", "doc_id": "NIST.FIPS.204", "start_page": 62, "end_page": 63, "text": "ops or the amount of output that is extracted from the XOFs when executing these functions.14 If an implementation bounds the number of iterations or the number of bytes that may be extracted from the XOF, it shall not use a limit lower than those presented in Table 3. The limits yield a probability of approximately 2−256 (or less) of being reached in a correct implementation of this standard. The probability is calculated under standard assumptions about the output distributions of XOFs and hash functions.\n\nTable 3. While loop and XOF output limits for a 2−256 or less probability of failure\n\nAlgorithm Minimum allowable limit Minimum allowable limit (Loop iterations) (XOF output bytes) ML-DSA.Sign_internal 814 N/A RejBoundedPoly 481 481 RejNTTPoly 298 894 SampleInBall 121 221\n\nImplementations may limit the number of iterations of a while loop or the number of bytes drawn from the XOF to not exceed the maximum values in Table 3. If this option is used and the maximum number of iterations or XOF output bytes is exceeded, the algorithm shall destroy all intermediate results. If a return value or exception is produced, it shall be the same for any execution in which the maximum number of iterations or output bytes is exceeded. There is essentially no performance penalty for using a larger than necessary limit, as the limit will only be reached on a faulty execution of the loop. Because of this, limits were chosen that lower-bound the probability of reaching them to 2−256. ML-DSA.Sign_internal Table 1 contains the expected repetitions in the rejection sampling loop of ML-DSA.Sign_internal. These are 4.25, 5.1, and 3.85 for Categories 2, 3, and 5, respectively. Therefore, the probability that the number of repetitions exceeds n is less than or equal to ( 5.1−1)n for all categories. Solving ( 5.1−1)n ≤ 2−256 yields n = 814. 5.1 5.1 RejBoundedPoly Let X be the number of coefficients generated in n iterations of the while loop of RejBoundedPoly15. Then X is Binomial(2n, θ), where θ is either 9 or 15 , depending on the parameter η. For θ = 9 , 256 coefficient16 16 16 the probability that fewer than s are generated in 481 iterations of the main loop in RejBoundedPoly is less than 2−256. Each iteration consumes one byte of output from H.\n\n14RejBoundedPoly, RejNTTPoly, and SampleInBall use the incremental APIs described in Section 3.7 in order to extract the amount of output needed from the XOFs, given that the amount needed is not known in advance. 15Note that 0, 1, or 2 coefficients are generated in each iteration.\n\nRejNTTPoly The number of valid coefficients generated in n calls to G.Squeeze in RejNTTPoly is Binomial(n, 2−23q). It follows that after 298 calls, the probability of failure is less than 2−256. Each iteration consumes three bytes of output from G. SampleInBall Step 9 in SampleInBall is executed every time a pseudorandom byte is greater than a value i in the range [256 − τ , 255]. The parameter τ is 39, 49, and 60 for categories 2, 3, and 5, respectively. Therefore, the probability that this step is executed more than n times in a single iteration of the for loop is less than or equal to ( 59 )n ≤ ( τ )n. Solving ( 59 )n ≤ 2−256 yields a bound of n = 121 for the while loop on step 8 of 256 256 256 SampleInBall. Each iteration consumes one byte of output from H. Each call to SampleInBall extracts eight bytes from H and then performs τ iterations of the for loop, each of which extracts an indeterminate amount of data from H. The probability that more than n bytes of output will be required from H during an execution of SampleInBall for a given value of τ is\n\n⎧ 1 if n ≤ 8 P (n, τ) = { 0 if τ = 1 and n > 8 . ⎨ { ( 257−τ ) P (n − 1, τ − 1) + ( τ−1) P (n − 1, τ) if τ > 1 and n > 8 ⎩ 256 256", "char_len": 3754, "approx_tokens": 938}
{"chunk_id": "NIST.FIPS.204::c00040", "doc_id": "NIST.FIPS.204", "start_page": 63, "end_page": 64, "text": "( τ )n. Solving ( 59 )n ≤ 2−256 yields a bound of n = 121 for the while loop on step 8 of 256 256 256 SampleInBall. Each iteration consumes one byte of output from H. Each call to SampleInBall extracts eight bytes from H and then performs τ iterations of the for loop, each of which extracts an indeterminate amount of data from H. The probability that more than n bytes of output will be required from H during an execution of SampleInBall for a given value of τ is\n\n⎧ 1 if n ≤ 8 P (n, τ) = { 0 if τ = 1 and n > 8 . ⎨ { ( 257−τ ) P (n − 1, τ − 1) + ( τ−1) P (n − 1, τ) if τ > 1 and n > 8 ⎩ 256 256\n\nP (n, 60) is less than 2−256 when n is 221 or greater. Implementations may limit the number of bytes extracted from H to n ≥ 221. Such implementations must stop the execution of SampleInBall, return a constant that represents an error and no other output, and destroy all intermediate results after n bytes of output have been consumed.\n\nAppendix D — Differences from the CRYSTALS-DILITHIUM Submission\n\nML-DSA is derived from Version 3.1 of CRYSTALS-DILITHIUM [6]. Version 3.1 differs slightly from the most recent version that appears on the NIST website (i.e., Version 3 CRYSTALS-DILITHIUM [5]). Appendices D.1, D.2, and D.3 document the differences between Versions 3 and 3.1, the differences between Version 3.1 and the initial public draft of the ML-DSA, and the differences between the initial public draft and the ML-DSA standard as published in this document, respectively.\n\nD.1 Differences Between Version 3.1 and the Round 3 Version of CRYSTALS- DILITHIUM The lengths of the variables ρ′ (private random seed) and μ (message representative) in the signing algorithm were increased from 384 to 512 bits. The increase in the length of μ corrects a security flaw that appeared in the third-round submission, where a collision attack against SHAKE256 with a 384-bit output would make it so that parameters targeting NIST security strength category 5 could only meet category 4 [32]. Additionally, the length of the variable tr (the hash of the public key) was reduced from 384 to 256 bits. In key generation, the variable ς was relabeled as ρ′ and increased in size from 256 bits to 512 bits.\n\nD.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft In order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases the length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c. In Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string. The draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed input while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not strongly existentially unforgeable [34].", "char_len": 3459, "approx_tokens": 864}
{"chunk_id": "NIST.FIPS.204::c00041", "doc_id": "NIST.FIPS.204", "start_page": 64, "end_page": 65, "text": "it random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string. The draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed input while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not strongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions\n\nthat call an internal function corresponding to the signing or verification functions from the draft FIPS. Domain separation is included in the input to the internal function (see Algorithms 2, 3, 4, 5, 7, and 8). To simplify APIs and for testing purposes, this document also introduced a similar external/internal split for key generation (see Algorithms 1 and 6), but this is a purely editorial change, as the external key generation algorithm is functionally equivalent to the key-generation algorithm from the draft FIPS. Finally, to offer misuse resistance against the possibility that keys for different parameter sets might be expanded from the same seed [35], domain separation was added to line 1 of Algorithm 6.", "char_len": 2142, "approx_tokens": 535}
{"chunk_id": "NIST.FIPS.205::c00000", "doc_id": "NIST.FIPS.205", "start_page": 1, "end_page": 4, "text": "FIPS 205\n\nFederal Information Processing Standards Publication\n\nStateless Hash-Based Digital Signature Standard\n\nCategory: Computer Security Subcategory: Cryptography\n\nInformation Technology Laboratory National Institute of Standards and Technology Gaithersburg, MD 20899-8900\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.FIPS.205\n\nPublished: August 13, 2024\n\nU.S. Department of Commerce Gina M. Raimondo, Secretary\n\n0 National Institute of Standards and Technology Laurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology\n\nCheck for updates\n\nForeword\n\nThe Federal Information Processing Standards Publication (FIPS) series of the National Institute of Standards and Technology (NIST) is the official series of publications relating to standards and guidelines developed under 15 U.S.C. 278g-3, and issued by the Secretary of Commerce under 40 U.S.C. 11331. Comments concerning this Federal Information Processing Standard publication are welcomed and should be submitted using the contact information in the “Inquiries and comments” clause of the announcement section.\n\nKevin M. Stine, Director Information Technology Laboratory\n\nAbstract This standard specifies the stateless hash-based digital signature algorithm (SLH-DSA). Digital signatures are used to detect unauthorized modifications to data and to authenticate the identity of the signatory. In addition, the recipient of signed data can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. SLH-DSA is based on SPHINCS+, which was selected for standardization as part of the NIST Post-Quantum Cryptography Standardization process.\n\nKeywords: computer security; cryptography; digital signatures; Federal Information Processing Standards; hash-based signatures; post-quantum; public-key cryptography.\n\nFederal Information Processing Standards Publication 205\n\nPublished: August 13, 2024 Effective: August 13, 2024\n\nAnnouncing the Stateless Hash-Based Digital Signature Standard\n\nFederal Information Processing Standards (FIPS) publications are developed by the National Institute of Standards and Technology (NIST) under 15 U.S.C. 278g-3 and issued by the Secretary of Commerce under 40 U.S.C. 11331. 1. Name of Standard. Stateless Hash-Based Digital Signature Standard (FIPS 205). 2. Category of Standard. Computer Security. Subcategory. Cryptography. 3. Explanation. This standard specifies a stateless hash-based digital signature scheme (SLH- DSA) for applications that require a digital signature rather than a written signature. Additional digital signature schemes are specified and approved in other NIST Special Publications and FIPS publications (e.g., FIPS 186-5 [1]). A digital signature is represented in a computer as a string of bits and computed using a set of rules and parameters that allow the identity of the signatory and the integrity of the data to be verified. Digital signatures may be generated on both stored and transmitted data. Signature generation uses a private key to generate a digital signature. Signature verification uses a public key that corresponds to but is not the same as the private key. Each signatory possesses a private and public key pair. Public keys may be known by the public, but private keys must be kept secret. Anyone can verify the signature by employing the signatory’s public key. Only the user who possesses the private key can perform signature generation. The digital signature is provided to the intended verifier along with the signed data. The verifying entity verifies the signature by using the claimed signatory’s public key. Similar procedures may be used to generate and verify signatures for both stored and transmitted data.", "char_len": 3921, "approx_tokens": 980}
{"chunk_id": "NIST.FIPS.205::c00001", "doc_id": "NIST.FIPS.205", "start_page": 4, "end_page": 5, "text": "is not the same as the private key. Each signatory possesses a private and public key pair. Public keys may be known by the public, but private keys must be kept secret. Anyone can verify the signature by employing the signatory’s public key. Only the user who possesses the private key can perform signature generation. The digital signature is provided to the intended verifier along with the signed data. The verifying entity verifies the signature by using the claimed signatory’s public key. Similar procedures may be used to generate and verify signatures for both stored and transmitted data. This standard specifies several parameter sets for SLH-DSA that are approved for use. Addi- tional parameter sets may be specified and approved in future NIST Special Publications. 4. Approving Authority. Secretary of Commerce. 5. Maintenance Agency. Department of Commerce, National Institute of Standards and Tech- nology, Information Technology Laboratory (ITL). 6. Applicability. This standard is applicable to all federal departments and agencies for the protection of sensitive unclassified information that is not subject to section 2315 of Title 10, United States Code, or section 3502 (2) of Title 44, United States Code. Either this standard, FIPS 204, FIPS 186-5, or NIST Special Publication 800-208 shall be used in designing and implementing public-key-based signature systems that federal departments and agencies op- erate or that are operated for them under contract. In the future, additional digital signature\n\ni\n\nschemes may be specified and approved in FIPS publications or NIST Special Publications. The adoption and use of this standard are available to private and commercial organizations. 7. Applications. A digital signature algorithm allows an entity to authenticate the integrity of signed data and the identity of the signatory. The recipient of a signed message can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. A digital signature algorithm is intended for use in electronic mail, electronic funds transfer, electronic data interchange, software distribution, data storage, and other applications that require data integrity assurance and data origin authentication. 8. Implementations. A digital signature algorithm may be implemented in software, firmware, hardware, or any combination thereof. NIST will develop a validation program to test imple- mentations for conformance to the algorithms in this standard. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent process. In other words, different procedures that produce the correct output for every input are permitted. Information about validation programs is available at https://csrc.nist.gov/projects/cmvp. Examples for digital signature algorithms are available at https://csrc.nist.gov/projects/cryptographic-standards- and-guidelines/example-values. Agencies are advised that digital signature key pairs shall not be used for other purposes. 9. Other Approved Security Functions. Digital signature implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Fed- eral Government-sensitive information. Approved cryptographic algorithms and techniques include those that are either: a. Specified in a Federal Information Processing Standard (FIPS) publication, b. Adopted in a FIPS or NIST recommendation, or c. Specified in the list of approved security functions in SP 800-140C. 10. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls.", "char_len": 3877, "approx_tokens": 969}
{"chunk_id": "NIST.FIPS.205::c00002", "doc_id": "NIST.FIPS.205", "start_page": 5, "end_page": 7, "text": "Functions. Digital signature implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Fed- eral Government-sensitive information. Approved cryptographic algorithms and techniques include those that are either: a. Specified in a Federal Information Processing Standard (FIPS) publication, b. Adopted in a FIPS or NIST recommendation, or c. Specified in the list of approved security functions in SP 800-140C. 10. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with these federal regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 11. Patents. The algorithm in this standard may be covered by U.S. or foreign patents. 12. Implementation Schedule. This standard becomes effective immediately upon final publica- tion. 13. Specifications. Federal Information Processing Standard (FIPS) 205, Stateless Hash-Based Digital Signature Standard (affixed).\n\nii\n\n14. Qualifications. The security of a digital signature system depends on the secrecy of the signatory’s private keys. Signatories shall, therefore, guard against the disclosure of their private keys. While it is the intent of this standard to specify general security requirements for generating digital signatures, conformance to this standard does not ensure that a particular implementation is secure. It is the responsibility of an implementer to ensure that any module that implements a digital signature capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The re- sponsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. Since a standard of this nature must be flexible enough to adapt to advancements and innovations in science and technology, this standard will be reviewed every five years in order to assess its adequacy. 15. Waiver Procedure. The Federal Information Security Management Act (FISMA) does not allow for waivers to Federal Information Processing Standards (FIPS) that are made mandatory by the Secretary of Commerce. 16. Where to Obtain Copies of the Standard. This publication is available by accessing https: //csrc.nist.gov/publications. Other computer security publications are available at the same website. 17. How to Cite This Publication. NIST has assigned NIST FIPS 205 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Stateless Hash-Based Dig- ital Signature Standard. (Department of Commerce, Washington, D.C.), Fed- eral Information Processing Standards Publication (FIPS) NIST FIPS 205. https: //doi.org/10.6028/NIST.FIPS.205 18. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-205-comments@nist.gov.\n\niii\n\nFederal Information Processing Standards Publication 205\n\nStateless Specification for the Hash-Based Digital Signature Standard\n\nTable of Contents\n\n1 Introduction 1 1.1 Purpose and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n\n2 Glossary of Terms, Acronyms, and Symbols 2 2.1 Terms and Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2.2 Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.3 Mathematical Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5", "char_len": 3978, "approx_tokens": 994}
{"chunk_id": "NIST.FIPS.205::c00003", "doc_id": "NIST.FIPS.205", "start_page": 7, "end_page": 9, "text": "05\n\nStateless Specification for the Hash-Based Digital Signature Standard\n\nTable of Contents\n\n1 Introduction 1 1.1 Purpose and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n\n2 Glossary of Terms, Acronyms, and Symbols 2 2.1 Terms and Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2.2 Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.3 Mathematical Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\n3 Overview of the SLH-DSA Signature Scheme 7 3.1 Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2 Implementation Considerations . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n4 Functions and Addressing 11 4.1 Hash Functions and Pseudorandom Functions . . . . . . . . . . . . . . . . . 11 4.2 Addresses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 4.3 Member Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4.4 Arrays, Byte Strings, and Integers . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n5 Winternitz One-Time Signature Plus Scheme 17 5.1 WOTS+ Public-Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 18 5.2 WOTS+ Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 19 5.3 Computing a WOTS+ Public Key From a Signature . . . . . . . . . . . . . . . 21\n\n6 eXtended Merkle Signature Scheme (XMSS) 22 6.1 Generating a Merkle Hash Tree . . . . . . . . . . . . . . . . . . . . . . . . . 22 6.2 Generating an XMSS Signature . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6.3 Computing an XMSS Public Key From a Signature . . . . . . . . . . . . . . . . 25\n\n7 The SLH-DSA Hypertree 26 iv\n\n7.1 Hypertree Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . 26 7.2 Hypertree Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n8 Forest of Random Subsets (FORS) 29 8.1 Generating FORS Secret Values . . . . . . . . . . . . . . . . . . . . . . . . . . 29 8.2 Generating a Merkle Hash Tree . . . . . . . . . . . . . . . . . . . . . . . . . 30 8.3 Generating a FORS Signature . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 8.4 Computing a FORS Public Key From a Signature . . . . . . . . . . . . . . . . . 31\n\n9 SLH-DSA Internal Functions 33 9.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 9.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 34 9.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n10 SLH-DSA External Functions 37 10.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 10.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 37 10.2.1 Pure SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 38 10.2.2 HashSLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 39 10.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n11 Parameter Sets 43 11.1 SLH-DSA Using SHAKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 11.2 SLH-DSA Using SHA2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 11.2.1 SLH-DSA Using SHA2 for Security Category 1 . . . . . . . . . . . . . . . 45 11.2.2 SLH-DSA Using SHA2 for Security Categories 3 and 5 . . . . . . . . . . 46\n\nReferences 47\n\nAppendix A — Differences From the SPHINCS+ Submission 51 A.1 Changes From FIPS 205 Initial Public Draft . . . . . . . . . . . . . . . . . . . . 51\n\nv\n\nList of Tables\n\nTable 1 Member functions for addresses . . . . . . . . . . . . . . . . . . . . . . 14 Table 2 SLH-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . 43 Table 3 Member functions for compressed addresses . . . . . . . . . . . . . . . 45\n\nList of Figures", "char_len": 3994, "approx_tokens": 998}
{"chunk_id": "NIST.FIPS.205::c00004", "doc_id": "NIST.FIPS.205", "start_page": 8, "end_page": 10, "text": "SHA2 for Security Category 1 . . . . . . . . . . . . . . . 45 11.2.2 SLH-DSA Using SHA2 for Security Categories 3 and 5 . . . . . . . . . . 46\n\nReferences 47\n\nAppendix A — Differences From the SPHINCS+ Submission 51 A.1 Changes From FIPS 205 Initial Public Draft . . . . . . . . . . . . . . . . . . . . 51\n\nv\n\nList of Tables\n\nTable 1 Member functions for addresses . . . . . . . . . . . . . . . . . . . . . . 14 Table 2 SLH-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . 43 Table 3 Member functions for compressed addresses . . . . . . . . . . . . . . . 45\n\nList of Figures\n\nFigure 1 An SLH-DSA signature . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Figure 2 Address (ADRS) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 Figure 3 WOTS+ hash address . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 Figure 4 WOTS+ public-key compression address . . . . . . . . . . . . . . . . . 12 Figure 5 Hash tree address . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 Figure 6 FORS tree address . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 Figure 7 FORS tree roots compression address . . . . . . . . . . . . . . . . . . . 13 Figure 8 WOTS+ key generation address . . . . . . . . . . . . . . . . . . . . . . 14 Figure 9 FORS key generation address . . . . . . . . . . . . . . . . . . . . . . . 14 Figure 10 WOTS+ signature data format . . . . . . . . . . . . . . . . . . . . . . . 19 Figure 11 XMSS signature data format . . . . . . . . . . . . . . . . . . . . . . . . 22 Figure 12 Merkle hash tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 Figure 13 HT signature data format . . . . . . . . . . . . . . . . . . . . . . . . . 26 Figure 14 FORS signature data format . . . . . . . . . . . . . . . . . . . . . . . . 29 Figure 15 SLH-DSA private key . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Figure 16 SLH-DSA public key . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Figure 17 SLH-DSA signature data format . . . . . . . . . . . . . . . . . . . . . . 34 Figure 18 Compressed address (ADRSc) . . . . . . . . . . . . . . . . . . . . . . 45\n\nList of Algorithms Algorithm 1 gen_len2 (n, lgw) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 Algorithm 2 toInt(X, n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Algorithm 3 toByte(x, n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Algorithm 4 base_2b(X, b, out_len) . . . . . . . . . . . . . . . . . . . . . . . . 16 Algorithm 5 chain(X, i, s, PK.seed, ADRS) . . . . . . . . . . . . . . . . . . . 18 Algorithm 6 wots_pkGen(SK.seed, PK.seed, ADRS) . . . . . . . . . . . . . . 18 Algorithm 7 wots_sign(M, SK.seed, PK.seed, ADRS) . . . . . . . . . . . . . 20 Algorithm 8 wots_pkFromSig(sig, M, PK.seed, ADRS) . . . . . . . . . . . . . 21 Algorithm 9 xmss_node(SK.seed, i, z, PK.seed, ADRS) . . . . . . . . . . . . 23 Algorithm 10 xmss_sign(M, SK.seed, idx, PK.seed, ADRS) . . . . . . . . . . . 24 Algorithm 11 xmss_pkFromSig(idx, SIGXMSS, M, PK.seed, ADRS) . . . . . . . 25 Algorithm 12 ht_sign(M, SK.seed, PK.seed, idxtree, idxleaf ) . . . . . . . . . . 27 Algorithm 13 ht_verify(M, SIGHT, PK.seed, idxtree, idxleaf , PK.root) . . . . . . 28 Algorithm 14 fors_skGen(SK.seed, PK.seed, ADRS, idx) . . . . . . . . . . . . 29\n\nvi\n\nAlgorithm 15 fors_node(SK.seed, i, z, PK.seed, ADRS) . . . . . . . . . . . . . 30 Algorithm 16 fors_sign(md, SK.seed, PK.seed, ADRS) . . . . . . . . . . . . . 31 Algorithm 17 fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) . . . . . . . . . . 32 Algorithm 18 slh_keygen_internal(SK.seed, SK.prf, PK.seed) . . . . . . . . . . 34 Algorithm 19 slh_sign_internal(M, SK, addrnd) . . . . . . . . . . . . . . . . . . . 35 Algorithm 20 slh_verify_internal(M, SIG, PK) . . . . . . . . . . . . . . . . . . . . 36 Algorithm 21 slh_keygen() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 22 slh_sign(M, ctx, SK) . . . . . . . . . . . . . . . . .", "char_len": 3998, "approx_tokens": 999}
{"chunk_id": "NIST.FIPS.205::c00005", "doc_id": "NIST.FIPS.205", "start_page": 10, "end_page": 12, "text": ". . . . . . . . . . . 30 Algorithm 16 fors_sign(md, SK.seed, PK.seed, ADRS) . . . . . . . . . . . . . 31 Algorithm 17 fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) . . . . . . . . . . 32 Algorithm 18 slh_keygen_internal(SK.seed, SK.prf, PK.seed) . . . . . . . . . . 34 Algorithm 19 slh_sign_internal(M, SK, addrnd) . . . . . . . . . . . . . . . . . . . 35 Algorithm 20 slh_verify_internal(M, SIG, PK) . . . . . . . . . . . . . . . . . . . . 36 Algorithm 21 slh_keygen() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 22 slh_sign(M, ctx, SK) . . . . . . . . . . . . . . . . . . . . . . . . . . 39 Algorithm 23 hash_slh_sign(M, ctx, PH, SK) . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 24 slh_verify(M, SIG, ctx, PK) . . . . . . . . . . . . . . . . . . . . . . . 41 Algorithm 25 hash_slh_verify(M, SIG, ctx, PH, PK) . . . . . . . . . . . . . . . . . 42\n\nvii\n\n1. Introduction\n\n1.1 Purpose and Scope This standard defines a method for digital signature generation that can be used for the protection of binary data (commonly called a message) and for the verification and validation of those digital signatures.1 The security of the stateless hash-based digital signature algorithm (SLH-DSA) relies on the presumed difficulty of finding preimages for hash functions as well as several related properties of the same hash functions. Unlike the algorithms specified in FIPS 186-5 [1], SLH-DSA is designed to provide resistance against attacks from a large-scale quantum computer. This standard specifies the mathematical steps that need to be performed for key generation, signature generation, and signature verification. Additional assurances are required for digital signatures to be valid (e.g., the assurance of identity and private key possession). SP 800-89, Recommendation for Obtaining Assurances for Digital Signature Applications [3], specifies the required assurances and the methods for obtaining these assurances.\n\n1.2 Context Over the past several years, there has been steady progress toward building quantum computers. The security of many commonly used public-key cryptosystems will be at risk if large-scale quantum computers are ever realized. This would include key-establishment schemes and digital signatures that are based on integer factorization and discrete logarithms (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantum-resistant public-key cryptographic algorithms for standardization. A total of 82 candidate algorithms were submitted to NIST for consideration. After three rounds of evaluation and analysis, NIST selected the first four algorithms for standardization. These algorithms are intended to protect sensitive U.S. Government information well into the foreseeable future, including after the advent of cryptographically relevant quantum computers. This standard includes the specification for one of the algorithms selected: SPHINCS+, a stateless hash-based digital signature scheme. This standard contains several minor modifications compared to Version 3 [4], which was submitted at the beginning of round three of the NIST PQC Standardization process. The changes are described in Appendix A. Throughout this standard, SPHINCS+ will be referred to as SLH-DSA for stateless hash-based digital signature algorithm.\n\n1NIST Special Publication (SP) 800-175B [2], Guideline for Using Cryptographic Standards in the Federal Government: Cryptographic Mechanisms, includes a general discussion of digital signatures.\n\n2. Glossary of Terms, Acronyms, and Symbols", "char_len": 3641, "approx_tokens": 910}
{"chunk_id": "NIST.FIPS.205::c00006", "doc_id": "NIST.FIPS.205", "start_page": 11, "end_page": 13, "text": "digital signature scheme. This standard contains several minor modifications compared to Version 3 [4], which was submitted at the beginning of round three of the NIST PQC Standardization process. The changes are described in Appendix A. Throughout this standard, SPHINCS+ will be referred to as SLH-DSA for stateless hash-based digital signature algorithm.\n\n1NIST Special Publication (SP) 800-175B [2], Guideline for Using Cryptographic Standards in the Federal Government: Cryptographic Mechanisms, includes a general discussion of digital signatures.\n\n2. Glossary of Terms, Acronyms, and Symbols\n\n2.1 Terms and Definitions approved FIPS-approved and/or NIST-recommended. An algorithm or tech- nique that is either 1) specified in a FIPS or NIST recommendation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security functions. [1] big-endian The property of a byte string having its bytes positioned in order of decreasing significance. In particular, the leftmost (first) byte is the most significant, and the rightmost (last) byte is the least significant. The term “big-endian” may also be applied in the same manner to bit strings. [5, adapted] byte string An array of integers in which each integer is in the set {0, ... , 255}. claimed signatory From the verifier’s perspective, the claimed signatory is the entity that purportedly generated a digital signature. [1] destroy An action applied to a key or a piece of secret data. After a key or a piece of secret data is destroyed, no information about its value can be recovered. [1] digital signature The result of a cryptographic transformation of data that, when prop- erly implemented, provides a mechanism for verifying origin authenti- cation, data integrity, and signatory non-repudiation. [1] entity An individual (person), organization, device, or process. Used inter- changeably with party. [1] equivalent process Two processes are equivalent if the same output is produced when the same values are input to each process (either as input parameters, as values made available during the process, or both). [1] extendable-output A function on bit strings in which the output can be extended to any function desired length. Approved XOFs (such as those specified in FIPS 202 [6]) are designed to satisfy the following properties as long as the specified output length is sufficiently long to prevent trivial attacks: 1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 2. (Collision-resistant) It is computationally infeasible to find any two distinct inputs that map to the same output. [7, adapted] fresh random value A previously unused output of a random bit generator. hash function A function on bit strings in which the length of the output is fixed. Approved hash functions (such as those specified in FIPS 180 [8] and FIPS 202 [6]) are designed to satisfy the following properties:\n\n1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output 2. (Collision-resistant) It is computationally infeasible to find any two distinct inputs that map to the same output. [1] hash value See message digest. key A parameter used in conjunction with a cryptographic algorithm that determines its operation. Examples applicable to this standard include: 1. The computation of a digital signature from data, and 2. The verification of a digital signature. [1] key pair A public key and its corresponding private key. [1] message The data that is signed. Also known as signed data during the signature verification and validation process. [1] message digest The result of applying a hash function to a message. Also known as a hash value.", "char_len": 3741, "approx_tokens": 935}
{"chunk_id": "NIST.FIPS.205::c00007", "doc_id": "NIST.FIPS.205", "start_page": 13, "end_page": 14, "text": "t inputs that map to the same output. [1] hash value See message digest. key A parameter used in conjunction with a cryptographic algorithm that determines its operation. Examples applicable to this standard include: 1. The computation of a digital signature from data, and 2. The verification of a digital signature. [1] key pair A public key and its corresponding private key. [1] message The data that is signed. Also known as signed data during the signature verification and validation process. [1] message digest The result of applying a hash function to a message. Also known as a hash value. [1] non-repudiation A service that is used to provide assurance of the integrity and origin of data in such a way that the integrity and origin can be verified and validated by a third party as having originated from a specific entity in possession of the private key (i.e., the signatory). [1] owner A key pair owner is the entity authorized to use the private key of a key pair. [1] party An individual (person), organization, device, or process. Used inter- changeably with entity. [1] private key A cryptographic key that is used with an asymmetric (public-key) cryp- tographic algorithm. The private key is uniquely associated with the owner and is not made public. The private key is used to compute a digital signature that may be verified using the corresponding public key. [1] pseudorandom A process or data produced by a process is said to be pseudorandom when the outcome is deterministic yet also effectively random as long as the internal action of the process is hidden from observation. For cryptographic purposes, “effectively random” means “computation- ally indistinguishable from random within the limits of the intended security strength.” [1] public key A cryptographic key that is used with an asymmetric (public-key) cryp- tographic algorithm and is associated with a private key. The public key is associated with an owner and may be made public. In the case of digital signatures, the public key is used to verify a digital signature that was generated using the corresponding private key. [1]\n\nsecurity category A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST (see [9, Sect. 5.6]). security strength A number associated with the amount of work (i.e., the number of operations) that is required to break a cryptographic algorithm or system. [1] shall Used to indicate a requirement of this standard. [1] should Used to indicate a strong recommendation but not a requirement of this standard. Ignoring the recommendation could result in undesir- able results. [1] signatory The entity that generates a digital signature on data using a private key. [1] signature generation The process of using a digital signature algorithm and a private key to generate a digital signature on data. [1] signature validation The (mathematical) verification of the digital signature and obtain- ing the appropriate assurances (e.g., public-key validity, private-key possession, etc.). [1] signature verification The process of using a digital signature algorithm and a public key to verify a digital signature on data. [1] signed data The data or message upon which a digital signature has been computed. Also see message. [1] verifier The entity that verifies the authenticity of a digital signature using the public key. [1]\n\n2.2 Acronyms ADRS Address ADRSc Compressed Address AES Advanced Encryption Standard DER Distinguished Encoding Rules FIPS Federal Information Processing Standard FORS Forest of Random Subsets ITL Information Technology Laboratory MGF Mask Generation Function NIST National Institute of Standards and Technology OID Object Identifier PQC Post-Quantum Cryptography PRF Pseudorandom Function", "char_len": 3787, "approx_tokens": 946}
{"chunk_id": "NIST.FIPS.205::c00008", "doc_id": "NIST.FIPS.205", "start_page": 14, "end_page": 17, "text": "[1] signed data The data or message upon which a digital signature has been computed. Also see message. [1] verifier The entity that verifies the authenticity of a digital signature using the public key. [1]\n\n2.2 Acronyms ADRS Address ADRSc Compressed Address AES Advanced Encryption Standard DER Distinguished Encoding Rules FIPS Federal Information Processing Standard FORS Forest of Random Subsets ITL Information Technology Laboratory MGF Mask Generation Function NIST National Institute of Standards and Technology OID Object Identifier PQC Post-Quantum Cryptography PRF Pseudorandom Function\n\nSHA Secure Hash Algorithm SHAKE Secure Hash Algorithm KECCAK SP Special Publication RFC Request for Comments WOTS+ Winternitz One-Time Signature Plus XMSS eXtended Merkle Signature Scheme XOF eXtendable-Output Function\n\n2.3 Mathematical Symbols X ∥ Y The concatenation of two arrays X and Y. If X is an array of length lx , and Y is an array of length ly, then Z = X ∥ Y is an array of length lx + ly such that\n\nZ[i] = { X[i] if 0 ≤ i < lx Y [i − lx ] if lx ≤ i < lx + ly.\n\nX[i ∶ j] A subarray of X. If X is an array of length lx , 0 ≤ i < j ≤ lx , and Y = X[i ∶ j], then Y is an array of length j − i such that Y [k] = X[i + k] for 0 ≤ k < j − i. Truncl(X) A truncation function that outputs the leftmost l bytes of the input byte string X. If Y = Truncl(X), then Y is a byte string (array) of length l such that Y [i] = X[i] for 0 ≤ i < l (i.e., Y = X[0 ∶ l]). |X| The length (in bytes) of byte string X. ⌈a⌉ The ceiling of a; the smallest integer that is greater than or equal to a. For example, ⌈5⌉ = 5, ⌈5.3⌉ = 6, and ⌈−2.1⌉ = −2. [1] ⌊a⌋ The floor of a; the largest integer that is less than or equal to a. For example, ⌊5⌋ = 5, ⌊5.3⌋ = 5, and ⌊−2.1⌋ = −3. [1] a mod n The unique remainder r, 0 ≤ r ≤ (n − 1), when integer a is divided by the positive integer n. For example, 23 mod 7 = 2. [1] a ⋅ b The product of a and b. For example, 3 ⋅ 5 = 15. ab a raised to the power b. For example, 25 = 32. log2 x The base 2 logarithm of x. For example, log2(16) = 4. 0b The prefix to a number that is represented in binary. 0x The prefix to a number that is represented in hexadecimal. [1, adapted] a ≫ b The logical right shift of a by b positions (i.e., a ≫ b = b ⌊a/2 ⌋). For example, 0x73 ≫ 4 = 7. [10, adapted]\n\na ≪ b The logical left shift of a by b positions (i.e., a ≪ b = a ⋅ 2b). For example, 0x73 ≪ 4 = 0x730. [10, adapted] a ⊕ b The bitwise exclusive-or of a and b. For example, 115 ⊕ 1 = 114 (115 ⊕ 1 = 0b01110011 ⊕ 0b00000001 = 0b01110010 = 114). s ← x In pseudocode, this notation means that the variable s is set to the value of the expression x. s $ n ← − B In pseudocode, this notation means that the variable s is set to a byte string of length n chosen at random. A fresh random value is generated for each time this step is performed. ⊥ A symbol indicating failure or the lack of output from an algorithm.\n\n3. Overview of the SLH-DSA Signature Scheme\n\nSLH-DSA is a stateless hash-based signature scheme that is constructed using other hash-based signature schemes as components: (1) a few-time signature scheme, forest of random subsets (FORS), and (2) a multi-time signature scheme, the eXtended Merkle Signature Scheme (XMSS). XMSS is constructed using the hash-based one-time signature scheme Winternitz One-Time Signature Plus (WOTS+) as a component.2 Conceptually, an SLH-DSA key pair consists of a very large set of FORS key pairs.3 The few-time signature scheme FORS allows each key pair to safely sign a small number of messages. An SLH-DSA signature is created by computing a randomized hash of the message, using part of the resulting message digest to pseudorandomly select a FORS key, and signing the remaining part of the message digest with that key. An SLH-DSA signature consists of the FORS signature and the information that authenticates the FORS public key. The authentication information is created using XMSS signatures.", "char_len": 3960, "approx_tokens": 990}
{"chunk_id": "NIST.FIPS.205::c00009", "doc_id": "NIST.FIPS.205", "start_page": 17, "end_page": 18, "text": "a component.2 Conceptually, an SLH-DSA key pair consists of a very large set of FORS key pairs.3 The few-time signature scheme FORS allows each key pair to safely sign a small number of messages. An SLH-DSA signature is created by computing a randomized hash of the message, using part of the resulting message digest to pseudorandomly select a FORS key, and signing the remaining part of the message digest with that key. An SLH-DSA signature consists of the FORS signature and the information that authenticates the FORS public key. The authentication information is created using XMSS signatures. XMSS is a multi-time signature scheme that is created using a combination of WOTS+ one-time signatures and Merkle hash trees [13]. An XMSS key consists of 2h′ WOTS+ keys and can sign 2h′ messages. The WOTS+ public keys are formed into a Merkle hash tree, and the root of the tree is the XMSS public key. (The Merkle hash tree formed from the WOTS+ keys is also referred to as an XMSS tree.) An XMSS signature consists of a WOTS+ signature and an authentication path within the Merkle hash tree for the WOTS+ public key. In Figure 1, triangles represent XMSS trees, squares represent the WOTS+ public keys, and circles represent the interior nodes of the hash tree. Within an XMSS tree, the square and circles that are filled in represent the authentication path for the WOTS+ public key needed to verify the signature. The authentication information for a FORS public key is a hypertree signature. A hypertree is a tree of XMSS trees, as depicted in Figure 1. The tree consists of d layers4 in which the top layer (layer d − 1) consists of a single XMSS tree, the next layer down (layer d − 2) consists of 2h′ XMSS trees, and the lowest layer (layer 0) consists of 2(d−1)h′ XMSS trees. The public key of each XMSS key at layers 0 through d − 2 is signed by an XMSS key at the next higher layer. The XMSS keys at layer 0 collectively have 2dh′ = 2h WOTS+ keys, which are used to sign the 2h FORS public keys in the SLH-DSA key pair. The sequence of d XMSS signatures needed to authenticate a FORS public key when starting with the public key of the XMSS key at layer d − 1 is a hypertree signature. An SLH-DSA signature consists of a FORS signature along with a hypertree signature. An SLH-DSA public key (Figure 16) contains two n-byte components: (1) PK.root, which is the public key of the XMSS key at layer d − 1, and (2) PK.seed, which is used to provide domain separation between different SLH-DSA key pairs. An SLH-DSA private key (Figure 15) consists of an n-byte seed SK.seed that is used to pseudorandomly generate all of the secret values for the WOTS+ and FORS keys and an n-byte key SK.prf that is used in the generation of the randomized hash of the message. An SLH-DSA private key also includes copies of PK.root and PK.seed, as these values are needed during both signature generation and signature verification.\n\n2The WOTS+ and XMSS schemes that are used as components of SLH-DSA are not the same as the WOTS+ and XMSS schemes in RFC 8391 [11] and SP 800-208 [12]. 3For the parameter sets in this standard, an SLH-DSA key pair contains 263 , 264 , 266 , or 268 FORS keys, which are pseudorandomly generated from a single seed. 4For the parameter sets in this standard, d is 7, 8, 17, or 22.\n\nPK.root\n\nlayer d − 1 = 2\n\nWOTS+ signature\n\nlayer 1\n\nMerkle tree node WOTS+ signature WOTS+ public key\n\nlayer 0 FORS public key\n\nWOTS+ signature\n\nFORS signature Message\n\nFigure 1. An SLH-DSA signature", "char_len": 3507, "approx_tokens": 876}
{"chunk_id": "NIST.FIPS.205::c00010", "doc_id": "NIST.FIPS.205", "start_page": 17, "end_page": 19, "text": "ture verification.\n\n2The WOTS+ and XMSS schemes that are used as components of SLH-DSA are not the same as the WOTS+ and XMSS schemes in RFC 8391 [11] and SP 800-208 [12]. 3For the parameter sets in this standard, an SLH-DSA key pair contains 263 , 264 , 266 , or 268 FORS keys, which are pseudorandomly generated from a single seed. 4For the parameter sets in this standard, d is 7, 8, 17, or 22.\n\nPK.root\n\nlayer d − 1 = 2\n\nWOTS+ signature\n\nlayer 1\n\nMerkle tree node WOTS+ signature WOTS+ public key\n\nlayer 0 FORS public key\n\nWOTS+ signature\n\nFORS signature Message\n\nFigure 1. An SLH-DSA signature\n\nThe WOTS+ one-time signature scheme is specified in Section 5, and the XMSS multi-time sig- nature scheme is specified in Section 6. Section 7 specifies the generation and verification of hypertree signatures. The FORS few-time signature scheme is specified in Section 8. Finally, Section 9 specifies the SLH-DSA key generation, signature, and verification functions. As the WOTS+, XMSS, hypertree, and FORS schemes described in this standard are not intended for use as stand-alone signature schemes, only the components of the schemes necessary to imple- ment SLH-DSA are described. In particular, these sections do not include functions for key pair generation, and a signature verification function is only specified for hypertree signatures. When used in this standard, WOTS+, XMSS, and FORS signatures are implicitly verified using functions to generate public keys from messages and signatures (see Sections 5.3, 6.3, and 8.4). When verifying an SLH-DSA signature, the randomized hash of the message and the FORS signature are used to compute a candidate FORS public key. The candidate FORS public key and the WOTS+ signature from the layer 0 XMSS key are used to compute a candidate WOTS+ public key, which is then used in conjunction with the corresponding authentication path to compute a candidate XMSS public key. The candidate layer 0 XMSS public key is used along with the layer 1\n\nXMSS signature to compute a candidate layer 1 XMSS public key. This process is repeated until a candidate layer d − 1 public key has been computed. SLH-DSA signature verification succeeds if the computed candidate layer d − 1 XMSS public key is the same as the SLH-DSA public key root PK.root.\n\n3.1 Additional Requirements This section specifies requirements for cryptographic modules that implement SLH-DSA. Section 3.2 discusses issues that implementers of cryptographic modules should take into consideration but that are not requirements. SP 800-89, Recommendation for Obtaining Assurances for Digital Signature Applications [3], specifies requirements that apply to the use of digital signature schemes.\n\nRandomness generation. SLH-DSA key generation (Algorithm 21) requires the generation of three random n-byte values: PK.seed, SK.seed, and SK.prf, where n is 16, 24, or 32, depending on the parameter set. For each invocation of key generation, each of these values shall be a fresh (i.e., not previously used) random value generated using an approved random bit generator (RBG), as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [14, 15, 16]. Moreover, the RBG used shall have a security strength of at least 8n bits. See Table 2 for the value of n for each parameter set.\n\nDestruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential.", "char_len": 3791, "approx_tokens": 947}
{"chunk_id": "NIST.FIPS.205::c00011", "doc_id": "NIST.FIPS.205", "start_page": 19, "end_page": 21, "text": "curity strength of at least 8n bits. See Table 2 for the value of n for each parameter set.\n\nDestruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of SLH-DSA shall ensure that any local copies of the inputs and any potentially sensitive intermediate data are destroyed as soon as they are no longer needed.\n\nKey checks. SP 800-89 imposes requirements for the assurance of public-key validity and privatekey possession. In the case of SLH-DSA, where public-key validation is required, implementations shall verify that the public key is 2n bytes in length. When the assurance of private key possession is obtained via regeneration, the owner of the private key shall check that the private key is 4n bytes in length and shall use SK.seed and PK.seed to recompute PK.root and compare the newly generated value with the value in the private key currently held.\n\nFloating-point arithmetic. Implementations of SLH-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. In all pseudocode in this standard in which division is performed (e.g., x/y) and y may not divide x, either ⌊x/y⌋ or ⌈x/y⌉ is used. Both of these can be computed without floating-point arithmetic, as ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative integers x and positive integers y.\n\nWhile the value of len2 (see Equation 5.3) may be computed without using floating-point arithmetic (see Algorithm 1), it is recommended that this value be precomputed. For all parameter sets in this standard, len2 is 3.\n\nAlgorithm 1 gen_len2 (n, lgw) Computes len2 (Equation 5.3). Input: Security parameter n, bits per hash chain lgw. Output: len2. 1: w ← 2lgw ▷ Equation 5.1 2: len1 ← ⌊ 8⋅n+lgw−1 ⌋ ▷ Equation 5.2 lgw 3: max_checksum = len1 ⋅ (w − 1) ▷ maximum possible checksum value 4: len2 ← 1 ▷ maximum value that may be signed using 5: capacity ← w ▷ len2 hash chains is wlen2 − 1 = capacity − 1 6: while capacity ≤ max_checksum do 7: len2 ← len2 + 1 8: capacity ← capacity ⋅ w 9: end while 10: return len2\n\n3.2 Implementation Considerations This section discusses some implementation considerations for SLH-DSA.\n\nDo not support component use. As WOTS+, XMSS, FORS, and hypertree signature schemes are not approved for use as stand-alone signature schemes, cryptographic modules should not make interfaces to these components available to applications. SP 800-208 [12] specifies approved stateful hash-based signature schemes.\n\nSide-channel and fault attacks. For signature schemes, the secrecy of the private key is critical. Care must be taken to protect implementations against attacks, such as side-channel attacks or fault attacks [17, 18, 19, 20, 21]. A cryptographic device may leak critical information with side-channel analysis or attacks that allow internal data or keying material to be extracted without breaking the cryptographic primitives.\n\n4. Functions and Addressing", "char_len": 3687, "approx_tokens": 921}
{"chunk_id": "NIST.FIPS.205::c00012", "doc_id": "NIST.FIPS.205", "start_page": 20, "end_page": 22, "text": "not make interfaces to these components available to applications. SP 800-208 [12] specifies approved stateful hash-based signature schemes.\n\nSide-channel and fault attacks. For signature schemes, the secrecy of the private key is critical. Care must be taken to protect implementations against attacks, such as side-channel attacks or fault attacks [17, 18, 19, 20, 21]. A cryptographic device may leak critical information with side-channel analysis or attacks that allow internal data or keying material to be extracted without breaking the cryptographic primitives.\n\n4. Functions and Addressing\n\n4.1 Hash Functions and Pseudorandom Functions The specification of SLH-DSA makes use of six functions — PRFmsg, Hmsg, PRF, Tl, H, and F — that are all implemented using hash functions or XOFs with fixed output lengths. The inputs and output of each function are byte strings. In the following definitions, B = {0, ... , 255} denotes the set of all bytes, Bn denotes the set of byte strings of length n bytes, and B∗ denotes the set of all byte strings. The ADRS input is described in Section 4.2. • PRFmsg(SK.prf, opt_rand, M ) (Bn × Bn × B∗ → Bn) is a pseudorandom function (PRF) that generates the randomizer (R) for the randomized hashing of the message to be signed. • Hmsg(R, PK.seed, PK.root, M ) (Bn × Bn × Bn × B∗ → Bm ) is used to generate the digest of the message to be signed. • PRF(PK.seed, SK.seed, ADRS) (Bn × Bn × B32 → Bn) is a PRF that is used to generate the secret values in WOTS+ and FORS private keys. • Tl(PK.seed, ADRS, Ml) (Bn × B32 × Bln → Bn) is a hash function that maps an ln-byte message to an n-byte message. • H(PK.seed, ADRS, M2) (Bn × B32 × B2n → Bn) is a special case of Tl that takes a 2n-byte message as input. • F(PK.seed, ADRS, M1) (Bn × B32 × Bn → Bn) is a hash function that takes an n-byte message as input and produces an n-byte output. The specific instantiations for these functions differ for different parameter sets and are specified in Section 11.\n\n4.2 Addresses Four of the functions described in Section 4.1 take a 32-byte address (i.e., ADRS) as input. An ADRS consists of public values that indicate the position of the value being computed by the function. A different ADRS value is used for each call to each function. In the case of PRF, this is used to generate a large number of different secret values from a single seed. In the case of Tl, H, and F, it is used to mitigate multi-target attacks. In the pseudocode, where addresses are passed as parameters, they may be passed either by reference or by value. The structure of an ADRS conforms to word boundaries, with each word being 4 bytes long and values encoded as unsigned integers in big-endian byte order (see Figure 2). The first word of ADRS specifies the layer address, which is the height of an XMSS tree within the hypertree. Trees on the bottom layer have a height of zero, and the single XMSS tree at the top has a height of d − 1 (see Figure 1). The next three words of ADRS specify the tree address, which is the position of an XMSS tree within a layer of the hypertree. The leftmost XMSS tree in a layer has a tree address of zero, and the rightmost XMSS tree in layer L has a tree address of 2(d−1−L)h′ − 1. The next word is used to specify the type of the address, which differs depending on the use case.\n\nThere are seven different types of address used in SLH-DSA, as described below.5 The address type determines how the final 12 bytes of the address are to be interpreted. The algorithms in this standard are written based on the assumption that whenever the type in an ADRS is changed, the final 12 bytes of the address are initialized to zero.\n\nlayer address 4 bytes\n\ntree address 12 bytes\n\ntype 4 bytes\n\n12 bytes\n\nFigure 2. Address (ADRS)", "char_len": 3773, "approx_tokens": 943}
{"chunk_id": "NIST.FIPS.205::c00013", "doc_id": "NIST.FIPS.205", "start_page": 21, "end_page": 23, "text": "XMSS tree in layer L has a tree address of 2(d−1−L)h′ − 1. The next word is used to specify the type of the address, which differs depending on the use case.\n\nThere are seven different types of address used in SLH-DSA, as described below.5 The address type determines how the final 12 bytes of the address are to be interpreted. The algorithms in this standard are written based on the assumption that whenever the type in an ADRS is changed, the final 12 bytes of the address are initialized to zero.\n\nlayer address 4 bytes\n\ntree address 12 bytes\n\ntype 4 bytes\n\n12 bytes\n\nFigure 2. Address (ADRS)\n\nThe type is set to WOTS_HASH (i.e., type = 0) for a WOTS+ hash address (see Figure 3), which is used when computing hash chains in WOTS+. When type is WOTS_HASH, the next word encodes the key pair address, which is the index of the WOTS+ key pair within the XMSS tree specified by the layer and tree addresses, with the leftmost WOTS+ key having an index of zero and the rightmost WOTS+ key having an index of 2h′ − 1. Next is the chain address, which encodes the index of the chain within WOTS+, followed by the hash address, which encodes the address of the hash function within the chain. layer address layer address\n\ntree address tree address\n\ntype = 0 (WOTS_HASH) type = 1 (WOTS_PK) key pair address 4 bytes key pair address 4 bytes chain address 4 bytes padding = 0 8 bytes hash address 4 bytes\n\nFigure 3. WOTS+ hash address Figure 4. WOTS+ public-key compression address\n\nThe type is set to WOTS_PK (i.e., type = 1) when compressing WOTS+ public keys (see Figure 4). As when the type is WOTS_HASH, the next word encodes the index of the WOTS+ key pair within the XMSS tree specified by the layer and tree addresses. The remaining two words of ADRS are not needed and are set to zero. The type is set to TREE (i.e., type = 2) when computing the hashes within the XMSS tree (see Figure 5). For this type of address, the next word is always set to zero. The following word 5The type word will have a value of 0, 1, 2, 3, 4, 5, or 6. In order to improve readability, these values will be referred to in this standard by the constants WOTS_HASH, WOTS_PK, TREE, FORS_TREE, FORS_ROOTS, WOTS_PRF, and FORS_PRF, respectively.\n\nencodes the height of the node within the tree that is being computed, and the final word encodes the index of the node at that height.\n\nlayer address\n\ntree address\n\ntype = 2 (TREE) padding = 0 4 bytes tree height 4 bytes tree index 4 bytes\n\nFigure 5. Hash tree address\n\nThe type is set to FORS_TREE (i.e., type = 3) when computing hashes within the FORS tree (see Figure 6). The next word is the key pair address, which encodes the FORS key that is used. The value is the same as the key pair address for the WOTS+ key used to sign the FORS key (see Figure 3 and Figure 4). The next two words — the tree height and tree index — encode the node within the FORS tree that is being computed. The tree height starts with zero for the leaf nodes. The tree index is counted continuously across the k different FORS trees. The leftmost node in the leftmost tree has an index of zero, and the rightmost node in the rightmost tree at level j has an index of k ⋅ 2(a−j) − 1, where a is the height of the tree.\n\nlayer address = 0 layer address = 0\n\ntree address tree address\n\ntype = 3 (FORS_TREE) type = 4 (FORS_ROOTS) key pair address 4 bytes key pair address 4 bytes tree height 4 bytes padding = 0 8 bytes tree index 4 bytes\n\nFigure 6. FORS tree address Figure 7. FORS tree roots compression address", "char_len": 3516, "approx_tokens": 879}
{"chunk_id": "NIST.FIPS.205::c00014", "doc_id": "NIST.FIPS.205", "start_page": 23, "end_page": 25, "text": "tree height starts with zero for the leaf nodes. The tree index is counted continuously across the k different FORS trees. The leftmost node in the leftmost tree has an index of zero, and the rightmost node in the rightmost tree at level j has an index of k ⋅ 2(a−j) − 1, where a is the height of the tree.\n\nlayer address = 0 layer address = 0\n\ntree address tree address\n\ntype = 3 (FORS_TREE) type = 4 (FORS_ROOTS) key pair address 4 bytes key pair address 4 bytes tree height 4 bytes padding = 0 8 bytes tree index 4 bytes\n\nFigure 6. FORS tree address Figure 7. FORS tree roots compression address\n\nThe type is set to FORS_ROOTS (i.e., type = 4) when compressing the k FORS tree roots (see Figure 7). The next word is the key pair address, which has the same meaning as it does in the FORS_TREE address. The remaining two words of ADRS are not needed and are set to zero. The type is set to WOTS_PRF (i.e., type = 5) when generating secret values for WOTS+ keys (see Figure 8). The values for the other words in the address are set to the same values as for the WOTS_HASH address (Figure 3) used for the chain. The hash address is always set to zero.\n\nlayer address layer address = 0\n\ntree address tree address\n\ntype = 5 (WOTS_PRF) type = 6 (FORS_PRF) key pair address 4 bytes key pair address 4 bytes chain address 4 bytes tree height = 0 4 bytes hash address = 0 4 bytes tree index 4 bytes\n\nFigure 8. WOTS+ key generation address Figure 9. FORS key generation address\n\nThe type is set to FORS_PRF (i.e., type = 6) when generating secret values for FORS keys (see Figure 9). The values for the other words in the address are set to the same values as for the FORS_TREE address (Figure 6) used for the same leaf node.\n\n4.3 Member Functions The algorithms in this standard make use of member functions. If a complex data structure (e.g., an ADRS) contains a component X, then ADRS.getX() returns the value of X, and ADRS.setX(Y) sets the component X in ADRS to the value held by Y. If a data structure s contains multiple instances of X, then s.getX(i) returns the value of the ith instance of X in s. For example, if s is a FORS signature (Figure 14), then s.getAUTH(i) returns the authentication path for the ith tree. Whenever the type in an address changes, the final 12 bytes of the address are initialized to zero. The member function ADRS.setTypeAndClear(Y) for addresses sets the type of the ADRS to Y and sets the final 12 bytes of the ADRS to zero.6 Table 1 shows alternative notation for each of the member functions that operates on addresses.\n\nTable 1. Member functions for addresses\n\nMember function ADRS.setLayerAddress(l) ADRS.setTreeAddress(t) ADRS.setTypeAndClear(Y) ADRS.setKeyPairAddress(i) ADRS.setChainAddress(i) ADRS.setTreeHeight(i) ADRS.setHashAddress(i) ADRS.setTreeIndex(i) i ← ADRS.getKeyPairAddress() i ← ADRS.getTreeIndex() Expanded notation ADRS ← toByte(l, 4) ∥ ADRS[4 ∶ 32] ADRS ← ADRS[0 ∶ 4] ∥ toByte(t, 12) ∥ ADRS[16 ∶ 32] ADRS ← ADRS[0 ∶ 16] ∥ toByte(Y , 4) ∥ toByte(0, 12) ADRS ← ADRS[0 ∶ 20] ∥ toByte(i, 4) ∥ ADRS[24 ∶ 32] ADRS ← ADRS[0 ∶ 24] ∥ toByte(i, 4) ∥ ADRS[28 ∶ 32]\n\nADRS ← ADRS[0 ∶ 28] ∥ toByte(i, 4)\n\ni ← toInt(ADRS[20 ∶ 24], 4) i ← toInt(ADRS[28 ∶ 32], 4)\n\n6As noted in Section 4.2, the type (Y) is an integer. However, in the pseudocode, the constants WOTS_HASH, WOTS_PK, TREE, FORS_TREE, FORS_ROOTS, WOTS_PRF, and FORS_PRF are used in order to improve readability.\n\n4.4 Arrays, Byte Strings, and Integers If X is a byte string of length n, then X[i] for i ∈ {0, ... , n − 1} will refer to the ith element in the string X. If X is an array of m n-byte strings, then X[i] for i ∈ {0, ... , m − 1} will refer to the ith n-byte string in X, and X will refer to the m ⋅ n-byte string X[0] ∥ X[1] ∥ ... X[m − 1]. A byte string may be interpreted as the big-endian representation of an integer. In such cases, a byte string X of length n is converted to the integer\n\nX[0] ⋅ 256n−1 + X[1] ⋅ 256n−2 + ... X[n − 2] ⋅ 256 + X[n − 1].", "char_len": 3973, "approx_tokens": 993}
{"chunk_id": "NIST.FIPS.205::c00015", "doc_id": "NIST.FIPS.205", "start_page": 24, "end_page": 27, "text": "re used in order to improve readability.\n\n4.4 Arrays, Byte Strings, and Integers If X is a byte string of length n, then X[i] for i ∈ {0, ... , n − 1} will refer to the ith element in the string X. If X is an array of m n-byte strings, then X[i] for i ∈ {0, ... , m − 1} will refer to the ith n-byte string in X, and X will refer to the m ⋅ n-byte string X[0] ∥ X[1] ∥ ... X[m − 1]. A byte string may be interpreted as the big-endian representation of an integer. In such cases, a byte string X of length n is converted to the integer\n\nX[0] ⋅ 256n−1 + X[1] ⋅ 256n−2 + ... X[n − 2] ⋅ 256 + X[n − 1].\n\nSimilarly, an integer x may be converted to a byte string of length n by finding coefficients x0, x1, ... xn−2, xn−1 ∈ {0, ... , 255} such that\n\nx = x0 ⋅ 256n−1 + x1 ⋅ 256n−2 + ... xn−2 ⋅ 256 + xn−1\n\nand then setting the byte string to be x0x1 ... xn−2xn−1. Algorithm 2 is a function that converts a byte string X of length n to an integer, and Algorithm 3 is a function that converts an integer x to a byte string of length n.\n\nAlgorithm 2 toInt(X, n) Converts a byte string to an integer. Input: n-byte string X. Output: Integer value of X. 1: total ← 0 2: for i from 0 to n − 1 do 3: total ← 256 ⋅ total + X[i] 4: end for 5: return total\n\nAlgorithm 3 toByte(x, n) Converts an integer to a byte string. Input: Integer x, string length n. Output: Byte string of length n containing binary representation of x in big-endian byte-order. 1: total ← x 2: for i from 0 to n − 1 do 3: S[n − 1 − i] ← total mod 256 ▷ least significant 8 bits of total 4: total ← total ≫ 8 5: end for 6: return S\n\nFor the WOTS+ and FORS schemes, the messages to be signed need to be split into a sequence of b-bit strings, where each b-bit string is interpreted as an integer between 0 and 2b − 1.7 This is the equivalent of creating the base-2b representation of the message. The base_2b function (Algorithm 4) takes a byte string X, a bit string length b, and an output length out_len as input and returns an array of base-2b integers that represent the first out_len ⋅ b bits of X if the individual bytes in X are encoded as 8-bit strings in big-endian bit order. X must be at least ⌈out_len ⋅ b/8⌉ bytes in length. As the value of bits will never exceed b + 7, a b + 7-bit unsigned integer is sufficient to store total (i.e., total may be stored as a 32-bit unsigned integer).\n\nAlgorithm 4 base_2b(X, b, out_len) Computes the base 2b representation of X. Input: Byte string X of length at least ⌈ out_len⋅b ⌉, integer b, output length out_len. Output: Array of out_len integers in the range [0, ... , 2b − 1]. 1: in ← 0 2: bits ← 0 3: total ← 0 4: for out from 0 to out_len − 1 do 5: while bits < b do 6: total ← (total ≪ 8) + X[in] 7: in ← in + 1 8: bits ← bits + 8 9: end while 10: bits ← bits − b 11: baseb[out] ← (total ≫ bits) mod 2b 12: end for 13: return baseb\n\n7b will be the value of lgw when the base_2b function is used in WOTS+, and b will be the value of a when the base_2b function is used in FORS. For the parameter sets in this standard, lgw is 4, and a is 6, 8, 9, 12, or 14.\n\n5. Winternitz One-Time Signature Plus Scheme\n\nThis section describes the WOTS+ one-time signature scheme that is a component of SLH-DSA. WOTS+ uses two parameters. The security parameter n is the length in bytes of the messages that may be signed as well as the length of the private key elements, public key elements, and signature elements. For the parameter sets specified in this standard, n may be 16, 24, or 32 (see Table 2). The second parameter lgw indicates the number of bits that are encoded by each hash chain that is used.8 lgw is 4 for all parameter sets in this standard. These parameters are used to compute four additional values:\n\nw = 2lgw (5.1)\n\nlen1 = ⌈ 8n ⌉ (5.2) lgw\n\nlen2 = ⌊ log2(len1 ⋅ (w − 1)) ⌋ + 1 (5.3) lgw len = len1 + len2 (5.4)", "char_len": 3833, "approx_tokens": 958}
{"chunk_id": "NIST.FIPS.205::c00016", "doc_id": "NIST.FIPS.205", "start_page": 27, "end_page": 28, "text": "s. The security parameter n is the length in bytes of the messages that may be signed as well as the length of the private key elements, public key elements, and signature elements. For the parameter sets specified in this standard, n may be 16, 24, or 32 (see Table 2). The second parameter lgw indicates the number of bits that are encoded by each hash chain that is used.8 lgw is 4 for all parameter sets in this standard. These parameters are used to compute four additional values:\n\nw = 2lgw (5.1)\n\nlen1 = ⌈ 8n ⌉ (5.2) lgw\n\nlen2 = ⌊ log2(len1 ⋅ (w − 1)) ⌋ + 1 (5.3) lgw len = len1 + len2 (5.4)\n\nWhen lgw = 4, w = 16, len1 = 2n, len2 = 3, and len = 2n + 3. A WOTS+ private key consists of len secret values of length n. In SLH-DSA, these are all generated from an n-byte seed SK.seed using a PRF. Chains of length w are then created from the secret values using a chaining function, and the end values from each of the chains are public values. The WOTS+ public key is computed as the hash of these public values. In order to create a signature, the 8n-bit message is first converted into an array of len1 base-w integers. A checksum is then computed for this string, and the checksum is converted into an array of len2 base-w integers. The signature consists of the appropriate entries from the chains for each of the integers in the message and checksum arrays. The WOTS+ functions make use of two helper functions: base_2b and chain. The base_2b function (Section 4.4) is used to break the message to be signed and the checksum value into arrays of base-w integers. The chain function (Algorithm 5) is used to compute the hash chains. The chain function takes an n-byte string X and integers s and i (where i + s < w) as input and returns the result of iterating a hash function F on the input s times, starting from an index of i.9 The chain function also requires as input PK.seed, which is part of the SLH-DSA public key, and an address ADRS. The type in ADRS must be set to WOTS_HASH, and the layer address, tree address, key pair address, and chain address must be set to the address of the chain being computed. The chain function updates the hash address in ADRS with each iteration to specify the current position in the chain prior to ADRS’s use in F.\n\n8In [10], the Winternitz parameter w is used as the second WOTS+ parameter, where w indicates the length of the\n\n9hash chains that are used. This standard uses the parameter lgw = log2(w) to simplify notation. A start index of 0 indicates the beginning of the chain.\n\nAlgorithm 5 chain(X, i, s, PK.seed, ADRS) Chaining function used in WOTS+. Input: Input string X, start index i, number of steps s, public seed PK.seed, address ADRS. Output: Value of F iterated s times on X. 1: tmp ← X 2: for j from i to i + s − 1 do 3: ADRS.setHashAddress(j) 4: tmp ← F(PK.seed, ADRS, tmp) 5: end for 6: return tmp\n\n5.1 WOTS+ Public-Key Generation The wots_pkGen function (Algorithm 6) generates WOTS+ public keys. It takes SK.seed and PK.seed from the SLH-DSA private key and an address as input. The type in the address ADRS must be set to WOTS_HASH, and the layer address, tree address, and key pair address must encode the address of the WOTS+ public key to be generated. Lines 4 through 9 in Algorithm 6 generate the public values, as described in Section 5. For each of the len public values, the corresponding secret value is generated in lines 5 and 6, and the chain function is called to compute the end value of the chain of length w. Once the len public values are computed, they are compressed into a single n-byte value in lines 10 through 13.", "char_len": 3612, "approx_tokens": 903}
{"chunk_id": "NIST.FIPS.205::c00017", "doc_id": "NIST.FIPS.205", "start_page": 28, "end_page": 30, "text": "SA private key and an address as input. The type in the address ADRS must be set to WOTS_HASH, and the layer address, tree address, and key pair address must encode the address of the WOTS+ public key to be generated. Lines 4 through 9 in Algorithm 6 generate the public values, as described in Section 5. For each of the len public values, the corresponding secret value is generated in lines 5 and 6, and the chain function is called to compute the end value of the chain of length w. Once the len public values are computed, they are compressed into a single n-byte value in lines 10 through 13.\n\nAlgorithm 6 wots_pkGen(SK.seed, PK.seed, ADRS) Generates a WOTS+ public key. Input: Secret seed SK.seed, public seed PK.seed, address ADRS. Output: WOTS+ public key pk. 1: skADRS ← ADRS ▷ copy address to create key generation key address 2: skADRS.setTypeAndClear(WOTS_PRF) 3: skADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 4: for i from 0 to len − 1 do 5: skADRS.setChainAddress(i) 6: sk ← PRF(PK.seed, SK.seed, skADRS) ▷ compute secret value for chain i 7: ADRS.setChainAddress(i) 8: tmp[i] ← chain(sk, 0, w − 1, PK.seed, ADRS) ▷ compute public value for chain i 9: end for 10: wotspkADRS ← ADRS ▷ copy address to create WOTS+public key address 11: wotspkADRS.setTypeAndClear(WOTS_PK) 12: wotspkADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 13: pk ← Tlen (PK.seed, wotspkADRS, tmp) ▷ compress public key 14: return pk\n\n5.2 WOTS+ Signature Generation A WOTS+ signature is an array of len byte strings of length n, as shown in Figure 10. The wots_sign function (Algorithm 7) generates the signature by converting the n-byte message M10 into an array of len1 base-w integers (line 2). A checksum is computed over M (lines 3 through 5). The checksum is converted to a byte string, which is then converted into an array of len2 base-w integers (lines 6 and 7). The len2 integers that represent the checksum are appended to the len1 integers that represent the message (line 7).11 For each of the len base-w integers, the signature consists of the corresponding node in one of the hash chains. For each of these integers, lines 12 and 13 compute the secret value for the hash chain, and lines 14 and 15 compute the node in the hash chain that corresponds to the integer. The selected nodes are concatenated to form the WOTS+ signature.\n\nsigots [0] n bytes ⋯ sigots [len − 1] n bytes\n\nFigure 10. WOTS+ signature data format\n\nIn addition to the n-byte message to be signed, wots_sign takes SK.seed and PK.seed from the SLH-DSA private key and an address as input. The type in the address ADRS must be set to WOTS_HASH, and the layer address, tree address, and key pair address must encode the address of the WOTS+ key that is used to sign the message.\n\n10In SLH-DSA, the message M that is signed using WOTS+ is either an XMSS public key or a FORS public key. 11In the case that lgw = 4, the n-byte message is converted into an array of 2n base-16 integers (i.e., hexadecimal digits). The checksum is encoded as two bytes with the least significant four bits being zeros, and the most significant 12 bits are appended to the message as an array of three base-16 integers.\n\nAlgorithm 7 wots_sign(M, SK.seed, PK.seed, ADRS) Generates a WOTS+ signature on an n-byte message. Input: Message M, secret seed SK.seed, public seed PK.seed, address ADRS. Output: WOTS+ signature sig. 1: csum ← 0 2: msg ← base_2b(M, lgw, len1) ▷ convert message to base w 3: for i from 0 to len1 − 1 do ▷ compute checksum 4: csum ← csum + w − 1 − msg[i] 5: end for 6: csum ← csum ≪ ((8 − ((len2 ⋅ lgw) mod 8)) mod 8) ▷ for lgw = 4, left shift by 4 7: msg ← msg ∥ base_2b (toByte (csum, ⌈ len2⋅lgw ⌉) , lgw, len2) ▷ convert to base w 8: skADRS ← ADRS ▷ copy address to create key generation key address 9: skADRS.setTypeAndClear(WOTS_PRF) 10: skADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 11: for i from 0 to len − 1 do 12: skADRS.setChainAddress(i) 13: sk ← PRF(PK.seed, SK.seed, skADRS) ▷ compute chain i secret value 14", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.FIPS.205::c00018", "doc_id": "NIST.FIPS.205", "start_page": 30, "end_page": 32, "text": "_2b(M, lgw, len1) ▷ convert message to base w 3: for i from 0 to len1 − 1 do ▷ compute checksum 4: csum ← csum + w − 1 − msg[i] 5: end for 6: csum ← csum ≪ ((8 − ((len2 ⋅ lgw) mod 8)) mod 8) ▷ for lgw = 4, left shift by 4 7: msg ← msg ∥ base_2b (toByte (csum, ⌈ len2⋅lgw ⌉) , lgw, len2) ▷ convert to base w 8: skADRS ← ADRS ▷ copy address to create key generation key address 9: skADRS.setTypeAndClear(WOTS_PRF) 10: skADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 11: for i from 0 to len − 1 do 12: skADRS.setChainAddress(i) 13: sk ← PRF(PK.seed, SK.seed, skADRS) ▷ compute chain i secret value 14: ADRS.setChainAddress(i) 15: sig[i] ← chain(sk, 0, msg[i], PK.seed, ADRS) ▷ compute chain i signature value 16: end for 17: return sig\n\n5.3 Computing a WOTS+ Public Key From a Signature Verifying a WOTS+ signature involves computing a public-key value from a message and signature value. Verification succeeds if the correct public-key value is computed, which is determined by using the computed public-key value along with other information to compute a candidate PK.root value and then comparing that value to the known value of PK.root from the SLH-DSA public key. This section describes wots_pkFromSig (Algorithm 8), a function that computes a candidate WOTS+ public key from a WOTS+ signature and corresponding message. In addition to an n-byte message M and a len ⋅ n-byte signature sig, which is interpreted as an array of len n-byte strings, the wots_pkFromSig function takes PK.seed from the SLH-DSA public key and an address as input. The type of the address ADRS must be set to WOTS_HASH, and the layer address, tree address, and key pair address must encode the address of the WOTS+ key that was used to sign the message. Lines 1 through 7 of wots_pkFromSig are the same as lines 1 through 7 of wots_sign (Algorithm 7). Lines 8 through 11 of wots_pkFromSig compute the end nodes for each of the chains using the signature value as the starting point and the message value to determine the number of iterations that need to be performed to get to the end node. Finally, as with lines 10 through 13 of Algorithm 6, the computed public-key values are compressed in lines 12 through 15.\n\nAlgorithm 8 wots_pkFromSig(sig, M, PK.seed, ADRS) Computes a WOTS+ public key from a message and its signature. Input: WOTS+ signature sig, message M, public seed PK.seed, address ADRS. Output: WOTS+ public key pksig derived from sig. 1: csum ← 0 2: msg ← base_2b(M, lgw, len1) ▷ convert message to base w 3: for i from 0 to len1 − 1 do ▷ compute checksum 4: csum ← csum + w − 1 − msg[i] 5: end for 6: csum ← csum ≪ ((8 − ((len2 ⋅ lgw) mod 8)) mod 8) ▷ for lgw = 4, left shift by 4 7: msg ← msg ∥ base_2b (toByte (csum, ⌈ len2⋅lgw ⌉) , lgw, len2) ▷ convert to base w 8: for i from 0 to len − 1 do 9: ADRS.setChainAddress(i) 10: tmp[i] ← chain(sig[i], msg[i], w − 1 − msg[i], PK.seed, ADRS) 11: end for 12: wotspkADRS ← ADRS ▷ copy address to create WOTS+ public key address 13: wotspkADRS.setTypeAndClear(WOTS_PK) 14: wotspkADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 15: pksig ← Tlen (PK.seed, wotspkADRS, tmp) 16: return pksig\n\n6. eXtended Merkle Signature Scheme (XMSS)\n\nXMSS extends the WOTS+ signature scheme into one that can sign multiple messages. A Merkle tree [13] of height h′ is used to allow 2h′ WOTS+ public keys to be authenticated using a single n-byte XMSS public key, which is the root of the Merkle tree.12 As each WOTS+ key may be used to sign one message, the XMSS key may be used to sign 2h′ messages. An XMSS signature is (h′ + len) ⋅ n bytes in length and consists of a WOTS+ signature and an authentication path (see Figure 11). The authentication path is an array of nodes from the Merkle tree — one from each level of the tree, except for the root — that allows the verifier to compute the root of the tree when used in conjunction with the WOTS+ public key that can be computed from the WOTS+ signature.\n\nSIGWOTS+ len ⋅ n bytes AUTH[0] n bytes ⋯ AUTH[h′ − 1] n bytes", "char_len": 3997, "approx_tokens": 999}
{"chunk_id": "NIST.FIPS.205::c00019", "doc_id": "NIST.FIPS.205", "start_page": 32, "end_page": 33, "text": "he root of the Merkle tree.12 As each WOTS+ key may be used to sign one message, the XMSS key may be used to sign 2h′ messages. An XMSS signature is (h′ + len) ⋅ n bytes in length and consists of a WOTS+ signature and an authentication path (see Figure 11). The authentication path is an array of nodes from the Merkle tree — one from each level of the tree, except for the root — that allows the verifier to compute the root of the tree when used in conjunction with the WOTS+ public key that can be computed from the WOTS+ signature.\n\nSIGWOTS+ len ⋅ n bytes AUTH[0] n bytes ⋯ AUTH[h′ − 1] n bytes\n\nFigure 11. XMSS signature data format\n\n6.1 Generating a Merkle Hash Tree The xmss_node function (Algorithm 9) computes the nodes of an XMSS tree. The xmss_node function takes as input SK.seed and PK.seed from the SLH-DSA private key; a target node index i, which is the index of the node being computed; a target node height z, which is the height within the Merkle tree of the node being computed; and an address. The address ADRS must have the layer address and tree address set to the XMSS tree within which the node is being computed. The target node height and index must satisfy z ≤ h′ and i < 2(h′−z) . Each node in an XMSS tree is the root of a subtree, and Algorithm 9 computes the root of the subtree recursively. If the subtree consists of a single leaf node, then the function simply returns the value of the node’s WOTS+ public key (lines 2 through 4). Otherwise, the function computes the roots of the left subtree (line 6) and right subtree (line 7) and hashes them together (lines 8 through 11).\n\n12The Merkle tree formed from the 2h′ WOTS+ keys of an XMSS key is referred to in this standard as an XMSS tree.\n\nAlgorithm 9 xmss_node(SK.seed, i, z, PK.seed, ADRS) Computes the root of a Merkle subtree of WOTS+ public keys. Input: Secret seed SK.seed, target node index i, target node height z, public seed PK.seed, address ADRS. Output: n-byte root node. 1: if z = 0 then 2: ADRS.setTypeAndClear(WOTS_HASH) 3: ADRS.setKeyPairAddress(i) 4: node ← wots_pkGen(SK.seed, PK.seed, ADRS) 5: else 6: lnode ← xmss_node(SK.seed, 2i, z − 1, PK.seed, ADRS) 7: rnode ← xmss_node(SK.seed, 2i + 1, z − 1, PK.seed, ADRS) 8: ADRS.setTypeAndClear(TREE) 9: ADRS.setTreeHeight(z) 10: ADRS.setTreeIndex(i) 11: node ← H(PK.seed, ADRS, lnode ∥ rnode) 12: end if 13: return node\n\n6.2 Generating an XMSS Signature The xmss_sign function (Algorithm 10) creates an XMSS signature on an n-byte message M13 by creating an authentication path (lines 1 through 4) and signing M with the appropriate WOTS+ key (lines 5 through 7). In addition to M, xmss_sign takes SK.seed and PK.seed from the SLH-DSA private key, an address, and an index as input. The address ADRS must have the layer address and tree address set to the XMSS key that is being used to sign the message, and the index idx must be the index of the WOTS+ key within the XMSS tree that will be used to sign the message. The authentication path consists of the sibling nodes of each node that is on the path from the WOTS+ key used to the root. For example, in Figure 12, if the message is signed with K2, then K2, n1,1 , and n2,0 are the on path nodes, and the authentication path consists of K3, n1,0 , and n2,1 . In line 2 of Algorithm 10, ⌊idx/2j⌋ is the on path node, and ⌊idx/2j⌋ ⊕ 1 is the authentication path node. Line 3 computes the value of the authentication path node.\n\n13In SLH-DSA, the message M that is signed using XMSS is either an XMSS public key or a FORS public key.", "char_len": 3535, "approx_tokens": 883}
{"chunk_id": "NIST.FIPS.205::c00020", "doc_id": "NIST.FIPS.205", "start_page": 33, "end_page": 36, "text": "ll be used to sign the message. The authentication path consists of the sibling nodes of each node that is on the path from the WOTS+ key used to the root. For example, in Figure 12, if the message is signed with K2, then K2, n1,1 , and n2,0 are the on path nodes, and the authentication path consists of K3, n1,0 , and n2,1 . In line 2 of Algorithm 10, ⌊idx/2j⌋ is the on path node, and ⌊idx/2j⌋ ⊕ 1 is the authentication path node. Line 3 computes the value of the authentication path node.\n\n13In SLH-DSA, the message M that is signed using XMSS is either an XMSS public key or a FORS public key.\n\nAlgorithm 10 xmss_sign(M, SK.seed, idx, PK.seed, ADRS) Generates an XMSS signature. Input: n-byte message M, secret seed SK.seed, index idx, public seed PK.seed, address ADRS. Output: XMSS signature SIGXMSS = (sig ∥ AUTH). 1: for j from 0 to h′ − 1 do ▷ build authentication path 2: k ← ⌊idx/2j⌋ ⊕ 1 3: AUTH[j] ← xmss_node(SK.seed, k, j, PK.seed, ADRS) 4: end for 5: ADRS.setTypeAndClear(WOTS_HASH) 6: ADRS.setKeyPairAddress(idx) 7: sig ← wots_sign(M, SK.seed, PK.seed, ADRS) 8: SIGXMSS ← sig ∥ AUTH 9: return SIGXMSS\n\nn3,0 = H(n2,0 ∥ n2,1 ) PPPPP P n2,0 = H(n1,0 ∥ n1,1 ) n2,1 = H(n1,2 ∥ n1,3 )\n\n�� @@ �� @@ n1,0 = H(K0 ∥ K1) n1,1 = H(K2 ∥ K3) n1,2 = H(K4 ∥ K5) n1,3 = H(K6 ∥ K7)\n\n�� @@ �� @@ �� @@ �� @@ K0 K1 K2 K3 K4 K5 K6 K7 Figure 12. Merkle hash tree\n\n6.3 Computing an XMSS Public Key From a Signature Verifying an XMSS signature involves computing a public-key value from a message and a signature value. Verification succeeds if the correct public-key value is computed, which is determined by using the computed public-key value along with other information to compute a candidate PK.root value and then comparing that value to the known value of PK.root from the SLH-DSA public key. This section describes xmss_pkFromSig (Algorithm 11), a function that computes a candidate XMSS public key from an XMSS signature and corresponding message. In addition to an n-byte message M and an (len+h′ )⋅n-byte signature SIGXMSS, xmss_pkFromSig takes PK.seed from the SLH-DSA public key, an address, and an index as input. The address ADRS must be set to the layer address and tree address of the XMSS key that was used to sign the message, and the index idx must be the index of the WOTS+ key within the XMSS tree that was used to sign the message. Algorithm 11 begins by computing the WOTS+ public key in lines 1 through 5. The root is then computed in lines 6 through 18. Starting with the leaf node (i.e., the WOTS+ public key), a node at each level of the tree is computed by hashing together the node computed in the previous iteration with the corresponding authentication path node. In lines 12 and 15, AUTH is interpreted as an array of h′ n-byte strings.\n\nAlgorithm 11 xmss_pkFromSig(idx, SIGXMSS, M, PK.seed, ADRS) Computes an XMSS public key from an XMSS signature. Input: Index idx, XMSS signature SIGXMSS = (sig ∥ AUTH), n-byte message M, public seed PK.seed, address ADRS. Output: n-byte root value node[0]. 1: ADRS.setTypeAndClear(WOTS_HASH) ▷ compute WOTS+ pk from WOTS+ sig 2: ADRS.setKeyPairAddress(idx) 3: sig ← SIGXMSS.getWOTSSig() ▷ SIGXMSS[0 ∶ len ⋅ n] 4: AUTH ← SIGXMSS.getXMSSAUTH() ▷ SIGXMSS[len ⋅ n ∶ (len + h′ ) ⋅ n] 5: node[0] ← wots_pkFromSig(sig, M , PK.seed, ADRS) 6: ADRS.setTypeAndClear(TREE) ▷ compute root from WOTS+ pk and AUTH 7: ADRS.setTreeIndex(idx) 8: for k from 0 to h′ − 1 do 9: ADRS.setTreeHeight(k + 1) 10: if ⌊idx/2k⌋ is even then 11: ADRS.setTreeIndex(ADRS.getTreeIndex()/2) 12: node[1] ← H(PK.seed, ADRS, node[0] ∥ AUTH[k]) 13: else 14: ADRS.setTreeIndex((ADRS.getTreeIndex() − 1)/2) 15: node[1] ← H(PK.seed, ADRS, AUTH[k] ∥ node[0]) 16: end if 17: node[0] ← node[1] 18: end for 19: return node[0]\n\n7. The SLH-DSA Hypertree", "char_len": 3771, "approx_tokens": 942}
{"chunk_id": "NIST.FIPS.205::c00021", "doc_id": "NIST.FIPS.205", "start_page": 35, "end_page": 37, "text": "] 4: AUTH ← SIGXMSS.getXMSSAUTH() ▷ SIGXMSS[len ⋅ n ∶ (len + h′ ) ⋅ n] 5: node[0] ← wots_pkFromSig(sig, M , PK.seed, ADRS) 6: ADRS.setTypeAndClear(TREE) ▷ compute root from WOTS+ pk and AUTH 7: ADRS.setTreeIndex(idx) 8: for k from 0 to h′ − 1 do 9: ADRS.setTreeHeight(k + 1) 10: if ⌊idx/2k⌋ is even then 11: ADRS.setTreeIndex(ADRS.getTreeIndex()/2) 12: node[1] ← H(PK.seed, ADRS, node[0] ∥ AUTH[k]) 13: else 14: ADRS.setTreeIndex((ADRS.getTreeIndex() − 1)/2) 15: node[1] ← H(PK.seed, ADRS, AUTH[k] ∥ node[0]) 16: end if 17: node[0] ← node[1] 18: end for 19: return node[0]\n\n7. The SLH-DSA Hypertree\n\nSLH-DSA requires a very large number of WOTS+ keys to sign FORS public keys. As it would not be feasible for the parameter sets in this standard to have a single XMSS key with so many WOTS+ keys, SLH-DSA uses a hypertree to sign the FORS keys. As depicted in Figure 1, a hypertree is a tree of XMSS trees. The XMSS keys at the lowest layer are used to sign FORS public keys (Section 8), and the XMSS keys at every other layer are used to sign the XMSS public keys at the layer below. The hypertree has d layers of XMSS trees with each XMSS tree being a Merkle tree of height h′ , so the total height of the hypertree is h = d ⋅ h′ (see Table 2). The top layer (layer d − 1) is a single XMSS tree, and the public key of this XMSS key pair (i.e., the root of the Merkle tree) is the public key of the hypertree (PK.root). The next layer down has 2h′ XMSS trees, and the public key of each of these XMSS keys is signed by one of the 2h′ WOTS+ keys that is part of the top layer’s XMSS key. The lowest layer has 2h−h′ XMSS trees, providing 2h WOTS+ keys to sign FORS keys.\n\n7.1 Hypertree Signature Generation A hypertree signature is (h + d ⋅ len) ⋅ n bytes in length and consists of a sequence of d XMSS signatures, starting with a signature generated using an XMSS key at the lowest layer and ending with a signature generated using the XMSS key at the top layer (see Figure 13).\n\nXMSS signature SIGXMSS (layer 0) (h′ + len) ⋅ n bytes XMSS signature SIGXMSS (layer 1) (h′ + len) ⋅ n bytes ⋯ XMSS signature SIGXMSS (layer d − 1) (h′ + len) ⋅ n bytes\n\nFigure 13. HT signature data format\n\nIn addition to the n-byte message M,14 the ht_sign function (Algorithm 12) takes as input SK.seed and PK.seed from the SLH-DSA private key, the index of the XMSS tree at the lowest layer that will sign the message idxtree, and the index of the WOTS+ key within the XMSS tree that will sign the message idxleaf . Algorithm 12 begins in lines 1 through 3 by signing M with the specified XMSS key using the WOTS+ key within that XMSS key specified by idxleaf . The XMSS public key is obtained (line 5 or 14) for each successive layer and signed by the appropriate key at the next higher level (lines 7 through 11).\n\n14In SLH-DSA, the message M that is provided to ht_sign is a FORS public key.\n\nAlgorithm 12 ht_sign(M, SK.seed, PK.seed, idxtree, idxleaf ) Generates a hypertree signature. Input: Message M, private seed SK.seed, public seed PK.seed, tree index idxtree, leaf index idxleaf . Output: HT signature SIGHT. 1: ADRS ← toByte(0, 32) 2: ADRS.setTreeAddress(idxtree) 3: SIGtmp ← xmss_sign(M, SK.seed, idxleaf , PK.seed, ADRS) 4: SIGHT ← SIGtmp 5: root ← xmss_pkFromSig(idxleaf , SIGtmp, M , PK.seed, ADRS) 6: for j from 1 to d − 1 do 7: idxleaf ← idxtree mod′2h′ ▷ h′ least significant bits of idxtree 8: idxtree ← idxtree ≫ h ▷ remove least significant h′ bits from idxtree 9: ADRS.setLayerAddress(j) 10: ADRS.setTreeAddress(idxtree) 11: SIGtmp ← xmss_sign(root, SK.seed, idxleaf , PK.seed, ADRS) 12: SIGHT ← SIGHT ∥ SIGtmp 13: if j < d − 1 then 14: endroot ← xmss_pkFromSig(idxleaf , SIGtmp, root, PK.seed, ADRS) 15: if 16: end for 17: return SIGHT", "char_len": 3740, "approx_tokens": 935}
{"chunk_id": "NIST.FIPS.205::c00022", "doc_id": "NIST.FIPS.205", "start_page": 37, "end_page": 39, "text": "dress(idxtree) 3: SIGtmp ← xmss_sign(M, SK.seed, idxleaf , PK.seed, ADRS) 4: SIGHT ← SIGtmp 5: root ← xmss_pkFromSig(idxleaf , SIGtmp, M , PK.seed, ADRS) 6: for j from 1 to d − 1 do 7: idxleaf ← idxtree mod′2h′ ▷ h′ least significant bits of idxtree 8: idxtree ← idxtree ≫ h ▷ remove least significant h′ bits from idxtree 9: ADRS.setLayerAddress(j) 10: ADRS.setTreeAddress(idxtree) 11: SIGtmp ← xmss_sign(root, SK.seed, idxleaf , PK.seed, ADRS) 12: SIGHT ← SIGHT ∥ SIGtmp 13: if j < d − 1 then 14: endroot ← xmss_pkFromSig(idxleaf , SIGtmp, root, PK.seed, ADRS) 15: if 16: end for 17: return SIGHT\n\n7.2 Hypertree Signature Verification Hypertree signature verification works by making d calls to xmss_pkFromSig (Algorithm 11) and comparing the result to the public key of the hypertree. In addition to the n-byte message M and the (h + d ⋅ len) ⋅ n-byte signature SIGHT, ht_verify (Algorithm 13) takes as input PK.seed and PK.root from the SLH-DSA public key, the index of the XMSS tree at the lowest layer that signed the message idxtree, and the index of the WOTS+ key within the XMSS tree that signed the message idxleaf . At each layer, either the message M or the computed public key of the XMSS key at the lower layer is provided along with the appropriate XMSS signature to xmss_pkFromSig in order to obtain the layer’s computed XMSS public key. If the computed XMSS public key of the top layer tree is the same as the known hypertree public key, PK.root, then verification succeeds.\n\nAlgorithm 13 ht_verify(M, SIGHT, PK.seed, idxtree, idxleaf , PK.root) Verifies a hypertree signature. Input: Message M, signature SIGHT, public seed PK.seed, tree index idxtree, leaf index idxleaf , HT public key PK.root. Output: Boolean. 1: ADRS ← toByte(0, 32) 2: ADRS.setTreeAddress(idxtree) ′ 3: SIGtmp ← SIGHT.getXMSSSignature(0) ▷ SIGHT[0 ∶ (h + len) ⋅ n] 4: node ← xmss_pkFromSig(idxleaf , SIGtmp, M , PK.seed, ADRS) 5: for j from 1 to d − 1 do 6: idxleaf ← idxtree mod′2h′ ▷ h′ least significant bits of idxtree 7: idxtree ← idxtree ≫ h ▷ remove least significant h′ bits from idxtree 8: ADRS.setLayerAddress(j) 9: ADRS.setTreeAddress(idxtree) 10: SIGtmp ← SIGHT.getXMSSSignature(j) ▷ SIGHT[j ⋅ (h′ + len) ⋅ n ∶ (j + 1)(h′ + len) ⋅ n] 11: endnode ← xmss_pkFromSig(idxleaf , SIGtmp, node, PK.seed, ADRS) 12: for 13: if node = PK.root then 14: return true 15: else 16: return false 17: end if\n\n8. Forest of Random Subsets (FORS)\n\nFORS is a few-time signature scheme that is used to sign the digests of the actual messages. Unlike WOTS+, for which forgeries become feasible if a key is used twice [22], the security of a FORS key degrades gradually as the number of signatures increases. FORS uses two parameters: k and t = 2a (see Table 2). A FORS private key consists of k sets of t n-byte strings, all of which are pseudorandomly generated from the seed SK.seed. Each of the k sets is formed into a Merkle tree, and the roots of the trees are hashed together to form the FORS public key. A signature on a k ⋅ a-bit message digest consists of k elements from the private key, one from each set selected using a bits of the message digest, along with the authentication paths for each of these elements (see Figure 14).\n\nprivate key value (tree 0) n bytes AUTH (tree 0) a ⋅ n bytes ⋯ private key value (tree k − 1) n bytes AUTH (tree k − 1) a ⋅ n bytes\n\nFigure 14. FORS signature data format\n\n8.1 Generating FORS Secret Values The fors_skGen function (Algorithm 14) generates the n-byte strings of the FORS private key. The function takes SK.seed and PK.seed from the SLH-DSA private key, an address, and an index as input. The type in the address ADRS must be set to FORS_TREE, and the tree address and key pair address must be set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The layer address must be set to zero. The index idx is the index of the FORS secret value within the sets of FORS trees.", "char_len": 3929, "approx_tokens": 982}
{"chunk_id": "NIST.FIPS.205::c00023", "doc_id": "NIST.FIPS.205", "start_page": 39, "end_page": 41, "text": "e k − 1) a ⋅ n bytes\n\nFigure 14. FORS signature data format\n\n8.1 Generating FORS Secret Values The fors_skGen function (Algorithm 14) generates the n-byte strings of the FORS private key. The function takes SK.seed and PK.seed from the SLH-DSA private key, an address, and an index as input. The type in the address ADRS must be set to FORS_TREE, and the tree address and key pair address must be set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The layer address must be set to zero. The index idx is the index of the FORS secret value within the sets of FORS trees.\n\nAlgorithm 14 fors_skGen(SK.seed, PK.seed, ADRS, idx) Generates a FORS private-key value. Input: Secret seed SK.seed, public seed PK.seed, address ADRS, secret key index idx. Output: n-byte FORS private-key value. 1: skADRS ← ADRS ▷ copy address to create key generation address 2: skADRS.setTypeAndClear(FORS_PRF) 3: skADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 4: skADRS.setTreeIndex(idx) 5: return PRF(PK.seed, SK.seed, skADRS)\n\n8.2 Generating a Merkle Hash Tree The fors_node function (Algorithm 15) computes the nodes of a Merkle tree. It is the same as xmss_node, except that the leaf nodes are the hashes of the FORS secret values instead of WOTS+ public keys. The fors_node function takes as input SK.seed and PK.seed from the SLH-DSA private key; a target node index i, which is the index of the node being computed; a target node height z, which is the height within the Merkle tree of the node being computed; and an address. The address ADRS must have the layer address set to zero (since the XMSS tree that signs a FORS key is always at layer 0), the tree address set to the XMSS tree that signs the FORS key, the type set to FORS_TREE, and the key pair address set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The target node height and index must satisfy z ≤ a and i < k ⋅ 2(a−z). Each node in the Merkle tree is the root of a subtree, and Algorithm 15 computes the root of a subtree recursively. If the subtree consists of a single leaf node, then the function simply returns a hash of the node’s private n-byte string (lines 2 through 5). Otherwise, the function computes the roots of the left subtree (line 7) and right subtree (line 8) and hashes them together (lines 9 through 11).\n\nAlgorithm 15 fors_node(SK.seed, i, z, PK.seed, ADRS) Computes the root of a Merkle subtree of FORS public values. Input: Secret seed SK.seed, target node index i, target node height z, public seed PK.seed, address ADRS. Output: n-byte root node. 1: if z = 0 then 2: sk ← fors_skGen(SK.seed, PK.seed, ADRS, i) 3: ADRS.setTreeHeight(0) 4: ADRS.setTreeIndex(i) 5: node ← F(PK.seed, ADRS, sk) 6: else 7: lnode ← fors_node(SK.seed, 2i, z − 1, PK.seed, ADRS) 8: rnode ← fors_node(SK.seed, 2i + 1, z − 1, PK.seed, ADRS) 9: ADRS.setTreeHeight(z) 10: ADRS.setTreeIndex(i) 11: node ← H(PK.seed, ADRS, lnode ∥ rnode) 12: end if 13: return node\n\n8.3 Generating a FORS Signature The fors_sign function (Algorithm 16) signs a k ⋅ a-bit message digest md.15 In addition to the message digest, fors_sign takes SK.seed and PK.seed from the SLH-DSA private key and an address as input. The address ADRS must have the layer address set to zero (since the XMSS\n\n15For convenience, fors_sign takes a ⌈k⋅a⌉ byte message digest as input and extracts k ⋅ a bits to sign.\n\ntree that signs a FORS key is always at layer 0), the tree address set to the XMSS tree that signs the FORS key, the type set to FORS_TREE, and the key pair address set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The fors_sign function splits k⋅a bits of md into k a-bit strings (line 2), each of which is interpreted as an integer between 0 and t − 1. Each of these integers is used to select a secret value from one of the k sets (line 4). For each secret value selected, an authentication path is computed and added to the signature (lines 5 through 9).", "char_len": 3975, "approx_tokens": 993}
{"chunk_id": "NIST.FIPS.205::c00024", "doc_id": "NIST.FIPS.205", "start_page": 40, "end_page": 42, "text": "to sign.\n\ntree that signs a FORS key is always at layer 0), the tree address set to the XMSS tree that signs the FORS key, the type set to FORS_TREE, and the key pair address set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The fors_sign function splits k⋅a bits of md into k a-bit strings (line 2), each of which is interpreted as an integer between 0 and t − 1. Each of these integers is used to select a secret value from one of the k sets (line 4). For each secret value selected, an authentication path is computed and added to the signature (lines 5 through 9).\n\nAlgorithm 16 fors_sign(md, SK.seed, PK.seed, ADRS) Generates a FORS signature. Input: Message digest md, secret seed SK.seed, address ADRS, public seed PK.seed. Output: FORS signature SIGF ORS . 1: SIGF ORS = NULL b ▷ initialize SIGF ORS as a zero-length byte string 2: indices ← base_2 (md, a, k) 3: for i from 0 to k − 1 do ▷ compute signature elements 4: SIGF ORS ← SIGF ORS ∥ fors_skGen(SK.seed, PK.seed, ADRS, i ⋅ 2a + indices[i]) 5: for j from 0 to a − 1 do ▷ compute auth path 6: s ← ⌊indices[i]/2j⌋ ⊕ 1 7: AUTH[j] ← fors_node(SK.seed, i ⋅ 2a−j + s, j, PK.seed, ADRS) 8: end for 9: endSIGF ORS ← SIGF ORS ∥ AUTH 10: for 11: return SIGF ORS\n\n8.4 Computing a FORS Public Key From a Signature Verifying a FORS signature involves computing a public-key value from a message digest and a signature value. Verification succeeds if the correct public-key value is computed, which is determined by verifying the hypertree signature on the computed public-key value using the SLH- DSA public key. This section describes fors_pkFromSig (Algorithm 17), a function that computes a candidate FORS public key from a FORS signature and corresponding message digest. In addition to a message digest md and a k ⋅ (a + 1) ⋅ n-byte signature SIGF ORS , fors_pkFromSig takes PK.seed from the SLH-DSA public key and an address as input.16 The address ADRS must have the layer address set to zero (since the XMSS tree that signs a FORS key is always at layer 0), the tree address set to the XMSS tree that signs the FORS key, the type set to FORS_TREE, and the key pair address set to the index of the WOTS+ key within the XMSS tree that signs the FORS key. The fors_pkFromSig function begins by computing the roots of each of the k Merkle trees (lines 2 through 20). As in fors_sign, k ⋅ a bits of the message digest are split into k a-bit strings (line 1), each of which is interpreted as an integer between 0 and t − 1. The integers are used to determine the locations in the Merkle trees of the secret values from the signature (lines 3 16As with fors_sign, fors_pkFromSig takes a ⌈k⋅a⌉ byte message digest as input and extracts k ⋅ a bits.\n\nthrough 5). The hashes of the secret values are computed (line 6), and the hash values are used along with the corresponding authentication paths from the signature to compute the Merkle tree roots (lines 7 through 19). Once all of the Merkle tree roots have been computed, they are hashed together to compute the FORS public key (lines 21 through 24).\n\nAlgorithm 17 fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) Computes a FORS public key from a FORS signature. Input: FORS signature SIGF ORS , message digest md, public seed PK.seed, address ADRS. Output: FORS public key. 1: indices ← base_2b(md, a, k) 2: for i from 0 to k − 1 do 3: sk ← SIGF ORS .getSK(i) ▷ SIGF ORS [i ⋅ (a + 1) ⋅ n ∶ (i ⋅ (a + 1) + 1) ⋅ n] 4: ADRS.setTreeHeight(0) ▷ compute leaf 5: ADRS.setTreeIndex(i ⋅ 2a + indices[i]) 6: node[0] ← F(PK.seed, ADRS, sk) 7: auth ← SIGF ORS .getAUTH(i) ▷ SIGF ORS [(i ⋅ (a + 1) + 1) ⋅ n ∶ (i + 1) ⋅ (a + 1) ⋅ n] 8: for j from 0 to a − 1 do ▷ compute root from leaf and AUTH 9: ADRS.setTreeHeight(j + 1) 10: if ⌊indices[i]/2j⌋ is even then 11: ADRS.setTreeIndex(ADRS.getTreeIndex()/2) 12: node[1] ← H(PK.seed, ADRS, node[0] ∥ auth[j]) 13: else 14: ADRS.setTreeIndex((ADRS.getTreeIndex() − 1)/2) 15: node[1] ← H(PK.seed, ADRS, auth[j] ∥ node[0]) 16: end if 17: nod", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.FIPS.205::c00025", "doc_id": "NIST.FIPS.205", "start_page": 42, "end_page": 43, "text": "S [i ⋅ (a + 1) ⋅ n ∶ (i ⋅ (a + 1) + 1) ⋅ n] 4: ADRS.setTreeHeight(0) ▷ compute leaf 5: ADRS.setTreeIndex(i ⋅ 2a + indices[i]) 6: node[0] ← F(PK.seed, ADRS, sk) 7: auth ← SIGF ORS .getAUTH(i) ▷ SIGF ORS [(i ⋅ (a + 1) + 1) ⋅ n ∶ (i + 1) ⋅ (a + 1) ⋅ n] 8: for j from 0 to a − 1 do ▷ compute root from leaf and AUTH 9: ADRS.setTreeHeight(j + 1) 10: if ⌊indices[i]/2j⌋ is even then 11: ADRS.setTreeIndex(ADRS.getTreeIndex()/2) 12: node[1] ← H(PK.seed, ADRS, node[0] ∥ auth[j]) 13: else 14: ADRS.setTreeIndex((ADRS.getTreeIndex() − 1)/2) 15: node[1] ← H(PK.seed, ADRS, auth[j] ∥ node[0]) 16: end if 17: node[0] ← node[1] 18: end for 19: root[i] ← node[0] 20: end for 21: forspkADRS ← ADRS ▷ copy address to create a FORS public-key address 22: forspkADRS.setTypeAndClear(FORS_ROOTS) 23: forspkADRS.setKeyPairAddress(ADRS.getKeyPairAddress()) 24: pk ← Tk(PK.seed, forspkADRS, root) ▷ compute the FORS public key 25: return pk\n\n9. SLH-DSA Internal Functions\n\nSLH-DSA uses the hypertree and the FORS keys to create a stateless hash-based signature scheme. The SLH-DSA private key contains a secret seed value and a secret PRF key. The public key consists of a key identifier PK.seed and the root of the hypertree. A signature is created by hashing the message, using part of the message digest to select a FORS key, signing other bits from the message digest with the FORS key, and generating a hypertree signature for the FORS key. The parameters for SLH-DSA are those specified previously for WOTS+, XMSS, the SLH-DSA hypertree, and FORS (see Table 2). SLH-DSA uses one additional parameter m, which is the length in bytes of the message digest. It is computed as:\n\nm = ⌈h − h′ ⌉ + ⌈h′ ⌉ + ⌈k ⋅ a ⌉ 8 8 8\n\nSLH-DSA uses h bits of the message digest to select a FORS key: h − h′ bits to select an XMSS tree at the lowest layer and h′ bits to select a WOTS+ key and corresponding FORS key from that tree. k ⋅ a bits of the digest are signed by the selected FORS key. While only h + k ⋅ a bits of the message digest are used, implementation is simplified by extracting the necessary bits from a slightly larger digest. This section describes the functions for SLH-DSA key generation, signature generation, and signature verification. In the functions in this section, where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of SLH-DSA implementations is performed through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to obtain the assurance of private key possession via regeneration, as described in Section 3.1. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 10 provides guidance on the interfaces to be made available to applications.\n\n9.1 SLH-DSA Key Generation SLH-DSA public keys contain two elements (see Figure 16). The first is an n-byte public seed PK.seed, which is used in many hash function calls to provide domain separation between different SLH-DSA key pairs. The second value is the hypertree public key (i.e., the root of the top layer XMSS tree). PK.seed shall be generated using an approved random bit generator (see\n\nSK.seed n bytes SK.prf n bytes PK.seed n bytes PK.seed n bytes PK.root n bytes PK.root n bytes\n\nFigure 15. SLH-DSA private key Figure 16. SLH-DSA public key", "char_len": 3601, "approx_tokens": 900}
{"chunk_id": "NIST.FIPS.205::c00026", "doc_id": "NIST.FIPS.205", "start_page": 43, "end_page": 45, "text": "ces to be made available to applications.\n\n9.1 SLH-DSA Key Generation SLH-DSA public keys contain two elements (see Figure 16). The first is an n-byte public seed PK.seed, which is used in many hash function calls to provide domain separation between different SLH-DSA key pairs. The second value is the hypertree public key (i.e., the root of the top layer XMSS tree). PK.seed shall be generated using an approved random bit generator (see\n\nSK.seed n bytes SK.prf n bytes PK.seed n bytes PK.seed n bytes PK.root n bytes PK.root n bytes\n\nFigure 15. SLH-DSA private key Figure 16. SLH-DSA public key\n\n[14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength. The SLH-DSA private key contains two random, secret n-byte values (see Figure 15). SK.seed is used to generate all of the WOTS+ and FORS private key elements. SK.prf is used to generate a randomization value for the randomized hashing of the message in SLH-DSA. The private key also includes a copy of the public key. Both SK.seed and SK.prf shall be generated using an approved random bit generator, where the instantiation of the random bit generator supports at least 8n bits of security strength. Algorithm 18 generates an SLH-DSA key pair. Lines 1 through 3 compute the root of the top layer XMSS tree. Line 4 bundles the three inputs and the computed PK.seed into the private and public keys. SLH-DSA signing has two variants — “hedged” and deterministic (see Section 9.2) — whose keys should only be used for the generation and verification of hedged and deterministic SLH-DSA digital signatures, respectively.\n\nAlgorithm 18 slh_keygen_internal(SK.seed, SK.prf, PK.seed) Generates an SLH-DSA key pair. Input: Secret seed SK.seed, PRF key SK.prf, public seed PK.seed Output: SLH-DSA key pair (SK, PK). 1: ADRS ← toByte(0, 32) ▷ generate the public key for the top-level XMSS tree 2: ADRS.setLayerAddress(d − 1) 3: PK.root ← xmss_node(SK.seed, 0, h′ , PK.seed, ADRS) 4: return ( (SK.seed, SK.prf, PK.seed, PK.root), (PK.seed, PK.root) )\n\n9.2 SLH-DSA Signature Generation An SLH-DSA signature consists of a randomization string, a FORS signature, and a hypertree signature, as shown in Figure 17. Generating an SLH-DSA signature (Algorithm 19) begins by creating an m-byte message digest (lines 2 through 5). A PRF is used to create a message randomizer (line 3), and it is hashed along with the message to create the digest (line 5). Bits are then extracted from the message digest to be signed by the FORS key (line 6), to select an XMSS tree (lines 7 and 9), and to select a WOTS+ key and corresponding FORS key within that XMSS tree (lines 8 and 10). Next, the FORS signature is computed (lines 11 through 14), and the corresponding FORS public key is obtained (line 16). Finally, the FORS public key is signed (line 17).\n\nRandomness R n bytes FORS signature SIGFORS k(1 + a) ⋅ n bytes HT signature SIGHT (h + d ⋅ len) ⋅ n bytes\n\nFigure 17. SLH-DSA signature data format\n\nAlgorithm 19 slh_sign_internal(M, SK, addrnd) Generates an SLH-DSA signature. Input: Message M, private key SK = (SK.seed, SK.prf, PK.seed, PK.root), (optional) additional randomness addrnd. Output: SLH-DSA signature SIG. 1: ADRS ← toByte(0, 32) 2: opt_rand ← addrnd ▷ substitute opt_rand ← PK.seed for the deterministic variant 3: R ← PRFmsg(SK.prf, opt_rand, M ) ▷ generate randomizer 4: SIG ← R 5: digest ← Hmsg(R, PK.seed, PK.root, M ) ▷ compute message digest 6: md ← digest [0 ∶ ⌈k⋅a⌉] ▷ first ⌈k⋅a⌉ bytes 8 h−h/d 8 7: tmp_idxtree ← digest [⌈ k⋅a⌉ ∶ ⌈k⋅a⌉ + ⌈ ⌉] ▷ next ⌈ h−h/d ⌉ bytes 8 8 8 8 8: tmp_idxleaf ← digest [⌈ k⋅a⌉ + ⌈ h−h/d ⌉ ∶ ⌈k⋅a⌉ + ⌈ h−h/d ⌉ + ⌈ h ⌉] ▷ next ⌈ h ⌉ bytes 8 8 8 8 8d 8d 9: idxtree ← toInt (tmp_idxtree, ⌈ h−h/d ⌉) mod 2h−h/d 10: idxleaf ← toInt (tmp_idxleaf , ⌈ h ⌉) mod 2h/d 8d 11: ADRS.setTreeAddress(idxtree) 12: ADRS.setTypeAndClear(FORS_TREE) 13: ADRS.setKeyPairAddress(idxleaf ) 14: SIGF ORS ← fors_sign(md, SK.seed, PK.seed, ADRS) 15: SIG ← SIG ∥ SIGF ORS 16: PK", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.FIPS.205::c00027", "doc_id": "NIST.FIPS.205", "start_page": 45, "end_page": 47, "text": "st ← Hmsg(R, PK.seed, PK.root, M ) ▷ compute message digest 6: md ← digest [0 ∶ ⌈k⋅a⌉] ▷ first ⌈k⋅a⌉ bytes 8 h−h/d 8 7: tmp_idxtree ← digest [⌈ k⋅a⌉ ∶ ⌈k⋅a⌉ + ⌈ ⌉] ▷ next ⌈ h−h/d ⌉ bytes 8 8 8 8 8: tmp_idxleaf ← digest [⌈ k⋅a⌉ + ⌈ h−h/d ⌉ ∶ ⌈k⋅a⌉ + ⌈ h−h/d ⌉ + ⌈ h ⌉] ▷ next ⌈ h ⌉ bytes 8 8 8 8 8d 8d 9: idxtree ← toInt (tmp_idxtree, ⌈ h−h/d ⌉) mod 2h−h/d 10: idxleaf ← toInt (tmp_idxleaf , ⌈ h ⌉) mod 2h/d 8d 11: ADRS.setTreeAddress(idxtree) 12: ADRS.setTypeAndClear(FORS_TREE) 13: ADRS.setKeyPairAddress(idxleaf ) 14: SIGF ORS ← fors_sign(md, SK.seed, PK.seed, ADRS) 15: SIG ← SIG ∥ SIGF ORS 16: PKF ORS ← fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) ▷ get FORS key 17: SIGHT ← ht_sign(PKF ORS , SK.seed, PK.seed, idxtree, idxleaf ) 18: SIG ← SIG ∥ SIGHT 19: return SIG\n\nThe message randomizer may be set in either a non-deterministic or deterministic way, depending on whether addrnd is provided as an input. For the “hedged” variant, addrnd is provided as an input, and opt_rand is set to addrnd. The hedged variant is the default and should be used on platforms where side-channel attacks are a concern. When using the hedged version, addrnd shall be an n-byte random value. While addrnd should ideally be generated by an approved random bit generator, other methods for generating fresh random values may be used. For the deterministic variant, addrnd is not provided as an input, and opt_rand is set to PK.seed, which results in signing being deterministic (i.e., signing the same message twice will result in the same signature). The deterministic variant is available for platforms where a random bit generator is not available.\n\n9.3 SLH-DSA Signature Verification As with signature generation, SLH-DSA signature verification (Algorithm 20) begins by computing a message digest (line 8) and then extracting md (line 9), idxtree (lines 10 and 12), and idxleaf (lines 11 and 13) from the digest. A candidate FORS public key is then computed (line 17), and the signature on the FORS key is verified (line 18). If this signature verification succeeds, then the correct FORS public key was computed, and the signature SIG on message M is valid.\n\nAlgorithm 20 slh_verify_internal(M, SIG, PK) Verifies an SLH-DSA signature. Input: Message M, signature SIG, public key PK = (PK.seed, PK.root). Output: Boolean. 1: if |SIG| ≠ (1 + k(1 + a) + h + d ⋅ len) ⋅ n then 2: return false 3: end if 4: ADRS ← toByte(0, 32) 5: R ← SIG.getR() ▷ SIG[0 ∶ n] 6: SIGF ORS ← SIG.getSIG_FORS() ▷ SIG[n ∶ (1 + k(1 + a)) ⋅ n] 7: SIGHT ← SIG.getSIG_HT() ▷ SIG[(1 + k(1 + a)) ⋅ n ∶ (1 + k(1 + a) + h + d ⋅ len) ⋅ n] 8: digest ← Hmsg(R, PK.seed, PK.root, M ) ▷ compute message digest 9: md ← digest [0 ∶ ⌈k⋅a⌉] ▷ first ⌈k⋅a⌉ bytes 8 h−h/d 8 10: tmp_idxtree ← digest [⌈ k⋅a⌉ ∶ ⌈k⋅a⌉ + ⌈ ⌉] ▷ next ⌈ h−h/d ⌉ bytes 8 8 8 8 11: tmp_idxleaf ← digest [⌈ k⋅a⌉ + ⌈ h−h/d ⌉ ∶ ⌈k⋅a⌉ + ⌈ h−h/d ⌉ + ⌈ h ⌉] ▷ next ⌈ h ⌉ bytes 8 8 8 8 8d 8d 12: idxtree ← toInt (tmp_idxtree, ⌈ h−h/d ⌉) mod 2h−h/d 13: idxleaf ← toInt (tmp_idxleaf , ⌈ h ⌉) mod 2h/d 8d 14: ADRS.setTreeAddress(idxtree) ▷ compute FORS public key 15: ADRS.setTypeAndClear(FORS_TREE) 16: ADRS.setKeyPairAddress(idxleaf ) 17: PKF ORS ← fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) 18: return ht_verify(PKF ORS , SIGHT, PK.seed, idxtree, idxleaf , PK.root)\n\n10. SLH-DSA External Functions\n\nThis section provides guidance on the key generation, signature generation, and signature verification functions that should be provided for use by applications. The functions in this section use the functions in Section 9 to implement the underlying SLH-DSA scheme.", "char_len": 3580, "approx_tokens": 895}
{"chunk_id": "NIST.FIPS.205::c00028", "doc_id": "NIST.FIPS.205", "start_page": 46, "end_page": 48, "text": "tmp_idxleaf , ⌈ h ⌉) mod 2h/d 8d 14: ADRS.setTreeAddress(idxtree) ▷ compute FORS public key 15: ADRS.setTypeAndClear(FORS_TREE) 16: ADRS.setKeyPairAddress(idxleaf ) 17: PKF ORS ← fors_pkFromSig(SIGF ORS , md, PK.seed, ADRS) 18: return ht_verify(PKF ORS , SIGHT, PK.seed, idxtree, idxleaf , PK.root)\n\n10. SLH-DSA External Functions\n\nThis section provides guidance on the key generation, signature generation, and signature verification functions that should be provided for use by applications. The functions in this section use the functions in Section 9 to implement the underlying SLH-DSA scheme.\n\n10.1 SLH-DSA Key Generation Algorithm 21 generates an SLH-DSA key pair. Lines 1 through 3 generate the random values for the private and public keys, and line 7 calls slh_keygen_internal to compute PK.root and return the private and public key. PK.seed, SK.seed, and SK.prf shall be generated using an approved random bit generator (see [14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength.\n\nAlgorithm 21 slh_keygen() Generates an SLH-DSA key pair. Input: (none) Output: SLH-DSA key pair (SK, PK). SK.seed $ n ← 1: − B ▷ set SK.seed, SK.prf, and PK.seed to random n-byte SK.prf $ n ← 2: − B ▷ strings using an approved random bit generator PK.seed $ n ← 3: − B 4: if SK.seed = NULL or SK.prf = NULL or PK.seed = NULL then 5: return ⊥ ▷ return an error indication if random bit generation failed 6: end if 7: return slh_keygen_internal(SK.seed, SK.prf, PK.seed)\n\n10.2 SLH-DSA Signature Generation This section presents two versions of SLH-DSA signature generation: a “pure” version (slh_sign) and a “pre-hash” version (hash_slh_sign). Both versions use slh_sign_internal, but they differ in how the message input to slh_sign_internal is created from the content to be signed. In the pure version, the content is signed by slh_sign_internal along with some domain separation information. In the pre-hash version, a hash of the content is signed by slh_sign_internal along with some domain separation information. Both versions take the content to be signed, the private key, and a context as input. The pre-hash version also takes as input a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string. However, applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a pure signature or a pre-hash signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash.17 While 17In the case of a XOF, this would also include the length of the output from the XOF.\n\na single key pair may be used for both pure and pre-hash signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or the application with which the signature is being used. If the default hedged variant of slh_sign_internal is used, the n-byte random value addrnd shall be generated by the cryptographic module that runs slh_sign_internal. However, M′ in Algorithms 22 and 23 may be constructed outside of the crytographic module. In the case of hash_slh_sign, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that runs slh_sign_internal. In general, the pure version is preferred. However, for some cryptographic modules that generate SLH-DSA signatures, performing lines 3 and 5 of Algorithm 19 may be infeasible if the message M is large. This may, for example, be the result of the module having limited memory to store the message to be signed.", "char_len": 3937, "approx_tokens": 984}
{"chunk_id": "NIST.FIPS.205::c00029", "doc_id": "NIST.FIPS.205", "start_page": 48, "end_page": 49, "text": "23 may be constructed outside of the crytographic module. In the case of hash_slh_sign, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that runs slh_sign_internal. In general, the pure version is preferred. However, for some cryptographic modules that generate SLH-DSA signatures, performing lines 3 and 5 of Algorithm 19 may be infeasible if the message M is large. This may, for example, be the result of the module having limited memory to store the message to be signed. Similarly, for some cryptographic modules that verify SLH-DSA signatures, performing line 8 of Algorithm 20 may be infeasible if the message M is large. For some use cases, these issues may be addressed by signing a digest of the content rather than signing the content directly. In many cases where the content to be signed is large, hashing of the content is performed at the application level. For example, in the Cryptographic Message Syntax [23], a digest of the content may be computed, and that digest is signed along with other attributes. In cases in which the content is not hashed at the application level, the pre-hash version of SLH-DSA signing (Section 10.2.2) may be used. To maintain the same level of security strength when the content is hashed at the application level or when using the pre-hash version of SLH-DSA, the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180-4 [8] or FIPS 202 [6]) that provides at least 8n bits of classical security strength against both collision and second preimage attacks [6, Table 4].18 Verification of a signature created in this way will require the verify function to generate a digest from the message in the same way for input to the verification function. Even if it is feasible to compute collisions on the hash functions or XOF used to instantiate Hmsg, PRF, PRFmsg, F, H, and Tl, there is believed to be no adverse effect on the security of SLH-DSA.19 However, if the input to the signing function is a digest of the content, then collisions on the function used to compute the digest can result in forged messages.\n\n10.2.1 Pure SLH-DSA Signature Generation In the pure version, the content to be signed is prepended with a one-byte domain separator, one byte that indicates the length of the context string, and the context string. The domain separator, which has a value of zero for pure signing, is included to prevent pre-hash signatures from verifying as pure signatures and vice versa. In the default case in which the context string\n\n18Obtaining at least 8n bits of classical security strength against collision attacks requires that the digest to be signed is at least 2n bytes in length. 19As noted in Section 11, applications that require message-bound signatures may be adversely affected if it is feasible to compute collisions on Hmsg.\n\nis empty, pure signing simply involves prepending two zero bytes to the content to be signed and passing the result to slh_sign_internal along with the private key and, in the case of hedged signing, an n-byte random value.\n\nAlgorithm 22 slh_sign(M, ctx, SK) Generates a pure SLH-DSA signature. Input: Message M, context string ctx, private key SK. Output: SLH-DSA signature SIG. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if addrnd $ n ← 4: − B ▷ skip lines 4 through 7 for the deterministic variant 5: if addrnd = NULL then 6: return ⊥ ▷ return an error indication if random bit generation failed 7: end if 8: M′ ← toByte(0, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ M 9: SIG ← slh_sign_internal(M ′ , SK, addrnd) ▷ omit addrnd for the deterministic variant 10: return SIG", "char_len": 3790, "approx_tokens": 947}
{"chunk_id": "NIST.FIPS.205::c00030", "doc_id": "NIST.FIPS.205", "start_page": 49, "end_page": 51, "text": "lgorithm 22 slh_sign(M, ctx, SK) Generates a pure SLH-DSA signature. Input: Message M, context string ctx, private key SK. Output: SLH-DSA signature SIG. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if addrnd $ n ← 4: − B ▷ skip lines 4 through 7 for the deterministic variant 5: if addrnd = NULL then 6: return ⊥ ▷ return an error indication if random bit generation failed 7: end if 8: M′ ← toByte(0, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ M 9: SIG ← slh_sign_internal(M ′ , SK, addrnd) ▷ omit addrnd for the deterministic variant 10: return SIG\n\n10.2.2 HashSLH-DSA Signature Generation In the pre-hash version, the message input to slh_sign_internal is the result of applying either a hash function or a XOF to the content to be signed. The output of the hash function or XOF is prepended by a one-byte domain separator, one byte that indicates the length of the context string, the context string, and the distinguished encoding rules (DER) encoding of the hash function or XOF’s OID. The domain separator has a value of one for pre-hash signing. The DER encoding of the OID includes the tag and length. Algorithm 23 shows the DER encodings of the OIDs for SHA-256, SHA-512, SHAKE128, and SHAKE256. However, hash_slh_sign may be used with other hash functions or XOFs. SHA-256 and SHAKE128 are only appropriate for use with SLH-DSA parameter sets that are claimed to be in security category 1 (see Section 11).\n\nAlgorithm 23 hash_slh_sign(M, ctx, PH, SK) Generates a pre-hash SLH-DSA signature. Input: Message M, context string ctx, pre-hash function PH, private key SK. Output: SLH-DSA signature SIG. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if addrnd $ n ← 4: − B ▷ skip lines 4 through 7 for the deterministic variant 5: if addrnd = NULL then 6: return ⊥ ▷ return an error indication if random bit generation failed 7: end if 8: switch PH do 9: case SHA-256: 10: OID ← toByte(0x0609608648016503040201, 11) ▷ 2.16.840.1.101.3.4.2.1 11: PHM ← SHA-256(M) 12: case SHA-512: 13: OID ← toByte(0x0609608648016503040203, 11) ▷ 2.16.840.1.101.3.4.2.3 14: PHM ← SHA-512(M) 15: case SHAKE128: 16: OID ← toByte(0x060960864801650304020B, 11) ▷ 2.16.840.1.101.3.4.2.11 17: PHM ← SHAKE128(M, 256) 18: case SHAKE256: 19: OID ← toByte(0x060960864801650304020C, 11) ▷ 2.16.840.1.101.3.4.2.12 20: PHM ← SHAKE256(M, 512) 21: case ... ▷ other approved hash functions or XOFs 22: ... 23: end switch 24: M′ ← toByte(1, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM 25: SIG ← slh_sign_internal(M ′ , SK, addrnd) ▷ omit addrnd for the deterministic variant 26: return SIG\n\n10.3 SLH-DSA Signature Verification Algorithms 24 and 25 present the pure and pre-hash versions of SLH-DSA signature verification that correspond to the pure and pre-hash versions of SLH-DSA signature generation in Section 10.2. These functions construct M′ in the same way as Algorithms 22 and 23, respectively, and pass the resulting M′ to slh_verify_internal for verification. As with signature generation, M′ may be constructed outside of the cryptographic module that performs slh_verify_internal. However, in the case of hash_slh_verify, the hash or XOF of the content must be computed within a FIPS 140-validated cryptographic module, which may be a different cryptographic module than the one that performs slh_verify_internal. The identifier associated with the signature should indicate whether the pure or pre-hash version of signature verification should be used, and in the pre-hash case, the hash function or XOF to use to compute the pre-hash. A non-empty context string should be used in verification if one is specified in the signature’s identifier or by the application with which the signature is being used.", "char_len": 3792, "approx_tokens": 948}
{"chunk_id": "NIST.FIPS.205::c00031", "doc_id": "NIST.FIPS.205", "start_page": 51, "end_page": 53, "text": "h_slh_verify, the hash or XOF of the content must be computed within a FIPS 140-validated cryptographic module, which may be a different cryptographic module than the one that performs slh_verify_internal. The identifier associated with the signature should indicate whether the pure or pre-hash version of signature verification should be used, and in the pre-hash case, the hash function or XOF to use to compute the pre-hash. A non-empty context string should be used in verification if one is specified in the signature’s identifier or by the application with which the signature is being used.\n\nAlgorithm 24 slh_verify(M, SIG, ctx, PK) Verifies a pure SLH-DSA signature. Input: Message M, signature SIG, context string ctx, public key PK. Output: Boolean. 1: if |ctx| > 255 then 2: return false 3: end if 4: M′ ← toByte(0, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ M 5: return slh_verify_internal(M ′ , SIG, PK)\n\nAlgorithm 25 hash_slh_verify(M, SIG, ctx, PH, PK) Verifies a pre-hash SLH-DSA signature. Input: Message M, signature SIG, context string ctx, pre-hash function PH, public key PK. Output: Boolean. 1: if |ctx| > 255 then 2: return false 3: end if 4: switch PH do 5: case SHA-256: 6: OID ← toByte(0x0609608648016503040201, 11) ▷ 2.16.840.1.101.3.4.2.1 7: PHM ← SHA-256(M) 8: case SHA-512: 9: OID ← toByte(0x0609608648016503040203, 11) ▷ 2.16.840.1.101.3.4.2.3 10: PHM ← SHA-512(M) 11: case SHAKE128: 12: OID ← toByte(0x060960864801650304020B, 11) ▷ 2.16.840.1.101.3.4.2.11 13: PHM ← SHAKE128(M, 256) 14: case SHAKE256: 15: OID ← toByte(0x060960864801650304020C, 11) ▷ 2.16.840.1.101.3.4.2.12 16: PHM ← SHAKE256(M, 512) 17: case ... ▷ other approved hash functions or XOFs 18: ... 19: end switch 20: M′ ← toByte(1, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM 21: return slh_verify_internal(M ′ , SIG, PK)\n\n11. Parameter Sets\n\nThis standard approves 12 parameter sets for use with SLH-DSA. A parameter set consists of parameters for WOTS+ (n and lgw), XMSS and the SLH-DSA hypertree (h and d), and FORS (k and a), as well as instantiations for the functions Hmsg, PRF, PRFmsg, F, H, and Tl. Table 2 lists the parameter sets that are approved for use.20 Each parameter set name indicates the hash function family (SHA2 or SHAKE) that is used to instantiate the hash functions, the length in bits of the security parameter n, and whether the parameter set was designed to create relatively small signatures (‘s’) or to have relatively fast signature generation (‘f’). There are six sets of values for n, lgw, h, d, k, and a that are approved for use.21 For each of the six sets of values, the functions Hmsg, PRF, PRFmsg, F, H, and Tl may be instantiated using either SHAKE [6] or SHA-2 [8]. For the SHAKE parameter sets, the functions shall be instantiated as specified in Section 11.1. For the SHA2 parameter sets, the functions shall be instantiated as specified in Section 11.2.1 if n = 16 and shall be instantiated as specified in Section 11.2.2 if n = 24 or n = 32.\n\nTable 2. SLH-DSA parameter sets\n\nsecurity pk sig n h d h′ a k lgw m category bytes bytes SLH-DSA-SHA2-128s 16 63 7 9 12 14 4 30 1 32 7 856 SLH-DSA-SHAKE-128s SLH-DSA-SHA2-128f 16 66 22 3 6 33 4 34 1 32 17 088 SLH-DSA-SHAKE-128f SLH-DSA-SHA2-192s 24 63 7 9 14 17 4 39 3 48 16 224 SLH-DSA-SHAKE-192s SLH-DSA-SHA2-192f 24 66 22 3 8 33 4 42 3 48 35 664 SLH-DSA-SHAKE-192f SLH-DSA-SHA2-256s 32 64 8 8 14 22 4 47 5 64 29 792 SLH-DSA-SHAKE-256s SLH-DSA-SHA2-256f 32 68 17 4 9 35 4 49 5 64 49 856 SLH-DSA-SHAKE-256f\n\nThe 12 parameter sets included in Table 2 were designed to meet certain security strength categories defined by NIST in its original Call for Proposals [25] with respect to existential unforgeability under chosen message attack (EUF-CMA) when each key pair is used to sign at most 264 messages.22 These security strength categories are explained further in SP 800-57, Part 1 [9].", "char_len": 3856, "approx_tokens": 964}
{"chunk_id": "NIST.FIPS.205::c00032", "doc_id": "NIST.FIPS.205", "start_page": 53, "end_page": 54, "text": "KE-192s SLH-DSA-SHA2-192f 24 66 22 3 8 33 4 42 3 48 35 664 SLH-DSA-SHAKE-192f SLH-DSA-SHA2-256s 32 64 8 8 14 22 4 47 5 64 29 792 SLH-DSA-SHAKE-256s SLH-DSA-SHA2-256f 32 68 17 4 9 35 4 49 5 64 49 856 SLH-DSA-SHAKE-256f\n\nThe 12 parameter sets included in Table 2 were designed to meet certain security strength categories defined by NIST in its original Call for Proposals [25] with respect to existential unforgeability under chosen message attack (EUF-CMA) when each key pair is used to sign at most 264 messages.22 These security strength categories are explained further in SP 800-57, Part 1 [9].\n\n20SP 800-230 [24] specifies additional parameter sets that are approved for use. While key pairs generated for the parameter sets specified in this standard may be used to sign up to 264 messages, key pairs generated for the parameter sets in SP 800-230 are more limited in the number of signatures that may be generated. 21In addition to n, lgw, h, d, k, and a, Table 2 also lists values for parameters that may be computed from these values (h′, m, public-key size(pk bytes), and signature size(sig bytes)). The security category is the security category in which the parameter set is claimed to be [10]. 22If a key pair were used to sign 10 billion (1010 ) messages per second, it would take over 58 years to sign 264 messages.\n\nUsing this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each parameter set is claimed to be at least as secure as a generic block cipher with a prescribed key size. More precisely, it is claimed that the computational resources needed to break SLH-DSA are greater than or equal to the computational resources needed to break the block cipher when these computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models are discussed in [26]. Concretely, the parameter sets with n = 16 are claimed to be in security category 1, the parameter sets with n = 24 are claimed to be in security category 3, and the parameter sets with n = 32 are claimed to be in security category 5 [10]. For additional discussion of the security strength of SLH-DSA, see [10, 27]. Some applications require a property known as message-bound signatures [28, 29], which intuitively requires that it be infeasible for anyone to create a public key and a signature that are valid for two different messages. Signature schemes are not required to have this property under the EUF-CMA security definition used in assigning security categories. In the case of SLH-DSA, the key pair owner could create two messages with the same signature by finding a collision on Hmsg. Due to the length of the output of Hmsg, finding such a collision would be expected to require fewer computational resources than specified for the parameter sets’ claimed security categories in all cases except SLH-DSA-SHA2-128f and SLH-DSA-SHAKE-128f.23 Therefore, applications that require message-bound signatures should either take the expected cost of finding collisions on Hmsg into account when choosing an appropriate parameter set or apply a technique (e.g., the BUFF transformation [29]) to obtain the message-bound signatures property.\n\n11.1 SLH-DSA Using SHAKE Hmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHAKE- 128s, SLH-DSA-SHAKE-128f, SLH-DSA-SHAKE-192s, SLH-DSA-SHAKE-192f, SLH-DSA-SHAKE-256s, and SLH-DSA-SHAKE-256f parameter sets: Hmsg(R, PK.seed, PK.root, M) = SHAKE256(R ∥ PK.seed ∥ PK.root ∥ M , 8m) PRF(PK.seed, SK.seed, ADRS) = SHAKE256(PK.seed ∥ ADRS ∥ SK.seed, 8n) PRFmsg(SK.prf, opt_rand, M) = SHAKE256(SK.prf ∥ opt_rand ∥ M , 8n) F(PK.seed, ADRS, M1) = SHAKE256(PK.seed ∥ ADRS ∥ M1, 8n) H(PK.seed, ADRS, M2) = SHAKE256(PK.seed ∥ ADRS ∥ M2, 8n) Tl(PK.seed, ADRS, Ml) = SHAKE256(PK.seed ∥ ADRS ∥ Ml, 8n)", "char_len": 3985, "approx_tokens": 996}
{"chunk_id": "NIST.FIPS.205::c00033", "doc_id": "NIST.FIPS.205", "start_page": 54, "end_page": 57, "text": "SHAKE Hmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHAKE- 128s, SLH-DSA-SHAKE-128f, SLH-DSA-SHAKE-192s, SLH-DSA-SHAKE-192f, SLH-DSA-SHAKE-256s, and SLH-DSA-SHAKE-256f parameter sets: Hmsg(R, PK.seed, PK.root, M) = SHAKE256(R ∥ PK.seed ∥ PK.root ∥ M , 8m) PRF(PK.seed, SK.seed, ADRS) = SHAKE256(PK.seed ∥ ADRS ∥ SK.seed, 8n) PRFmsg(SK.prf, opt_rand, M) = SHAKE256(SK.prf ∥ opt_rand ∥ M , 8n) F(PK.seed, ADRS, M1) = SHAKE256(PK.seed ∥ ADRS ∥ M1, 8n) H(PK.seed, ADRS, M2) = SHAKE256(PK.seed ∥ ADRS ∥ M2, 8n) Tl(PK.seed, ADRS, Ml) = SHAKE256(PK.seed ∥ ADRS ∥ Ml, 8n)\n\n11.2 SLH-DSA Using SHA2 In Sections 11.2.1 and 11.2.2, the functions MGF1-SHA-256 and MGF1-SHA-512 are MGF1 from Appendix B.2.1 of RFC 8017 [30], where Hash is SHA-256 or SHA-512, respectively. The functions\n\n23Finding a collision would be expected to require computing Hmsg for approximately 2(h+k⋅a)/2 different mes- sages.\n\nHMAC-SHA-256 and HMAC-SHA-512 are the HMAC function from FIPS 198-1 [31, 32], where H is SHA-256 or SHA-512, respectively. The functions in Sections 11.2.1 and 11.2.2 make use of a compressed version of ADRS (see Figure 18). A compressed address (ADRSc) is a 22-byte string that is the same as an ADRS with the exceptions that the encodings of the layer address and type are reduced to one byte each and the encoding of the tree address is reduced to eight bytes (i.e., ADRSc = ADRS[3] ∥ ADRS[8 ∶ 16] ∥ ADRS[19] ∥ ADRS[20 ∶ 32]). For implementations of the SHA2 parameter sets that store addresses in compressed form (i.e., 22 bytes), the member functions (Section 4.3) are as shown in Table 3 rather than Table 1.\n\nlayer address 1 byte tree address 8 bytes type 1 byte\n\n12 bytes\n\nFigure 18. Compressed address (ADRSc)\n\nTable 3. Member functions for compressed addresses\n\nMember function ADRS.setLayerAddress(l) ADRS.setTreeAddress(t) ADRS.setTypeAndClear(Y) ADRS.setKeyPairAddress(i) ADRS.setChainAddress(i) ADRS.setTreeHeight(i) ADRS.setHashAddress(i) ADRS.setTreeIndex(i) i ← ADRS.getKeyPairAddress() i ← ADRS.getTreeIndex() Expanded notation ADRS ← toByte(l, 1) ∥ ADRS[1 ∶ 22] ADRS ← ADRS[0 ∶ 1] ∥ toByte(t, 8) ∥ ADRS[9 ∶ 22] ADRS ← ADRS[0 ∶ 9] ∥ toByte(Y , 1) ∥ toByte(0, 12) ADRS ← ADRS[0 ∶ 10] ∥ toByte(i, 4) ∥ ADRS[14 ∶ 22] ADRS ← ADRS[0 ∶ 14] ∥ toByte(i, 4) ∥ ADRS[18 ∶ 22]\n\nADRS ← ADRS[0 ∶ 18] ∥ toByte(i, 4)\n\ni ← toInt(ADRS[10 ∶ 14], 4) i ← toInt(ADRS[18 ∶ 22], 4)\n\n11.2.1 SLH-DSA Using SHA2 for Security Category 1 Hmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHA2-128s and SLH-DSA-SHA2-128f parameter sets: Hmsg(R, PK.seed, PK.root, M) = MGF1-SHA-256(R ∥ PK.seed ∥ SHA-256(R ∥ PK.seed ∥ PK.root ∥ M ), m)\n\nPRF(PK.seed, SK.seed, ADRS) =\n\nPRF Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRSc ∥ SK.seed)) msg(SK.prf, opt_rand, M) =\n\nF(PK.seed, Truncn(HMAC-SHA-256(SK.prf, opt_rand ∥ M )) ADRS, M1) = c\n\nH(PK.seed, Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRS ∥ M1)) ADRS, M2) = c\n\nT (PK.seed, Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRS ∥ M2)) l ADRS, Ml) = c Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRS ∥ Ml))\n\n11.2.2 SLH-DSA Using SHA2 for Security Categories 3 and 5 Hmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHA2-192s, SLH-DSA-SHA2-192f, SLH-DSA-SHA2-256s, and SLH-DSA-SHA2-256f parameter sets: Hmsg(R, PK.seed, PK.root, M) = MGF1-SHA-512(R ∥ PK.seed ∥ SHA-512(R ∥ PK.seed ∥ PK.root ∥ M ), m) PRF(PK.seed, SK.seed, ADRS) =\n\nPRF Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRSc ∥ SK.seed)) msg(SK.prf, opt_rand, M) =\n\nF(PK.seed, Truncn(HMAC-SHA-512(SK.prf, opt_rand ∥ M )) ADRS, M1) = c\n\nH(PK.seed, Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRS ∥ M1)) ADRS, M2) = c\n\nT (PK.seed, Truncn(SHA-512(PK.seed ∥ toByte(0, 128 − n) ∥ ADRS ∥ M2)) l ADRS, Ml) = c Truncn(SHA-512(PK.seed ∥ toByte(0, 128 − n) ∥ ADRS ∥ Ml))\n\nReferences", "char_len": 3862, "approx_tokens": 965}
{"chunk_id": "NIST.FIPS.205::c00034", "doc_id": "NIST.FIPS.205", "start_page": 56, "end_page": 57, "text": "A2-192f, SLH-DSA-SHA2-256s, and SLH-DSA-SHA2-256f parameter sets: Hmsg(R, PK.seed, PK.root, M) = MGF1-SHA-512(R ∥ PK.seed ∥ SHA-512(R ∥ PK.seed ∥ PK.root ∥ M ), m) PRF(PK.seed, SK.seed, ADRS) =\n\nPRF Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRSc ∥ SK.seed)) msg(SK.prf, opt_rand, M) =\n\nF(PK.seed, Truncn(HMAC-SHA-512(SK.prf, opt_rand ∥ M )) ADRS, M1) = c\n\nH(PK.seed, Truncn(SHA-256(PK.seed ∥ toByte(0, 64 − n) ∥ ADRS ∥ M1)) ADRS, M2) = c\n\nT (PK.seed, Truncn(SHA-512(PK.seed ∥ toByte(0, 128 − n) ∥ ADRS ∥ M2)) l ADRS, Ml) = c Truncn(SHA-512(PK.seed ∥ toByte(0, 128 − n) ∥ ADRS ∥ Ml))\n\nReferences\n\n[1] National Institute of Standards and Technology (2023) Digital Signature Standard (DSS). (Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publications (FIPS) NIST FIPS 186-5. https://doi.org/10.6028/NIST.FIPS.186-5. [2] National Institute of Standards and Technology (2024) Guideline for Using Cryptographic Standards in the Federal Government: Cryptographic Mechanisms. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-175B, Rev. 2. [Forthcoming: will be available at https://csrc.nist.gov/publications]. [3] National Institute of Standards and Technology (2024) Recommendation for Obtaining Assurances for Digital Signature Applications. (National Institute of Standards and Technol- ogy, Gaithersburg, MD), NIST Special Publication (SP) 800-89, Rev. 1. [Forthcoming: will be available at https://csrc.nist.gov/publications]. [4] Aumasson JP, Bernstein DJ, Beullens W, Dobraunig C, Eichlseder M, Fluhrer S, Gazdag SL, Hülsing A, Kampanakis P, Kölbl S, Lange T, Lauridsen MM, Mendel F, Niederhagen R, Rechberger C, Rijneveld J, Schwabe P, Westerbaan B (2020) SPHINCS+ – Submission to the NIST post-quantum project, v.3. [5] Barker EB, Chen L, Roginsky AL, Vassilev A, Davis R, Simon S (2019) Recommendation for Pair-Wise Key-Establishment Using Integer Factorization Cryptography. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56B, Rev. 2. https://doi.org/10.6028/NIST.SP.800-56Br2. [6] National Institute of Standards and Technology (2015) SHA-3 Standard: Permutation-Based Hash and Extendable-Output Functions. (Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) NIST FIPS 202. https://doi.org/ 10.6028/NIST.FIPS.202. [7] Kelsey JM, Chang SjH, Perlner RA (2016) SHA-3 Derived Functions: cSHAKE, KMAC, Tuple- Hash and ParallelHash. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-185. https://doi.org/10.6028/NIST.SP.800-185. [8] National Institute of Standards and Technology (2015) Secure Hash Standard (SHS). (De- partment of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) NIST FIPS 180-4. https://doi.org/10.6028/NIST.FIPS.180-4. [9] National Institute of Standards and Technology (2024) Recommendation for Key Manage- ment: Part 1 – General. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev 6. [Forthcoming: will be available at https://csrc.nist.gov/publications]. [10] Aumasson JP, Bernstein DJ, Beullens W, Dobraunig C, Eichlseder M, Fluhrer S, Gazdag SL, Hülsing A, Kampanakis P, Kölbl S, Lange T, Lauridsen MM, Mendel F, Niederhagen R, Rechberger C, Rijneveld J, Schwabe P, Westerbaan B (2022) SPHINCS+ – Submission to the NIST post-quantum project, v.3.1. Available at https://sphincs.org/data/sphincs+-r3.1- specification.pdf.", "char_len": 3602, "approx_tokens": 900}
{"chunk_id": "NIST.FIPS.205::c00035", "doc_id": "NIST.FIPS.205", "start_page": 57, "end_page": 58, "text": "or Key Manage- ment: Part 1 – General. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev 6. [Forthcoming: will be available at https://csrc.nist.gov/publications]. [10] Aumasson JP, Bernstein DJ, Beullens W, Dobraunig C, Eichlseder M, Fluhrer S, Gazdag SL, Hülsing A, Kampanakis P, Kölbl S, Lange T, Lauridsen MM, Mendel F, Niederhagen R, Rechberger C, Rijneveld J, Schwabe P, Westerbaan B (2022) SPHINCS+ – Submission to the NIST post-quantum project, v.3.1. Available at https://sphincs.org/data/sphincs+-r3.1- specification.pdf.\n\n[11] Hülsing A, Butin D, Gazdag SL, Rijneveld J, Mohaisen A (2018) XMSS: eXtended Merkle Signature Scheme. (Internet Research Task Force (IRTF)), IRTF Request for Comments (RFC) 8391. https://doi.org/10.17487/RFC8391. [12] Cooper DA, Apon D, Dang QH, Davidson MS, Dworkin MJ, Miller CA (2020) Recommendation for Stateful Hash-Based Signature Schemes. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-208. https://doi.org/10.6028/NIST.SP. 800-208. [13] Merkle RC (1979) Secrecy, Authentication, and Public Key Systems. Ph.D. thesis. Stanford university, . [14] Barker EB, Kelsey JM (2015) Recommendation for Random Number Generation Using Deterministic Random Bit Generators. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90A, Rev. 1. https://doi.org/10.6028/ NIST.SP.800-90Ar1. [15] Sönmez Turan M, Barker EB, Kelsey JM, McKay KA, Baish ML, Boyle M (2018) Recom- mendation for the Entropy Sources Used for Random Bit Generation. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90B. https://doi.org/10.6028/NIST.SP.800-90B. [16] Barker EB, Kelsey JM, McKay KA, Roginsky AL, Sönmez Turan M (2022) Recommendation for Random Bit Generator (RBG) Constructions. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-90C 4pd. https://doi.org/10.6028/ NIST.SP.800-90C.4pd. [17] Kannwischer MJ, Genêt A, Butin D, Krämer J, Buchmann J (2018) Differential Power Analysis of XMSS and SPHINCS. Constructive Side-Channel Analysis and Secure Design, eds Fan J, Gierlichs B (Springer International Publishing, Cham), pp 168–188. https://doi.org/10.1007/ 978-3-319-89641-0_10. [18] Castelnovi L, Martinelli A, Prest T (2018) Grafting Trees: A Fault Attack Against the SPHINCS Framework. Post-Quantum Cryptography, eds Lange T, Steinwandt R (Springer International Publishing, Cham), pp 165–184. https://doi.org/10.1007/978-3-319-79063-3_8. [19] Genêt A, Kannwischer MJ, Pelletier H, McLauchlan A (2018) Practical Fault Injection Attacks on SPHINCS, Cryptology ePrint Archive preprint. https://ia.cr/2018/674. [20] Amiet D, Leuenberger L, Curiger A, Zbinden P (2020) FPGA-based SPHINCS+ Implementa- tions: Mind the Glitch. 2020 23rd Euromicro Conference on Digital System Design (DSD), pp 229–237. https://doi.org/10.1109/DSD51259.2020.00046. [21] Genêt A (2023) On Protecting SPHINCS+ Against Fault Attacks. IACR Transactions on Cryp- tographic Hardware and Embedded Systems 2023(2):80–114. https://doi.org/10.46586/ tches.v2023.i2.80-114. [22] Groot Bruinderink L, Hülsing A (2018) “Oops, I Did It Again” – Security of One-Time Signatures Under Two-Message Attacks. Selected Areas in Cryptography – SAC 2017, eds Adams C, Camenisch J (Springer International Publishing, Cham), pp 299–322. https://doi.org/10. 1007/978-3-319-72565-9_15.", "char_len": 3530, "approx_tokens": 882}
{"chunk_id": "NIST.FIPS.205::c00036", "doc_id": "NIST.FIPS.205", "start_page": 58, "end_page": 61, "text": "cro Conference on Digital System Design (DSD), pp 229–237. https://doi.org/10.1109/DSD51259.2020.00046. [21] Genêt A (2023) On Protecting SPHINCS+ Against Fault Attacks. IACR Transactions on Cryp- tographic Hardware and Embedded Systems 2023(2):80–114. https://doi.org/10.46586/ tches.v2023.i2.80-114. [22] Groot Bruinderink L, Hülsing A (2018) “Oops, I Did It Again” – Security of One-Time Signatures Under Two-Message Attacks. Selected Areas in Cryptography – SAC 2017, eds Adams C, Camenisch J (Springer International Publishing, Cham), pp 299–322. https://doi.org/10. 1007/978-3-319-72565-9_15.\n\n[23] Housley R (2009) Cryptographic Message Syntax (CMS). (Internet Engineering Task Force (IETF)), IETF Request for Comments (RFC) 5652. https://doi.org/10.17487/RFC5652. [24] National Institute of Standards and Technology (2024) Recommendation for Additional Stateless Hash-Based Digital Signature Parameter Sets. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-230. [Forthcoming: will be available at https://csrc.nist.gov/publications]. [25] National Institute of Standards and Technology (2016) Submission Requirements and Eval- uation Criteria for the Post-Quantum Cryptography Standardization Process. Available at https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/ call-for-proposals-final-dec-2016.pdf. [26] Alagic G, Apon D, Cooper DA, Dang QH, Dang T, Kelsey JM, Lichtinger J, Liu YK, Miller CA, Moody D, Peralta R, Perlner RA, Robinson A, Smith-Tone D (2022) Status Report on the Third Round of the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) NIST IR 8413-upd1, includes updates as of September 26, 2022. https://doi.org/ 10.6028/NIST.IR.8413-upd1. [27] Hülsing A, Kudinov M (2022) Recovering the Tight Security Proof of SPHINCS+. Advances in Cryptology – ASIACRYPT 2022, eds Agrawal S, Lin D (Springer Nature Switzerland, Cham), pp 3–33. https://doi.org/10.1007/978-3-031-22972-5_1. [28] Stern J, Pointcheval D, Malone-Lee J, Smart NP (2002) Flaws in Applying Proof Methodologies to Signature Schemes. Advances in Cryptology — CRYPTO 2002, ed Yung M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 93–110. https://doi.org/10.1007/3-540-45708-9_7. [29] Cremers C, Düzlü S, Fiedler R, Janson C, Fischlin M (2021) BUFFing Signature Schemes Beyond Unforgeability and the Case of Post-Quantum Signatures. 2021 IEEE Symposium on Security and Privacy (SP) (IEEE Computer Society, Los Alamitos, CA, USA), pp 1696–1714. https://doi.org/10.1109/SP40001.2021.00093. [30] Moriarty K, Kaliski B, Jonsson J, Rusch A (2016) PKCS #1: RSA Cryptography Specifications Version 2.2. (Internet Engineering Task Force (IETF)), IETF request for comments (RFC) 8017. https://doi.org/10.17487/RFC8017. [31] National Institute of Standards and Technology (2008) The Keyed-Hash Message Authentica- tion Code (HMAC). (Department of Commerce, Washington, DC), Federal Information Pro- cessing Standards Publication (FIPS) NIST FIPS 198-1. https://doi.org/10.6028/NIST.FIPS.198- 1. [32] Krawczyk H, Bellare M, Canetti R (1997) HMAC: Keyed-Hashing for Message Authentication. (Internet Engineering Task Force (IETF)), IETF request for comments (RFC) 2104. https: //doi.org/10.17487/RFC2104. [33] Stern M (2021) Re: Diversity of signature schemes. Available at https://groups.google.com/ a/list.nist.gov/g/pqc-forum/c/2LEoSpskELs/m/LkUdQ5mKAwAJ. [34] Antonov S (2022) ROUND 3 OFFICIAL COMMENT: SPHINCS+. Available at https://groups. google.com/a/list.nist.gov/g/pqc-forum/c/FVItvyRea28/m/mGaRi5iZBwAJ.\n\n[35] Perlner R, Kelsey J, Cooper D (2022) Breaking Category Five SPHINCS+ with SHA-256. Post- Quantum Cryptography, eds Cheon JH, Johansson T (Springer International Publishing, Cham), pp 501–522. https://doi.org/10.1007/978-3-031-17234-2_23.\n\nAppendix A — Differences From the SPHINCS+ Submission", "char_len": 3989, "approx_tokens": 997}
{"chunk_id": "NIST.FIPS.205::c00037", "doc_id": "NIST.FIPS.205", "start_page": 59, "end_page": 61, "text": "M (2021) Re: Diversity of signature schemes. Available at https://groups.google.com/ a/list.nist.gov/g/pqc-forum/c/2LEoSpskELs/m/LkUdQ5mKAwAJ. [34] Antonov S (2022) ROUND 3 OFFICIAL COMMENT: SPHINCS+. Available at https://groups. google.com/a/list.nist.gov/g/pqc-forum/c/FVItvyRea28/m/mGaRi5iZBwAJ.\n\n[35] Perlner R, Kelsey J, Cooper D (2022) Breaking Category Five SPHINCS+ with SHA-256. Post- Quantum Cryptography, eds Cheon JH, Johansson T (Springer International Publishing, Cham), pp 501–522. https://doi.org/10.1007/978-3-031-17234-2_23.\n\nAppendix A — Differences From the SPHINCS+ Submission\n\nThis standard is based on Version 3.1 of the SPHINCS+ specification [10] and contains several minor modifications compared to Version 3 [4], which was submitted at the beginning of round three of the NIST PQC Standardization process: • Two new address types — WOTS_PRF and FORS_PRF — were defined for WOTS+ and FORS secret key value generation. • PK.seed was added as an input to PRF in order to mitigate multi-key attacks. • For the category 3 and 5 SHA2 parameter sets, SHA-256 was replaced by SHA-512 in Hmsg, PRFmsg, H, and Tl based on weaknesses that were discovered when using SHA-256 to obtain category 5 security [33, 34, 35]. • R and PK.seed were added as inputs to MGF1 when computing Hmsg for the SHA2 parameter sets in order to mitigate multi-target long-message second preimage attacks. This standard also differs from the Version 3 specification in its method for extracting bits from the message digest to select a FORS key. This change was made in order to align with the reference implementation that was submitted along with the round three specification. The description of the method for extracting indices for FORS signature generation and verification from the message digest was also changed due to ambiguity in the submitted specification. The method described in this standard is not compatible with the method used in the reference implementation that was submitted along with the round three specification. Additionally, line 6 in both wots_sign and wots_pkFromSig were changed to match the reference implementation, as the pseudocode in [10, 4] will sometimes shift csum by the incorrect amount when lgw is not 4. This standard approves the use of only 12 of the 36 parameter sets defined in [10, 4]. As specified in Section 11, only the ‘simple’ instances of the SHA2 and SHAKE parameter sets are approved.\n\nA.1 Changes From FIPS 205 Initial Public Draft The differences from Version 3 of the SPHINCS+ specification described in Appendix A were included in the draft version of this standard (FIPS 205 ipd) that was posted on August 24, 2023. Based on comments that were submitted on FIPS 205 ipd, the SLH-DSA signature generation and verification functions were modified to include domain separation cases in which the message is signed directly and in which a digest of the message is signed. The changes were made by modifying the inputs to the signing and verification functions (see Algorithms 22, 23, 24, and 25).", "char_len": 3047, "approx_tokens": 761}
{"chunk_id": "NIST.IR.8545::c00000", "doc_id": "NIST.IR.8545", "start_page": 1, "end_page": 4, "text": "NIST Internal Report NIST IR 8545 Status Report on the Fourth Round of the NIST Post-Quantum Cryptography Standardization Process\n\nGorjan Alagic Maxime Bros Pierre Ciadoux David Cooper Quynh Dang Thinh Dang John Kelsey Jacob Lichtinger Yi-Kai Liu Carl Miller Dustin Moody Rene Peralta Ray Perlner Angela Robinson Hamilton Silberg Daniel Smith-Tone Noah Waller\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8545\n\nNST NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY Check for U.S. DEPARTMENT OF COMMERCE updates\n\nNIST Internal Report NIST IR 8545\n\nStatus Report on the Fourth Round of the NIST Post-Quantum Cryptography Standardization Process\n\nGorjan Alagic Carl Miller Maxime Bros Dustin Moody Pierre Ciadoux Rene Peralta David Cooper Ray Perlner Quynh Dang Angela Robinson Thinh Dang Hamilton Silberg John Kelsey Daniel Smith-Tone Jacob Lichtinger Noah Waller Computer Security Division Information Technology Laboratory\n\nYi-Kai Liu Applied and Computational Mathematics Division Information Technology Laboratory\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8545\n\nU.S. Department of Commerce Howard Lutnick, Secretary National Institute of Standards and Technology Craig Burkhardt, Acting Under Secretary of Commerce for Standards and Technology and Acting NIST Director\n\nCertain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this paper in order to specify the experimental procedure adequately. Such identification does not imply recommendation or endorsement of any product or service by NIST, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose. There may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST. Organizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at https://csrc.nist.gov/publications.\n\nNIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax\n\nPublication History Approved by the NIST Editorial Review Board on 2025-03-05 How to cite this NIST Technical Series Publication: Alagic G, Bros M, Ciadoux P, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Silberg H, Smith-Tone D, Waller N (2025) Status Report on the Fourth Round of the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Internal Report (IR) NIST IR 8545. https://doi.org/10.6028/NIST.IR.8545\n\nAuthor ORCID iDs Gorjan Alagic: 0000-0002-0107-6037 Maxime Bros: 0000-0001-7838-2529 Pierre Ciadoux: 0009-0001-2272-681X David Cooper: 0009-0001-2410-5830 Quynh Dang: 0009-0005-9801-6805 Thinh Dang: 0000-0001-9705-0925 John Kelsey: 0000-0002-3427-1744 Jacob Lichtinger: 0000-0003-2407-5309 Yi-Kai Liu: 0000-0001-7458-4721 Carl Miller: 0000-0003-1917-1531 Dustin Moody: 0000-0002-4868-6684 Rene Peralta: 0000-0002-2318-7563 Ray Perlner: 0000-0001-8793-2238 Angela Robinson: 0000-0002-1209-0379 Hamilton Silberg: 0009-0004-4178-8954 Daniel Smith-Tone: 0000-0002-7995-8734 Noah Waller: 0000-0002-6979-9725 Contact Information pqc-comments@nist.gov Additional Information Additional information about this publication is available at https://csrc.nist", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.IR.8545::c00001", "doc_id": "NIST.IR.8545", "start_page": 4, "end_page": 6, "text": "10-5830 Quynh Dang: 0009-0005-9801-6805 Thinh Dang: 0000-0001-9705-0925 John Kelsey: 0000-0002-3427-1744 Jacob Lichtinger: 0000-0003-2407-5309 Yi-Kai Liu: 0000-0001-7458-4721 Carl Miller: 0000-0003-1917-1531 Dustin Moody: 0000-0002-4868-6684 Rene Peralta: 0000-0002-2318-7563 Ray Perlner: 0000-0001-8793-2238 Angela Robinson: 0000-0002-1209-0379 Hamilton Silberg: 0009-0004-4178-8954 Daniel Smith-Tone: 0000-0002-7995-8734 Noah Waller: 0000-0002-6979-9725 Contact Information pqc-comments@nist.gov Additional Information Additional information about this publication is available at https://csrc.nist.gov/pubs/ir/8545/final, including related content, potential updates, and document history. All comments are subject to release under the Freedom of Information Act (FOIA).\n\nAbstract\n\nNIST is selecting public-key cryptographic algorithms through a public, competition-like process to specify additional digital signature, public-key encryption, and key-establishment algorithms to supplement FIPS 186-5, SP 800-56Ar3, and SP 800-56Br2. These algorithms are intended to protect sensitive information well into the foreseeable future, including after the advent of quantum computers. In the fourth round of the Post-Quantum Cryptography Standardization Process, NIST selected four candidate algorithms for key establishment to be studied: BIKE, Classic McEliece, HQC, and SIKE. This report describes the evaluation and selection process of these fourth-round candidates based on public feedback and internal review. The report summarizes each of the candidate algorithms and identifies those selected for standardization. The only key-establishment algorithm that will be standardized is HQC, and NIST will develop a standard based on HQC to augment its key-establishment portfolio.\n\nKeywords\n\ncryptography; key-encapsulation mechanism (KEM); key establishment; post-quantum cryptography; quantum-resistant; quantum-safe.\n\nReports on Computer Systems Technology\n\nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology (NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and technical analyses to advance the development and productive use of information technology. ITL’s responsibilities include the development of management, administrative, technical, and physical standards and guidelines for the cost-effective security and privacy of other than national security-related information in federal information systems.\n\ni\n\nContents\n\n1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1. Purpose and Organization of This Document . . . . . . . . . . . . . . . . . . 3 2. Evaluation Criteria and Selection Process . . . . . . . . . . . . . . . . . . . . . . . . 4 2.1. Acceptance of the Fourth-Round Candidates . . . . . . . . . . . . . . . . . . 4 2.2. Evaluation Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2.1. Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2.2. Cost and Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2.3. Algorithm and Implementation Characteristics . . . . . . . . . . . . . 8 2.3. Selection of the Candidates for Standardization . . . . . . . . . . . . . . . . . 8 3. Summary of the Fourth-Round Candidates . . . . . . . . . . . . . . . . . . . . . . . 10 3.1. HQC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3.2. BIKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.3. Classic McEliece . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.4. SIKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 4. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . .", "char_len": 3998, "approx_tokens": 999}
{"chunk_id": "NIST.IR.8545::c00002", "doc_id": "NIST.IR.8545", "start_page": 6, "end_page": 8, "text": "s for Standardization . . . . . . . . . . . . . . . . . 8 3. Summary of the Fourth-Round Candidates . . . . . . . . . . . . . . . . . . . . . . . 10 3.1. HQC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3.2. BIKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.3. Classic McEliece . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.4. SIKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 4. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Appendix A. List of Symbols, Abbreviations, and Acronyms . . . . . . . . . . . . . . . 26\n\nList of Tables\n\nTable 1. Timeline of the NIST Post-Quantum Cryptography Standardization Process . 2 Table 2. Fourth-round KEM candidates organized by category, with the candidate se- lected for standardization bolded and in blue . . . . . . . . . . . . . . . . . . 4 Table 3. Performance of BIKE in thousands of cycles on x86_64 [1] . . . . . . . . . . . 6 Table 4. Performance of HQC in thousands of cycles on x86_64 [1] . . . . . . . . . . . 6 Table 5. Performance of Classic McEliece in thousands of cycles on x86_64 [1] . . . . 6 Table 6. BIKE keys and ciphertext sizes in bytes . . . . . . . . . . . . . . . . . . . . . . 7 Table 7. HQC keys and ciphertext sizes in bytes . . . . . . . . . . . . . . . . . . . . . . 7 Table 8. Classic McEliece keys and ciphertext sizes in bytes . . . . . . . . . . . . . . . 7\n\nii\n\nSupplemental Content\n\nThe NIST Post-Quantum Cryptography Standardization Process web page is available at https://cs rc.nist.gov/Projects/post-quantum-cryptography/post-quantum-cryptography-standardization.\n\nAcknowledgments\n\nNIST would like to thank all of the candidate submission teams who developed, designed, and analyzed the post-quantum candidate algorithms and prepared detailed submission packages. NIST is also grateful for the efforts of those in the cryptographic community who provided security, implementation, and performance analyses of the candidate algorithms during the four rounds of the process. NIST would not be able to select post-quantum digital algorithms for standardization without the combined efforts of these individuals and the algorithm submitters. The authors of this report also appreciate the efforts by other members of NIST’s PQC team who reviewed candidate algorithms, analyses, and public comments; performed testing; provided technical and administrative support; and participated in numerous meetings to discuss the selection of the candidate to be standardized. They are Zuzana Bajcsy, Lily Chen, Morris Dworkin, Sara Kerman, and Andrew Regenscheid.\n\niii\n\n1. Introduction\n\nThe National Institute of Standards and Technology (NIST) initiated the Post-Quantum Cryptography (PQC) Standardization Process in December 2016 to select quantum-resistant public-key cryptographic algorithms for standardization in response to the substantial development and advancement of quantum computing. After three rounds of evaluation and analysis, NIST announced the selection of the first algorithms to be standardized [2]. The key encapsulation mechanism (KEM) selected for standardization was CRYSTALS-Kyber (ML-KEM [3]). The digital signatures selected were CRYSTALS-Dilithium (ML-DSA [4]), Falcon (FN-DSA), and SPHINCS+ (SLH-DSA [5]). For a detailed explanation of NIST’s choices, as well as a summary of the third round, see NIST IR 8413 [2]. In addition to those initial selections, NIST advanced four KEM candidates to the fourth round for continued evaluation: BIKE [6], Classic McEliece [7], HQC [8], and SIKE [9]. These algorithms were all based on different security assumptions than ML-KEM. NIST indicated that it would select one or two of the algorithms for standardization at the conclusion of the fourth round.", "char_len": 3998, "approx_tokens": 999}
{"chunk_id": "NIST.IR.8545::c00003", "doc_id": "NIST.IR.8545", "start_page": 8, "end_page": 9, "text": "digital signatures selected were CRYSTALS-Dilithium (ML-DSA [4]), Falcon (FN-DSA), and SPHINCS+ (SLH-DSA [5]). For a detailed explanation of NIST’s choices, as well as a summary of the third round, see NIST IR 8413 [2]. In addition to those initial selections, NIST advanced four KEM candidates to the fourth round for continued evaluation: BIKE [6], Classic McEliece [7], HQC [8], and SIKE [9]. These algorithms were all based on different security assumptions than ML-KEM. NIST indicated that it would select one or two of the algorithms for standardization at the conclusion of the fourth round. The fourth round began in July 2022 and involved a thorough analysis of the theoretical and empirical evidence used to justify the security of the candidates. During this time, the submitters of SIKE acknowledged its insecurity and recommended against its further use. The submission teams of the unbroken fourth-round candidates were invited to present updates for their candidate algorithms at the Fifth NIST PQC Standardization Conference in Rockville, Maryland, on April 10-12, 2024. The submitters participated in a joint panel to discuss the candidates’ merits, and several researchers presented work that was relevant to the PQC standardization process. Throughout the fourth round, NIST received valuable feedback from the cryptographic community. Based on this feedback and internal reviews of the fourth-round candidates, NIST announced the selection of HQC in March 2025 for standardization. Table 1 shows a timeline of major events with respect to the NIST PQC Standardization Process to date.\n\nTable 1. Timeline of the NIST Post-Quantum Cryptography Standardization Process\n\nDate Event April 2015 Workshop on Cybersecurity in a Post-Quantum World, NIST, Gaithersburg, MD February 2016 PQC Standardization: Announcement and outline of NIST’s Call for Submissions presentation given at PQCrypto 2016 April 2016 Release of IR 8105, Report on Post-Quantum Cryptography [10] December 2016 Federal Register Notice – Announcing Request for Nominations for Public-Key Post-Quantum Cryptographic Algorithms [11] November 30, 2017 Submission Deadline for NIST PQC Standardization Process December 2017 Announcement of first-round candidates and beginning of first- round public comment period April 2018 First NIST PQC Standardization Conference, Ft. Lauderdale, FL January 2019 Announcement of second-round candidates; release of IR 8240, Status Report on the First Round of the NIST Post-Quantum Cryp- tography Standardization Process [12]; and beginning of second- round public comment period August 2019 Second NIST PQC Standardization Conference, Santa Barbara, CA April 2020 Call for feedback on the selection of third-round candidates July 2020 Announcement of third-round finalists and alternate candidates; release of IR 8309, Status Report on the Second Round of the NIST Post-Quantum Cryptography Standardization Process [13]; and beginning of third-round public comment period June 2021 Third NIST PQC Standardization Conference, held virtually July 2022 Announcement of candidate algorithms to be standardized and alternate candidates advancing to the fourth round; release of IR 8413, Status Report on the Third Round of the NIST Post-Quantum Cryptography Standardization Process; and beginning of fourth- round public comment period October 2022 Fourth round specifications published on NIST’s PQC website November 2022 Fourth NIST PQC Standardization Conference, held virtually August 2023 Draft versions of FIPS 203 [14], FIPS 204 [4], and FIPS 205 [5] posted for public comment April 2024 Fifth NIST PQC Standardization Conference, Gaithersburg, MD August 2024 Final versions of FIPS 203 [14], FIPS 204 [4], and FIPS 205 [5] pub- lished January 2025 Draft for KEM guidance SP 800-227 posted for public comment March 2025 Announcement of fourth-round candidate algorithm to be stan- dardized and release of IR 8545, Status Report on the Fourth Round of the NIST Post-Quantum Crypto", "char_len": 4000, "approx_tokens": 1000}
{"chunk_id": "NIST.IR.8545::c00004", "doc_id": "NIST.IR.8545", "start_page": 9, "end_page": 11, "text": "on NIST’s PQC website November 2022 Fourth NIST PQC Standardization Conference, held virtually August 2023 Draft versions of FIPS 203 [14], FIPS 204 [4], and FIPS 205 [5] posted for public comment April 2024 Fifth NIST PQC Standardization Conference, Gaithersburg, MD August 2024 Final versions of FIPS 203 [14], FIPS 204 [4], and FIPS 205 [5] pub- lished January 2025 Draft for KEM guidance SP 800-227 posted for public comment March 2025 Announcement of fourth-round candidate algorithm to be stan- dardized and release of IR 8545, Status Report on the Fourth Round of the NIST Post-Quantum Cryptography Standardization Process\n\n1.1. Purpose and Organization of This Document This report summarizes the fourth round of the NIST PQC Standardization Process. Section 2 enumerates the candidates that were included in the fourth round. It also describes the evaluation criteria and selection process used to ultimately select HQC for standardization. Section 3 summarizes each of the fourth-round candidates, including a brief description of the algorithm and its characteristics with regard to security, performance, and implementation. This section also presents the rationale for standardizing some candidate algorithms and not others. Section 4 concludes and describes the next steps in the standardization process.\n\n2. Evaluation Criteria and Selection Process\n\n2.1. Acceptance of the Fourth-Round Candidates NIST selected four candidate algorithms for the fourth round, all of which were KEMs. Classic McEliece was a third-round finalist, and the other three algorithms were alternates [13]. The set of finalists included the algorithms that NIST considered to be the most promising to fit the majority of use cases and be ready for standardization soon after the third round. The alternate candidates were regarded as potential candidates for future standardization, most likely after another round of evaluation. The submission teams were allowed to make minor modifications and resubmit their packages, which had to meet the same requirements as the original submissions. The complete updated specifications were posted on NIST’s PQC website [15] for public review on October 27, 2022. Most of the changes focused on fixing minor issues that were identified during the third round and clarifying or simplifying the submission specification. One modification of note that occurred during the fourth round is BIKE’s decoder. The thresholds for the decoder were altered to reduce the risk of decryption failure. No major redesigns or changes were allowed.\n\nTable 2. Fourth-round KEM candidates organized by category, with the candidate selected for standardization bolded and in blue\n\nCode-Based Isogeny-Based BIKE SIKE HQC Classic McEliece\n\n2.2. Evaluation Criteria NIST’s Call for Proposals [16] identified three broad aspects of the evaluation criteria that would be used to compare candidate algorithms throughout the NIST PQC Standardization Process: 1) security, 2) cost and performance, and 3) algorithm and implementation characteristics. These criteria are described below, along with a discussion of how they impacted the fourth-round candidate evaluations.\n\n2.2.1. Security As with the previous phases of the PQC Standardization Process, security was the most important factor that NIST considered when evaluating the fourth-round candidate schemes. In the third round of the PQC Standardization Process, NIST selected one KEM — Kyber — that was then standardized as ML-KEM in FIPS 203 [14]. The security of ML-KEM is based primarily on the presumed hardness of certain computational problems in lattices. As discussed in the third-round report, NIST values having a variety of computational hardness", "char_len": 3716, "approx_tokens": 929}
{"chunk_id": "NIST.IR.8545::c00005", "doc_id": "NIST.IR.8545", "start_page": 11, "end_page": 12, "text": "they impacted the fourth-round candidate evaluations.\n\n2.2.1. Security As with the previous phases of the PQC Standardization Process, security was the most important factor that NIST considered when evaluating the fourth-round candidate schemes. In the third round of the PQC Standardization Process, NIST selected one KEM — Kyber — that was then standardized as ML-KEM in FIPS 203 [14]. The security of ML-KEM is based primarily on the presumed hardness of certain computational problems in lattices. As discussed in the third-round report, NIST values having a variety of computational hardness\n\nassumptions and aims to reduce the risk that a single cryptanalytic breakthrough will leave no viable standard for key establishment. In pursuit of that goal, NIST selected fourthround candidates whose security was based on computational assumptions that differ significantly from that of ML-KEM. Specifically, the candidates consisted of the isogeny-based KEM SIKE and the code-based KEMs BIKE, HQC, and Classic McEliece. See Table 2. NIST’s key-establishment standards are currently utilized in a wide variety of applications. The specific properties required for a key-establishment scheme to provide security in a given application can vary. However, in terms of formal security definitions, a single notion suffices for key-establishment schemes that are intended for general use: semantic security with respect to adaptive chosen ciphertext attacks (equivalently, IND-CCA2 security). ML-KEM is believed to satisfy IND-CCA2 security and is expected to serve as a general-purpose scheme in any application that calls for NIST-approved post-quantum keyestablishment. The formal security statuses of the fourth-round KEM candidates vary significantly. SIKE, the sole isogeny-based candidate, was broken and thus does not satisfy IND-CCA2 security [17]. The code-based candidates BIKE, HQC, and Classic McEliece are believed to satisfy IND-CCA2 security. However, NIST’s level of confidence in the IND-CCA2 security of these schemes is not equal. Notably, NIST has a higher level of confidence in the IND-CCA2 security of HQC than BIKE (see Sec. 3 for further details). Submitters to the fourth round were encouraged but not required to provide proofs of IND- CCA2 security (from clearly stated computational assumptions) in relevant models. NIST defined five security categories to compare the security strengths provided by the submissions. Submitters were asked to provide a classification of the security of the parameter sets of their schemes following the definitions provided in [16]. NIST also listed other desirable security properties, such as resistance to side-channel and multi-key attacks and resistance to misuse. Submissions were encouraged to note any additional desirable security properties that they provided. Finally, NIST required submission packages to summarize known cryptanalytic attacks on the scheme and complexity estimates for those attacks.\n\n2.2.2. Cost and Performance The second-most important criterion when evaluating candidate algorithms was their performance characteristics: • Sizes of encapsulation keys and ciphertexts • Computational efficiencies of encapsulations, decapsulations, and key generations (i.e., the speeds of the algorithms) Tables 3 through 5 show representative benchmarks for key generations, encapsulations, and decapsulations of BIKE, HQC, and Classic McEliece, respectively. Each row is a specific", "char_len": 3458, "approx_tokens": 864}
{"chunk_id": "NIST.IR.8545::c00006", "doc_id": "NIST.IR.8545", "start_page": 12, "end_page": 14, "text": "ion packages to summarize known cryptanalytic attacks on the scheme and complexity estimates for those attacks.\n\n2.2.2. Cost and Performance The second-most important criterion when evaluating candidate algorithms was their performance characteristics: • Sizes of encapsulation keys and ciphertexts • Computational efficiencies of encapsulations, decapsulations, and key generations (i.e., the speeds of the algorithms) Tables 3 through 5 show representative benchmarks for key generations, encapsulations, and decapsulations of BIKE, HQC, and Classic McEliece, respectively. Each row is a specific\n\nparameter set from the corresponding submission. The “Level” columns indicate the security categories that the submission parameter sets claim to meet. BIKE and HQC each had one parameter set per security category, while Classic McEliece had two. The Classic McEliece f versions have faster key generation, while the non-f versions have simpler key generation. In these benchmarks, BIKE is 6-10 times slower than HQC in key generation, 5-7 times slower than HQC in decapsulation, and about twice as fast as HQC in encapsulation. Key generation in Classic McEliece is an outlier, being three orders of magnitude more costly than HQC.\n\nParameter Set Level keygen encaps decaps BIKE Level 1 I 637 111 1 428 BIKE Level 3 III 1 892 251 4 313 BIKE Level 5 V 4 535 505 10 382\n\nTable 3. Performance of BIKE in thousands of cycles on x86_64 [1]\n\nParameter Set Level keygen encaps decaps hqc-128 I 105 197 360 hqc-192 III 244 460 746 hqc-256 V 447 844 1 410\n\nTable 4. Performance of HQC in thousands of cycles on x86_64 [1]\n\nParameter Set Level keygen encaps decaps mceliece348864 I 137 345 49 120 mceliece348864f 114 189 45 120 mceliece460896 III 430 364 91 232 mceliece460896f 313 600 92 231 mceliece6688128 V 674 012 196 273 mceliece6688128f 493 758 176 274 mceliece6960119 V 602 164 167 252 mceliece6960119f 404 166 169 253 mceliece8192128 V 686 110 203 269 mceliece8192128f 453 985 206 269\n\nTable 5. Performance of Classic McEliece in thousands of cycles on x86_64 [1]\n\nTables 6 through 8 show the sizes of keys and ciphertexts for BIKE, HQC, and Classic McEliece. The encapsulation keys of HQC are about 41-47 % larger than those of BIKE. The ciphertexts of HQC are about three times larger than the ciphertexts of BIKE.\n\nParameter Set Level Encapsulation Key Decapsulation Key Ciphertext BIKE Level 1 I 1 541 281 1 573 BIKE Level 3 III 3 083 419 3 115 BIKE Level 5 V 5 122 580 5 154\n\nTable 6. BIKE keys and ciphertext sizes in bytes\n\nParameter Set Level Encapsulation Key Decapsulation Key Ciphertext hqc-128 I 2 249 40 4 497 hqc-192 III 4 522 40 9 042 hqc-256 V 7 245 40 14 485\n\nTable 7. HQC keys and ciphertext sizes in bytes\n\nParameter Set Level Encapsulation Key Decapsulation Key Ciphertext mceliece348864 I 261 120 6 492 96 mceliece348864f mceliece460896 III 524 160 13 608 156 mceliece460896f mceliece6688128 V 1 044 992 13 932 208 mceliece6688128f mceliece6960119 V 1 047 319 13 948 194 mceliece6960119f mceliece8192128 V 1 357 824 14 120 208 mceliece8192128f\n\nTable 8. Classic McEliece keys and ciphertext sizes in bytes\n\nThere are a few studies comparing the performances of the KEMs in various protocols [18–21]. The study on the performance of post-quantum XML encryption and SAML SSO [21] contains data that compare BIKE and Classic McEliece in those protocols. For hybrid XML encryption, Classic McEliece slightly outperforms BIKE in decryption time and total time but results in much larger data sizes. When used for SAML SSO, BIKE generally outperforms Classic McEliece in time and produces much smaller bandwidths. Experiments on the performance of post-quantum KEMs in TLS 1.3 and QUIC [18–20] produce data that compare BIKE and HQC. Generally, when network conditions (e.g., transmission rates and packet loss) are ignored or sufficiently good, HQC results in faster handshakes. In contrast,", "char_len": 3907, "approx_tokens": 976}
{"chunk_id": "NIST.IR.8545::c00007", "doc_id": "NIST.IR.8545", "start_page": 14, "end_page": 15, "text": "ata that compare BIKE and Classic McEliece in those protocols. For hybrid XML encryption, Classic McEliece slightly outperforms BIKE in decryption time and total time but results in much larger data sizes. When used for SAML SSO, BIKE generally outperforms Classic McEliece in time and produces much smaller bandwidths. Experiments on the performance of post-quantum KEMs in TLS 1.3 and QUIC [18–20] produce data that compare BIKE and HQC. Generally, when network conditions (e.g., transmission rates and packet loss) are ignored or sufficiently good, HQC results in faster handshakes. In contrast,\n\nwhen network conditions are sufficiently bad, BIKE outperforms HQC. Packet delay seems to affect both HQC and BIKE equally. These results align with a prior expectation about the performances of BIKE and HQC based on their differences in speeds and sizes. When the size differences between HQC and BIKE do not affect the protocol execution time, the protocol runs faster with HQC. When the differences affect the protocol execution time noticeably, BIKE is more attractive than HQC. For TLS, BIKE would likely be more attractive than HQC over the web. The cited studies do not provide data for Classic McEliece, which is likely not a desirable choice for TLS 1.3 and QUIC due to its generally large encapsulation keys.\n\n2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization In relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE was insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media /Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round 4.pdf", "char_len": 3487, "approx_tokens": 871}
{"chunk_id": "NIST.IR.8545::c00008", "doc_id": "NIST.IR.8545", "start_page": 15, "end_page": 17, "text": "Selection of the Candidates for Standardization In relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE was insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media /Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round 4.pdf\n\nIn IR 8413 [2], NIST requested feedback on specific use cases for which Classic McEliece would be a good solution. Responses noted that Classic McEliece may provide better performance than BIKE or HQC for applications in which a public key can be transferred once and then used for several encapsulations (e.g., file encryption and virtual private networks [VPNs]) due to its small ciphertext size and fast encapsulation and decapsulation. There was also some interest in Classic McEliece based on the perception that it is a conservative choice. However, the interest expressed in Classic McEliece was limited, and having more standards to implement adds complexity to protocols and PQC migration. Classic McEliece is currently under consideration for standardization by the International Organization for Standardization (ISO). Concurrent standardization of Classic McEliece by NIST and ISO risks the creation of incompatible standards. After the ISO standardization process has been completed, NIST may consider developing a standard for Classic McEliece based on the ISO standard. However, Classic McEliece is no longer under consideration for standardization as part of the current NIST PQC Standardization Process. At the end of the third round, NIST indicated its intent to standardize at most one of BIKE or HQC for use as a general-purpose KEM [2]. As specified in the Call for Proposals [22], submitted KEMs were evaluated based on how well they appear to provide IND-CCA2 security, particularly for KEMs intended for general use. While NIST has confidence in the indistinguishability under chosen-plaintext attack (IND-CPA) security of BIKE and HQC, both schemes require a sufficiently low decryption failure rate (DFR) in order to be IND-CCA2- secure. There is evidence that HQC has a sufficiently low DFR and recent work indicates that with minor modifications, BIKE achieves the same [26]. However, NIST does not consider the DFR analysis for BIKE to be as mature as that for HQC. Additionally, HQC is not believed to require additional modifications to achieve the desired security properties. Given the critical need for strong IND-CCA2 security in a general-purpose KEM, HQC was selected for standardization. In summary, NIST has only selected HQC for standardization. The algorithms that were not selected are not under consideration for standardization by NIST as part of the current NIST PQC Standardization Process.\n\n3. Summary of the Fourth-Round Candidates\n\nThis section describes each of the fourth-round candidates, including their advantages and disadvantages and why a scheme was selected for standardization or not. Section 3 of IR 8413[2] introduces some computational and security concepts and history that might be referenced throughout the subsequent subsections. The provided information reduced redundancy, as some of the candidates’ security analyses have properties in common. The information was not intended to be an exhaustive security or literature review.", "char_len": 3595, "approx_tokens": 898}
{"chunk_id": "NIST.IR.8545::c00009", "doc_id": "NIST.IR.8545", "start_page": 16, "end_page": 18, "text": "rent NIST PQC Standardization Process.\n\n3. Summary of the Fourth-Round Candidates\n\nThis section describes each of the fourth-round candidates, including their advantages and disadvantages and why a scheme was selected for standardization or not. Section 3 of IR 8413[2] introduces some computational and security concepts and history that might be referenced throughout the subsequent subsections. The provided information reduced redundancy, as some of the candidates’ security analyses have properties in common. The information was not intended to be an exhaustive security or literature review.\n\n3.1. HQC HQC (Hamming Quasi-Cyclic) is a KEM based on quasi-cyclic codes, where no trapdoor is hidden in the code [27]. It was designed to leverage the structural advantages of quasicyclic codes while maintaining a more direct security reduction to the problem of decoding a random linear code. Unlike the other code-based candidates, the only coding-theory hardness assumptions required by HQC’s security proof are parameterizations of the decisional Quasi-Cyclic Syndrome Decoding (QCSD) assumption. BIKE additionally assumes the hardness of Quasi-Cyclic Codeword Finding (QCCF), and Classic McEliece requires assumptions concerning binary Goppa codes [27, 28].\n\nDesign. HQC is similar in structure to Learning with Errors (LWE)-based cryptosystems, like Regev [29], LPR (Lyubashevsky, Peikert, Regev) [30], and ML-KEM [14]. The IND-CPA-secure public-key encryption (PKE) can be described as follows. Let R = F2[x]/(xn − 1) for n prime such that xn − 1 has only two irreducible factors modulo 2. The secret key is a randomly sampled pair (x, y) ∈ R2, and the public key is the pair (h, s = x + h · y), where h is randomly sampled from R. Because the secret key is generated independently of the underlying quasi-cyclic code, there is no hidden structure in the HQC public parity-check matrix. This enables the security reduction to be independent of the decoding algorithm used for decryption [27]. In addition to h, the public key includes a public generator matrix G ∈ Fk×n for a concatenated Reed-Muller Reed-Solomon (RMRS) code. The structure of this 2 code is assumed to be visible to all parties. To encrypt a message m ∈ Fk, the sender randomly samples three polynomials e, r1, r2 ∈ R of appropriate low weights 2 and responds with the ciphertext\n\nc = (u, v) := (r1 + h · r2, mG + s · r2 + e). (1)\n\nTo decrypt, the receiver uses the decoding algorithm for an RMRS code to decode (v − u · y).\n\nSecurity. The IND-CPA security of HQC relies on the difficulty of the QCSD with parity problem. Applying the Fujisaki Okamoto (FO) transform [31] to the CPA-secure PKE achieves an IND-CCA2 KEM.\n\nThe decoder used in HQC has a well-defined minimum distance d and, consequently, a determinable error-correction capability δ = b d−1 c. The probability that an HQC ciphertext δ is captured 2 includes error e such that |e| > in a closed-form analysis and used to produce a heuristic2 upper bound on the DFR. A sufficiently low DFR is required for the IND-CCA2 security proof of the relevant FO⊥ transform [31] to be valid and to prevent key-recovery attacks in a key-pair-reuse setting [32]. As with the other code-based schemes, the best known attacks are based on information set decoding.\n\nPerformance. The quasi-cyclic structure of HQC enables small public-key and ciphertext sizes, although they are noticeably larger than the structured lattice KEMs. HQC ciphertexts and public keys are roughly 2.9 and 1.5 times the size of BIKE ciphertexts and public keys, respectively (see Tables 6 and 7). Although the bandwidth of HQC exceeds that of BIKE, HQC’s key generation and decapsulation are significantly faster than those of BIKE (see Tables 3 and 4). As a result, the performances of HQC and BIKE in applications are difficult to compare. Experiments on TLS 1.3 handshake performance under varying network conditions have revealed that HQC outperforms BIKE under ideal network conditions [33].", "char_len": 3996, "approx_tokens": 999}
{"chunk_id": "NIST.IR.8545::c00010", "doc_id": "NIST.IR.8545", "start_page": 18, "end_page": 19, "text": "are noticeably larger than the structured lattice KEMs. HQC ciphertexts and public keys are roughly 2.9 and 1.5 times the size of BIKE ciphertexts and public keys, respectively (see Tables 6 and 7). Although the bandwidth of HQC exceeds that of BIKE, HQC’s key generation and decapsulation are significantly faster than those of BIKE (see Tables 3 and 4). As a result, the performances of HQC and BIKE in applications are difficult to compare. Experiments on TLS 1.3 handshake performance under varying network conditions have revealed that HQC outperforms BIKE under ideal network conditions [33]. However, in the case of nonzero packet loss rates, BIKE outperforms HQC. In addition to the benchmarks included in the HQC submission for a hardware implementation, there have been several hardware implementation results published in the literature [34–36]. Significant events since Round 3. To address security and performance, HQC added a salt to mitigate multi-ciphertext attacks and switched to using implicit rejection for their FO transform. Additionally, several changes to the implementation were made to avoid timing attacks.\n\nOverall assessment. NIST determined that HQC would provide a good complement to ML- KEM, since it is based on a different underlying security problem and still retains reasonable performance characteristics for general applications. The only other fourth-round candidate that could potentially serve this purpose was BIKE, which relies on similar code-based assumptions to HQC. Compared to BIKE, HQC has larger public key and ciphertext sizes but cheaper key generation and decryption. NIST was unable to make a definitive assessment as to which performance profile is better but found it likely that either performance profile would be acceptable for most general applications. The decisive factor in favor of HQC relative to BIKE is HQC’s stable DFR analysis. A sufficiently low DFR is required to achieve IND-CCA2 security, and there have been persistent uncertainties regarding BIKE’s DFR. While DFR estimation techniques for BIKE have recently\n\n2HQC’s DFR analysis makes the simplifying assumption that the coordinates of e′ = x · r2 − r1 · y + e are independent variables. The HQC submission document [8] gives theoretical and experimental justifications for this assumption.\n\nimproved, previous inaccurate DFR estimates have resulted in BIKE being attacked as late as the fourth round, and BIKE would likely require post-selection tweaks to achieve IND- CCA2 security. In contrast, DFR estimates for all HQC parameter sets have remained stable throughout the NIST PQC Standardization Process. The IND-CCA2 security of HQC has not been successfully attacked since May 2020 when HQC discarded parameter sets targeting a higher DFR than 2−λ for λ bits of security. NIST is confident that HQC as submitted provides a low enough DFR to achieve IND-CCA2 security.\n\n3.2. BIKE\n\nBIKE (Bit-Flipping Key Encapsulation) is a KEM based on binary linear quasi-cyclic moderate density parity check (QC-MDPC) codes [37]. The BIKE cryptosystem was initially designed for ephemeral key use but now claims to also support static key use.\n\nDesign. The binary linear QC-MDPC code C(n, k) used in BIKE is constructed as follows. The secret key is a parity check matrix Hr×2r for a quasi-cyclic moderate density parity check code composed of two circulant blocks, where r is prime and chosen so that xr−1 has only two irreducible factors modulo 2. Each row of H has Hamming weight w ≈ √n, where w ≡ 2 mod 4 . All matrix operations in BIKE can be viewed as polynomial operations due to the isomorphism between the ring of v × v circulant matrices and the polynomial ring F2[x]/(xv + 1) for any v ∈ N. The secret key may then be thought of as a 1 × 2 module (h0, h1). The public key Hpub = (1, h−1h1) is the secret key in systematic form, which is computed by multiplying H by h−1. 0 The underlying BIKE PKE follows Niederreiter-style encryption.", "char_len": 3963, "approx_tokens": 990}
{"chunk_id": "NIST.IR.8545::c00011", "doc_id": "NIST.IR.8545", "start_page": 19, "end_page": 20, "text": "circulant blocks, where r is prime and chosen so that xr−1 has only two irreducible factors modulo 2. Each row of H has Hamming weight w ≈ √n, where w ≡ 2 mod 4 . All matrix operations in BIKE can be viewed as polynomial operations due to the isomorphism between the ring of v × v circulant matrices and the polynomial ring F2[x]/(xv + 1) for any v ∈ N. The secret key may then be thought of as a 1 × 2 module (h0, h1). The public key Hpub = (1, h−1h1) is the secret key in systematic form, which is computed by multiplying H by h−1. 0 The underlying BIKE PKE follows Niederreiter-style encryption. At a high level, a message is encoded as an error vector e of weight t , and the corresponding ciphertext is computed as HpubeT . Decryption is accomplished by multiplying the ciphertext by h0 to produce the syndrome HeT and then using the recommended Black-Grey-Flip bit-flipping decoder [38] to recover e.\n\nSecurity. The proof of IND-CPA security of the underlying PKE in the random oracle model (ROM) depends on the difficulty of solving the decisional QCSD and QCCF problems. The FO transform, as described in [31], is applied to the CPA-secure PKE to achieve a claimed IND-CCA2 KEM. The PKE must be δ -correct3 for δ ≤ 2−λ to apply this transformation. Iterative bit-flipping decoders for QC-MDPC codes are difficult to analyze in closed form, and the anticipated DFR is too low to compute directly. Moreover, the DFR of MDPC and LDPC codes under iterative decoding follows two regimes: a waterfall region in which decoding failures decrease rapidly followed by an error floor region in which decoding failures decrease at a much slower pace as the signal-to-noise ratio increases. Understanding the 3A KEM is δ -correct if the decapsulation fails (i.e., disagrees with encapsulation) with probability at most δ on average over all keys and messages. Similarly, a decoder will be δ -correct if its failure rate is at most δ on average when the input is drawn uniformly.\n\nDFR of BIKE has remained an open problem during the fourth round. Analyzing the BIKE DFR has involved studying the impacts of weak keys and near codewords on decoding performance. The first classification of weak keys for QC-MDPC codes was given in [39] and generalized in [40, 41]. Since these classes of weak keys have small cardinality, they were determined to have minimal impact on the overall BIKE DFR. A new class of weak keys was discovered [42] based on the gathering property. These weak keys were shown to cause an average DFR of a least 2−117 for BIKE level 1 parameters, defeating the IND-CCA2 security of BIKE. The BIKE team studied the weak keys with the gathering property and found that the decoding failures were largely caused by incorrect flips happening early in the decoding process. Namely, bits not in error were incorrectly flipped during the first iterations of the decoder. To mitigate the effect of the gathering keys, the BIKE team introduced a new decoder known as BIKE-flip that sets a high bit-flipping threshold at the first decoding iteration and then gradually lowers the threshold throughout decoding [6]. Results indicated that the BIKE-flip decoder significantly reduced the impact of gathering keys, although this analysis was limited to classes of weak keys with a high enough DFR to be directly measured. Subsequently, a model introduced by [26] was able to predict variations in DFR based on the structure of a key. This would allow a modification of the BIKE key-generation algorithm in which keys that are not expected to have a typical value for the DFR are rejected. Near codewords are error vectors of low weight (u) that map to syndromes of low weight (v) and are well-studied in the LDPC literature as impediments to the iterative decoding process. Moreover, these vectors are known to significantly contribute to error floor behavior. A particular class of near codewords, where u = v = w , was defined in [41] and shown to exist for BIKE.", "char_len": 3964, "approx_tokens": 991}
{"chunk_id": "NIST.IR.8545::c00012", "doc_id": "NIST.IR.8545", "start_page": 20, "end_page": 21, "text": "able to predict variations in DFR based on the structure of a key. This would allow a modification of the BIKE key-generation algorithm in which keys that are not expected to have a typical value for the DFR are rejected. Near codewords are error vectors of low weight (u) that map to syndromes of low weight (v) and are well-studied in the LDPC literature as impediments to the iterative decoding process. Moreover, these vectors are known to significantly contribute to error floor behavior. A particular class of near codewords, where u = v = w , was defined in [41] and shown to exist for BIKE. The impact of these near codewords 2 on the decoding performance for BIKE was initially analyzed in [41] and further studied in [26]. In [26], a Markov model that tracked proximity to near codewords was used to predict the error floors for QC-MDPC codes under a generic iterative decoder. Results indicated that the error floor behavior in the BIKE DFR curves was dominated by convergence to these near codewords during failed decoding instances [26]. Furthermore, the model predicted that increasing BIKE security level 1 block lengths from r = 12323 to r = 13477 would result in a conservative DFR estimate of 2−129.5 for typical keys.\n\nPerformance. The sizes of BIKE’s public keys and ciphertexts were roughly 70% and 30% of HQC’s, respectively. However, BIKE’s decapsulation and key-generation algorithms were roughly 5-6 times slower than HQC’s, respectively. The performance of BIKE and HQC in applications was difficult to compare. Experiments on TLS 1.3 handshake performance under varying network conditions have revealed that HQC outperforms BIKE under ideal network conditions [33]. However, BIKE outperforms HQC when non-zero packet loss rates are introduced.\n\nSignificant events since Round 3. The BIKE specification was updated at the beginning of the fourth round and included a change from the previous approach of sampling fixedweight vectors to a data-oblivious technique. This modification had no noticeable performance impacts but eliminated certain side-channel attacks. To offer more resistance against multi-target key attacks, BIKE’s FO transform to attain IND-CCA2 security now includes a hash of part of the public key. As noted in the Security section above, a new decoder (BIKE-Flips) was used, which has better resilience to decryption failure for weak keys.\n\nOverall assessment. NIST found that BIKE is a KEM that would complement ML-KEM well with respect to having a different underlying security problem and balanced performance characteristics. BIKE also offers smaller keys and ciphertexts than HQC. NIST reviewed several DFR analyses of BIKE, including recent results indicating that an approximate 9% increase in block size leads to a sufficiently low DFR for security level 1 parameters. Despite these promising results, NIST found the security analysis of HQC to be more mature and stable than that of BIKE. As such, NIST has not selected BIKE for standardization.\n\n3.3. Classic McEliece Design. Classic McEliece is a code-based KEM that uses binary Goppa codes in the Niederreiter variant of the McEliece cryptosystem combined with standard techniques to achieve IND-CCA2 security. Due to the use of Goppa codes, the KEM has perfect correctness.4 It is a merger of the second-round submissions Classic McEliece and NTS-KEM. The original McEliece cryptosystem was published in [43] and was also based on binary Goppa codes.", "char_len": 3460, "approx_tokens": 865}
{"chunk_id": "NIST.IR.8545::c00013", "doc_id": "NIST.IR.8545", "start_page": 21, "end_page": 22, "text": "found the security analysis of HQC to be more mature and stable than that of BIKE. As such, NIST has not selected BIKE for standardization.\n\n3.3. Classic McEliece Design. Classic McEliece is a code-based KEM that uses binary Goppa codes in the Niederreiter variant of the McEliece cryptosystem combined with standard techniques to achieve IND-CCA2 security. Due to the use of Goppa codes, the KEM has perfect correctness.4 It is a merger of the second-round submissions Classic McEliece and NTS-KEM. The original McEliece cryptosystem was published in [43] and was also based on binary Goppa codes.\n\nSecurity. The Classic McEliece submission cites [44] and other results as giving a tight proof of the submitted KEM’s IND-CCA2 security in the quantum random oracle model based on the assumption that the 1978 McEliece scheme provides one-way under chosen-plaintext attacks (OW-CPA) security. Confidence in the security of the 1978 scheme was mostly established based on the scheme’s long history of surviving cryptanalysis with only minor changes in the complexity of the best-known attack. Alternatively, the security of the scheme could be established under the assumptions that row-reduced parity check matrices for the binary Goppa codes used by Classic McEliece are indistinguishable from rowreduced parity check matrices for random linear codes of the same dimensions and that the syndrome decoding problem is hard for random linear codes with those dimensions. The state of the art in cryptanalysis does not contradict these assumptions, although binary Goppa codes with very different dimensions from those used by the Classic McEliece submission have been shown to be distinguishable from random codes [45]. More recent work [46] has proposed a distinguisher that claims to asymptotically break the indistinguishabil-\n\n4A perfectly correct KEM or PKE is one for which every ciphertext generated using the encapsulation/encryption function may be correctly decrypted using the decapsulation/decryption function. In contrast, some KEMs and PKEs have a very small decryption failure rate.\n\nity of Goppa codes with parameters that are similar to those used by Classic McEliece but that target a much higher security level. A number of approaches to the cryptanalysis of Classic McEliece have been studied. The most effective known attacks and those used to set the parameters of Classic McEliece are information set decoding attacks, which are similar to the best-known attacks against BIKE and HQC. Unlike the other two schemes, information set decoding is only applicable to message recovery, not key recovery. These attacks ignore the structure of the binary code and seek to recover the error vector based on its low Hamming weight. These techniques originated with Prange’s algorithm in 1962 [47] and have undergone a series of improvements [48–56]. However, the net effect of these improvements has been fairly modest, and most of the change in concrete security is due to improvements that were discovered more than 30 years ago. Quantum versions of information set decoding (ISD) algorithms have also been studied [57]. These results represent a generic Grover-based speedup of classical ISD algorithms and indicate that ISD algorithms can be sped up nearly as much as brute force search problems. In a multi-ciphertext setting, a further improvement [58] can reduce the cost of decoding a single ciphertext by a factor equal to approximately the square root of the number of ciphertexts. Key-recovery attacks have also been studied, which attempt to find the private key by algebraic techniques or brute-force searches. Algebraic techniques have been used to break variants of McEliece based on other algebraic codes [59–63] or Goppa codes with additional structure imposed [64], but they appear to be significantly more costly than ISD for attacking the parameters submitted for Classic McEliece.", "char_len": 3911, "approx_tokens": 977}
{"chunk_id": "NIST.IR.8545::c00014", "doc_id": "NIST.IR.8545", "start_page": 22, "end_page": 23, "text": "n a multi-ciphertext setting, a further improvement [58] can reduce the cost of decoding a single ciphertext by a factor equal to approximately the square root of the number of ciphertexts. Key-recovery attacks have also been studied, which attempt to find the private key by algebraic techniques or brute-force searches. Algebraic techniques have been used to break variants of McEliece based on other algebraic codes [59–63] or Goppa codes with additional structure imposed [64], but they appear to be significantly more costly than ISD for attacking the parameters submitted for Classic McEliece. Nonetheless, algebraic attacks that target the structure of Goppa codes and achieve either key recovery or a distinguisher from a random linear code have remained an active area of research [46, 65–69].\n\nPerformance. Classic McEliece has a very large public-key size and fairly slow key generation, which will likely make it undesirable in many common settings. However, its profile could have some advantages in settings where a public key is reused many times and does not need to be retransmitted for each new communication [70]. In particular, Classic McEliece has the smallest ciphertext sizes of any of the NIST PQC candidates.\n\nSignificant events since Round 3. At the beginning of the fourth round, the submission team introduced a modification to the FO transform to incorporate implicit rejection without plaintext confirmation. This tweak aimed to reduce the potential for patent concerns and simplify the specification and software code. During the fourth round, there has been significant progress in cryptanalysis techniques that are applicable to key recovery and the related problem of distinguishing a Goppa code from a random linear code [46, 66–69]. While these techniques are still far from concretely affecting the security of the submitted parameter sets of Classic McEliece, they somewhat weaken the argument that the long-term security of Classic McEliece is guaranteed by its long history of cryptanalysis.\n\nAdditionally, during the third round, Classic McEliece was proposed to be added to the ISO/International Electrotechnical Commission (IEC) standard ISO/IEC 18033-2. This concurrent standardization effort remains active and ongoing.\n\nOverall assessment. NIST remains confident in the security of Classic McEliece,5 although recent progress in cryptanalysis somewhat undermines the case for treating it as an especially conservative choice. Its large public-key size makes Classic McEliece an unattractive choice for most common applications, but it offers an excellent performance profile for applications that are sensitive to ciphertext size, where public keys are rarely transmitted. NIST does not find the case for standardizing Classic McEliece compelling, due to skepticism that it will see widespread use. In the event that Classic McEliece does become widely used through other standards, and that NIST remains confident in its security while also determining that there is sufficient need, NIST may develop a NIST standard based on the widely used version.\n\n3.4. SIKE Cryptographic schemes that are based on the hardness of the discrete logarithm problem on elliptic curves are known to be quantum-insecure because of Shor’s algorithm. However, elliptic curves can be used in a different way to construct PKE and KEM protocols. An isogeny from one elliptic curve to another elliptic curve (over the same field) is a rational map that is also a group homomorphism. Given two isogenous curves E and E ′, efficiently constructing an isogeny from E to E ′ is generally unknown. The assumed hardness of finding an isogeny between two elliptic curves combined with the Diffie–Hellman model for key exchange enables the construction of a family of isogeny-based KEMs. SIKE is a KEM based on isogenies of supersingular elliptic curves that follows and improves upon the construction known as Supersingular Isogeny Diffie–Hellman (SIDH) [72].", "char_len": 3974, "approx_tokens": 993}
{"chunk_id": "NIST.IR.8545::c00015", "doc_id": "NIST.IR.8545", "start_page": 23, "end_page": 26, "text": "geny from one elliptic curve to another elliptic curve (over the same field) is a rational map that is also a group homomorphism. Given two isogenous curves E and E ′, efficiently constructing an isogeny from E to E ′ is generally unknown. The assumed hardness of finding an isogeny between two elliptic curves combined with the Diffie–Hellman model for key exchange enables the construction of a family of isogeny-based KEMs. SIKE is a KEM based on isogenies of supersingular elliptic curves that follows and improves upon the construction known as Supersingular Isogeny Diffie–Hellman (SIDH) [72]. In SIKE, one party prepares a secret isogeny φ from a publicly known elliptic curve E0 to a new curve E and computes the images of the generators of a known torsion subgroup (under φ ) as the public key. This public key is then used to carry out a Diffie–Hellman procedure. The security of SIKE depends crucially on the assumption that it is infeasible for an adversary to compute the secret isogeny φ from public information. However, in mid-2022, researchers showed that the secret isogeny φ can be efficiently recovered from the public key [17]. Attacks on SIKE were further improved and generalized by other researchers [25, 73], and the authors of SIKE have acknowledged the break [9]. Attempts to patch the vulnerabilities were ineffective or had weaknesses in some instances [74]. While these attacks were devastating for SIKE, they do not apply to many\n\n5Independent estimates [56, 71] of the cost of information set decoding algorithms have long suggested that Classic McEliece’s parameter sets (i.e., mceliece460896 and mceliece460896f) that claim Category 3 security fall short of their security target. However, NIST remains confident that these parameter sets at least meet the criteria for Category 2 security.\n\nother isogeny-based cryptographic schemes. The attacks relied on the information provided by the image of a torsion subgroup in the SIKE public key, while other isogeny-based schemes do not utilize these auxiliary torsion points. SIKE is an insecure KEM, and it has been eliminated from the NIST PQC project.\n\n4. Conclusion\n\nThis report summarizes the evaluation criteria for selecting the fourth-round candidate algorithms, their basic designs, and their advantages and disadvantages. NIST greatly appreciates the participation in the NIST PQC Standardization Process. The announcement of the standardization of HQC marks the end of the fourth round, and also marks an end to the standardization process which began with the NIST Call for Proposals in 2016 [22]. We note that not all NIST PQC standardization is concluded, as NIST is also currently evaluating additional digital signatures [75]. NIST will create a draft standard based on HQC and post it for public comment. After the comments are adjudicated, NIST will publish a final version in approximately two years. The standardization of HQC will be the second PQC KEM after ML-KEM. NIST recently published draft SP 800-227, Recommendations for Key-Encapsulation Mechanisms [76], which describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner. NIST plans to host another NIST PQC Standardization Conference in September 2025, with more details to be provided.\n\nReferences\n\n[1] Open quantum safe (OQS) algorithm performance visualizations. Available at https: //openquantumsafe.org/benchmarking. [2] Alagic G, Apon D, Cooper DA, Dang QH, Dang T, Kelsey JM, Lichtinger J, Liu YK, Miller CA, Moody D, Peralta R, Perlner RA, Robinson A, Smith-Tone D (2022) Status Report on the Third Round of the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) NIST IR 8413-upd1, Includes updates as of September 26, 2022.", "char_len": 3902, "approx_tokens": 975}
{"chunk_id": "NIST.IR.8545::c00016", "doc_id": "NIST.IR.8545", "start_page": 25, "end_page": 27, "text": "2025, with more details to be provided.\n\nReferences\n\n[1] Open quantum safe (OQS) algorithm performance visualizations. Available at https: //openquantumsafe.org/benchmarking. [2] Alagic G, Apon D, Cooper DA, Dang QH, Dang T, Kelsey JM, Lichtinger J, Liu YK, Miller CA, Moody D, Peralta R, Perlner RA, Robinson A, Smith-Tone D (2022) Status Report on the Third Round of the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) NIST IR 8413-upd1, Includes updates as of September 26, 2022. https://doi.org/10.6028/NIST.IR.8413-upd1 [3] National Institute of Standards and Technology (2015) SHA-3 Standard: Permutation- Based Hash and Extendable-Output Functions. (Department of Commerce, Washing- ton, DC), Federal Information Processing Standards Publication (FIPS) NIST FIPS 202. https://doi.org/10.6028/NIST.FIPS.202 [4] National Institute of Standards and Technology (2024) Module-Lattic-Based Digi- tal Signature Standard. (Department of Commerce, Washington, DC), Federal In- formation Processing Standards Publication (FIPS) NIST FIPS 204. https://doi.org/ 10.6028/NIST.FIPS.204 [5] National Institute of Standards and Technology (2024) Stateless Hash-Based Digi- tal Signature Standard. (Department of Commerce, Washington, DC), Federal In- formation Processing Standards Publication (FIPS) NIST FIPS 205. https://doi.org/ 10.6028/NIST.FIPS.205 [6] Aragon N, Barreto PSLM, Bettaieb S, Bidoux L, Blazy O, Deneuville JC, Gaborit P, Ghosh S, Gueron S, Güneysu T, Melchor CA, Misoczk R, Persichetti E, Richter-Brockmann J, Sendrier N, Tillich JP, Vasseur V, Zémor G (2022) BIKE: Bit Flipping Key Encapsulation, 4th Round submission to the NIST’s post-quantum cryptography standardization pro- cess. https://csrc.nist.gov/projects/post-quantum-cryptography/round-4-submiss ions. [7] Bernstein DJ, Chou T, Cid C, Gilcher J, Lange T, Maram V, von Maurich I, Misoczki R, Niederhagen R, Persichetti E, Peters C, Sendrier N, Szefer J, Tjhai CJ, Tomlinson M, Wang W (2022) Classic McEliece algorithm specifications and supporting documen- tation, 4th Round submission to the NIST’s post-quantum cryptography standardiza- tion process. https://csrc.nist.gov/projects/post-quantum-cryptography/round-4-s ubmissions. [8] Melchor CA, Aragon N, Bettaieb S, Bidoux L, Blazy O, Deneuville JC, Gaborit P, Per- sichetti E, Zémor G, Bos J, Dion A, Lacan J, Robert JM, Veron P (2022) HQC algorithm specifications and supporting documentation, 4th Round submission to the NIST’s post-quantum cryptography standardization process. https://csrc.nist.gov/projects /post-quantum-cryptography/round-4-submissions. [9] Jao D, Azarderakhsh R, Campagna M, Costello C, Feo LD, Hess B, Jalali A, Koziel B, LaMacchia B, Longa P, Naehrig M, Renes J, Soukharev V, Urbanik D, Pereira G, Kara- bina K, Hutchinson A (2022) Supersingular Isogeny Key Encapsulation, 4th Round\n\nsubmission to the NIST’s post-quantum cryptography standardization process. https: //csrc.nist.gov/projects/post-quantum-cryptography/round-4-submissions. [10] Chen L, Jordan S, Liu YK, Moody D, Peralta R, Perlner R, Smith-Tone D (2016) Re- port on post-quantum cryptography (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8105. https://doi.org/ 10.6028/NIST.IR.8105 [11] National Institute of Standards and Technology (2016) Announcing request for nom- inations for public-key post-quantum cryptographic algorithms. Federal Register 81(244):92787–92788. https://federalregister.gov/a/2016-30615. [12] Alagic G, Alperin-Sheriff J, Apon D, Cooper D, Dang Q, Liu YK, Miller C, Moody D, Per- alta R, Perlner R, Robinson A, Smith-Tone D (2019) Status report on the first round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8240.", "char_len": 3964, "approx_tokens": 991}
{"chunk_id": "NIST.IR.8545::c00017", "doc_id": "NIST.IR.8545", "start_page": 27, "end_page": 28, "text": "028/NIST.IR.8105 [11] National Institute of Standards and Technology (2016) Announcing request for nom- inations for public-key post-quantum cryptographic algorithms. Federal Register 81(244):92787–92788. https://federalregister.gov/a/2016-30615. [12] Alagic G, Alperin-Sheriff J, Apon D, Cooper D, Dang Q, Liu YK, Miller C, Moody D, Per- alta R, Perlner R, Robinson A, Smith-Tone D (2019) Status report on the first round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8240. https://doi.org/10.6028/NIST.IR.8240 [13] Alagic G, Alperin-Sheriff J, Apon D, Cooper D, Dang Q, Kelsey J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Smith-Tone D (2020) Status report on the second round of the NIST post-quantum cryptography standardization process (National In- stitute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8309. https://doi.org/10.6028/NIST.IR.8309 [14] National Institute of Standards and Technology (2024) Module-Lattice-Based Key- Encapsulation Mechanism Standard. (Department of Commerce, Washington, DC), Federal Information Processing Standards Publication (FIPS) NIST FIPS 203. https://doi.org/10.6028/NIST.FIPS.203 [15] National Institute of Standards and Technology (2016) NIST post-quantum cryptogra- phy standardization. Available at https://csrc.nist.gov/projects/post-quantum-crypt ography/post-quantum-cryptography-standardization. [16] National Institute of Standards and Technology (2022) Call for Additional Digital Signa- ture Schemes for the Post-Quantum Cryptography Standardization Process. Available at https://csrc.nist.gov/csrc/media/Projects/pqc-dig-sig/documents/call-for-propo sals-dig-sig-sept-2022.pdf. [17] Castryck W, Decru T (2023) An Efficient Key Recovery Attack on SIDH. Advances in Cryptology – EUROCRYPT 2023, eds Hazay C, Stam M (Springer Nature Switzerland, Cham), pp 423–447. https://doi.org/https://doi.org/10.1007/978-3-031-30589-4_1 [18] Kempf M, Gauder N, Jaeger B, Zirngibl J, Carle G (2024) A Quantum of QUIC: Dis- secting Cryptography with Post-Quantum Insights. IFIP Networking, pp 195–203. https://doi.org/10.23919/IFIPNetworking62109.2024.10619916 [19] Sosnowski M, Wiedner F, Hauser E, Steger L, Schoinianakis D, Gallenmüller S, Carle G (2023) The performance of post-quantum TLS 1.3. Companion of the 19th Interna- tional Conference on emerging Networking EXperiments and Technologies, pp 19–27. https://doi.org/https://doi.org/10.1145/3624354.3630585\n\n[20] Henrich J, Heinemann A, Wiesmaier A, Schmitt N (2023) Performance impact of PQC KEMs on TLS 1.3 under varying network characteristics. ISC 2023: 26th International Conference on Information Security, eds Athanasopoulos E, Mennink B (Springer, Cham, Switzerland, Groningen, The Netherlands), Lecture Notes in Computer Science, Vol. 14411, pp 267–287. https://doi.org/10.1007/978-3-031-49187-0_14 [21] Müller J, Oupický J (2024) Post-quantum XML and SAML single sign-on. Proceedings on Privacy Enhancing Technologies 2024(4):525–543. https://doi.org/10.56553/pop ets-2024-0128 [22] National Institute of Standards and Technology (2016) Submission requirements and evaluation criteria for the post-quantum cryptography standardization process. Avail- able at https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/do cuments/call-for-proposals-final-dec-2016.pdf. [23] National Institute of Standards and Technology (2022) NIST post-quantum cryptogra- phy standardization round 4 submissions. Available at https://csrc.nist.gov/Projects /post-quantum-cryptography/round-4-submissions. [24] Maino L, Martindale C (2022) An attack on SIDH with arbitrary starting curve, Cryp- tology ePrint Archive preprint. Available at https://ia.cr/2022/1026. [25] Robert D (2023) Breaking SIDH in Polynomial Time.", "char_len": 3907, "approx_tokens": 976}
{"chunk_id": "NIST.IR.8545::c00018", "doc_id": "NIST.IR.8545", "start_page": 28, "end_page": 29, "text": "graphy standardization process. Avail- able at https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/do cuments/call-for-proposals-final-dec-2016.pdf. [23] National Institute of Standards and Technology (2022) NIST post-quantum cryptogra- phy standardization round 4 submissions. Available at https://csrc.nist.gov/Projects /post-quantum-cryptography/round-4-submissions. [24] Maino L, Martindale C (2022) An attack on SIDH with arbitrary starting curve, Cryp- tology ePrint Archive preprint. Available at https://ia.cr/2022/1026. [25] Robert D (2023) Breaking SIDH in Polynomial Time. Advances in Cryptology – EURO- CRYPT 2023, eds Hazay C, Stam M (Springer Nature Switzerland, Cham), pp 472–503. https://doi.org/https://doi.org/10.1007/978-3-031-30589-4_17 [26] Arpin S, Lau JB, Perlner R, Robinson A, Tillich JP, Vasseur V (2025) Error floor prediction with Markov models for QC-MDPC codes, Cryptology ePrint Archive, Paper 2025/153. Available at https://eprint.iacr.org/2025/153. [27] Aguilar-Melchor C, Blazy O, Deneuville JC, Gaborit P, Zémor G (2018) Efficient en- cryption from random quasi-cyclic codes. IEEE Transactions on Information Theory 64(5):3927–3943. https://doi.org/https://doi.org/10.1109/TIT.2018.2804444 [28] Aragon N, Gaborit P, Z’emor G (2020) HQC-RMRS, an instantiation of the HQC encryption framework with a more efficient auxiliary error-correcting code. ArXiv abs/2005.10741. [29] Regev O (2005) On lattices, learning with errors, random linear codes, and cryptog- raphy. Proceedings of the Thirty-Seventh Annual ACM Symposium on Theory of Com- puting STOC ’05 (Association for Computing Machinery, New York, NY, USA), p 84–93. https://doi.org/10.1145/1060590.1060603 [30] Lyubashevsky V, Peikert C, Regev O (2010) On ideal lattices and learning with errors over rings. Advances in Cryptology – EUROCRYPT 2010, ed Gilbert H (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 1–23. https://doi.org/https://doi.org/10.1007/ 978-3-642-13190-5_1 [31] Hofheinz D, Hövelmanns K, Kiltz E (2017) A modular analysis of the Fujisaki-Okamoto transformation. Theory of Cryptography, eds Kalai Y, Reyzin L (Springer International Publishing, Cham), pp 341–371. https://doi.org/https://doi.org/10.1007/978-3-319 -70500-2_12\n\n[32] Guo Q, Johansson T (2020) A new decryption failure attack against HQC. Advances in Cryptology – ASIACRYPT 2020, eds Moriai S, Wang H (Springer International Publish- ing, Cham), pp 353–382. https://doi.org/https://doi.org/10.1007/978-3-030-64837 -4_12 [33] Henrich J, Heinemann A, Wiesmaier A, Schmitt N (2023) Performance Impact of PQC KEMs on TLS 1.3 Under Varying Network Characteristics. Information Security, eds Athanasopoulos E, Mennink B (Springer Nature Switzerland, Cham), pp 267–287. https://doi.org/https://doi.org/10.1007/978-3-031-49187-0_14 [34] Deshpande S, Xu C, Nawan M, Nawaz K, Szefer J (2023) Fast and efficient hardware implementation of HQC. Selected Areas in Cryptography - SAC 2023 - 30th Interna- tional Conference, Fredericton, Canada, August 14-18, 2023, Revised Selected Papers, eds Carlet C, Mandal K, Rijmen V (Springer), Lecture Notes in Computer Science, Vol. 14201, pp 297–321. https://doi.org/10.1007/978-3-031-53368-6\\_15 [35] Li C, Song S, Tian J, Wang Z, Koç ÇK (2023) An efficient hardware design for fast imple- mentation of HQC. 36th IEEE International System-on-Chip Conference, SOCC 2023, Santa Clara, CA, USA, September 5-8, 2023, eds Becker J, Marshall A, Harbaum T, Gan- guly A, Siddiqui F, McLaughlin K (IEEE), pp 1–6. https://doi.org/10.1109/SOCC58585. 2023.10257054 [36] Antognazza F, Barenghi A, Pelosi G, Susella R (2024) A high efficiency hardware de- sign for the post-quantum KEM HQC. IEEE International Symposium on Hardware Ori- ented Security and Trust, HOST 2024, Tysons Corner, VA, USA, May 6-9, 2024 (IEEE), pp 431–441.", "char_len": 3840, "approx_tokens": 960}
{"chunk_id": "NIST.IR.8545::c00019", "doc_id": "NIST.IR.8545", "start_page": 29, "end_page": 30, "text": "n J, Wang Z, Koç ÇK (2023) An efficient hardware design for fast imple- mentation of HQC. 36th IEEE International System-on-Chip Conference, SOCC 2023, Santa Clara, CA, USA, September 5-8, 2023, eds Becker J, Marshall A, Harbaum T, Gan- guly A, Siddiqui F, McLaughlin K (IEEE), pp 1–6. https://doi.org/10.1109/SOCC58585. 2023.10257054 [36] Antognazza F, Barenghi A, Pelosi G, Susella R (2024) A high efficiency hardware de- sign for the post-quantum KEM HQC. IEEE International Symposium on Hardware Ori- ented Security and Trust, HOST 2024, Tysons Corner, VA, USA, May 6-9, 2024 (IEEE), pp 431–441. https://doi.org/10.1109/HOST55342.2024.10545409 [37] Misoczki R, Tillich JP, Sendrier N, Barreto PSLM (2013) MDPC-McEliece: New McEliece variants from moderate density parity-check codes. 2013 IEEE International Sympo- sium on Information Theory, pp 2069–2073. https://doi.org/https://doi.org/10.110 9/ISIT.2013.6620590 [38] Drucker N, Gueron S, Kostic D (2020) QC-MDPC decoders with several shades of gray. Post-Quantum Cryptography, eds Ding J, Tillich JP (Springer International Publishing, Cham), pp 35–50. https://doi.org/https://doi.org/10.1007/978-3-030-44223-1_3 [39] Drucker N, Gueron S, Kostic D (2020) On constant-time QC-MDPC decoders with negligible failure rate. Code-Based Cryptography, eds Baldi M, Persichetti E, San- tini P (Springer International Publishing, Cham), pp 50–79. https://doi.org/https: //doi.org/10.1007/978-3-030-54074-6_4 [40] Aydin N, Yildiz B, Uludag S (2020) A class of weak keys for the QC-MDPC cryptosystem. Algebraic and Combinatorial Coding Theory 2020, pp 1–4. https://doi.org/10.1109/ ACCT51235.2020.9383383 [41] Vasseur V (2021) Post-quantum cryptography: a study of the decoding of QC-MDPC codes. Ph.D. thesis. Université de Paris, Paris, France. [42] Wang T, Wang A, Wang X (2023) Exploring decryption failures of BIKE: New class of weak keys and key recovery attacks. Advances in Cryptology – CRYPTO 2023, eds Handschuh H, Lysyanskaya A (Springer Nature Switzerland, Cham), pp 70–100. https://doi.org/https://doi.org/10.1007/978-3-031-38548-3_3\n\n[43] McEliece RJ (1978) A Public-Key Cryptosystem Based On Algebraic Coding Theory. Deep Space Network Progress Report 44:114–116. [44] Bindel N, Hamburg M, Hövelmanns K, Hülsing A, Persichetti E (2019) Tighter proofs of CCA security in the quantum random oracle model. Theory of Cryptography, eds Hofheinz D, Rosen A (Springer International Publishing, Cham), pp 61–90. https://doi.org/https://doi.org/10.1007/978-3-030-36033-7_3 [45] Faugère JC, Gauthier-Umanã V, Otmani A, Perret L, Tillich JP (2011) A distinguisher for high rate McEliece cryptosystems. 2011 IEEE Information Theory Workshop, pp 282–286. https://doi.org/https://doi.org/10.1109/ITW.2011.6089437 [46] Randriambololona H (2024) The syzygy distinguisher. IACR Cryptol ePrint Arch :1193Available at https://eprint.iacr.org/2024/1193. [47] Prange E (1962) The use of information sets in decoding cyclic codes. IRE Transactions on Information Theory 8(5):5–9. https://doi.org/https://doi.org/10.1109/TIT.1962.1 [48] Stern J (1989) A method for finding codewords of small weight. Coding Theory and Applications, eds Cohen G, Wolfmann J (Springer Berlin Heidelberg, Berlin, Heidel- berg), pp 106–113. https://doi.org/https://doi.org/10.1007/BFb0019850 [49] Dumer I (1991) On minimum distance decoding of linear codes. Proc. 5th Joint Soviet-\n\n[50] Swedish Int. Workshop Inform. Theory, pp 50–52. ̃ 0.054n May A, Meurer A, Thomae E (2011) Decoding random linear codes in O(2 ). Ad- vances in Cryptology – ASIACRYPT 2011, eds Lee DH, Wang X (Springer Berlin Heidel- berg, Berlin, Heidelberg), pp 107–124. https://doi.org/https://doi.org/10.1007/97 8-3-642-25385-0_6 [51] Bernstein DJ, Lange T, Peters C (2011) Smaller decoding exponents: Ball-collision de- coding. Advances in Cryptology – CRYPTO 2011, ed Rogaway P (Springer Berlin Hei- delberg, Berlin, Heidelberg), pp 743–760.", "char_len": 3933, "approx_tokens": 983}
{"chunk_id": "NIST.IR.8545::c00020", "doc_id": "NIST.IR.8545", "start_page": 30, "end_page": 31, "text": "imum distance decoding of linear codes. Proc. 5th Joint Soviet-\n\n[50] Swedish Int. Workshop Inform. Theory, pp 50–52. ̃ 0.054n May A, Meurer A, Thomae E (2011) Decoding random linear codes in O(2 ). Ad- vances in Cryptology – ASIACRYPT 2011, eds Lee DH, Wang X (Springer Berlin Heidel- berg, Berlin, Heidelberg), pp 107–124. https://doi.org/https://doi.org/10.1007/97 8-3-642-25385-0_6 [51] Bernstein DJ, Lange T, Peters C (2011) Smaller decoding exponents: Ball-collision de- coding. Advances in Cryptology – CRYPTO 2011, ed Rogaway P (Springer Berlin Hei- delberg, Berlin, Heidelberg), pp 743–760. https://doi.org/https://doi.org/10.1007/ 978-3-642-22792-9_42 [52] Becker A, Joux A, May A, Meurer A (2012) Decoding random binary linear codes in 2n/20: How 1 + 1 = 0 improves information set decoding. Advances in Cryptology – EUROCRYPT 2012, eds Pointcheval D, Johansson T (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 520–536. https://doi.org/https://doi.org/10.1007/978-3-642-290 11-4_31 [53] May A, Ozerov I (2015) On computing nearest neighbors with applications to decoding of binary linear codes. Advances in Cryptology – EUROCRYPT 2015, eds Oswald E, Fis- chlin M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 203–228. https://doi.org/ https://doi.org/10.1007/978-3-662-46800-5_9 [54] Canto Torres R, Sendrier N (2016) Analysis of information set decoding for a sub-linear error weight. Post-Quantum Cryptography, ed Takagi T (Springer International Pub- lishing, Cham), pp 144–161. https://doi.org/https://doi.org/10.1007/978-3-319-293 60-8_10 [55] Both L, May A (2017) Optimizing BJMM with nearest neighbors: full decoding in 22n/21 and McEliece security. The Tenth International Workshop on Coding and Cryptogra-\n\nphy, pp –. Available at https://www.cits.ruhr-uni-bochum.de/imperia/md/content/ may/paper/bjmm+.pdf. [56] Guo Q, Johansson T, Nguyen V (2024) A new sieving-style information-set decoding algorithm. IEEE Trans Inf Theory 70(11):8303–8319. https://doi.org/10.1109/TIT.20 24.3457150 [57] Kirshanova E (2018) Improved quantum information set decoding. Post-Quantum Cryptography, eds Lange T, Steinwandt R (Springer International Publishing, Cham), pp 507–527. https://doi.org/https://doi.org/10.1007/978-3-319-79063-3_24 [58] Sendrier N (2011) Decoding one out of many. Post-Quantum Cryptography, ed Yang BY (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 51–67. https://doi.org/https: //doi.org/10.1007/978-3-642-25405-5_4 [59] Sidelnikov VM, Shestakov SO (1992) On insecurity of cryptosystems based on gen- eralized Reed-Solomon codes. Discrete Mathematics and Applications 2(4):439–444. https://doi.org/doi:10.1515/dma.1992.2.4.439 [60] Wieschebrink C (2010) Cryptanalysis of the Niederreiter public key scheme based on GRS subcodes. Post-Quantum Cryptography, ed Sendrier N (Springer Berlin Heidel- berg, Berlin, Heidelberg), pp 61–72. https://doi.org/https://doi.org/10.1007/978-3 -642-12929-2_5 [61] Couvreur A, Gaborit P, Gauthier-Umaña V, Otmani A, Tillich JP (2014) Distinguisher- based attacks on public-key cryptosystems using Reed—Solomon codes. Designs, Codes and Cryptography 73(2):641–666. https://doi.org/10.1007/s10623-014-996 7-z [62] Minder L, Shokrollahi A (2007) Cryptanalysis of the Sidelnikov cryptosystem. Ad- vances in Cryptology - EUROCRYPT 2007, ed Naor M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 347–360. https://doi.org/https://doi.org/10.1007/978-3 -540-72540-4_20 [63] Borodin MA, Chizhov IV (2014) Effective attack on the McEliece cryptosystem based on Reed-Muller codes. Discrete Mathematics and Applications 24(5):273–280. https://doi.org/10.1515/dma-2014-0024 [64] Faugère JC, Otmani A, Perret L, de Portzamparc F, Tillich JP (2015) Structural crypt- analysis of McEliece schemes with compact keys. Designs, Codes and Cryptography 79:87 – 112.", "char_len": 3831, "approx_tokens": 957}
{"chunk_id": "NIST.IR.8545::c00021", "doc_id": "NIST.IR.8545", "start_page": 31, "end_page": 32, "text": "alysis of the Sidelnikov cryptosystem. Ad- vances in Cryptology - EUROCRYPT 2007, ed Naor M (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 347–360. https://doi.org/https://doi.org/10.1007/978-3 -540-72540-4_20 [63] Borodin MA, Chizhov IV (2014) Effective attack on the McEliece cryptosystem based on Reed-Muller codes. Discrete Mathematics and Applications 24(5):273–280. https://doi.org/10.1515/dma-2014-0024 [64] Faugère JC, Otmani A, Perret L, de Portzamparc F, Tillich JP (2015) Structural crypt- analysis of McEliece schemes with compact keys. Designs, Codes and Cryptography 79:87 – 112. https://doi.org/https://doi.org/10.1007/s10623-015-0036-z [65] Couvreur A, Otmani A, Tillich J (2014) Polynomial time attack on wild McEliece over quadratic extensions. Advances in Cryptology - EUROCRYPT 2014 - 33rd Annual In- ternational Conference on the Theory and Applications of Cryptographic Techniques, Copenhagen, Denmark, May 11-15, 2014. Proceedings, eds Nguyen PQ, Oswald E (Springer), Lecture Notes in Computer Science, Vol. 8441, pp 17–39. https://doi.org/ 10.1007/978-3-642-55220-5\\_2 [66] Mora R, Tillich J (2023) On the dimension and structure of the square of the dual of a Goppa code. Des Codes Cryptogr 91(4):1351–1372. https://doi.org/10.1007/S106 23-022-01153-W\n\n[67] Bardet M, Mora R, Tillich J (2024) Polynomial time key-recovery attack on high rate random alternant codes. IEEE Trans Inf Theory 70(6):4492–4511. https://doi.org/10 .1109/TIT.2023.3334592 [68] Couvreur A, Mora R, Tillich J (2023) A new approach based on quadratic forms to attack the mceliece cryptosystem. Advances in Cryptology - ASIACRYPT 2023 - 29th International Conference on the Theory and Application of Cryptology and Informa- tion Security, Guangzhou, China, December 4-8, 2023, Proceedings, Part IV, eds Guo J, Steinfeld R (Springer), Lecture Notes in Computer Science, Vol. 14441, pp 3–38. https://doi.org/10.1007/978-981-99-8730-6\\_1 [69] Mora R (2024) On the matrix code of quadratic relationships for a Goppa code. Ad- vances in Mathematics of Communications 19. https://doi.org/10.3934/amc.202402 [70] Hülsing A, Ning KC, Schwabe P, Weber FJ, Zimmermann PR (2021) Post-quantum wireguard. 2021 IEEE Symposium on Security and Privacy (SP), pp 304–321. https://doi.org/https://doi.org/10.1109/SP40001.2021.00030 [71] Esser A, Bellini E (2022) Syndrome decoding estimator. Public-Key Cryptography – PKC 2022, eds Hanaoka G, Shikata J, Watanabe Y (Springer International Publishing, Cham), pp 112–141. https://doi.org/https://doi.org/10.1007/978-3-030-97121-2_5 [72] Jao D, De Feo L (2011) Towards quantum-resistant cryptosystems from supersingu- lar elliptic curve isogenies. Post-Quantum Cryptography, ed Yang BY (Springer Berlin Heidelberg, Berlin, Heidelberg), pp 19–34. https://doi.org/https://doi.org/10.1007/ 978-3-642-25405-5_2 [73] Maino L, Martindale C, Panny L, Pope G, Wesolowski B (2023) A Direct Key Recovery Attack on SIDH. Advances in Cryptology – EUROCRYPT 2023, eds Hazay C, Stam M (Springer Nature Switzerland, Cham), pp 448–471. https://doi.org/https://doi.org/ 10.1007/978-3-031-30589-4_16 [74] Castryck W, Vercauteren F (2023) A Polynomial Time Attack on Instances of M-SIDH and FESTA. Advances in Cryptology – ASIACRYPT 2023, eds Guo J, Steinfeld R (Springer Nature Singapore, Singapore), pp 127–156. https://doi.org/https://doi.org/10.1007/ 978-981-99-8739-9_5 [75] Alagic G, Bros M, Ciadoux P, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Silberg H, Smith-Tone D, Waller N (2024) Status Report on the First Round of the Additional Digital Signature Schemes for the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) NIST IR 8528.", "char_len": 3835, "approx_tokens": 958}
{"chunk_id": "NIST.IR.8545::c00022", "doc_id": "NIST.IR.8545", "start_page": 32, "end_page": 34, "text": "IACRYPT 2023, eds Guo J, Steinfeld R (Springer Nature Singapore, Singapore), pp 127–156. https://doi.org/https://doi.org/10.1007/ 978-981-99-8739-9_5 [75] Alagic G, Bros M, Ciadoux P, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Silberg H, Smith-Tone D, Waller N (2024) Status Report on the First Round of the Additional Digital Signature Schemes for the NIST Post-Quantum Cryptography Standardization Process. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) NIST IR 8528. https://doi.org/10.6028/NIST.IR.8528 [76] Alagic G, Barker EB, Chen L, Moody D, Robinson A, Silberg H, Waller N (2025) Rec- ommendation for key-encapsulation mechanisms (U.S. Department of Commerce, Washington, D.C.), Special Publication 800-227 (Initial Public Draft). https://doi.org/ 10.6028/NIST.SP.800-227.ipd\n\nAppendix A. List of Symbols, Abbreviations, and Acronyms\n\nBIKE Bit-Flipping Key Encapsulation CCA Chosen Ciphertext Attack CPA Chosen Plaintext Attack DFR Decryption Failure Rate FIPS Federal Information Processing Standards FO Fujisaki Okamoto IEC International Electrotechnical Commission IND-CCA2 Indistinguishability under Adaptive Chosen-Ciphertext Attack IND-CPA Indistinguishability under Chosen-Plaintext Attack IPsec Internet Protocol Security ISD Information Set Decoding ISO International Organization for Standardization HQC Hamming Quasi-Cyclic KEM Key-Encapsulation Mechanism LWE Learning With Errors ML-KEM Module Lattice-Based Key-Encapsulation Mechanism (based on Kyber) NIST National Institute of Standards and Technology NIST IR NIST Interagency or Internal Report OW-CPA One-Way under Chosen Plaintext Attack PKE Public-Key Encryption PQC Post-Quantum Cryptography QC-MDPC Quasi-Cyclic Moderate Density Parity Check QCCF Quasi-Cyclic Codeword Finding QCSD Quasi-Cyclic Syndrome Decoding QUIC Quick UDP Internet Connections RMRS Reed-Muller Reed-Solomon ROM Random Oracle Model SAML SSO Security Assertion Markup Language Single Sign-On\n\nSIKE Supersingular Isogeny Key Encapsulation SIDH Supersingular Isogeny Diffie-Hellman SP Special Publication SSH Secure Shell TLS Transport Layer Security VPN Virtual Private Network XML Extensible Markup Language", "char_len": 2287, "approx_tokens": 571}
{"chunk_id": "NIST.IR.8547.ipd::c00000", "doc_id": "NIST.IR.8547.ipd", "start_page": 1, "end_page": 3, "text": "NIST Internal Report NIST IR 8547 ipd\n\nTransition to Post-Quantum Cryptography Standards\n\nInitial Public Draft\n\nDustin Moody Ray Perlner Andrew Regenscheid Angela Robinson David Cooper\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8547.ipd\n\n0 NST NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY U.S. DEPARTMENT OF COMMERCE Check for updates\n\nNIST Internal Report NIST IR 8547 ipd\n\nTransition to Post-Quantum Cryptography Standards\n\nInitial Public Draft\n\nDustin Moody Ray Perlner Andrew Regenscheid Angela Robinson David Cooper Computer Security Division Information Technology Lab\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8547.ipd\n\nOF\n\n* *\n\nFESOF U.S. Department of Commerce Gina M. Raimondo, Secretary National Institute of Standards and Technology Laurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology\n\nCertain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this paper in order to specify the experimental procedure adequately. Such identification does not imply recommendation or endorsement of any product or service by NIST, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose.\n\nThere may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST.\n\nOrganizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at https://csrc.nist.gov/publications.\n\nNIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax\n\nPublication History Approved by the NIST Editorial Review Board on YYYY-MM-DD [Will be added to final publication.]\n\nHow to Cite this NIST Technical Series Publication Moody D, Perlner R, Regenscheid A, Robinson A, Cooper D (2024) Transition to Post-Quantum Cryptography Standards. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Internal Report (IR) NIST IR 8547 ipd. https://doi.org/10.6028/NIST.IR.8547.ipd\n\nAuthor ORCID iDs David Cooper: 0009-0001-2410-5830 Dustin Moody: 0000-0002-4868-6684 Ray Perlner: 0000-0001-8793-2238 Andrew Regenscheid: 0000-0002-3930-527X Angela Robinson: 0000-0002-1209-0379\n\nPublic Comment Period November 12, 2024 – January 10, 2025\n\nSubmit Comments pqc-transition@nist.gov National Institute of Standards and Technology Attn: Computer Security Division, Information Technology Laboratory 100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930\n\nAdditional Information Additional information about this publication is available at https://csrc.nist.gov/pubs/ir/8547/ipd, including related content, potential updates, and document history.\n\nAll comments are subject to release under the Freedom of Information Act (FOIA).", "char_len": 3461, "approx_tokens": 865}
{"chunk_id": "NIST.IR.8547.ipd::c00001", "doc_id": "NIST.IR.8547.ipd", "start_page": 3, "end_page": 5, "text": "30-527X Angela Robinson: 0000-0002-1209-0379\n\nPublic Comment Period November 12, 2024 – January 10, 2025\n\nSubmit Comments pqc-transition@nist.gov National Institute of Standards and Technology Attn: Computer Security Division, Information Technology Laboratory 100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930\n\nAdditional Information Additional information about this publication is available at https://csrc.nist.gov/pubs/ir/8547/ipd, including related content, potential updates, and document history.\n\nAll comments are subject to release under the Freedom of Information Act (FOIA).\n\n1 Abstract 2 This report describes NIST’s expected approach to transitioning from quantum-vulnerable 3 cryptographic algorithms to post-quantum digital signature algorithms and key-establishment 4 schemes. It identifies existing quantum-vulnerable cryptographic standards and the quantum- 5 resistant standards to which information technology products and services will need to 6 transition. It is intended to foster engagement with industry, standards organizations, and 7 relevant agencies to facilitate and accelerate the adoption of post-quantum cryptography.\n\n8 Keywords 9 cryptography; post-quantum cryptography; public key cryptography; quantum computing.\n\n10 Reports on Computer Systems Technology 11 The Information Technology Laboratory (ITL) at the National Institute of Standards and 12 Technology (NIST) promotes the U.S. economy and public welfare by providing technical 13 leadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test 14 methods, reference data, proof of concept implementations, and technical analyses to advance 15 the development and productive use of information technology. ITL’s responsibilities include 16 the development of management, administrative, technical, and physical standards and 17 guidelines for the cost-effective security and privacy of other than national security-related 18 information in federal information systems.\n\ni\n\n19 Call for Patent Claims 20 This public review includes a call for information on essential patent claims (claims whose use 21 would be required for compliance with the guidance or requirements in this Information 22 Technology Laboratory (ITL) draft publication). Such guidance and/or requirements may be 23 directly stated in this ITL Publication or by reference to another publication. This call also 24 includes disclosure, where known, of the existence of pending U.S. or foreign patent 25 applications relating to this ITL draft publication and of any relevant unexpired U.S. or foreign 26 patents. 27 ITL may require from the patent holder, or a party authorized to make assurances on its behalf, 28 in written or electronic form, either: 29 a) assurance in the form of a general disclaimer to the effect that such party does not hold 30 and does not currently intend holding any essential patent claim(s); or 31 b) assurance that a license to such essential patent claim(s) will be made available to 32 applicants desiring to utilize the license for the purpose of complying with the guidance 33 or requirements in this ITL draft publication either: 34 i. under reasonable terms and conditions that are demonstrably free of any unfair 35 discrimination; or 36 ii. without compensation and under reasonable terms and conditions that are 37 demonstrably free of any unfair discrimination. 38 Such assurance shall indicate that the patent holder (or third party authorized to make 39 assurances on its behalf) will include in any documents transferring ownership of patents 40 subject to the assurance, provisions sufficient to ensure that the commitments in the assurance 41 are binding on the transferee, and that the transferee will similarly include appropriate 42 provisions in the event of future transfers with the goal of binding each successor-in-interest.", "char_len": 3883, "approx_tokens": 970}
{"chunk_id": "NIST.IR.8547.ipd::c00002", "doc_id": "NIST.IR.8547.ipd", "start_page": 5, "end_page": 6, "text": "without compensation and under reasonable terms and conditions that are 37 demonstrably free of any unfair discrimination. 38 Such assurance shall indicate that the patent holder (or third party authorized to make 39 assurances on its behalf) will include in any documents transferring ownership of patents 40 subject to the assurance, provisions sufficient to ensure that the commitments in the assurance 41 are binding on the transferee, and that the transferee will similarly include appropriate 42 provisions in the event of future transfers with the goal of binding each successor-in-interest. 43 The assurance shall also indicate that it is intended to be binding on successors-in-interest 44 regardless of whether such provisions are included in the relevant transfer documents. 45 Such statements should be addressed to: pqc-transition@nist.gov\n\nii\n\n46 Table of Contents 47 1. Introduction ...................................................................................................................................1 50 2. Background....................................................................................................................................3 52 2.1.1. Digital Signature Algorithms......................................................................................................... 3 53 2.1.2. Key Establishment ........................................................................................................................ 4 54 2.1.3. Symmetric Cryptography.............................................................................................................. 4 56 2.2.1. Network Protocol and Security Technology Standards................................................................ 5 57 2.2.2. Software Cryptographic Libraries ................................................................................................. 5 58 2.2.3. Cryptographic Hardware .............................................................................................................. 6 59 2.2.4. PKI and Other Infrastructure Components .................................................................................. 6 60 2.2.5. IT Applications and Services ......................................................................................................... 6 61 3. Migration Considerations ...............................................................................................................7 63 3.1.1. Code Signing ................................................................................................................................. 7 64 3.1.2. User and Machine Authentication ............................................................................................... 7 65 3.1.3. Network Security Protocols.......................................................................................................... 8 66 3.1.4. Email and Document Signing and Encryption .............................................................................. 8 68 3.2.1. Hybrid Key-Establishment Techniques......................................................................................... 9 69 3.2.2. Hybrid Digital Signature Techniques .......................................................................................... 10 70 4. Towards a PQC Standards Transition Timeline...............................................................................11 72 4.1.1. Digital Signatures........................................................................................................................ 13 73 4.1.2. Key Establishment ...................................................................................................................... 14 74 4.1.3. Symmetric Cryptography............................................................................................................", "char_len": 3888, "approx_tokens": 972}
{"chunk_id": "NIST.IR.8547.ipd::c00003", "doc_id": "NIST.IR.8547.ipd", "start_page": 6, "end_page": 8, "text": "...................... 10 70 4. Towards a PQC Standards Transition Timeline...............................................................................11 72 4.1.1. Digital Signatures........................................................................................................................ 13 73 4.1.2. Key Establishment ...................................................................................................................... 14 74 4.1.3. Symmetric Cryptography............................................................................................................ 15 76 References.......................................................................................................................................18 77 Appendix A. Glossary .......................................................................................................................20\n\niii\n\n79 List of Tables 80 Table 1: Post-Quantum Security Categories ......................................................................................12 81 Table 2: Quantum-vulnerable digital signature algorithms ................................................................13 82 Table 3. Post-quantum digital signature algorithms ..........................................................................13 83 Table 4: Quantum-vulnerable key-establishment schemes ................................................................14 84 Table 5: Post-quantum key-establishment schemes ..........................................................................15 85 Table 6: Block ciphers.......................................................................................................................15 86 Table 7: Hash functions and XOFs .....................................................................................................16\n\niv\n\n88 1. Introduction 89 Cryptographic algorithms are vital for safeguarding confidential electronic information from 90 unauthorized access. For decades, these algorithms have proved strong enough to defend 91 against attacks using conventional computers that attempt to defeat cryptography. However, 92 future quantum computing may be able to break these algorithms, rendering data and 93 information vulnerable. Countering this future quantum capability requires new cryptographic 94 methods that can protect data from both current conventional computers and the quantum 95 computers of tomorrow. These methods are referred to as post-quantum cryptography (PQC). 96 In response, NIST has released three PQC standards to start the next and significantly large 97 stage of working on the transition to post-quantum cryptography: the Module-Lattice-Based 98 Key-Encapsulation Mechanism [FIPS203], the Module-Lattice-Based Digital Signature Algorithm 99 [FIPS204], and the Stateless Hash-Based Signature Algorithm [FIPS205]. Historically, the journey 100 from algorithm standardization to full integration into information systems can take 10 to 20 101 years. This timeline reflects the complexity of companies building the algorithms into products 102 and services, procuring those products and services, and integrating those products and 103 services into technology infrastructures. 104 Even though the transition to post-quantum cryptography is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent.", "char_len": 3900, "approx_tokens": 975}
{"chunk_id": "NIST.IR.8547.ipd::c00004", "doc_id": "NIST.IR.8547.ipd", "start_page": 8, "end_page": 10, "text": "is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent.\n\n111 1.1. Scope and Purpose 112 Updating cryptographic technology has occurred many times at different scales, such as 113 increasing key sizes or phasing out insecure hash functions and block ciphers. While the 114 transition to PQC is unprecedented in scale, it benefits from a level of awareness and 115 understanding that previous cryptographic changes did not have. NIST recognizes the 116 complexity of migrating the vast array of systems that currently rely on public-key cryptography 117 and acknowledges that this transition will demand substantial effort across diverse applications 118 and infrastructures with specific requirements and constraints. 119 This report serves as the initial step in a broader strategy to manage and guide the transition to 120 post-quantum cryptography. This transition will involve the adoption of new PQC algorithms as 121 well as the careful deprecation, controlled legacy use, and eventual removal of quantum- 122 vulnerable algorithms that are currently widespread in technological infrastructures. Public- 123 private engagement will be crucial on the path toward PQC. Additionally, this report continues 124 NIST’s ongoing dialogue with industry, standards organizations, and relevant agencies to 125 develop a clear roadmap and realistic timeline for transitioning to PQC. NIST is committed to\n\n126 ensuring that this transition is as smooth and coordinated as possible, balancing the urgency of 127 adopting PQC with the need to minimize disruption across critical systems.\n\n128 1.2. Audience 129 This document is intended for a broad audience, including federal agencies, technology 130 providers, standards organizations, and Cryptographic Module Validation Program (CMVP) 131 laboratories. These groups play a critical role in preparing for the migration to PQC by 132 developing, implementing, and standardizing the new cryptographic methods necessary to 133 secure information in the era of quantum computing. This document should inform these 134 stakeholder’s efforts and timelines for migrating information technology products, services, and 135 infrastructure to PQC.\n\n136 2. Background\n\n137 2.1. Cryptographic Standards 138 Federal Information Processing Standards (FIPS) and the NIST Special Publication (SP) 800-series 139 specify a broad set of cryptographic primitives, algorithms, and schemes, including many public- 140 key cryptosystems that will be deprecated and ultimately disallowed as part of the transition to 141 post-quantum cryptography. This section identifies quantum-vulnerable algorithms in NIST’s 142 existing cryptographic standards as well as the post-quantum algorithm standards that have 143 been recently published. Section 4.1 provides the transition plan for the quantum-vulnerable 144 algorithms in these standards.", "char_len": 3402, "approx_tokens": 850}
{"chunk_id": "NIST.IR.8547.ipd::c00005", "doc_id": "NIST.IR.8547.ipd", "start_page": 10, "end_page": 11, "text": "ocessing Standards (FIPS) and the NIST Special Publication (SP) 800-series 139 specify a broad set of cryptographic primitives, algorithms, and schemes, including many public- 140 key cryptosystems that will be deprecated and ultimately disallowed as part of the transition to 141 post-quantum cryptography. This section identifies quantum-vulnerable algorithms in NIST’s 142 existing cryptographic standards as well as the post-quantum algorithm standards that have 143 been recently published. Section 4.1 provides the transition plan for the quantum-vulnerable 144 algorithms in these standards.\n\n145 2.1.1. Digital Signature Algorithms 146 Digital signature algorithms are used to provide identity authentication, integrity 147 authentication, source authentication, and support for non-repudiation. Digital signature 148 algorithms are used in conjunction with hash functions or eXtendable-Output Functions (XOFs) 149 to sign messages of arbitrary length. 150 NIST-approved digital signature algorithms were historically specified in FIPS 186 [FIPS186]. The 151 current revision of FIPS 186 specifies the Elliptic Curve Digital Signature Algorithm (ECDSA) and 152 adopts the RSA algorithm specified in RFC 8017 and PKCS 1 (version 1.5 and higher) and the 153 Edwards-Curve Digital Signature Algorithm (EdDSA) specified in RFC 8032. The related SP 800- 154 186 [SP800186] specifies the elliptic curves to be used with ECDSA and the elliptic curve 155 cryptography (ECC) based key establishment schemes in SP 800-56A [SP80056A]. These 156 algorithms are vulnerable to Shor’s Algorithm on a cryptographically relevant quantum 157 computer. 158 FIPS 204 and 205 each specify quantum-resistant digital signature schemes. FIPS 204 specifies 159 the Module-Lattice-Based Digital Signature Algorithm (ML-DSA) [FIPS204], which is derived 160 from the CRYSTALS-Dilithium submission. FIPS 205 specifies the Stateless Hash-Based Digital 161 Signature Algorithm (SLH-DSA), which is derived from the SPHINCS+ submission [FIPS205]. 162 SP 800-208, Recommendation for Stateful Hash-Based Signature Schemes, specifies two stateful 163 hash-based signature (HBS) schemes — the Leighton-Micali Signature (LMS) system and the 164 eXtended Merkle Signature Scheme (XMSS) — along with their multi-tree variants, the 165 Hierarchical Signature System (HSS) and multi-tree XMSS (XMSSMT) [SP800208]. These schemes 166 are also resistant to attacks by quantum computers. In stateful hash-based signature (HBS) 167 schemes, the HBS private key consists of a large set of one-time signature (OTS) private keys. 168 The security of these schemes relies on the signer to ensure that no individual OTS key is ever 169 used to sign more than one message. Due to this need to maintain state, HBS schemes are not 170 intended for general use. 171 In the future, NIST intends to develop a FIPS that specifies a digital signature algorithm derived 172 from FALCON as an additional alternative to these standards. In addition, NIST is evaluating 173 other proposed digital signature algorithms for possible standardization through the Additional\n\n174 Digital Signature Schemes for the NIST Post-Quantum Cryptography Standardization Process 175 [NISTIR8528].\n\n176 2.1.2. Key Establishment 177 Key establishment is the means by which keys are generated and provided to the entities that 178 are authorized to use them. Current NIST-approved key-establishment schemes are specified in 179 SP 800-56A, Recommendation for Pair-Wise Key-Establishment Schemes Using Discrete 180 Logarithm-Based Cryptography [SP80056A], and SP 800-56B, Recommendation for Pair-Wise 181 Key Establishment Schemes Using Integer Factorization Cryptography [SP80056B]. 182 SP 800-56A specifies key-establishment schemes based on the discrete logarithm problem over 183 finite fields and elliptic curves, including several variations of Diffie-Hellman and Menezes-Qu- 184 Vanstone (MQV) key establishment schemes.", "char_len": 3952, "approx_tokens": 988}
{"chunk_id": "NIST.IR.8547.ipd::c00006", "doc_id": "NIST.IR.8547.ipd", "start_page": 11, "end_page": 12, "text": "178 are authorized to use them. Current NIST-approved key-establishment schemes are specified in 179 SP 800-56A, Recommendation for Pair-Wise Key-Establishment Schemes Using Discrete 180 Logarithm-Based Cryptography [SP80056A], and SP 800-56B, Recommendation for Pair-Wise 181 Key Establishment Schemes Using Integer Factorization Cryptography [SP80056B]. 182 SP 800-56A specifies key-establishment schemes based on the discrete logarithm problem over 183 finite fields and elliptic curves, including several variations of Diffie-Hellman and Menezes-Qu- 184 Vanstone (MQV) key establishment schemes. 185 SP 800-56B specifies key-establishment schemes based on the RSA public key cryptosystem. 186 This publication includes approved methods for both key agreement and key transport. 187 FIPS 203 specifies a cryptographic scheme called Module-Lattice-Based Key-Encapsulation 188 Mechanism (ML-KEM), which is derived from the CRYSTALS-KYBER submission. A key- 189 encapsulation mechanism (KEM) is a particular type of key-establishment scheme that can be 190 used to establish a shared secret key between two parties communicating over a public 191 channel. The fourth round of the NIST PQC Standardization process is evaluating additional KEM 192 algorithms, and NIST anticipates selecting one or more alternatives to ML-KEM in the future.\n\n193 2.1.3. Symmetric Cryptography 194 Symmetric-key algorithms (sometimes called secret-key algorithms) use a single key to both 195 apply cryptographic protection and to remove or check the protection (i.e., the same key is 196 used for a cryptographic operation and its inverse). For example, the key used to encrypt data 197 (i.e., apply protection) is also used to decrypt the encrypted data (i.e., remove the protection). 198 In the case of encryption, the original data is called the plaintext, while the encrypted form of 199 the data is called the ciphertext. The key must be kept secret if the data is to remain protected. 200 Several classes of symmetric-key algorithms have been approved: those based on block cipher 201 algorithms (e.g., AES) and those based on the use of hash functions (e.g., a keyed-hash message 202 authentication code based on a hash function). 203 Symmetric-key algorithms are used for: 204 • Block ciphers 205 • Hash functions 206 • Encryption using block cipher modes of operation 207 • Data authentication using block cipher modes of operation 208 • Data authentication using key-hash constructions\n\n209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.", "char_len": 3769, "approx_tokens": 942}
{"chunk_id": "NIST.IR.8547.ipd::c00007", "doc_id": "NIST.IR.8547.ipd", "start_page": 12, "end_page": 13, "text": "re built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces.\n\n238 2.2.2. Software Cryptographic Libraries 239 Software cryptographic libraries are collections of cryptographic algorithms and protocols that 240 are implemented in software to provide essential cryptographic functions to applications. 241 OpenSSL, BoringSSL, Libsodium, and the Java Cryptography Architecture (JCA) are a few 242 examples of cryptographic libraries that are used to provide cryptographic support for 243 applications.\n\n244 These libraries need to incorporate PQC algorithms that are standardized by bodies like NIST. 245 Updating them ensures that developers have access to quantum-resistant cryptographic 246 functions without implementing complex algorithms themselves. This transition involves adding 247 new algorithms, optimizing their implementations for performance, and ensuring those 248 implementations are secure against side-channel attacks.\n\n249 2.2.3. Cryptographic Hardware 250 Cryptographic hardware modules, such as hardware security modules (HSMs) and Trusted 251 Platform Modules (TPMs), provide secure environments for performing cryptographic 252 operations and storing sensitive keys. They are used in various applications, from securing 253 server infrastructure to protecting cryptographic keys on personal devices. 254 Hardware modules must be upgraded or redesigned to support PQC algorithms, which often 255 have larger key sizes and different computational requirements. This includes updating 256 firmware or hardware to handle new algorithms and ensuring that the modules can perform 257 quantum-resistant cryptographic operations efficiently while maintaining the high security 258 standards expected of these devices.\n\n259 2.2.4. PKI and Other Infrastructure Components 260 Public key infrastructure (PKI) systems manage digital certificates and public-private key pairs to 261 enable secure communication and authentication across networks. Other infrastructure 262 components include certification authorities (CAs), registration authorities, key management 263 systems, and directory services. 264 PKI components must be updated to issue, distribute, and manage certificates that use PQC 265 algorithms and to sign certificates and revocation status information using PQC algorithms.", "char_len": 3882, "approx_tokens": 970}
{"chunk_id": "NIST.IR.8547.ipd::c00008", "doc_id": "NIST.IR.8547.ipd", "start_page": 13, "end_page": 14, "text": "rds expected of these devices.\n\n259 2.2.4. PKI and Other Infrastructure Components 260 Public key infrastructure (PKI) systems manage digital certificates and public-private key pairs to 261 enable secure communication and authentication across networks. Other infrastructure 262 components include certification authorities (CAs), registration authorities, key management 263 systems, and directory services. 264 PKI components must be updated to issue, distribute, and manage certificates that use PQC 265 algorithms and to sign certificates and revocation status information using PQC algorithms. This 266 includes supporting new cryptographic algorithms in certificate issuance processes and 267 modifying validation and revocation mechanisms. Ensuring backward compatibility and 268 interoperability during the transition period is crucial to maintaining trust and security across 269 the network.\n\n270 2.2.5. IT Applications and Services 271 IT applications and services encompass a wide array of software and platforms used by 272 organizations, including web applications, databases, communication tools, cloud services, and 273 enterprise software. These applications rely on cryptography for securing data, authenticating 274 users, and ensuring secure transactions. 275 Applications and services must be modified to support PQC algorithms for encryption, digital 276 signatures, and key exchange. This requires updating the underlying cryptographic 277 implementations, adjusting to changes in key sizes and algorithm performance, and ensuring 278 compatibility with updated protocols and libraries. Developers need to refactor code, conduct 279 extensive testing, and potentially redesign user interfaces to accommodate these changes.\n\n280 3. Migration Considerations 281 Even though there are no existing cryptographically relevant quantum computers that currently 282 threaten levels of security, it will take a significant amount of time to transition to new post- 283 quantum algorithms. Past cryptographic migrations have taken over a decade, and this more 284 complex migration will likely take at least that long. 285 Mosca’s theorem emphasizes the urgency of migrating to post-quantum algorithms by 286 introducing a simple but powerful timeline: if “X” represents the number of years that data 287 must be kept secure, and “Y” is the estimated time needed to complete the transition, then 288 organizations must start transitioning to post-quantum algorithms before X + Y exceeds the 289 expected time Z for a cryptographically relevant quantum computer to be built. This means that 290 even if quantum computers are a decade away, organizations must begin the migration to post- 291 quantum cryptography today to avoid having their encrypted data exposed once quantum 292 computers become operational in the future. This threat, often referred to as “harvest now, 293 decrypt later,” underscores the necessity of acting immediately, especially for data with long- 294 term sensitivity, such as government secrets or medical records. Ensuring security today will 295 safeguard it for the future.\n\n296 3.1. Use Cases\n\n297 3.1.1. Code Signing 298 Code signing involves digitally signing executables and software packages to verify the author’s 299 identity and ensure that the code has not been tampered with. This process is critical for 300 maintaining trust in software distribution channels and preventing the spread of malicious 301 code. 302 The devices that install and execute this code need the ability to verify the signatures on the 303 code. In some cases, it is not feasible to update the code that performs the signature 304 verification after the devices have been manufactured. When this is the case, it is important for 305 the devices to be designed to require quantum-resistant signatures on the executables, if there 306 is a risk that the devices will still be in use after cryptographically relevant quantum computers 307 become available.", "char_len": 3980, "approx_tokens": 995}
{"chunk_id": "NIST.IR.8547.ipd::c00009", "doc_id": "NIST.IR.8547.ipd", "start_page": 14, "end_page": 15, "text": "software distribution channels and preventing the spread of malicious 301 code. 302 The devices that install and execute this code need the ability to verify the signatures on the 303 code. In some cases, it is not feasible to update the code that performs the signature 304 verification after the devices have been manufactured. When this is the case, it is important for 305 the devices to be designed to require quantum-resistant signatures on the executables, if there 306 is a risk that the devices will still be in use after cryptographically relevant quantum computers 307 become available.\n\n308 3.1.2. User and Machine Authentication 309 User and machine authentication systems verify identities to control access to resources. This 310 often involves cryptographic protocols that use asymmetric algorithms for secure key exchange 311 and authentication, ensuring that only authorized users or devices can access sensitive data or 312 services. Depending on the protocol, authentication may be performed using either a digital 313 signature algorithm or a key-establishment scheme. 314 Unlike with encryption, where there is a threat of “harvest now, decrypt later,” an 315 authentication system remains secure as long as the cryptographic algorithms and keys used to 316 perform the authentication are secure when the authentication is performed. Authentication\n\n317 systems may continue to use quantum-vulnerable algorithms until quantum computers that are 318 capable of breaking current, quantum-vulnerable algorithms become available, at which point 319 authentication using these algorithms will need to be disabled. 320 Supporting quantum-resistant algorithms for authentication will require upgrades to both the 321 system performing and accepting the authentication, as well as to any supporting 322 infrastructure, such as a PKI. It may also require obtaining hardware cryptographic tokens that 323 support the quantum-resistant algorithms.\n\n324 3.1.3. Network Security Protocols 325 Network security protocols like TLS and virtual private networks secure data transmission over 326 public networks. They use cryptographic techniques to provide confidentiality, integrity, and 327 authentication between communicating parties. 328 Modern network security protocols tend to use separate asymmetric keys for key 329 establishment and authentication. While long-term keys are used for authentication, key- 330 establishment keys are used for a short period of time, usually for a single key establishment. 331 This provides the property of forward secrecy, where the compromise of a long-term key does 332 not result in the compromise of communication sessions that occurred before the compromise. 333 As symmetric keys that are established through the key-establishment process are used to 334 provide confidentiality, the “harvest now, decrypt later” threat needs to be considered when 335 determining a migration timeline for the key-establishment scheme. The cryptographic 336 algorithm used for authentication may be transitioned at a different time, and for that the 337 considerations in Sec. 3.1.2 apply.\n\n338 3.1.4. Email and Document Signing and Encryption 339 Email and document signing employ digital signatures to verify the authenticity and integrity of 340 electronic communications and documents. Common algorithms like RSA and ECDSA are widely 341 used to create a cryptographic binding between the content and the sender’s identity, ensuring 342 that the message has not been altered and that it originates from a legitimate source. 343 Secure/Multipurpose Internet Mail Extensions (S/MIME) is a standard for public-key encryption 344 and the signing of MIME data. It provides end-to-end encryption and authentication for email 345 and file exchanges to ensure that only intended recipients can access the content. As with other 346 applications providing data confidentiality, email encryption is subject to “harvest now, decrypt 347 later.”", "char_len": 3975, "approx_tokens": 993}
{"chunk_id": "NIST.IR.8547.ipd::c00010", "doc_id": "NIST.IR.8547.ipd", "start_page": 15, "end_page": 16, "text": "41 used to create a cryptographic binding between the content and the sender’s identity, ensuring 342 that the message has not been altered and that it originates from a legitimate source. 343 Secure/Multipurpose Internet Mail Extensions (S/MIME) is a standard for public-key encryption 344 and the signing of MIME data. It provides end-to-end encryption and authentication for email 345 and file exchanges to ensure that only intended recipients can access the content. As with other 346 applications providing data confidentiality, email encryption is subject to “harvest now, decrypt 347 later.”\n\n348 3.2. PQC-Classical Hybrid Protocols 349 The migration to post-quantum cryptography may initially include hybrid solutions that 350 incorporate the use of quantum-resistant and quantum-vulnerable algorithms when 351 establishing cryptographic keys or generating digital signatures. These hybrid solutions are 352 typically designed to remain secure if at least one of the component algorithms is secure.\n\n353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures.\n\n378 3.2.1. Hybrid Key-Establishment Techniques 379 A hybrid key-establishment mode is defined here to be a key establishment scheme that is a 380 combination of two or more components that are themselves cryptographic key-establishment 381 schemes. The hybrid key-establishment scheme becomes a composite of these component 382 schemes. 383 NIST currently allows a generic composite key-establishment technique described in SP 800-56C 384 [SP80056C]. Assume that the value Z is a shared secret that was generated as specified by SP 385 800-56A or 800-56B and that a shared secret T is generated or distributed through other 386 schemes.", "char_len": 3834, "approx_tokens": 958}
{"chunk_id": "NIST.IR.8547.ipd::c00011", "doc_id": "NIST.IR.8547.ipd", "start_page": 16, "end_page": 18, "text": "echniques 379 A hybrid key-establishment mode is defined here to be a key establishment scheme that is a 380 combination of two or more components that are themselves cryptographic key-establishment 381 schemes. The hybrid key-establishment scheme becomes a composite of these component 382 schemes. 383 NIST currently allows a generic composite key-establishment technique described in SP 800-56C 384 [SP80056C]. Assume that the value Z is a shared secret that was generated as specified by SP 385 800-56A or 800-56B and that a shared secret T is generated or distributed through other 386 schemes. The value Z’=Z||T may then be treated as a shared secret and any of the key 387 derivation methods given in SP 800-56C may be applied to Z’ to derive secret keying material. 388 NIST intends to update SP 800-56C so that the value Z may be generated as specified by any 389 current and future NIST key-establishment standards. This will include SP 800-56A, SP 800-56B, 390 FIPS 203, and any additional post-quantum key-establishment standards. The desired property 391 of hybrid techniques is that derived keys remain secure if at least one of the component 392 schemes is secure. Security properties can be complex, and for composite key establishment\n\n393 schemes they will need to be analyzed on a case-by-case basis with the requirements of the 394 application in mind. NIST intends to offer guidance on various key combiners in the forthcoming 395 SP 800-227, Recommendations for Key Encapsulation Mechanisms. 396 Additionally, the output of the key-establishment scheme specified in FIPS 203 is a shared 397 secret key which is a shared secret that does not require further key derivation. NIST 398 emphasizes that any shared secret key generated as specified in FIPS 203 may be used as the 399 value Z in the generic composite mode described in SP 800-56C. These same properties will 400 apply to any future FIPS which standardize KEMs.\n\n401 3.2.2. Hybrid Digital Signature Techniques 402 Common techniques for hybrid digital signatures involve the use of dual signatures, which 403 consist of two or more signatures on a common message. It may also be known as a hybrid 404 signature or composite signature. The verification of the dual signature requires all of the 405 component signatures to be successfully verified, such as by creating a single logical composite 406 signature from two or more component signature algorithms. 407 Dual signatures could be used to sign user data (e.g., a document or e-mail) or digital 408 certificates that contain references to user key pairs within a PKI. Existing NIST standards and 409 guidelines accommodate their use provided that at least one component digital signature 410 algorithm is NIST-approved. 411 NIST leaves the decision to each specific application as to whether it can afford the 412 implementation cost, performance reduction, and engineering complexity (including proper 413 and independent security reviews) of a hybrid mode for key establishment or the use of dual 414 signatures. To assist external parties that desire such a mechanism, NIST will accommodate the 415 use of a hybrid key-establishment mode and dual signatures in FIPS 140 validation when 416 suitably combined with a NIST-approved scheme.\n\n417 4. Towards a PQC Standards Transition Timeline 418 NIST’s cryptography standards provide comprehensive guidance on a broad spectrum of 419 cryptographic mechanisms that are essential for securing sensitive information across both 420 federal and nonfederal systems. These standards cover fundamental areas that are crucial for 421 ensuring the confidentiality, integrity, and authenticity of data, such as encryption algorithms, 422 digital signatures, hash functions, key establishment, and random number generation. 423 Additionally, NIST’s standards define key-management practices and offer frameworks for 424 securely generating, storing, distributing, and destroying cryptographic keys.", "char_len": 3972, "approx_tokens": 993}
{"chunk_id": "NIST.IR.8547.ipd::c00012", "doc_id": "NIST.IR.8547.ipd", "start_page": 18, "end_page": 19, "text": "rehensive guidance on a broad spectrum of 419 cryptographic mechanisms that are essential for securing sensitive information across both 420 federal and nonfederal systems. These standards cover fundamental areas that are crucial for 421 ensuring the confidentiality, integrity, and authenticity of data, such as encryption algorithms, 422 digital signatures, hash functions, key establishment, and random number generation. 423 Additionally, NIST’s standards define key-management practices and offer frameworks for 424 securely generating, storing, distributing, and destroying cryptographic keys. 425 Beyond individual algorithms, NIST standards provide guidance on cryptographic protocols that 426 secure communications, such as the TLS protocol, which protects internet data exchanges. They 427 also specify requirements for cryptographic modules through the CMVP to ensure that 428 implementations meet stringent security standards. NIST has also developed PQC standards to 429 safeguard systems against future quantum attacks. Through collaboration with industry, 430 academia, and other stakeholders, NIST continually updates its cryptographic standards to 431 address evolving security threats and technological advances. 432 National Security Memorandum 10 (NSM-10) establishes the year 2035 as the primary target 433 for completing the migration to PQC across Federal systems [NSM10]: 434 “Any digital system that uses existing public standards for public‐key cryptography, or 435 that is planning to transition to such cryptography, could be vulnerable to an attack by a 436 Cryptographically Relevant Quantum Computer (CRQC). To mitigate this risk, the United 437 States must prioritize the timely and equitable transition of cryptographic systems to 438 quantum-resistant cryptography, with the goal of mitigating as much of the quantum 439 risk as is feasible by 2035.” 440 This date reflects the urgency of transitioning to cryptographic methods that can withstand 441 future quantum threats. However, it is important to recognize that migration timelines may 442 vary based on the specific use case or application. Some systems, particularly those with long- 443 term confidentiality needs or more complex cryptographic infrastructures, may require earlier 444 transitions, while others may adopt PQC at a slower pace due to legacy constraints or lower risk 445 profiles. Flexibility in migration planning is essential to balance the urgency of securing critical 446 systems with the practical challenges that different sectors face during this transition. NIST will 447 work to ensure that these varying timelines are acknowledged and supported while maintaining 448 the overall goal of achieving widespread PQC adoption by 2035.\n\n449 4.1. NIST Cryptographic Algorithm Standards and Guidelines 450 SP 800-131A [SP800131A] [SP800131A] describes the transitions associated with the use of 451 cryptography by Federal Government agencies to protect controlled unclassified information. 452 The document addresses the use of algorithms and key lengths specified in FIPS and NIST SPs. 453 During the transition to post-quantum cryptography, NIST will revise SP 800-131A with more 454 detailed guidelines and schedules.\n\n455 The terms “acceptable,” “deprecated, “disallowed,” and “legacy use” are used throughout SP 456 800-131A to indicate the approval status of an algorithm: 457 • Acceptable means that the algorithm and key length/ strength in a FIPS or SP are 458 approved for use in accordance with any associated guidance. 459 • Deprecated means that the algorithm and key length/strength may be used, but there is 460 some security risk. The data owner must examine this risk potential and decide whether 461 to continue to use a deprecated algorithm or key length. 462 • Disallowed means that the algorithm, key length/strength, parameter set, or scheme is 463 no longer allowed for the stated purpose.", "char_len": 3923, "approx_tokens": 980}
{"chunk_id": "NIST.IR.8547.ipd::c00013", "doc_id": "NIST.IR.8547.ipd", "start_page": 19, "end_page": 20, "text": "SP 456 800-131A to indicate the approval status of an algorithm: 457 • Acceptable means that the algorithm and key length/ strength in a FIPS or SP are 458 approved for use in accordance with any associated guidance. 459 • Deprecated means that the algorithm and key length/strength may be used, but there is 460 some security risk. The data owner must examine this risk potential and decide whether 461 to continue to use a deprecated algorithm or key length. 462 • Disallowed means that the algorithm, key length/strength, parameter set, or scheme is 463 no longer allowed for the stated purpose. 464 • Legacy use means that the algorithm, scheme, or parameter set may only be used to 465 process already protected information (e.g., to decrypt ciphertext data or to verify a 466 digital signature). 468 Transition schedules are primarily driven by the level of cryptographic protection that a given 469 algorithm and associated parameter set can provide, which is described as a rough measure 470 known as security strength. Historically, the security strength that an algorithm could provide 471 was defined in terms of the amount of work (i.e., the number of operations) that is required to 472 break the algorithm (i.e., an algorithm has s bits of security strength if breaking the algorithm 473 requires 2s operations of some kind, where s = 112, 128, 192, or 256). However, there are 474 significant uncertainties in estimating the security strengths of post-quantum cryptosystems 475 given the difficulty of accurately predicting the performance characteristics of future quantum 476 computers, such as their cost, speed, and memory size. 477 While NIST guidelines continue to use bit-length security strengths to describe the level of 478 protection offered by an algorithm and parameter set against attacks by classical computers, 479 post-quantum security is described using a collection of broad security categories. Each 480 category is defined by a comparatively easy-to-analyze reference primitive, whose security 481 serves as a floor for a wide variety of metrics that are deemed potentially relevant to practical 482 security. NIST based its classification on the range of security strengths offered by the existing 483 standards in symmetric cryptography. Table 1 provides a summary of these security categories. 484 Table 1: Post-Quantum Security Categories Security Attack Type Example Category 1 Key search on a block cipher with a 128-bit key AES-128 2 Collision search on a 256-bit hash function SHA-256 3 Key search on a block cipher with a 192-bit key AES-192 4 Collision search on a 384-bit hash function SHA3-384 5 Key search on a block cipher with a 256-bit key AES-256\n\n485 4.1.1. Digital Signatures 486 Table 2 lists currently approved quantum-vulnerable digital signature algorithm standards. 488 Table 2: Quantum-vulnerable digital signature algorithms\n\nDigital Signature Parameters Transition Algorithm Family\n\nECDSA 112 bits of security strength Deprecated after 2030 [FIPS186] Disallowed after 2035 ≥ 128 bits of security strength Disallowed after 2035 EdDSA ≥ 128 bits of security strength Disallowed after 2035 [FIPS186]\n\nRSA 112 bits of security strength Deprecated after 2030 [FIPS186] Disallowed after 2035 ≥ 128 bits of security strength Disallowed after 2035\n\n491 NIST’s long-term cryptographic algorithm transition plans are outlined in SP 800-57pt1 (Part 1) 492 [SP80057]. These guidelines had projected that NIST would disallow public-key schemes that 493 provide 112 bits of security on January 1, 2031. However, based on the need to migrate to 494 quantum-resistant algorithms during this timeframe, NIST intends to instead deprecate classical 495 digital signatures at the 112-bit security level. Organizations may continue using these 496 algorithms and parameter sets as they migrate to the post-quantum signatures identified in 497 Table 3.\n\n499 Table 3. Post-quantum digital signature algorithms", "char_len": 3949, "approx_tokens": 987}
{"chunk_id": "NIST.IR.8547.ipd::c00014", "doc_id": "NIST.IR.8547.ipd", "start_page": 20, "end_page": 22, "text": "ansition plans are outlined in SP 800-57pt1 (Part 1) 492 [SP80057]. These guidelines had projected that NIST would disallow public-key schemes that 493 provide 112 bits of security on January 1, 2031. However, based on the need to migrate to 494 quantum-resistant algorithms during this timeframe, NIST intends to instead deprecate classical 495 digital signatures at the 112-bit security level. Organizations may continue using these 496 algorithms and parameter sets as they migrate to the post-quantum signatures identified in 497 Table 3.\n\n499 Table 3. Post-quantum digital signature algorithms\n\nDigital Signature Parameter Sets Security Security Algorithm Family Strength Category ML-DSA ML-DSA-44 128 bits 2 [FIPS204] ML-DSA-65 192 bits 3\n\nML-DSA-87 256 bits 5\n\nDigital Signature Parameter Sets Security Security Algorithm Family Strength Category SLH-DSA SLH-DSA-SHA2-128[s/f] 128 bits 1 [FIPS205] SLH-DSA-SHAKE-128[s/f] SLH-DSA-SHA2-192[s/f] 192 bits 3 SLH-DSA-SHAKE-192[s/f] SLH-DSA-SHA2-256[s/f] 256 bits 5 SLH-DSA-SHAKE-256[s/f] LMS, HSS With SHA-256/192 192 bits 3 [SP800208] With SHAKE256/192 With SHA-256 256 bits 5 With SHAKE256 XMSS, XMSSMT With SHA-256/192 192 bits 3 [SP800208] With SHAKE256/192 With SHA-256 256 bits 5 With SHAKE256\n\n501 4.1.2. Key Establishment 502 Table 4 lists currently approved quantum-vulnerable key-establishment. 503 Table 4: Quantum-vulnerable key-establishment schemes\n\nKey Establishment Parameters Transition Scheme\n\nFinite Field 112 bits of security strength Deprecated after 2030 DH and MQV Disallowed after 2035 [SP80056A] ≥ 128 bits of security strength Disallowed after 2035\n\nElliptic Curve 112 bits of security strength Deprecated after 2030 DH and MQC Disallowed after 2035 [SP80056A] ≥ 128 bits of security strength Disallowed after 2035\n\nRSA 112 bits of security strength Deprecated after 2030 [SP80056B] Disallowed after 2035 ≥ 128 bits of security strength Disallowed after 2035\n\n505 Similar to the transition for digital signature algorithms, NIST intends to instead deprecate 506 rather than fully disallow classical key-establishment schemes at the 112-bit security level. 507 Organizations may continue using these algorithms and parameter sets as they migrate to ML- 508 KEM or other approved quantum-resistant techniques. However, in order to mitigate the risk of 509 “harvest now, decrypt later” attacks on network communications, application-specific 510 guidance, as described in Sec. 4.2, may require or recommend migration to quantum-resistant 511 key establishment schemes before the classical schemes are generally disallowed. 512 Table 5 lists current quantum-resistant key establishment schemes. At this time, ML-KEM is the 513 only approved post-quantum key-establishment scheme based on public key cryptography. 514 Additional algorithms are still being considered as part of the fourth round of the NIST PQC 515 Standardization process. NIST expects to select one or more alternatives to ML-KEM in the 516 future. 517 Table 5: Post-quantum key-establishment schemes\n\nKey Establishment Scheme Parameter Sets Security Strength Security Category ML-KEM ML-KEM-512 128 bits 1 [FIPS203] ML-DSA-768 192 bits 3\n\nML-DSA-1024 256 bits 5\n\n519 4.1.3. Symmetric Cryptography 520 NIST’s existing standards in symmetric cryptography — including hash functions, XOFs, block 521 ciphers, KDFs, and DRBGs — are significantly less vulnerable to known quantum attacks than 522 the public-key cryptography standards in SP 800-56A, SP 800-56B, and FIPS 186. In particular, all 523 NIST-approved symmetric primitives that provide at least 128 bits of classical security are 524 believed to meet the requirements of at least Category 1 security within the system of five 525 security strength categories for evaluating parameter sets in the NIST PQC standardization 526 process (see Table 1). NIST has a few symmetric cryptography standards at the 112-bit security 527 level, which will be disallowed in 2030.", "char_len": 3962, "approx_tokens": 990}
{"chunk_id": "NIST.IR.8547.ipd::c00015", "doc_id": "NIST.IR.8547.ipd", "start_page": 22, "end_page": 24, "text": "— are significantly less vulnerable to known quantum attacks than 522 the public-key cryptography standards in SP 800-56A, SP 800-56B, and FIPS 186. In particular, all 523 NIST-approved symmetric primitives that provide at least 128 bits of classical security are 524 believed to meet the requirements of at least Category 1 security within the system of five 525 security strength categories for evaluating parameter sets in the NIST PQC standardization 526 process (see Table 1). NIST has a few symmetric cryptography standards at the 112-bit security 527 level, which will be disallowed in 2030. Applications should move away from these when 528 transitioning to post-quantum cryptography. 529 Table 6: Block ciphers\n\nBlock Cipher Parameter Sets Security Security Strength Category\n\nAES AES-128 128 bits 1 [FIPS197] AES-192 192 bits 3\n\nAES-256 256 bits 5\n\n531 Table 7: Hash functions and XOFs\n\nHash/XOF Variants Collision Collision Preimage Preimage Algorithm Security Security Security Security Family Strength Category Strength Category SHA-1 SHA-1 80 bits < 1 160 bits 1 [FIPS180] SHA-2 SHA-224 112 bits < 1 224 bits 3 [FIPS180] SHA-512/224 SHA-256 128 bits 2 256 bits 5 SHA-512/256 SHA-384 192 bits 4 384 bits 5\n\nSHA-512 256 bits 5 512 bits 5\n\nSHA-3 SHA3-224 112 bits < 1 224 bits 3 [FIPS202] SHA3-256 128 bits 2 256 bits 5\n\nSHAKE128 128 bits 2 128 bits 2\n\nSHA3-384 192 bits 4 384 bits 5\n\nSHA3-512 256 bits 5 512 bits 5\n\nSHAKE256 256 bits 5 512 bits 5\n\n533 4.2. Application-Specific Standards and Guidelines 534 NIST develops and maintains standards and guidelines addressing cryptography used in certain 535 security technologies, protocols, and systems. For example, FIPS 201-3 and its supporting 536 technical guidelines in NIST Special Publications specify the Personal Identity Verification 537 standard, including security and interoperability requirements for PKI-based credentials used to 538 authenticate federal employees and contractors. Other Special Publications provide guidance 539 on the configuration and use of cryptographic technologies, such as NIST SP 800-52 Revision 2 540 on the use of TLS servers and clients. These standards and guidelines are regularly updated to 541 address changes to underlying standards and technologies as well as new threats. 542 Throughout the migration to PQC, NIST will revise its documents to provide more detailed 543 guidelines for deprecating quantum-vulnerable algorithms, tailored to relevant applications. 544 While NIST’s cryptographic algorithm standards may continue to specify quantum-vulnerable\n\n545 techniques until 2035 and generally allow their use, these application-specific standards and 546 guidelines may specify earlier transitions for certain cryptographic algorithms, techniques, and 547 protocols used within these applications. These guidelines will be developed based on the 548 expected impact that a cryptographically relevant quantum computer would have on these 549 applications as well as the level of support for PQC in the relevant standards, products, and 550 services. NIST expects to prioritize the migration to quantum-resistant key-establishment 551 schemes within these updates to protect against “harvest now, decrypt later” attacks, 552 particularly in interactive protocols like TLS and IKE. 553 NIST will also coordinate with standards-developing organizations and industry to ensure that 554 critical security protocols and technologies are updated to support PQC in a timely manner, 555 recognizing that different application areas will have different risks, security needs, and 556 adoption challenges.", "char_len": 3607, "approx_tokens": 901}
{"chunk_id": "NIST.IR.8547.ipd::c00016", "doc_id": "NIST.IR.8547.ipd", "start_page": 24, "end_page": 25, "text": "n the relevant standards, products, and 550 services. NIST expects to prioritize the migration to quantum-resistant key-establishment 551 schemes within these updates to protect against “harvest now, decrypt later” attacks, 552 particularly in interactive protocols like TLS and IKE. 553 NIST will also coordinate with standards-developing organizations and industry to ensure that 554 critical security protocols and technologies are updated to support PQC in a timely manner, 555 recognizing that different application areas will have different risks, security needs, and 556 adoption challenges.\n\n558 References 559 [FIPS140] National Institute of Standards and Technology (2019) Security Requirements 560 for Cryptographic Modules. (Department of Commerce, Washington, DC), 561 Federal Information Processing Standards Publication (FIPS) FIPS 140-3. 562 https://doi.org/10.6028/NIST.FIPS.140-3 563 [FIPS180] National Institute of Standards and Technology (2015) Secure Hash Standard 564 (SHS). (Department of Commerce, Washington, DC), Federal Information 565 Processing Standards Publication (FIPS) FIPS 180-4. 566 https://doi.org/10.6028/NIST.FIPS.180-4 567 [FIPS186] National Institute of Standards and Technology. Digital signature standard 568 (DSS). (Department of Commerce, Washington, DC), Federal Information 569 Processing Standards Publication (FIPS) FIPS 186-5. 570 https://doi.org/10.6028/NIST.FIPS.186-5 571 [FIPS197] National Institute of Standards and Technology (2001) Advanced Encryption 572 Standard (AES). (Department of Commerce, Washington, DC), Federal 573 Information Processing Standards Publication (FIPS) FIPS 197. 574 https://doi.org/10.6028/NIST.FIPS.197 575 [FIPS198] National Institute of Standards and Technology (2008) The Keyed-Hash 576 Message Authentication Code (HMAC). (Department of Commerce, 577 Washington, DC), Federal Information Processing Standards Publication (FIPS) 578 FIPS 198-1. https://doi.org/10.6028/NIST.FIPS.198-1 579 [FIPS202] National Institute of Standards and Technology (2015) SHA-3 Standard: 580 Permutation-Based Hash and Extendable-Output Functions. (Department of 581 Commerce, Washington, DC), Federal Information Processing Standards 582 Publication (FIPS) FIPS 202. https://doi.org/10.6028/NIST.FIPS.202 583 [FIPS203] National Institute of Standards and Technology (2024) Module-Lattice-Based 584 Key-Encapsulation Mechanism Standard. (Department of Commerce, 585 Washington, DC), Federal Information Processing Standards Publication (FIPS) 586 FIPS 203. https://doi.org/10.6028/NIST.FIPS.203 587 [FIPS204] National Institute of Standards and Technology (2024) Module-Lattice-Based 588 Digital Signature Standard. (Department of Commerce, Washington, DC), 589 Federal Information Processing Standards Publication (FIPS) FIPS 204. 590 https://doi.org/10.6028/NIST.FIPS.204 591 [FIPS205] National Institute of Standards and Technology (2024) Stateless Hash-Based 592 Digital Signature Standard. (Department of Commerce, Washington, DC), 593 Federal Information Processing Standards Publication (FIPS) FIPS 205. 594 https://doi.org/10.6028/NIST.FIPS.205 595 [NISTIR8528] Alagic G, Bros M, Ciadoux P, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, 596 Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Silberg H, Smith- 597 Tone D, Waller N (2024) Status Report on the First Round of the Additional 598 Digital Signature Schemes for the NIST Post-Quantum Cryptography 599 Standardization Process. (National Institute of Standards and Technology, 600 Gaithersburg, MD), NIST IR 8528.", "char_len": 3563, "approx_tokens": 890}
{"chunk_id": "NIST.IR.8547.ipd::c00017", "doc_id": "NIST.IR.8547.ipd", "start_page": 25, "end_page": 26, "text": "Department of Commerce, Washington, DC), 593 Federal Information Processing Standards Publication (FIPS) FIPS 205. 594 https://doi.org/10.6028/NIST.FIPS.205 595 [NISTIR8528] Alagic G, Bros M, Ciadoux P, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, 596 Liu YK, Miller C, Moody D, Peralta R, Perlner R, Robinson A, Silberg H, Smith- 597 Tone D, Waller N (2024) Status Report on the First Round of the Additional 598 Digital Signature Schemes for the NIST Post-Quantum Cryptography 599 Standardization Process. (National Institute of Standards and Technology, 600 Gaithersburg, MD), NIST IR 8528.\n\n601 https://doi.org/10.6028/NIST.IR.8528 602 [NSM10] Biden J (2022) National Security Memorandum on Promoting United States 603 Leadership in Quantum Computing While Mitigating Risks to Vulnerable 604 Cryptographic Systems. (The White House, Washington, DC), National Security 605 Memorandum 10, May 4 2022. Available at 606 https://www.whitehouse.gov/briefing-room/statements- 607 releases/2022/05/04/national-security-memorandum-on-promoting-united- 608 states-leadership-in-quantum-computing-while-mitigating-risks-to-vulnerable- 609 cryptographic-systems/ 610 [SP80056A] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R (2018) Recommendation for 611 Pair-Wise Key-Establishment Using Schemes Using Discrete Logarithm 612 Cryptography. (National Institute of Standards and Technology, Gaithersburg, 613 MD), NIST Special Publication (SP) NIST SP 800-56Ar3. 614 https://doi.org/10.6028/NIST.SP.800-56Ar3 615 [SP80056B] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R, Simon Scott (2019) 616 Recommendation for Pair-Wise Key-Establishment Schemes Integer 617 Factorization Cryptography. (National Institute of Standards and Technology, 618 Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-56Br2. 619 https://doi.org/10.6028/NIST.SP.800-56Br2 620 [SP80056C] Barker E, Chen L, Davis R (2020) Recommendation for Key-Derivation Methods 621 in Key-Establishment Schemes. (National Institute of Standards and 622 Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800- 623 56Cr2. https://doi.org/10.6028/NIST.SP.800-56Cr2 624 [SP80057] Barker EB, Barker WC (2020) Recommendation for Key Management: Part 1 – 625 General. (National Institute of Standards and Technology, Gaithersburg, MD), 626 NIST Special Publication (SP) NIST SP 800-57pt1r5. 627 https://doi.org/10.6028/NIST.SP.800-57pt1r5 628 [SP800131A] Barker E, Roginsky A (2019) Transitions: Recommendation for Transitioning the 629 Use of Cryptographic Algorithms and Key Lengths. (National Institute of 630 Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 631 NIST SP 800-131Ar2. https://doi.org/10.6028/NIST.SP.800-131Ar2 632 [SP800185] Kelsey JM, Chang S-jH, Perlner RA (2016) SHA-3 Derived Functions: cSHAKE, 633 KMAC, TupleHash, and ParallelHash. (National Institute of Standards and 634 Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-185. 635 https://doi.org/10.6028/NIST.SP.800-185 636 [SP800186] Chen L, Moody D, Regenscheid A, Robinson A, Randall K (2023) 637 Recommendations for Discrete Logarithm-based Cryptography: Elliptic Curve 638 Domain Parameters (National Institute of Standards and Technology, 639 Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-186. 640 https://doi.org/10.6028/NIST.SP.800-186 641 [SP800208] Cooper DA, Apon DC, Dang QH, Davidson MS, Dworkin MJ, Miller CA (2020) 642 Recommendation for Stateful Hash-Based Signature Schemes, (National 643 Institute of Standards and Technology, Gaithersburg, MD), NIST Special 644 Publication (SP) NIST SP 800-208. https://doi.org/10.6028/NIST.SP.800-208", "char_len": 3678, "approx_tokens": 919}
{"chunk_id": "NIST.IR.8547.ipd::c00018", "doc_id": "NIST.IR.8547.ipd", "start_page": 26, "end_page": 28, "text": "nson A, Randall K (2023) 637 Recommendations for Discrete Logarithm-based Cryptography: Elliptic Curve 638 Domain Parameters (National Institute of Standards and Technology, 639 Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-186. 640 https://doi.org/10.6028/NIST.SP.800-186 641 [SP800208] Cooper DA, Apon DC, Dang QH, Davidson MS, Dworkin MJ, Miller CA (2020) 642 Recommendation for Stateful Hash-Based Signature Schemes, (National 643 Institute of Standards and Technology, Gaithersburg, MD), NIST Special 644 Publication (SP) NIST SP 800-208. https://doi.org/10.6028/NIST.SP.800-208\n\n645 Appendix A. Glossary 646 acceptable 647 Approved for use. An allowed algorithm and key length/strength in a FIPS or SP is approved for use in accordance 648 with any associated guidance. 649 approved 650 FIPS-approved and/or NIST-recommended. An algorithm or technique that is either 1) specified in a FIPS or NIST 651 recommendation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security 652 functions. 653 asymmetric (cryptography) 654 Cryptography that uses two separate keys to exchange data — one to encrypt or digitally sign the data and one to 655 decrypt the data or verify the digital signature. Also known as public-key cryptography. 656 block cipher 657 An invertible symmetric-key cryptographic algorithm that transforms one block of information at a time using a 658 cryptographic key. The resulting output block is the same length as the input block. 659 certificate 660 A set of data that uniquely identifies a public key that has a corresponding private key and an owner that is 661 authorized to use the key pair. The certificate contains the owner’s public key and possibly other information and 662 is digitally signed by a certification authority (i.e., a trusted party), thereby binding the public key to the owner. 663 cryptographic module 664 The set of hardware, software, and/or firmware that implements approved cryptographic functions (including key 665 generation) that are contained within the cryptographic boundary of the module. 666 cryptographically relevant quantum computer 667 A quantum computer which is capable of actually attacking real world cryptographic systems that would be 668 infeasible to attack with a normal computer. 669 deprecated 670 The algorithm and key length may be used, but the user must accept some security risk. The term is used when 671 discussing the key lengths or algorithms that may be used to apply cryptographic protection. 672 digital certificate 673 See certificate. 674 digital signature 675 The result of a cryptographic transformation of data that, when properly implemented, provides a mechanism to 676 verify origin authenticity and data integrity and to enforce signatory non-repudiation. 677 disallowed 678 The algorithm or key length is no longer allowed for applying cryptographic protection. 679 dual signature 680 A dual signature consists of two (or more) signatures on a common message. It may also be known as a hybrid 681 signature or composite signature. 682 encryption 683 The process of transforming plaintext into ciphertext using a cryptographic algorithm and key. 684 eXtendable-Output Function (XOF) 685 A function on bit strings in which the output can be extended to any desired length.\n\n687 forward secrecy 688 Providing protection against the use of compromised old keys that could be used to attack the newer derived keys 689 still in use for integrity and confidentiality protection. 690 hash function 691 A function on bit strings in which the length of the output is fixed. Approved hash functions (such as those 692 specified in FIPS 180 and FIPS 202) are designed to satisfy the following properties: 693 1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 694 2. (Collision-resistant) It is computationally infeasible to find any two distinct inputs that map to the same 695 output.", "char_len": 3987, "approx_tokens": 996}
{"chunk_id": "NIST.IR.8547.ipd::c00019", "doc_id": "NIST.IR.8547.ipd", "start_page": 28, "end_page": 29, "text": "e of compromised old keys that could be used to attack the newer derived keys 689 still in use for integrity and confidentiality protection. 690 hash function 691 A function on bit strings in which the length of the output is fixed. Approved hash functions (such as those 692 specified in FIPS 180 and FIPS 202) are designed to satisfy the following properties: 693 1. (One-way) It is computationally infeasible to find any input that maps to any new pre-specified output. 694 2. (Collision-resistant) It is computationally infeasible to find any two distinct inputs that map to the same 695 output. 696 KEM combiner 697 A function that takes in two or more shared secret keys and returns a combined shared secret key. 698 key agreement 699 A (pair-wise) key-establishment procedure where the resultant secret keying material is a function of information 700 contributed by two participants so that no party can predetermine the value of the secret keying material 701 independently from the contributions of the other party. Contrast with key-transport. 702 key derivation 703 The process of deriving a key in a non-reversible manner from shared information, some of which is secret. 704 key encapsulation mechanism (KEM) 705 A set of three cryptographic algorithms (KeyGen, Encaps, and Decaps) that can be used by two parties to establish 706 a shared secret key over a public channel. 707 key establishment 708 A procedure that results in establishing secret keying material that is shared among different parties. 709 key transport 710 A (pair-wise) key-establishment procedure whereby one party (the sender) selects a value for the secret keying 711 material and then securely distributes that value to another party (the receiver). Contrast with key agreement. 712 key wrapping 713 A method of protecting secret keying material (along with associated integrity information) that provides both 714 confidentiality and integrity protection when using symmetric-key algorithms. 715 legacy use 716 The algorithm or key length may be used only to process already protected information (e.g., to decrypt ciphertext 717 data or to verify a digital signature). 718 message authentication code (MAC) 719 A cryptographic checksum on data that uses a symmetric key to detect both accidental and intentional 720 modifications of data. 721 mode of operation 722 An algorithm for the cryptographic transformation of data that features a symmetric key block cipher. 723 public key infrastructure (PKI) 724 A framework that is established to issue, maintain and revoke public key certificates. 725 public key cryptography 726 Cryptography that uses two separate keys to exchange data — one to encrypt or digitally sign the data and one to 727 decrypt the data or verify the digital signature. Also known as asymmetric cryptography.\n\n728 security category 729 A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST. 730 security strength 731 A number associated with the amount of work (i.e., the number of operations) that is required to break a 732 cryptographic algorithm or system. 733 shared secret 734 A secret value that has been computed during a key-establishment scheme, is known by both participants, and is 735 used as input to a key-derivation method to produce keying material. 736 shared secret key 737 A shared secret that can be used directly as a cryptographic key in symmetric-key cryptography. It does not require 738 additional key derivation. The shared secret key must be kept private and must be destroyed when no longer 739 needed. 740 symmetric key cryptography 741 A cryptographic algorithm that uses the same secret key for its operation and, if applicable, for reversing the 742 effects of the operation (e.g., an AES key for encryption and decryption).", "char_len": 3827, "approx_tokens": 956}
{"chunk_id": "NIST.SP.800-227::c00000", "doc_id": "NIST.SP.800-227", "start_page": 1, "end_page": 3, "text": "NIST Special Publication 800\n\nRecommendations for Key-Encapsulation Mechanisms\n\nGorjan Alagic Elaine Barker Lily Chen Dustin Moody Angela Robinson Hamilton Silberg Noah Waller\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-227\n\nNST NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY Check for U.S. DEPARTMENT OF COMMERCE updates\n\nNIST Special Publication 800\n\nRecommendations for Key-Encapsulation Mechanisms\n\nGorjan Alagic Elaine Barker Lily Chen Dustin Moody Angela Robinson Hamilton Silberg Noah Waller Computer Security Division Information Technology Laboratory\n\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-227\n\nSeptember 2025\n\nU.S. Department of Commerce Howard Lutnick, Secretary National Institute of Standards and Technology Craig Burkhardt, Acting Under Secretary for Standards and Technology and Acting NIST Director\n\nCertain commercial equipment, instruments, software, or materials, commercial or non-commercial, are identified in this paper in order to specify the experimental procedure adequately. Such identification does not imply recommendation or endorsement of any product or service by NIST, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose. There may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST. Organizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at https://csrc.nist.gov/publications.\n\nAuthority This publication has been developed by NIST in accordance with its statutory responsibilities under the Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems, but such standards and guidelines shall not apply to national security systems without the express approval of appropriate federal officials exercising policy authority over such systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130. Nothing in this publication should be taken to contradict the standards and guidelines made mandatory and binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the OMB, or any other federal official. This publication may be used by nongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. Attribution would, however, be appreciated by NIST.\n\nNIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax\n\nPublication History Approved by the NIST Editorial Review Board on 2025-09-03\n\nHow to cite this NIST Technical Series Publication: Alagic G, Barker EB, Chen L, Moody D, Robinson A, Silberg H, Waller N (2025) Recommendations for Key-Encapsulation Mechanisms. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-227. https://doi.org/10.6028/NIST.SP.800-227", "char_len": 3915, "approx_tokens": 978}
{"chunk_id": "NIST.SP.800-227::c00001", "doc_id": "NIST.SP.800-227", "start_page": 3, "end_page": 7, "text": "States. Attribution would, however, be appreciated by NIST.\n\nNIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax\n\nPublication History Approved by the NIST Editorial Review Board on 2025-09-03\n\nHow to cite this NIST Technical Series Publication: Alagic G, Barker EB, Chen L, Moody D, Robinson A, Silberg H, Waller N (2025) Recommendations for Key-Encapsulation Mechanisms. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-227. https://doi.org/10.6028/NIST.SP.800-227\n\nAuthor ORCID iDs Gorjan Alagic: 0000-0002-0107-6037 Elaine Barker: 0000-0003-0454-0461 Lily Chen: 0000-0003-2726-4279 Dustin Moody: 0000-0002-4868-6684 Angela Robinson: 0000-0002-1209-0379 Hamilton Silberg: 0009-0004-4178-8954 Noah Waller: 0000-0002-6979-9725\n\nContact Information sp800-227-comments@nist.gov\n\nAdditional Information Additional information about this publication is available at https://csrc.nist.gov/pubs/sp/800/227/final, including related content, potential updates, and document history. All comments are subject to release under the Freedom of Information Act (FOIA).\n\nSeptember 2025\n\nAbstract\n\nA key-encapsulation mechanism (KEM) is a set of algorithms that can be used by two parties under certain conditions to securely establish a shared secret key over a public channel. A shared secret key that is established using a KEM can then be used with symmetric-key cryptographic algorithms to perform essential tasks in secure communications, such as encryption and authentication. This document describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner.\n\nKeywords\n\ncryptography; encryption; key-encapsulation mechanism; key establishment; public-key cryptography.\n\nReports on Computer Systems Technology\n\nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology (NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and technical analyses to advance the development and productive use of information technology. ITL’s responsibilities include the development of management, administrative, technical, and physical standards and guidelines for the cost-effective security and privacy of other than national security-related information in federal information systems. The Special Publication 800- series reports on ITL’s research, guidelines, and outreach efforts in information system security, and its collaborative activities with industry, government, and academic organizations.\n\ni\n\nSeptember 2025\n\nPatent Disclosure Notice\n\nNOTICE: ITL has requested that holders of patent claims whose use may be required for compliance with the guidance or requirements of this publication disclose such patent claims to ITL. However, holders of patents are not obligated to respond to ITL calls for patents and ITL has not undertaken a patent search in order to identify which, if any, patents may apply to this publication. As of the date of publication and following call(s) for the identification of patent claims whose use may be required for compliance with the guidance or requirements of this publication, no such patent claims have been identified to ITL. No representation is made or implied by ITL that licenses are not required to avoid patent infringement in the use of this publication.\n\nii\n\nSeptember 2025\n\nTable of Contents", "char_len": 3663, "approx_tokens": 915}
{"chunk_id": "NIST.SP.800-227::c00002", "doc_id": "NIST.SP.800-227", "start_page": 6, "end_page": 8, "text": "s of patents are not obligated to respond to ITL calls for patents and ITL has not undertaken a patent search in order to identify which, if any, patents may apply to this publication. As of the date of publication and following call(s) for the identification of patent claims whose use may be required for compliance with the guidance or requirements of this publication, no such patent claims have been identified to ITL. No representation is made or implied by ITL that licenses are not required to avoid patent infringement in the use of this publication.\n\nii\n\nSeptember 2025\n\nTable of Contents\n\n1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1. Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2. Scope and Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.3. Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2. Overview of Key-Encapsulation Mechanisms . . . . . . . . . . . . . . . . . . . . . 4 2.1. Overview and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2. Basic Definitions and Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.3. Theoretical Security of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 3. Requirements for Secure KEM Implementations . . . . . . . . . . . . . . . . . . . 11 3.1. Compliance With NIST Standards and Validation . . . . . . . . . . . . . . . . 11 3.2. Managing Cryptographic Data . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.3. Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4. Using KEMs Securely in Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 15 4.1. How to Establish a Key With a KEM . . . . . . . . . . . . . . . . . . . . . . . 15 4.2. Conditions for Using KEMs Securely . . . . . . . . . . . . . . . . . . . . . . . 17 4.3. Post Processing of the Shared Secret Key . . . . . . . . . . . . . . . . . . . . 19 4.4. Key Confirmation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.4.1. Creating the MAC Data . . . . . . . . . . . . . . . . . . . . . . . . . . 21 4.4.2. Obtaining the Key-Confirmation Key . . . . . . . . . . . . . . . . . . 21 4.4.3. Key-Confirmation Example . . . . . . . . . . . . . . . . . . . . . . . . 22 4.5. Proof of Possession for KEM Keys . . . . . . . . . . . . . . . . . . . . . . . . 24 4.6. Multi-Algorithm KEMs and PQ/T Hybrids . . . . . . . . . . . . . . . . . . . . 26 4.6.1. Constructing a Composite KEM . . . . . . . . . . . . . . . . . . . . . 27 4.6.2. Approved Key Combiners . . . . . . . . . . . . . . . . . . . . . . . . 28 4.6.3. Security Considerations for Composite Schemes . . . . . . . . . . . 31 5. Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.1. Examples of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.1.1. A KEM From Diffie-Hellman . . . . . . . . . . . . . . . . . . . . . . . 33 5.1.2. A KEM From RSA Secret-Value Encapsulation . . . . . . . . . . . . . 34 5.1.3. ML-KEM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\niii\n\n5.2. Examples of KEM Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 35 5.2.1. KEM-DEM Public-Key Encryption . . . . . . . . . . . . . . . . . . . . 35 5.2.2. Unilateral Authenticated Key Establishment Using a KEM . . . . . . 37 5.2.3. Ephemeral Authenticated Key Establishment . . . . . . . . . . . . . 38 5.2.4. Static-Ephemeral Unilateral Authenticated Key Establishment Using KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 5.2.5. Authenticated Key Establishment Using KEMs . . . . . . . . . . . . . 41 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Appendix A. List of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "char_len": 3987, "approx_tokens": 996}
{"chunk_id": "NIST.SP.800-227::c00003", "doc_id": "NIST.SP.800-227", "start_page": 8, "end_page": 9, "text": ". . . . . . . . 35 5.2.2. Unilateral Authenticated Key Establishment Using a KEM . . . . . . 37 5.2.3. Ephemeral Authenticated Key Establishment . . . . . . . . . . . . . 38 5.2.4. Static-Ephemeral Unilateral Authenticated Key Establishment Using KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 5.2.5. Authenticated Key Establishment Using KEMs . . . . . . . . . . . . . 41 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Appendix A. List of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 Appendix B. Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 Appendix C. Cryptographic Components . . . . . . . . . . . . . . . . . . . . . . . . . 53 C.1. Message Authentication Codes (MACs) . . . . . . . . . . . . . . . . . . . . . 53 C.2. Nonces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 Appendix D. Changes From Draft SP 800-227 . . . . . . . . . . . . . . . . . . . . . . . 56\n\nList of Tables\n\nTable 1. Approved MAC algorithms for key confirmation . . . . . . . . . . . . . . . . 54\n\nList of Figures\n\nFig. 1. Outline of key establishment using a KEM . . . . . . . . . . . . . . . . . . . . 5 Fig. 2. The IND-CPA security experiment for a KEM Π . . . . . . . . . . . . . . . . . 9 Fig. 3. The IND-CCA security experiment for a KEM Π . . . . . . . . . . . . . . . . . 9 Fig. 4. Simple key establishment using a KEM . . . . . . . . . . . . . . . . . . . . . 16 Fig. 5. Key-confirmation example with an ephemeral key pair . . . . . . . . . . . . 23 Fig. 6. KEM PoP between a key-pair owner and CA . . . . . . . . . . . . . . . . . . 25 Fig. 7. Sending a message using the KEM-DEM paradigm . . . . . . . . . . . . . . . 36 Fig. 8. Unilateral authenticated key establishment using a KEM . . . . . . . . . . . 37 Fig. 9. Using a KEM for key establishment with unilateral authentication . . . . . . 39 Fig. 10. Static-ephemeral unilateral authenticated key establishment using KEMs . 40 Fig. 11. Authenticated key establishment using KEMs . . . . . . . . . . . . . . . . . . 42\n\niv\n\n1. Introduction\n\n1.1. Background A key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication. Many widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016, NIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information Processing Standards (FIPS) publication 203 [3]. At the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.", "char_len": 3754, "approx_tokens": 938}
{"chunk_id": "NIST.SP.800-227::c00004", "doc_id": "NIST.SP.800-227", "start_page": 9, "end_page": 10, "text": "key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information Processing Standards (FIPS) publication 203 [3]. At the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose This recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods. This recommendation does not discuss how or when to migrate from quantum-vulnerable key-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such as the specification of ML-KEM in FIPS 203 [3]. This recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is\n\napproved, this SP describes KEMs both generally and with respect to what is approved. Specific requirements will be clearly noted with “shall” and “must” statements.\n\n1.3. Requirements Conforming implementations of approved KEMs are required to satisfy all of the requirements below. Requirements that are testable by a Cryptographic Module Validation Program (CMVP) validation lab are enumerated with the prefix “RS,” and requirements that are not testable by a validation lab are enumerated with the prefix “RM.” Each requirement is directly quoted from the corresponding referenced section. Requirements RS6, RS7, RS8, RS10, and RS11 pertain to key confirmation (Sec. 4.4), which is recommended but not required. The following requirements are testable by a CMVP validation lab (i.e., shall statements): RS1 (Section 3.1) KEM implementations shall comply with a specific NIST FIPS or SP that specifies the algorithms of the relevant KEM. For example, a conforming implemen- tation of ML-KEM shall comply with FIPS 203 [3]. 1 RS2 (Section 3.1) KEM implementations shall follow the guidelines given in FIPS 140-3 [5] and associated implementation guidance. RS3 (Section 3.1) KEM implementations shall use approved components with security strengths that meet or exceed the required strength for each KEM parameter set. RS4 (Section 3.1) Random bits shall be generated using approved techniques, as de- scribed in the latest revisions of SP 800-90A, SP 800-90B, and SP 800-90C [6–8]. RS5 (Section 3.2) Except for random seeds and data that can be easily computed from public information, all intermediate values used in any given KEM algorithm (i.e., KeyGen, Encaps, and Decaps) shall be destroyed before the algorithm terminates. RS6 (Section 4.2) If an application uses an ephemeral key pair, the key pair shall be used for only one execution of key-establishment via a KEM and shall be destroyed as soon as possible after its use. RS7 (Section 4.4.1) When a nonce is used by the decapsulator during key confirmation (as specified herein), a nonce with a bit length that is (at least) equal to the targeted security strength of the KEM key-establishment process shall be used (see Appendix C.2).", "char_len": 3830, "approx_tokens": 957}
{"chunk_id": "NIST.SP.800-227::c00005", "doc_id": "NIST.SP.800-227", "start_page": 10, "end_page": 12, "text": "ediate values used in any given KEM algorithm (i.e., KeyGen, Encaps, and Decaps) shall be destroyed before the algorithm terminates. RS6 (Section 4.2) If an application uses an ephemeral key pair, the key pair shall be used for only one execution of key-establishment via a KEM and shall be destroyed as soon as possible after its use. RS7 (Section 4.4.1) When a nonce is used by the decapsulator during key confirmation (as specified herein), a nonce with a bit length that is (at least) equal to the targeted security strength of the KEM key-establishment process shall be used (see Appendix C.2). RS8 (Section 4.4.1) For key confirmation, the MAC algorithm and key-confirmation key used shall have security strengths that are equal to or greater than the desired se- curity strength of the application. 1The CMVP will perform random input-output tests in an attempt to ascertain whether this requirement is satisfied. Ensuring full functional equivalence to the specification via testing is not possible (see the “must” requirement RM1).\n\nRS9 (Section 4.4.2) The key-confirmation key shall only be used for key confirmation and destroyed after use. RS10 (Appendix C.1) When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (e.g., HMAC, AES-CMAC, KMAC). In addition, AES- GMAC (specified in [9]) is an approved MAC algorithm and may be used. RS11 (Appendix C.1) When a MAC tag is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a MacKey that is determined from a shared secret key. The following requirements are not testable by a CMVP validation lab (i.e., must state- ments): RM1 (Section 3.1). Implementations must correctly implement the mathematical func- tionality of the target KEM. 2 RM2 (Section 4.2) In applications of KEMs, a parameter set with an application-appropriate security strength must be selected (see [10, Section 2.2]). RM3 (Section 4.2) If an encapsulating party obtains the static encapsulation key of another party, it must have assurance of the other party’s ownership of the key before or during the execution of key-establishment. RM4 (Section 4.2) The devices used to execute KEM algorithms and store any sensitive data (e.g., decapsulation keys) must be appropriately secured. RM5 (Section 4.2) The key-establishment process that takes place over the channel used by Alice and Bob must satisfy an application-appropriate notion of integrity.\n\n2The CMVP will perform random input-output tests in an attempt to ascertain whether this requirement is satisfied. Ensuring full functional equivalence to the specification is not possible.\n\n2. Overview of Key-Encapsulation Mechanisms\n\nThis section provides a high-level overview of KEMs, which are collections of mathematical functions (some of which include random inputs) and data that specify parameters. Section 3 describes how to implement a KEM as a collection of computer programs, and Sec. 4 describes how to deploy KEMs in applications.\n\n2.1. Overview and Motivation Modern symmetric-key cryptography provides a wide range of useful functionalities, including secure and highly efficient computation and communication. Before symmetrickey cryptography can be used, the participating parties need to establish a shared secret (i.e., symmetric) key. One approach to establishing such a key is over a public communication channel. Any algorithmic method that establishes a shared secret key over a public channel is called a key-establishment scheme. A general key-establishment scheme can require multiple rounds of communication and involve any number of parties. A KEM is a specific type of key-establishment scheme. Typical key establishment via a KEM involves two parties (here referred to as Alice and Bob) and consists of the following three stages (see Fig. 1): 1. (Key generation) Alice generates a (private) decapsulation key and a (public) encap- sulation key. 2.", "char_len": 3970, "approx_tokens": 992}
{"chunk_id": "NIST.SP.800-227::c00006", "doc_id": "NIST.SP.800-227", "start_page": 12, "end_page": 13, "text": "hing such a key is over a public communication channel. Any algorithmic method that establishes a shared secret key over a public channel is called a key-establishment scheme. A general key-establishment scheme can require multiple rounds of communication and involve any number of parties. A KEM is a specific type of key-establishment scheme. Typical key establishment via a KEM involves two parties (here referred to as Alice and Bob) and consists of the following three stages (see Fig. 1): 1. (Key generation) Alice generates a (private) decapsulation key and a (public) encap- sulation key. 2. (Encapsulation) Bob uses Alice’s encapsulation key to generate a shared secret key and an associated ciphertext. The ciphertext is sent to Alice. 3. (Decapsulation) Alice uses the ciphertext and her decapsulation key to compute an- other copy of the shared secret key.\n\nSecurity of KEMs. When a KEM is used as in Fig. 1, the result should be a shared secret key that is random, unknown to adversaries, and identical for Alice and Bob with high probability. Ensuring that security holds in practice is a complex task that relies on three conditions: 1. Theoretical security: Selecting a KEM that is well-defined, correct, and satisfies an application-appropriate mathematical notion of security (see Sec. 2.2 and 2.3) 2. Implementation security: Implementing the selected KEM in a real-world algorithm (e.g., a collection of routines) in a secure manner (see Sec. 3) 3. Deployment security: Deploying the implemented KEM in a manner that is secure for the relevant application and using the shared secret key in a secure manner (see Sec. 4.2) Each of these three conditions is essential for security. For example, a KEM that is theoretically secure (i.e., satisfies condition 1) but is implemented without side-channel coun-\n\nAlice Bob\n\nKey Generation\n\ndecapsulation key encapsulation key\n\nDecapsulation ciphertext Encapsulation\n\nshared secret key shared secret key (Alice’s copy) (Bob’s copy)\n\nFig. 1. Outline of key establishment using a KEM\n\ntermeasures (i.e., does not satisfy condition 2) or is deployed on a device with physical vulnerabilities (i.e., does not satisfy condition 3) is likely to be insecure in practice.\n\nHistory and development. KEMs were first introduced by Cramer and Shoup [11, 12] as a building block for constructing highly efficient public-key encryption (PKE) schemes. Their approach combines a KEM with a data encryption mechanism (DEM), which is simply a symmetric-key encryption scheme. The KEM is used to generate a shared secret key, while the DEM is used to encrypt an arbitrarily long stream of messages under that key. This is commonly referred to as the KEM/DEM paradigm (see the HPKE example in Sec. 5.2.1). This approach to constructing highly efficient public-key encryption has been the subject of several standards [1, 2, 11, 13–16]. Most recently, KEMs have attracted significant attention due to most of the post-quantum key-establishment candidates in the NIST PQC standardization process being KEMs. This ongoing process has produced one KEM standard so far — ML-KEM in FIPS 203 [3] — with more KEM standards likely to follow.\n\n2.2. Basic Definitions and Examples This section establishes the basic definitions and properties of KEMs. Note that probabilistic algorithms require randomness, while deterministic algorithms do not. Definition 1. A KEM denoted by Π consists of the following four components: 1. Π.ParamSets (parameters): A collection of parameter sets", "char_len": 3511, "approx_tokens": 877}
{"chunk_id": "NIST.SP.800-227::c00007", "doc_id": "NIST.SP.800-227", "start_page": 13, "end_page": 15, "text": "ignificant attention due to most of the post-quantum key-establishment candidates in the NIST PQC standardization process being KEMs. This ongoing process has produced one KEM standard so far — ML-KEM in FIPS 203 [3] — with more KEM standards likely to follow.\n\n2.2. Basic Definitions and Examples This section establishes the basic definitions and properties of KEMs. Note that probabilistic algorithms require randomness, while deterministic algorithms do not. Definition 1. A KEM denoted by Π consists of the following four components: 1. Π.ParamSets (parameters): A collection of parameter sets\n\n2. Π.KeyGen (key-generation algorithm): An efficient probabilistic algorithm that ac- cepts a parameter set p ∈ Π.ParamSets as input and produces an encapsulation key ek and a decapsulation key dk as output 3. Π.Encaps (encapsulation algorithm): An efficient probabilistic algorithm that ac- cepts a parameter set p ∈ Π.ParamSets and an encapsulation key ek as input and produces a shared secret key K and a ciphertext c as output 4. Π.Decaps (decapsulation algorithm): An efficient deterministic algorithm that ac- cepts a parameter set p ∈ Π.ParamSets, a decapsulation key dk, and a ciphertext c as input and produces a shared secret key K′ as output As this section views KEMs purely as mathematical objects, the labels p, ek, dk, c, K, and K′ in Definition 1 are viewed as abstract variables that represent, for example, numbers or bit strings. In implementations, these variables will be represented with concrete data types (see Sec. 3). In general, Definition 1 only requires some very basic properties from the four components that make up a KEM (see Example 1 below). In order to be useful and secure, a KEM should fulfill a number of additional properties. The first such property is correctness of the KEM algorithm. Correctness ensures that, in an ideal setting, the process in Fig. 1 almost always produces the same shared secret key value for both parties. Definition 2. The key-encapsulation correctness experiment for a KEM Π and parameter set p ∈ Π.ParamSets consists of the following three steps: 1. (ek, dk) ← Π.KeyGen(p) (perform key generation) (1) 2. (K, c) ← Π.Encaps(p, ek) (perform encapsulation) (2) 3. K′ ← Π.Decaps(p, dk, c) (perform decapsulation) (3) The KEM Π is correct if, for all p ∈ Π.ParamSets, the correctness experiment for p results in K = K′ with all but negligible probability. Recall that Π.KeyGen and Π.Encaps are probabilistic algorithms. When they are invoked as above (i.e., Π.KeyGen with only a parameter set as input, and Π.Encaps with only a parameter set and encapsulation key as input), it is implied that their randomness is generated internally and uniformly at random. If one wishes to explicitly refer to the randomness used by these algorithms, then the following expressions can be used: Key generation (using randomness r): (ek, dk) ← Π.KeyGen(p; r) (4) Encapsulation (using randomness s): (K, c) ← Π.Encaps(p, ek; s) (5) These expressions can, for example, refer to the process of re-expanding a key pair (ek, dk) by running KeyGen using a stored seed r. The following two simple but instructive examples show abstract KEMs that satisfy Definition 1 and Definition 2.\n\nExample 1: Simple but insecure. As the following example shows, a correct and efficient KEM can still be completely insecure. Define a KEM DONOTUSE as follows: • DONOTUSE.ParamSets: Contains a single, empty parameter set • DONOTUSE.KeyGen: On randomness r, outputs dk := r and ek := r • DONOTUSE.Encaps: On input ek and randomness s, outputs K := s and c := s • DONOTUSE.Decaps: On input dk and c, outputs K′ := c While DONOTUSE is obviously a correct KEM since K′ always equals K, it is also completely insecure since the shared secret key K is transmitted in plaintext. This shows that a KEM needs to satisfy additional properties in order to be secure (see Sec. 2.3).", "char_len": 3898, "approx_tokens": 974}
{"chunk_id": "NIST.SP.800-227::c00008", "doc_id": "NIST.SP.800-227", "start_page": 15, "end_page": 16, "text": "t and efficient KEM can still be completely insecure. Define a KEM DONOTUSE as follows: • DONOTUSE.ParamSets: Contains a single, empty parameter set • DONOTUSE.KeyGen: On randomness r, outputs dk := r and ek := r • DONOTUSE.Encaps: On input ek and randomness s, outputs K := s and c := s • DONOTUSE.Decaps: On input dk and c, outputs K′ := c While DONOTUSE is obviously a correct KEM since K′ always equals K, it is also completely insecure since the shared secret key K is transmitted in plaintext. This shows that a KEM needs to satisfy additional properties in order to be secure (see Sec. 2.3).\n\nExample 2: Key transport using PKE. The following is a simple construction of a KEM from any PKE scheme. A PKE scheme consists of a collection PKE.ParamSets of parameter sets and three algorithms: key generation PKE.KeyGen (that accepts a parameter set), encryption PKE.Encrypt (that accepts a parameter set, an encryption key, and a plaintext), and decryption PKE.Decrypt (that accepts a parameter set, a decryption key, and a ciphertext). One can construct a KEM KEMFROMPKE from the PKE scheme as follows: • KEMFROMPKE.ParamSets = PKE.ParamSets • KEMFROMPKE.KeyGen = PKE.KeyGen • KEMFROMPKE.Encaps: On input p, ek and randomness s, output key K := s and ciphertext c ← PKE.Encrypt(p, ek, s). • KEMFROMPKE.Decaps: On input p, dk, and c, output key K′ := PKE.Decrypt(p, dk, c). The efficiency, correctness, and security properties of KEMFROMPKE depend on the respective properties of PKE.\n\nKEM examples. Section 5.1 briefly discusses three additional examples of KEMs: 1. ECDH-KEM is a quantum-insecure KEM based on ECDH key exchange (see Sec. 5.1.1). 2. RSASVE-KEM is a quantum-insecure example of RSA key transport (see Sec. 5.1.2). 3. ML-KEM is a lattice-based, NIST-approved post-quantum KEM (see Sec. 5.1.3). ECDH-KEM and RSASVE-KEM are based on NIST-standardized key-establishment schemes that can easily be viewed as KEMs. ML-KEM is the first key-establishment scheme to be standardized by NIST directly as a KEM.\n\nA remark on key transport and key agreement. There are various ways to categorize twoparty key-establishment schemes. One particular categorization distinguishes between key agreement and key transport. In key agreement (e.g., a Diffie-Hellman key exchange), both parties contribute information that influences the final shared secret key so that neither\n\nparty can predetermine it. In key transport (e.g., RSA-OAEP [2]), one party selects the key and then transmits it (in some form) to the other party. Depending on the internal structure of the encapsulation function, a KEM could be viewed as either a key-agreement scheme or a key-transport scheme. For example, the shared secret key in ML-KEM [3] is a function of both the randomness provided by Bob and the (randomly generated) encapsulation key of Alice. Therefore, ML-KEM could be viewed as a key-agreement scheme. However, as the example KEMFROMPKE shows, the encapsulation operation in a KEM might simply consist of Bob generating the shared secret key and then encrypting it, which is key transport. An application can achieve a particular type of key establishment (i.e., key agreement or key transport) using any KEM by taking appropriate additional steps using standard symmetric-key cryptography techniques. That is, given a KEM Π, Alice and Bob can achieve key agreement by both executing Π.KeyGen, sending the encapsulation keys to each other, and completing the steps of key establishment using a KEM. This will result in two separate shared secret keys that can be combined using an appropriate key-derivation method. Conversely, Π can be used to achieve key transport by following the steps in Fig. 7 and replacing m with the shared secret key produced by Π.\n\n2.3. Theoretical Security of KEMs This section discusses the theoretical security of KEMs. Section 3 discusses KEM implementation security, and Sec. 4.2 discusses the secure deployment of KEMs.", "char_len": 3946, "approx_tokens": 986}
{"chunk_id": "NIST.SP.800-227::c00009", "doc_id": "NIST.SP.800-227", "start_page": 16, "end_page": 18, "text": "y agreement by both executing Π.KeyGen, sending the encapsulation keys to each other, and completing the steps of key establishment using a KEM. This will result in two separate shared secret keys that can be combined using an appropriate key-derivation method. Conversely, Π can be used to achieve key transport by following the steps in Fig. 7 and replacing m with the shared secret key produced by Π.\n\n2.3. Theoretical Security of KEMs This section discusses the theoretical security of KEMs. Section 3 discusses KEM implementation security, and Sec. 4.2 discusses the secure deployment of KEMs.\n\nSemantic security. Informally speaking, a secure key-establishment procedure produces a shared secret key K that is uniformly random and unknown to adversaries. This property should hold despite the fact that adversaries can freely observe the messages transmitted by Alice and Bob. In the case of KEMs, the encapsulation key ek and ciphertext c should reveal no information about the resulting shared secret key K or the decapsulation key dk. Moreover, even adversaries who somehow learn some partial information (e.g., if the first half of K is accidentally leaked) should not be able to combine that information with ek and c to learn more (e.g., the last bit of K). This informal notion of security can be rigorously formalized, and the resulting definition is called semantic security [17].\n\nPassive adversaries and IND-CPA. The formal way to define semantic security for KEMs involves an imaginary “ciphertext indistinguishability” experiment (see Fig. 2). In this experiment, an adversary is given an encapsulation key ek, a ciphertext c, and either the true shared secret key underlying c or a freshly generated random string. The adversary’s goal is to distinguish between these scenarios, and they are free to use ek to generate their own encapsulations to help them in this task. This experiment is called “indistinguishable under chosen-plaintext attack” (IND-CPA) [17].\n\nChallenger: Adversary: (ek, dk) ← Π.KeyGen( p) (K0, c) ← Π.Encaps( p, ek) K1 ← {0, 1}|K0| b ← {0, 1} − ek, c, Kb − − − − − − − −→ ←− b′ − − − − − − − − output WIN iff b = b′.\n\nFig. 2. The IND-CPA security experiment for a KEM Π\n\nDefinition 3 (IND-CPA, informal). A KEM Π has indistinguishable ciphertexts (or is IND-CPA) if, for every computationally bounded adversary A, the difference between the probability that A wins the experiment IND-CPA[Π] and 1/2 is negligible. In the IND-CPA experiment, the adversary is free to study the encapsulation key ek and the ciphertext c in order to identify whether Kb is the true key. However, the adversary is not capable of actively interfering with the challenger’s use of the decapsulation key. As a result, IND-CPA only captures security against passive adversaries (i.e., eavesdroppers).\n\nChallenger: Adversary: (ek, dk) ← Π.KeyGen( p) (K0, c) ← Π.Encaps( p, ek) K1 ← {0, 1}|K0| b ← {0, 1} − ek, c, Kb − − − − − − − −→ Π.Decaps(dk, ?)\n\n←− b′ − − − − − − − − output WIN iff b = b′.\n\nFig. 3. The IND-CCA security experiment for a KEM Π\n\nActive adversaries and IND-CCA. Real-world experience indicates that adversaries can sometimes actively interfere with key-establishment processes and use this ability to un- cover the shared secret key. For example, an active adversary may be able to convince an\n\nhonest user to decapsulate some ciphertexts of the adversary’s choosing. In such a scenario, it is natural to ask whether other ciphertexts are still protected. In this setting, IND- CPA security is insufficient. Instead, one must consider security against so-called chosenciphertext attacks (CCA)3 [17]. The IND-CCA[Π] experiment for a KEM Π is described in Fig. 3. It is similar to the IND-CPA experiment, except that the adversary is now also granted “black-box oracle access” to the decapsulation function c → Π.Decaps(p, dk, c). This means that the adversary is allowed to submit ciphertexts c∗ that they generate and get the response K∗ ← Π.Decaps(p, dk, c∗).", "char_len": 3995, "approx_tokens": 998}
{"chunk_id": "NIST.SP.800-227::c00010", "doc_id": "NIST.SP.800-227", "start_page": 18, "end_page": 19, "text": "osing. In such a scenario, it is natural to ask whether other ciphertexts are still protected. In this setting, IND- CPA security is insufficient. Instead, one must consider security against so-called chosenciphertext attacks (CCA)3 [17]. The IND-CCA[Π] experiment for a KEM Π is described in Fig. 3. It is similar to the IND-CPA experiment, except that the adversary is now also granted “black-box oracle access” to the decapsulation function c → Π.Decaps(p, dk, c). This means that the adversary is allowed to submit ciphertexts c∗ that they generate and get the response K∗ ← Π.Decaps(p, dk, c∗). The only restriction is that they cannot submit the actual ciphertext c produced by the challenger since that would make the game trivial to win for any KEM. Definition 4 (IND-CCA, informal). A KEM Π is IND-CCA if, for every computationally bounded adversary A, the difference between the probability that A wins the experiment IND-CCA[Π] and 1/2 is negligible. ML-KEM, the first post-quantum KEM standardized by NIST, is believed to satisfy IND-CCA security [3].\n\n3IND-CCA as used here is typically referred to as IND-CCA2 in cryptographic literature.\n\n3. Requirements for Secure KEM Implementations\n\nAs discussed in Sec. 2.1, a KEM (as a mathematical object) should satisfy both correctness (Definition 2) and an appropriate notion of security (Definition 3 or Definition 4). In order for such a KEM to be used in real-world applications, it needs to be implemented in actual code as part of a cryptographic module. The quality of the resulting implementation has a dramatic impact on usability and security in real-world applications. The following subsections detail requirements for cryptographic modules that implement approved KEMs. However, adherence to these requirements does not guarantee that a given implementation will be secure. For a discussion of requirements for applications that make use of a KEM cryptographic module, see Sec. 4.2.\n\n3.1. Compliance With NIST Standards and Validation Conforming implementations of approved KEMs are required to comply with the requirements outlined in this section as well as all other applicable NIST standards. In addition, such implementations are required to use only approved cryptographic elements and pass FIPS-140 validation.\n\nImplementing according to NIST standards. Implementations shall comply with a specific NIST FIPS or SP that specifies the algorithms of the relevant KEM. For example, a conforming implementation of ML-KEM shall comply with FIPS 203 [3]. Each FIPS or SP that specifies a KEM will have special requirements for the particular scheme in question, including specifications for all algorithms and parameter sets of the relevant KEM. In particular, concrete data types will be specified for the parameter sets, keys, ciphertexts, and shared secret keys (Definition 1) of the relevant KEM. Assurance of parameter validity is obtained by checking the lists of approved parameters in the appropriate publication. The requirements in any FIPS or SP that standardizes a particular KEM are in addition to the general requirements described in this section. Any implementations shall follow the guidelines given in FIPS 140-3 [5] and associated implementation guidance.\n\nApproved cryptographic elements. KEMs commonly make use of other cryptographic elements, such as RBGs and hash functions (see Appendix D). Typically, the security of a system consisting of multiple cryptographic elements is at best as secure as the weakest element. When not already specified by the KEM parameter set, KEM implementations shall use approved cryptographic elements with security strengths that meet or exeed the required strength for each KEM parameter set. The security strength of the selected parameter set should be at least the desired security strength of the application. In addition, random bits shall be generated using approved techniques, as described in the latest revisions of SP 800-90A, SP 800-90B, and SP 800-90C [6–8].", "char_len": 3998, "approx_tokens": 999}
{"chunk_id": "NIST.SP.800-227::c00011", "doc_id": "NIST.SP.800-227", "start_page": 19, "end_page": 20, "text": "e security of a system consisting of multiple cryptographic elements is at best as secure as the weakest element. When not already specified by the KEM parameter set, KEM implementations shall use approved cryptographic elements with security strengths that meet or exeed the required strength for each KEM parameter set. The security strength of the selected parameter set should be at least the desired security strength of the application. In addition, random bits shall be generated using approved techniques, as described in the latest revisions of SP 800-90A, SP 800-90B, and SP 800-90C [6–8]. For using randomness in key generation, see SP 800-133 [18].\n\nTesting and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed.\n\nInput checking. The correct and secure operation of cryptographic operations depends crucially on the validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:", "char_len": 3734, "approx_tokens": 933}
{"chunk_id": "NIST.SP.800-227::c00012", "doc_id": "NIST.SP.800-227", "start_page": 20, "end_page": 22, "text": "he validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:\n\n1. If the cryptographic module generated an input internally using an algorithm that ensures validity and stored that input in a manner that prevents modification, then the module is not required to check that input. For example, if the module gener- ated a decapsulation key dk via KeyGen and then stored dk in a manner that prevents modification, then the module can later invoke Decaps directly on dk without per- forming any input checking. 2. If the cryptographic module checks an input once and stores that input in a man- ner that prevents modification, then the module is not required to check that input again. For example, if the module performed input-checking on a given encapsula- tion key ek and stored it in a manner that prevents modification, then the module may invoke Encaps directly on ek (even repeatedly) without performing any further input checking. 3. If the cryptographic module imports the relevant input from a trusted third party (TTP), and the TTP can provide assurance that the input does not need input-checking, and the module stores that input in a manner that prevents modification, then the module is not required to check the input.\n\nIntermediate values. All intermediate values used in any given KEM algorithm (i.e., KeyGen, Encaps, Decaps) shall be destroyed before the algorithm terminates. However, there are two exceptions to this rule: 1. A random seed used for key generation may be stored as private data for the purpose of recomputing the same key pair at a later time. 2. Data that can be easily computed from public information (e.g., from the encapsu- lation key) may be stored as public data to improve efficiency. When values are stored under either of these exceptions, the storage needs to be performed according to the rules for data at rest. The outputs of a KEM algorithm are not considered to be intermediate values and will thus not be immediately destroyed in typical situations. The format in which outputs and inputs are stored depends on the implementation (see the discussion of data formats below.)\n\nData at rest. A cryptographic module that implements a KEM needs to maintain certain data at rest. This can include both private data (e.g., seeds, decapsulation keys) and public data (e.g., encapsulation keys). In general, private data needs to be stored within the cryptographic module in a manner that is secure against both leakage and unauthorized modification. Private data needs to be destroyed as soon as it is no longer needed. The import and export of private data (e.g., seeds, decapsulation keys, shared secret keys) needs to be performed in a secure manner. In general, public data stored within the cryptographic module needs to be stored in a manner that is secure against unauthorized modification [5, 19].\n\nData formats, import, and export. FIPS validation tests input and output the behavior of relevant KEM algorithms using a specific data format. Typically, this format is byte arrays that contain the inputs and outputs described in the FIPS or SP that specifies the relevant KEM. This format is required for testing but is not a requirement for internal storage, data import, or data export. A given cryptographic module may choose to store, import, or export data (whether sensitive or not) using other formats. The desired format can vary significantly depending on the application.", "char_len": 3970, "approx_tokens": 992}
{"chunk_id": "NIST.SP.800-227::c00013", "doc_id": "NIST.SP.800-227", "start_page": 21, "end_page": 23, "text": "cation [5, 19].\n\nData formats, import, and export. FIPS validation tests input and output the behavior of relevant KEM algorithms using a specific data format. Typically, this format is byte arrays that contain the inputs and outputs described in the FIPS or SP that specifies the relevant KEM. This format is required for testing but is not a requirement for internal storage, data import, or data export. A given cryptographic module may choose to store, import, or export data (whether sensitive or not) using other formats. The desired format can vary significantly depending on the application. For example, some applications might call for storing keys using only a short seed, while other applications might call for storing keys in an expanded format that allows for faster computations. In any case, the storage, import, and export of sensitive data needs to be performed securely, regardless of the chosen data format.\n\n3.3. Additional Requirements The following are additional requirements for cryptographic modules that implement approved KEMs.\n\nFailures and aborts. Any of the KEM algorithms (i.e., KeyGen, Encaps, Decaps) and their cryptographic elements (e.g., DRBGs, hash functions) can potentially fail or abort. This could be a result of normal KEM operations (e.g., decapsulating a ciphertext that was corrupted by the environment during transmission), a hardware or software failure (e.g., a failed DRBG execution due to a memory fault), or an adversarial attack. Implementers need to take precautions to ensure that the cryptographic module handles failures and aborts appropriately. In particular, leaking information about failures and aborts outside of the perimeter of the cryptographic module should be avoided.\n\nSide-channel protection. Cryptographic modules for KEMs should be designed with appropriate countermeasures against side-channel attacks. This includes protecting against timing attacks with constant-time implementations and protecting memory from leakage. Universal guidelines are unlikely to be helpful as exposure to side-channel attacks varies significantly with the desired application, and countermeasures are often costly.\n\n4. Using KEMs Securely in Applications\n\nThis section describes how to deploy a KEM in real-world applications in a manner that is useful and secure, assuming that the KEM under discussion satisfies an appropriate notion of theoretical security (see Sec. 2.3) and has been securely implemented in a cryptographic module (see Sec. 3).\n\n4.1. How to Establish a Key With a KEM This section describes how a KEM can be used to establish a shared secret key between two parties. The description will go into greater detail than the brief outline in Sec. 2.1. However, since KEMs are highly flexible and can be used in a wide range of applications and contexts, no single description can account for all variations. Section 5 provides more detailed examples of special cases of key establishment using a KEM. For simplicity of exposition, the two parties in the key establishment process will be referred to as Alice and Bob. It is assumed that Alice and Bob are communicating over a single bidirectional channel and will only use that channel to transmit data to each other. The key-establishment process using a KEM Π proceeds as follows: 1. Preparation. Before key establishment can begin, a parameter set p ∈ Π.ParamSets needs to be selected. Depending on the application, p may be selected by Alice, by Bob, or through an interactive negotiation between Alice and Bob. The choice of the KEM Π itself could also be made at this stage. 2. Key generation. Alice begins by running the key-generation algorithm in her crypto- graphic module: (ekA, dkA) ← Π.KeyGen(p). (6) During the execution of KeyGen, Alice’s module internally generates private random- ness using an appropriate RBG. Alice then transmits ekA to Bob and keeps dkA pri- vate. 3. Encapsulation.", "char_len": 3923, "approx_tokens": 980}
{"chunk_id": "NIST.SP.800-227::c00014", "doc_id": "NIST.SP.800-227", "start_page": 23, "end_page": 25, "text": "e key establishment can begin, a parameter set p ∈ Π.ParamSets needs to be selected. Depending on the application, p may be selected by Alice, by Bob, or through an interactive negotiation between Alice and Bob. The choice of the KEM Π itself could also be made at this stage. 2. Key generation. Alice begins by running the key-generation algorithm in her crypto- graphic module: (ekA, dkA) ← Π.KeyGen(p). (6) During the execution of KeyGen, Alice’s module internally generates private random- ness using an appropriate RBG. Alice then transmits ekA to Bob and keeps dkA pri- vate. 3. Encapsulation. Bob receives ekA from Alice and uses it to execute the encapsulation algorithm in his cryptographic module: (KB, cB) ← Π.Encaps(p, ekA). (7) During the execution of Encaps, Bob’s module internally generates private random- ness using an appropriate RBG. Bob then transmits cB to Alice and keeps KB private. 4. Decapsulation. Alice receives cB from Bob and runs the decapsulation algorithm in her module using her decapsulation key and Bob’s ciphertext: KA ← Π.Decaps(dkA, cB). (8) Alice keeps KA private.\n\n5. Using the shared secret key. If the appropriate conditions are satisfied (see Sec. 4.2), then KA will equal KB and can be used by Alice and Bob for any symmetric-key cryp- tographic protocol. A typical choice is to use KA = KB as the key for an authenticated encryption scheme (e.g., AES-GCM [9]), thereby establishing a communication chan- nel between Alice and Bob that satisfies both confidentiality and integrity. Figure 4 depicts the high-level stages of this process. Note that some desirable security properties might not be achieved by a protocol of this form and may require additional steps and ingredients.\n\nAlice: Bob: 1. ←− Π, p − − − − − −→ 2. (ekA, dkA) ← Π.KeyGen( p) − ekA − − − − − − − −→ 3. (KB, cB) ← Π.Encaps(ekA) ←− cB − − − − − − − 4. KA ← Π.Decaps(dkA, cB)\n\n5. output: KA output: KB\n\nFig. 4. Simple key establishment using a KEM\n\nAdditional considerations. Steps 1-5 in the key-establishment process might need to be modified, depending on the security and functionality needs of the application. Some common modifications are as follows. Static versus ephemeral key pairs. Consider an application in which Alice independently decides on a parameter set, performs key generation, and publishes the resulting encapsulation key ekA. Alice might then accept many connections from multiple parties over a long period of time, each initiated via ekA. Each such connection would follow stages 3-5 described above. While the other party in each connection would always encapsulate with ekA, each ciphertext is generated with new randomness and only applicable to the connection between Alice and that party. In this scenario, Alice’s encapsulation key is said to be static. In other applications, Alice might want to use a particular key pair to establish only a single connection (e.g., as part of a protocol that ensures forward secrecy). In that case, she will perform key generation, send her encapsulation key ekA to Bob, and discard ekA once the connection with Bob is established. In this scenario, Alice’s encapsulation key is said to be ephemeral.\n\nAuthentication. In most applications, some form of authentication and cryptographic integrity checking is required (e.g., to prevent “machine-in-the-middle” attacks). Assuring this is highly application-dependent and typically requires additional cryptographic elements, such as digital signatures and certificates. Section 5.2.4 and Sec. 5.2.3 provide some illustrative examples. Using the shared secret key. In some applications, Alice and Bob will use KA and KB directly as symmetric keys as soon as the decapsulation and encapsulation stages are successfully completed, respectively. If KA = KB, a failure in the desired symmetric-key functionality will likely follow.", "char_len": 3856, "approx_tokens": 964}
{"chunk_id": "NIST.SP.800-227::c00015", "doc_id": "NIST.SP.800-227", "start_page": 25, "end_page": 26, "text": "ptographic integrity checking is required (e.g., to prevent “machine-in-the-middle” attacks). Assuring this is highly application-dependent and typically requires additional cryptographic elements, such as digital signatures and certificates. Section 5.2.4 and Sec. 5.2.3 provide some illustrative examples. Using the shared secret key. In some applications, Alice and Bob will use KA and KB directly as symmetric keys as soon as the decapsulation and encapsulation stages are successfully completed, respectively. If KA = KB, a failure in the desired symmetric-key functionality will likely follow. For other applications, Alice and Bob might need to first post-process KA and KB appropriately and then use the results of that post-processing step — if successful — as their symmetric keys. This post-processing might include key derivation steps that securely produce multiple symmetric keys from the initial shared secret key (see Sec. 4.3). It might also include key confirmation steps to confirm that KA = KB and reject them otherwise (see Sec. 4.4). In some cases, key confirmation might also involve performing additional computations during the encapsulation and decapsulation stages to reduce the number of communication rounds.\n\n4.2. Conditions for Using KEMs Securely This section discusses general requirements for securely using approved KEMs in applications. As discussed in point 1 below, the first step involves selecting an approved KEM that has been implemented in a validated cryptographic module (see Section 3). Deploying such a cryptographic module in applications entails a number of additional requirements that are outlined below. Adherence to these requirements does not guarantee that the relevant KEM application will be secure. The overall requirements fall into four general categories: KEM algorithm security, device security, channel security, and key usage security. 1. KEM algorithm security: The selected KEM Π is approved, appropriate for the ap- plication, and implemented and deployed in a secure manner. Being an approved KEM, Π will satisfy correctness (Definition 2) and either IND-CPA or IND-CCA security (see Section 2.3). Whenever possible, IND-CCA-secure KEMs should be used. For some specific applications (e.g., ephemeral key establishment), IND-CPA security might be sufficient. Cryptographic module implementation. The implementations of Π used by Alice and Bob need to satisfy the requirements in Sec. 3. Whether a given implemen- tation is sufficiently secure is an application-dependent question. For example, an implementation might be secure enough for use on a web server in a physically se- cure location but have insufficient side-channel protections for use on an embedded device.\n\nParameter set selection. A parameter set of Π with application-appropriate security strength must be selected. KEM key-pair usage. If an application uses an ephemeral key pair, the key pair shall be used for only one execution of key-establishment via a KEM and shall be de- stroyed as soon as possible after its use. If an encapsulating party obtains the static encapsulation key of another party, it must have assurance of the other party’s ownership of the key before or during the execution of key-establishment. This assurance can be obtained from a trusted party (e.g., a certificate authority) or a combination of proof of possession (see Sec. 4.5) and verification of real-world identity. 2. Device security: The devices used to execute KEM algorithms and store any sensitive data (e.g., decapsulation keys) must be appropriately secured. Physical protection. Devices need to be appropriately protected against attacks (see [19, Section 5]). This includes protection against leakage, physical intrusion, remote access, and corruption. Secure storage.", "char_len": 3798, "approx_tokens": 949}
{"chunk_id": "NIST.SP.800-227::c00016", "doc_id": "NIST.SP.800-227", "start_page": 26, "end_page": 27, "text": "key before or during the execution of key-establishment. This assurance can be obtained from a trusted party (e.g., a certificate authority) or a combination of proof of possession (see Sec. 4.5) and verification of real-world identity. 2. Device security: The devices used to execute KEM algorithms and store any sensitive data (e.g., decapsulation keys) must be appropriately secured. Physical protection. Devices need to be appropriately protected against attacks (see [19, Section 5]). This includes protection against leakage, physical intrusion, remote access, and corruption. Secure storage. Devices need to provide appropriate secure storage for sensitive data (e.g., KEM keys, seeds, shared secret keys, any derived keys) and destroy that data when required by the cryptographic module (see Sec. 3.2). For further guide- lines on key storage considerations, see SP 800-57pt1 [19] and SP 800-152 [10, Sec- tion 2.2]. 3. Channel security: The key-establishment process that takes place over the channel used by Alice and Bob must satisfy an application-appropriate notion of integrity. Preestablished versus simultaneous. Ensuring the integrity of the key-establishment process could be achieved by first ensuring the integrity of the channel and then performing key establishment. More commonly, integrity is assured simultaneously with key establishment by augmenting the key-establishment process with addi- tional steps and checks (see, e.g., Section 5.2.3). Unilateral versus bilateral authentication. For some applications, only one of the parties is assured of the other’s identity and the integrity of their messages. This is commonly called a unilaterally authenticated key exchange (see Sec. 5.2.3). In other applications, both Alice and Bob require assurances of the other party’s identity and the integrity of their messages. This is commonly called a bilaterally authenticated key exchange. Secure authentication algorithms. For all applications, the cryptographic algorithms (e.g., digital signature algorithms) and other elements (e.g., certificates) required to establish channel integrity need to be selected and deployed securely.\n\n4. Shared-secret-key usage security: The shared secret key produced by the KEM is used appropriately and securely. Shared-secret-key processing and management. Key-derivation and key-confirmation steps are performed appropriately, as required by the application (see Sec. 4.3 and 4.4). Each shared secret key and any derived keys are destroyed as soon as they are no longer needed (see Sec. 4.2). Secure symmetric-key algorithms. The KEM shared secret key and any derived keys should only be used with appropriately secure symmetric-key cryptographic algo- rithms. In particular, the security of the symmetric-key algorithms used is appropri- ate for the security provided by the KEM so that the combined algorithm (consisting of key establishment followed by symmetric cryptography operations) fulfills the de- sired security properties.\n\n4.3. Post Processing of the Shared Secret Key Certain key-establishment schemes (e.g., Diffie-Hellman key exchange) can be viewed as first generating a shared secret and then performing a key-derivation step that transforms the shared secret into one or more shared secret keys. In contrast, KEMs by definition output a key K that is ready to use. Key derivation may be required for applications in which the amount of keying material needed does not match the output size of the KEM algorithm (i.e., the length of shared secret key K). As specified in SP 800-108 [20], key derivation consists of applying a key-derivation method (KDM) to a key-derivation key. A KDM is an algorithm for transforming a given key-derivation key (possibly with some other data) into keying material (e.g., a list of keys). If additional keying material is needed, a KDM can be used to expand K.", "char_len": 3872, "approx_tokens": 968}
{"chunk_id": "NIST.SP.800-227::c00017", "doc_id": "NIST.SP.800-227", "start_page": 27, "end_page": 28, "text": "s. In contrast, KEMs by definition output a key K that is ready to use. Key derivation may be required for applications in which the amount of keying material needed does not match the output size of the KEM algorithm (i.e., the length of shared secret key K). As specified in SP 800-108 [20], key derivation consists of applying a key-derivation method (KDM) to a key-derivation key. A KDM is an algorithm for transforming a given key-derivation key (possibly with some other data) into keying material (e.g., a list of keys). If additional keying material is needed, a KDM can be used to expand K. If keys with lengths less than K are needed, a KDM may be used, or the shared secret key K can be used directly as keying material by: • Truncating K or • Parsing K into non-overlapping segments to derive shorter keys. The derived shorter key is considered a shared secret key if K was a shared secret key. The security strength of any derived shorter key is the minimum of the security strength of K, the length of the derived key, and the strength of any KDM used. When key derivation for a KEM Π is needed, the shared secret key output by Π (i.e., as an output of Π.Encaps or Π.Decaps) may be used as a key-derivation key supplied to an approved key-derivation method specified in SP 800-108 [20], SP 800-56C [21], or SP 800- 133 [18]. If a KDM from SP 800-56C is used, the shared secret key of the KEM is used as\n\nan input to the KDM in place of the shared secret. A key derivation step is included in the example protocol in Sec. 5.2.3.\n\n4.4. Key Confirmation Key confirmation (KC) refers to the actions taken to provide assurance to one party (i.e., the key-confirmation recipient) that another party (i.e., the key-confirmation provider) possesses matching keying material. In the case of KEMs, this confirmation is done for keying material that was produced by encapsulation and/or decapsulation. Key confirmation should be used during KEM usage, as it may enhance the security properties of the overall key-establishment process. Confirming successful establishment of the shared secret key can also address potential errors in transmission or decapsulation. Key confirmation can also act as a proof of possession (see Sec. 4.5). While this section includes a description of an explicit process, key confirmation can be accomplished in a variety of other ways. For example, successful use of the shared secret key for authenticated encryption can act as key confirmation. Key confirmation is typically achieved by exchanging a value that can only be calculated correctly with very high probability if the key establishment was successful. Some common protocols perform key confirmation in a manner that is integrated into the steps of the protocol. For example, bilateral key confirmation is provided during a TLS handshake protocol by the generation and verification of a message authentication code (MAC) over all previous messages in the handshake using a symmetric MAC key that was established during the handshake. In some circumstances, it may be appropriate to perform key confirmation by including dedicated key-confirmation steps in a key-establishment scheme. An acceptable method for providing key confirmation during a key-establishment scheme involves the KC provider calculating a MAC tag on MAC_Data and sending the MAC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods.", "char_len": 3939, "approx_tokens": 984}
{"chunk_id": "NIST.SP.800-227::c00018", "doc_id": "NIST.SP.800-227", "start_page": 28, "end_page": 29, "text": "AC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods.\n\nKey-confirmation key. The key-confirmation steps specified in this recommendation can be incorporated into any scheme using a KEM to establish a shared secret key. To perform key confirmation, a dedicated KC key will be determined from the shared secret key produced by the KEM. The KC provider will use the KC key with an approved MAC algorithm to create a MAC tag on certain data and provide the tag to the KC recipient. The KC recipient\n\nwill then obtain the KC key from their copy of the shared secret key produced by the KEM and use it to verify the MAC tag.\n\n4.4.1. Creating the MAC Data During key confirmation, the KC provider creates a message with a MAC tag that is computed on MAC_Data that contains context-specific information. The MAC_Data is formatted as follows: MAC_Data = KC_Step_Label ‖ IDP ‖ IDR ‖ EphP ‖ EphR ‖ ExtraP ‖ ExtraR • KC_Step_Label is a six-byte character string that indicates that the MAC_Data is used for key confirmation, whether the MAC_Data is used for the first or second key-confirmation message, and the party serving as the KC provider, either the en- capsulator (E) or decapsulator (D). The four valid options are ”KC_1_E”, ”KC_2_E”, ”KC_1_D”, or ”KC_2_D”. As an example, ”KC_1_D” indicates that the decapsu- lator (D) is the KC provider and sends the first KC message. ”KC_2_E” could then be used by the encapsulator (E) to provide bilateral key confirmation. • IDP and IDR are the identifiers used to label the KC provider and recipient, respec- tively. • EphP and EphR are ephemeral data provided by the KC provider and recipient, re- spectively. The encapsulator’s ephemeral data is the ciphertext. The decapsulator’s ephemeral data is the encapsulation key ek if ek is ephemeral. Otherwise, the de- capsulator’s ephemeral data shall be a nonce with a bit length that is at least equal to the targeted security strength of the KEM key-establishment process (see Appendix C.2). When a nonce is used during key confirmation, it needs to be provided to the en- capsulator to construct MAC_Data for MAC tag generation or verification. • ExtraP and ExtraR are optional additional data provided by the KC provider and re- cipient, respectively. This could include additional identifiers, values computed dur- ing the key-establishment process but not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details.\n\n4.4.2. Obtaining the Key-Confirmation Key In order to create and validate the MAC tag for the created MAC_Data, the parties create a dedicated key-confirmation key (KC_Key). This can be either a portion of the KEM", "char_len": 3483, "approx_tokens": 870}
{"chunk_id": "NIST.SP.800-227::c00019", "doc_id": "NIST.SP.800-227", "start_page": 29, "end_page": 31, "text": "ut not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details.\n\n4.4.2. Obtaining the Key-Confirmation Key In order to create and validate the MAC tag for the created MAC_Data, the parties create a dedicated key-confirmation key (KC_Key). This can be either a portion of the KEM\n\nshared secret key or part of the keying material derived from the KEM shared secret key when using a derivation function (see Sec. 4.3). The KC_Key shall only be used for key confirmation and destroyed after use. See Appendix C.1 for KC_Key lengths. When a derivation function is used. After computing the shared secret value and applying the key-derivation method to obtain the derived keying material Derived_Keying_Material, the key-confirmation provider uses agreed-upon bit lengths to parse Derived_Keying_Material into two parts — the key-confirmation key (KC_Key) and the keys to subsequently protect data (Data_Key): Derived_Keying_Material = KC_Key‖Data_Key. When a derivation function is NOT used. The key-confirmation provider parses the output of the encapsulation process (i.e., KEM_shared_secret_key) into KC_Key and Data_Key: KEM_shared_secret_key = KC_Key‖Data_Key.\n\n4.4.3. Key-Confirmation Example The key-confirmation process can be achieved in multiple ways. The following example showcases unilateral key confirmation from the encapsulator to the decapsulator, which can be used for a client (e.g., Alice) requesting confirmation of successful key establishment from a server (e.g., Bob). Figure 5 shows this process. Some desirable security properties might not be achieved by a protocol of this form and may require additional steps and ingredients. 1. Alice (i.e., decapsulating party) generates a set of ephemeral keys (ek, dk) for KEM Π under the agreed parameter set p. Alice then sends ek, Alice’s identifying string (IDA), and any extra data ExtraA to include in the key confirmation to Bob (i.e., en- capsulating party). 2. Bob performs encapsulation with the received ek to generate ciphertext c and ini- tial key KB0. Bob then derives two keys from KB0: a key-confirmation key KBkc to perform key confirmation and additional keying material KB1. 3. Bob constructs MAC_Data using the following in order: • The constant string ”KC_1_E,” which indicates that Bob (i.e., the encapsulator) is providing key confirmation and that this is the first KC message • IDB, which is Bob’s identifier string • IDA, which is Alice’s identifier string • Ciphertext c, which serves as Bob’s (i.e., the KC provider’s) ephemeral value for the key-confirmation process\n\nAlice (Decapsulator, Client): Bob (Encapsulator, Server): 1. (ek, dk) ← Π.KeyGen( p) ek, IDA, ExtraA − − − − − − − − −→ 2. (c, KB0) ← Π.Encaps( p, ek) KBkc||KB1 ← KDF(KB0) 3. Construct MAC_Data t ← MAC(KBkc, MAC_Data) c, t, IDB, ExtraB ←− − − − − − − − − 4. KA0 ← Π.Decaps( p, dk, c) KAkc||KA1 ← KDF(KA0) 5. Construct MAC_Data if MAC.Ver(KAkc, MAC_Data, t) rejects, abort. 6. result: KA1 (KAkc destroyed ) result: KB1 (KBkc destroyed )\n\nFig. 5. Key-confirmation example with an ephemeral key pair\n\n• Encapsulation key ek, which is Alice’s (i.e., the KC recipient’s) ephemeral value for the key-confirmation process • ExtraB, which refers to any extra data that Bob (i.e., the KC provider) would like to include • ExtraA, which refers to the extra data provided by Alice (i.e., the KC recipient) Bob calculates the tag t using KBkc on MAC_Data and sends the following to Alice: 1) ciphertext c, 2) the generated tag t, 3) and any extra data ExtraB that Bob included in the MAC_Data. 4.", "char_len": 3864, "approx_tokens": 966}
{"chunk_id": "NIST.SP.800-227::c00020", "doc_id": "NIST.SP.800-227", "start_page": 31, "end_page": 32, "text": "A1 (KAkc destroyed ) result: KB1 (KBkc destroyed )\n\nFig. 5. Key-confirmation example with an ephemeral key pair\n\n• Encapsulation key ek, which is Alice’s (i.e., the KC recipient’s) ephemeral value for the key-confirmation process • ExtraB, which refers to any extra data that Bob (i.e., the KC provider) would like to include • ExtraA, which refers to the extra data provided by Alice (i.e., the KC recipient) Bob calculates the tag t using KBkc on MAC_Data and sends the following to Alice: 1) ciphertext c, 2) the generated tag t, 3) and any extra data ExtraB that Bob included in the MAC_Data. 4. Alice performs decapsulation on the received ciphertext c using the previously gen- erated decapsulation key dk to calculate initial key KA0. Alice then derives two keys from KA0 similarly to Bob (in step 2): key-confirmation key KAkc and additional keying material KA1. 5. Alice constructs MAC_Data as Bob did in step 3 and verifies the received t for the MAC_Data using key KAkc. Alice aborts if the tag is rejected or continues if it is verified. 6. Alice now has additional assurance that KA1 matches KB1. Alice and Bob destroy the key-confirmation keys KAkc and KBkc and can proceed to use KA1 and KB1 as planned.\n\nThis example only provides unilateral key confirmation. If Bob also wanted assurance, another round of key confirmation can be performed by swapping roles. During this additional round, Alice generates new MAC_Data using KC_2_D as the label and indicating herself as the KC provider (see Sec. 4.4.1), generates a tag on new MAC_Data, and sends the new tag to Bob for verification.\n\n4.5. Proof of Possession for KEM Keys A key-pair owner may need to provide proof-of-possession (PoP), which is the assurance that they possess the private decapsulation key corresponding to the public encapsulation key. In practice, PoP for RSA encryption key pairs (i.e., encryption key, decryption key) has historically been provided by reusing the same keys as a digital signature key pair (i.e., verification key, signing key). A key-pair owner can provide assurance that they possess the secret decryption key by signing a message using the private signing/decryption key. The party seeking assurance can verify the signature using the public verification/encryption key. Unfortunately, this shortcut does not necessarily apply to all KEMs, so it is important to consider alternative approaches to providing PoP for KEMs. Consider the case in which Bob has obtained another party’s static public encapsulation key and is communicating with a party purporting to be the key-pair owner corresponding to that encapsulation key. Bob may seek PoP from the other party before any further engagement. One method to obtain PoP is for Bob to participate in a KEM protocol that includes key confirmation (see Sec. 4.4) and in which assurance of the identity of the other party is provided. This method can be used for both static and ephemeral key pairs. However, for static key pairs, PoP can also be provided in a certificate by a certificate authority (CA). Consider the case in which Alice is the owner of a static KEM key pair and would like to acquire a certificate establishing her ownership. A certificate authority (CA) would require PoP from Alice prior to issuing and publishing a certificate. Bob could then acquire the certificate from either Alice or the CA and would have assurance that Alice possesses the private key. Methods for performing PoP by a CA for KEMs are being developed. For illustrative purposes, this section also describes a method proposed in [22] that can be used by a CA to obtain PoP for a private decapsulation key for which a certificate is requested for the corresponding public encapsulation key. In practice, a certificate not only links the identity of the key-pair owner to the static public key, but it also proves that a key-pair owner possesses the static private key that corresponds to a static public key.", "char_len": 3951, "approx_tokens": 987}
{"chunk_id": "NIST.SP.800-227::c00021", "doc_id": "NIST.SP.800-227", "start_page": 32, "end_page": 34, "text": "Alice or the CA and would have assurance that Alice possesses the private key. Methods for performing PoP by a CA for KEMs are being developed. For illustrative purposes, this section also describes a method proposed in [22] that can be used by a CA to obtain PoP for a private decapsulation key for which a certificate is requested for the corresponding public encapsulation key. In practice, a certificate not only links the identity of the key-pair owner to the static public key, but it also proves that a key-pair owner possesses the static private key that corresponds to a static public key. For the sake of simplicity, assume that Alice’s identifying information IDAlice has been submitted to and verified by the CA prior to the protocol run described below. Suppose that Alice has generated a static KEM key pair (ek, dk) and wants to obtain a certificate for ek. Let Π, p be the KEM and parameter set associated with (ek, dk). Let Sym = (Sym.KeyGen, Sym.Enc, Sym.Dec) denote a symmetric encryption scheme with corresponding key generation, encryption, and decryption algorithms, respectively. Let\n\nH denote a cryptographic hash function. Let Cert.Gen denote the process used by the CA to generate a certificate.\n\nAlice (key pair owner) Bob (CA) 1. static: (ek, dk) IDAlice − ek, IDAlice − − − − − − − − − −→ 2. (c, K) ← Π.Encaps( p, ek) cert[ek, p, Alice] ← Cert.Gen(ek, IDAlice) HB ← H(cert[ek, p, Alice]) ccert ← Sym.EncK (cert[ek, p, Alice]) ←− c, ccert − − − − − − − − − − 3. KA ← Π.Decaps( p, dk, c) cert′[ek, p, Alice] ← Sym.DecKA(ccert) HA ← H(cert′[ek, p, Alice]) − HA − − − − − − − − − −→ if HA = HB, abort. 4. publish: cert[ek, p, Alice]\n\nFig. 6. KEM PoP between a key-pair owner and CA\n\n0. Prior to the protocol initiation, Alice has submitted her identifying information IDAlice to the CA, and the CA has verified her identity. Throughout the protocol ex- ecution, messages coming from Alice are assumed to be authenticated so that no one can impersonate Alice within the protocol. 1. Alice sends ek, IDAlice to the CA to initiate the protocol. 2. The CA runs Π.Encaps(ek, p) to produce (K, c). The CA generates the certificate cert[ek, p, Alice] and links Alice’s identity to her encapsulation key ek. The CA com- putes HB, which is the hash of the certificate. The CA then computes ccert = Sym.EncK(cert[ek, p, Alice]) by encrypting the certificate with the key produced by KEM Π. Finally, the CA sends the two ciphertexts c and ccert to Alice. 3. Alice runs Π.Decaps(p, dk, c) to recover K and decrypts the certificate by comput- ing Sym.DecK(ccert) to obtain the plaintext certificate. Alice hashes the plaintext certificate and sends the resulting hash value HA to the CA. 4. The CA verifies the received hash value HA against HB, which is the hash of the plain- text certificate cert[ek, p, Alice] generated in step 2. If the two hash values are equal,\n\nthe CA sends an acknowledgment to Alice that the certification process was success- ful, and cert[ek, p, Alice] is published for use. Once the CA publishes cert[ek, p, Alice], relying parties using that certificate have assurance that the owner of that certificate (Alice, with identity ” Alice”) possessed the private decapsulation key corresponding to ek when the certificate was generated and published. If Alice manages to recover the certificate in step 3, this indirectly proves that she possesses the corresponding decapsulation key dk. However, the CA would not receive PoP from Alice unless step 4 is completed. This solution requires that the CA has the capabilities to run Π.Encaps(), which may not be true in practice.", "char_len": 3612, "approx_tokens": 903}
{"chunk_id": "NIST.SP.800-227::c00022", "doc_id": "NIST.SP.800-227", "start_page": 34, "end_page": 35, "text": ". Once the CA publishes cert[ek, p, Alice], relying parties using that certificate have assurance that the owner of that certificate (Alice, with identity ” Alice”) possessed the private decapsulation key corresponding to ek when the certificate was generated and published. If Alice manages to recover the certificate in step 3, this indirectly proves that she possesses the corresponding decapsulation key dk. However, the CA would not receive PoP from Alice unless step 4 is completed. This solution requires that the CA has the capabilities to run Π.Encaps(), which may not be true in practice.\n\n4.6. Multi-Algorithm KEMs and PQ/T Hybrids Combining multiple key-establishment schemes into a single key-establishment scheme can be advantageous for some applications (e.g., during the migration to post-quantum cryptography). The discussions of such schemes in this document will adhere to the terminology established in [23]. A multi-algorithm key-establishment scheme combines shared secret values that are generated using two or more key-establishment schemes. The underlying schemes are called the components of the overall scheme. In general, the multi-algorithm scheme does not need to have the same interface as its components. In this document, for example, multialgorithm schemes will always be KEMs, while their components need not be. A well-designed multi-algorithm scheme will be secure if at least one of the component schemes is secure. This may provide some protection against vulnerabilities that are discovered in one of the component schemes after deployment. Forexample, the migration to post-quantum key-establishment techniques might initially include multi-algorithm solutions that combine one new post-quantum algorithm with one tried-and-tested but quantum-vulnerable (or traditional) algorithm. This is sometimes referred to as hybrid post-quantum/traditional (PQ/T) key establishment. For example, X-Wing KEM is a hybrid PQ/T KEM built from two components: ML-KEM (a lattice-based post-quantum KEM) and X25519 (a traditional Diffie-Hellman-style key exchange) [24]. This section outlines approved approaches for multi-algorithm key establishment, which have two stages: 1. Establish shared secrets. All component key-establishment schemes are run (typi- cally in parallel), resulting in Alice and Bob sharing a collection of shared secrets — one for each component scheme. 2. Combine shared secrets. Alice and Bob individually use a key combiner to combine their individual shared secrets into a single shared secret each. Approved key com- biners are described in Sec. 4.6.2.\n\nFor simplicity, the exposition below focuses on a particular case: constructing a single KEM from two component KEMs. Since both the components and the multi-algorithm scheme in this case are of the same type (i.e., KEMs), the result is called a composite KEM. Most keyestablishment schemes of interest can easily be expressed as KEMs (see, e.g., ECDH-KEM in Sec. 5.1.1 and RSA-KEM in Sec. 5.1.2). Moreover, the hybrid PQ/T application typically calls for two component schemes: one post-quantum scheme, and one traditional scheme. The two-algorithm composite KEM described below is easily adapted to other cases, such as combining more than two schemes or combining KEMs with non-KEMs.\n\n4.6.1. Constructing a Composite KEM Given two KEMs Π1 and Π2, one can construct a composite KEM C[Π1, Π2] via the following sequence of steps: 1. Choose parameter sets. Choose a collection C[Π1, Π2].ParamSets of parameter sets. Each parameter set will be a pair p = (p1, p2), where p1 ∈ Π1.ParamSets and p2 ∈ Π2.ParamSets. 2. Select a key combiner. Choose a key combiner algorithm KeyCombine. The inputs to KeyCombine include a pair of shared secret keys (one from Π1 and one from Π2), a pair of ciphertexts, a pair of encapsulation keys, and a parameter set. The output is a single shared secret key. Section 4.6.2 discusses NIST-approved key combiners. 3.", "char_len": 3952, "approx_tokens": 988}
{"chunk_id": "NIST.SP.800-227::c00023", "doc_id": "NIST.SP.800-227", "start_page": 35, "end_page": 36, "text": "Π2, one can construct a composite KEM C[Π1, Π2] via the following sequence of steps: 1. Choose parameter sets. Choose a collection C[Π1, Π2].ParamSets of parameter sets. Each parameter set will be a pair p = (p1, p2), where p1 ∈ Π1.ParamSets and p2 ∈ Π2.ParamSets. 2. Select a key combiner. Choose a key combiner algorithm KeyCombine. The inputs to KeyCombine include a pair of shared secret keys (one from Π1 and one from Π2), a pair of ciphertexts, a pair of encapsulation keys, and a parameter set. The output is a single shared secret key. Section 4.6.2 discusses NIST-approved key combiners. 3. Construct a composite key-generation algorithm. When a parameter set p = (p1, p2) is input, the algorithm C[Π1, Π2].KeyGen will perform: 1. (ek1, dk1) ← Π1.KeyGen(p1). 2. (ek2, dk2) ← Π2.KeyGen(p2). 3. Output composite encapsulation key ek1‖ek2. 4. Output composite decapsulation key dk1‖dk2. 4. Construct a composite encapsulation algorithm. When a parameter set p = (p1, p2) and encapsulation key ek1‖ek2 are input, the algorithm C[Π1, Π2].Encaps will perform: 1. (K1, c1) ← Π1.Encaps(p1, ek1). 2. (K2, c2) ← Π2.Encaps(p2, ek2). 3. Output combined shared secret key\n\nK ← KeyCombine(K1, K2, c1, c2, ek1, ek2, p). (9)\n\n4. Output composite ciphertext c := c1‖c2.\n\n5. Construct a composite decapsulation algorithm. When a parameter set p = (p1, p2), decapsulation key dk1‖dk2, and ciphertext c1‖c2 are input, the algorithm C[Π1, Π2].Decaps will perform: 1. K′ ← Π1.Decaps(p1, dk1, c1). 2. K′ ← Π2.Decaps(p2, dk2, c2). 3. Output combined shared secret key\n\nK′ ← KeyCombine(K′ , K′ , c1, c2, ek1, ek2, p). (10) 1 2\n\nSince the inputs to KeyCombine include the composite encapsulation key, the decapsulating party must retain a copy of that key or maintain the ability to recreate it after performing key generation.\n\nGeneral multi-algorithm schemes. The above construction can be extended in the obvious way to composite constructions that use more than two component KEMs. Extending to the case of a completely general multi-algorithm key-establishment scheme can be more complex, as the components in such a scheme can vary widely. For example, such schemes could potentially include pre-shared keys or shared secrets established via quantum key distribution. Still, most multi-algorithm schemes will likely include a step in which a series of shared secrets are combined via a key combiner algorithm of a form similar to KeyCombine above. In those cases, an approved key combiner discussed in Sec. 4.6.2 shall be used.\n\n4.6.2. Approved Key Combiners This section describes approved methods for combining shared secrets as part of a multialgorithm key-establishment scheme. Choosing such a method amounts to selecting a key combiner KeyCombine. At a minimum, KeyCombine accepts two shared secrets as input, where one or both may be shared secret keys. Optionally, KeyCombine can also accept additional information, such as ciphertexts, encapsulation keys, parameter sets, or other context-dependent data (e.g., the composite KEM in Sec. 4.6.1). As output, KeyCombine produces a single shared secret key. This section describes how cryptographic methods standardized in other NIST publications can be used as key combiners under an appropriate interpretation. There are two categories of such key combiners: 1. Key combiners from key-derivation methods approved in SP 800-56C [21] 2. Key combiners from key-combination methods approved in SP 800-133 [18]\n\nConcatenation of inputs. The following descriptions involve invocations of functions (e.g., hash functions H : {0, 1}∗ → {0, 1}n) on multiple comma-separated inputs (e.g.,", "char_len": 3623, "approx_tokens": 905}
{"chunk_id": "NIST.SP.800-227::c00024", "doc_id": "NIST.SP.800-227", "start_page": 36, "end_page": 38, "text": "in Sec. 4.6.1). As output, KeyCombine produces a single shared secret key. This section describes how cryptographic methods standardized in other NIST publications can be used as key combiners under an appropriate interpretation. There are two categories of such key combiners: 1. Key combiners from key-derivation methods approved in SP 800-56C [21] 2. Key combiners from key-combination methods approved in SP 800-133 [18]\n\nConcatenation of inputs. The following descriptions involve invocations of functions (e.g., hash functions H : {0, 1}∗ → {0, 1}n) on multiple comma-separated inputs (e.g.,\n\nz := H(x, y)). This should be distinguished from invoking the same function on a single input that is formed by simply concatenating those inputs (e.g., w := H(x‖y)). For example, if the lengths of the two inputs can vary, concatenation can have unintended consequences (e.g., x‖y = x′‖y′ even though (x, y) = (x′, y′)). However, an appropriate encoding of a pair (x, y) as a single bitstring can specify the lengths of x and y such that invoking H on (x, y) is distinct from invoking H on (x′, y′). The interpretation of invoking a function on comma-separated inputs generally depends on the application and encoding and might also involve specifying the lengths of each individual input. In some scenarios, simple concatenation can also be appropriate. In any case, it is important to choose and fix this interpretation in a manner that is appropriate for the given application.\n\nKey derivation in SP 800-56C. SP 800-56C [21] specifies a collection of approved methods for performing key derivation. In SP 800-56C, a key derivation method (KDM) is applied to a shared secret Z generated as specified in SP 800-56A [1] or SP 800-56B [2] along with some additional input and results in keying material K: K ← KDM(Z, OtherInput). (11) The key-derivation method KDM can take one of two forms: 1. One-step key derivation. In this case, K is computed by applying a key-derivation function KDF to the two inputs Z and OtherInput. K ← KDF(Z, OtherInput). (12)\n\n2. Two-step key derivation. In this case, two functions are required: Extract (which is a randomness extractor) and Expand. The process begins with applying Extract to Z using a salt provided in OtherInput as the seed. Expand is then applied to the result along with FixedInfo, which is also provided in OtherInput. K ← Expand Extract salt FixedInfo ( ( , Z), ). (13) In this method, it is required that extraction is applied to the shared secret Z. SP 800-56C describes the specific approved choices of KDF, Extract, and Expand as well as the format and content of OtherInput. These details will not be discussed in this document. As discussed in Sec. 4.3, this publication approves the application of SP 800-56C KDMs to the shared secret keys of approved KEMs. In particular, this means that the quantity Z in Equation (11) (and hence, also in (12) and (13)) can be the shared secret key of an approved KEM.\n\nKey combiners derived from SP 800-56C. In both one-step and two-step key derivation, SP 800-56C allows the shared secret Z to have the form Z = (S1, S2), where S1 is a shared\n\nsecret generated as specified in SP 800-56A [1] or SP 800-56B [2], while S2 is a shared secret generated in some other (not necessarily approved) manner. This yields a key combiner K ← KDM((S1, S2), OtherInput) for a two-algorithm key-establishment scheme. One can also combine many shared secrets:\n\nK ← KDM((S1, S2, · · · , St ), OtherInput). (14)", "char_len": 3489, "approx_tokens": 872}
{"chunk_id": "NIST.SP.800-227::c00025", "doc_id": "NIST.SP.800-227", "start_page": 37, "end_page": 39, "text": "also in (12) and (13)) can be the shared secret key of an approved KEM.\n\nKey combiners derived from SP 800-56C. In both one-step and two-step key derivation, SP 800-56C allows the shared secret Z to have the form Z = (S1, S2), where S1 is a shared\n\nsecret generated as specified in SP 800-56A [1] or SP 800-56B [2], while S2 is a shared secret generated in some other (not necessarily approved) manner. This yields a key combiner K ← KDM((S1, S2), OtherInput) for a two-algorithm key-establishment scheme. One can also combine many shared secrets:\n\nK ← KDM((S1, S2, · · · , St ), OtherInput). (14)\n\nThis publication approves the use of the key combiner (14) for any t > 1 if at least one shared secret (i.e., S j for some j) is generated from the key-establishment methods in SP 800-56A [1] or SP 800-56B [2] or an approved KEM. If the KDM in the combiner (14) is a two-step method (i.e., using (13)), extraction is performed with all shared secrets as the input. SP 800-56C allows OtherInput to contain an input that is chosen arbitrarily by the protocol specification. This optional input is contained in a parameter called FixedInfo in SP 800-56C. By choosing FixedInfo appropriately, one can also construct approved key combiners of the form (14) that receive inputs in addition to shared secrets, such as encapsulation keys, ciphertexts, parameter sets, and domain separators. Several key combiners can be generated according to Expression (14). As a simple example, consider the following special case. Choose KDM to be the one-step key-derivation method, where KDF is an approved hash function. Set OtherInput to contain the list of ciphertexts and encapsulation keys together with a domain separator domain_sep (possibly including the parameter set p). Define a key combiner algorithm KeyCombine simply by setting\n\nKeyCombine(K1, K2, c1, c2, ek1, ek2, p) := H(K1, K2, c1, c2, ek1, ek2, domain_sep). (15)\n\nOne can then instantiate the composite KEM example from Sec. 4.6 by using this key combiner. The resulting composite KEM will have a shared secret key whose length is the output length of H.\n\nKey combiners derived from SP 800-133. SP 800-133 [18] provides three approved methods for combining cryptographic keys that were generated in an approved way. These methods can be broadly described as concatenation, XORing, and key extraction using HMAC. Some of these methods can also be applied to just a single key. As discussed in Sec. 4.3, these methods are approved for key derivation for approved KEMs. When combining multiple keys K1, K2, . . . , Kt , the key-combination methods found in SP 800-133 [18] require every key K j for j ∈ {1, 2, . . . , t } to be generated using approved methods. These methods can be used directly as key combiners for constructing multialgorithm schemes in cases where all of the component schemes are approved, and each one produces a key. Any protocol using multi-algorithm KEMs with a concatenation key combiner should ensure that the final shared secret key from the key combiner is passed through a KDF before use.\n\n4.6.3. Security Considerations for Composite Schemes The typical goal of a composite KEM construction is to ensure that security will hold if any of the component KEMs is secure. There are some important security considerations when constructing composite KEMs.\n\nTheoretical security. The two main security properties that KEMs can satisfy (see Sec. 2.3) are: 1. IND-CPA security (i.e., security against passive eavesdropping attacks) 2. IND-CCA security (i.e., security against active attacks) A well-constructed composite KEM C[Π1, Π2] should preserve the security properties of its component KEMs Π1 and Π2. This crucially depends on how the composite KEM is constructed and the choice of the key combiner. An important example is when the goal is active (i.e., IND-CCA) security, but only one of the two schemes Π1 and Π2 is itself IND-CCA, and the designer of the composite scheme may not know which one it is.", "char_len": 3982, "approx_tokens": 995}
{"chunk_id": "NIST.SP.800-227::c00026", "doc_id": "NIST.SP.800-227", "start_page": 39, "end_page": 41, "text": "s that KEMs can satisfy (see Sec. 2.3) are: 1. IND-CPA security (i.e., security against passive eavesdropping attacks) 2. IND-CCA security (i.e., security against active attacks) A well-constructed composite KEM C[Π1, Π2] should preserve the security properties of its component KEMs Π1 and Π2. This crucially depends on how the composite KEM is constructed and the choice of the key combiner. An important example is when the goal is active (i.e., IND-CCA) security, but only one of the two schemes Π1 and Π2 is itself IND-CCA, and the designer of the composite scheme may not know which one it is. In this case, the choice of the key combiner is particularly relevant. As shown in [24], the straightforward key combiner\n\nK ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-\n\ncapsulation keys can have other potential advantages in secure protocols, such as binding the final shared secret to the identities of the participating parties.\n\nSecurity in practice. While composite schemes are meant to increase security, they necessarily add a layer of additional complexity to the basic KEM framework. This additional complexity will be reflected in implementations and applications and could introduce security vulnerabilities. Moreover, adding composite schemes introduces additional choices in protocols, which could also introduce vulnerabilities (e.g., in the form of “downgrade attacks”). Implementers and users should be aware of the potential challenges in implementing and deploying composite schemes.\n\n5. Examples\n\nThis section is meant to help readers understand some aspects of how KEMs are constructed. It only provides examples, not requirements or specific guidelines.\n\n5.1. Examples of KEMs The following subsections discuss three key-encapsulation mechanisms: ECDH-KEM, RSA- KEM, and ML-KEM. While ECDH and RSA key transport are not typically described as KEMs, the discussions below will give a high-level description of how both can be naturally viewed as KEMs. The goal of these descriptions is illustrative only. As FIPS 203 already contains a complete description of ML-KEM, the discussion below will simply reference the relevant parts of FIPS 203 [3].", "char_len": 3441, "approx_tokens": 860}
{"chunk_id": "NIST.SP.800-227::c00027", "doc_id": "NIST.SP.800-227", "start_page": 41, "end_page": 42, "text": "e aspects of how KEMs are constructed. It only provides examples, not requirements or specific guidelines.\n\n5.1. Examples of KEMs The following subsections discuss three key-encapsulation mechanisms: ECDH-KEM, RSA- KEM, and ML-KEM. While ECDH and RSA key transport are not typically described as KEMs, the discussions below will give a high-level description of how both can be naturally viewed as KEMs. The goal of these descriptions is illustrative only. As FIPS 203 already contains a complete description of ML-KEM, the discussion below will simply reference the relevant parts of FIPS 203 [3].\n\n5.1.1. A KEM From Diffie-Hellman A KEM may be constructed from a Diffie-Hellman (DH) key-agreement scheme. The highlevel idea is that, if the two parties in a DH scheme send their messages in sequential order (e.g., Alice first, then Bob), then: 1. The public message and private randomness of Alice can be viewed as an encapsu- lation key and a decapsulation key, respectively, and 2. The public message of Bob can be viewed as a ciphertext. For example, a KEM can be constructed from the C(1e, 1s, ECC CDH) Scheme from SP 800- 56A [1] as follows: • ECDH-KEM.ParamSets. The parameter sets are the same as those specified for ECDH in Sec. 5.5.1.2 of SP 800-56A. • ECDH-KEM.KeyGen. The key-generation algorithm is the same as the one specified in Sec. 5.6.1.2 of SP 800-56A. Alice generates a static key pair and makes the static public key available as the encapsulation key. Bob generates an ephemeral key pair when initiating the key establishment with Alice. • ECDH-KEM.Encaps. To encapsulate, perform Party U’s actions from Sec. 6.2.2.2 of SP 800-56A. The output is the key (i.e., the derived secret keying material) along with the ciphertext (i.e., the ephemeral public key Qe,U ). • ECDH-KEM.Decaps. To decapsulate, perform Party V’s actions from Sec. 6.2.2.2 of SP 800-56A. The output key is the derived secret keying material. The use of this KEM requires that all assumptions for the scheme specified in SP 800-56A are met and that all necessary assurances have been obtained. This KEM is IND-CPAsecure if the computational Elliptic Curve Diffie Hellman problem is hard for parameter set ParamSets. The computational Elliptic Curve Diffie Hellman problem is efficiently solved by\n\na quantum computer so this KEM is considered to be quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCA-secure. In similar ways, KEMs could be constructed from the C(1e, 1s, FFC DH), C(2e, 0s, ECC CDH), and C(2e, 0s, FFC DH) schemes.\n\n5.1.2. A KEM From RSA Secret-Value Encapsulation As discussed in Sec. 2.2, any PKE scheme can be used to construct a KEM. A concrete example of this is RSA Secret-Value Encapsulation (RSASVE)4 with an agreed-upon key-derivation method applied to the shared secret value Z to derive a shared secret key. The high-level idea is described as follows: 1. Alice sends an RSA public key to Bob. Optionally, Alice can also send some other public information to Bob, such as a nonce for key derivation. 2. Bob generates a secret value and encapsulates it with Alice’s RSA public key to pro- duce the ciphertext. A key is derived from the secret value. The output of encapsu- lation is the ciphertext and the derived key. The ciphertext is sent to Alice. 3. Alice decapsulates the ciphertext using her RSA private key to obtain the secret value that is used to derive the key. For example, a KEM can be constructed from RSASVE from SP 800-56B [2] as follows: 1. RSASVE-KEM.ParamSets. The parameter set is the binary length of the modulus (specified in Table 2, Sec. 6.3 of SP 800-56B) along with the exponent e. 2. RSASVE-KEM.KeyGen. The key-generation algorithm is specified in Sec. 6.3 of SP 800-56B (also see Appendix C.2 of FIPS 186-5). 3. RSASVE-KEM.Encaps. To encapsulate, Bob (in his role as Party U) performs RSASVE.GENERATE, as specified in Sec. 7.2.1.2 of SP 800-56B. The output is the ci- phertext and a secret value Z.", "char_len": 3980, "approx_tokens": 995}
{"chunk_id": "NIST.SP.800-227::c00028", "doc_id": "NIST.SP.800-227", "start_page": 42, "end_page": 43, "text": "secret value that is used to derive the key. For example, a KEM can be constructed from RSASVE from SP 800-56B [2] as follows: 1. RSASVE-KEM.ParamSets. The parameter set is the binary length of the modulus (specified in Table 2, Sec. 6.3 of SP 800-56B) along with the exponent e. 2. RSASVE-KEM.KeyGen. The key-generation algorithm is specified in Sec. 6.3 of SP 800-56B (also see Appendix C.2 of FIPS 186-5). 3. RSASVE-KEM.Encaps. To encapsulate, Bob (in his role as Party U) performs RSASVE.GENERATE, as specified in Sec. 7.2.1.2 of SP 800-56B. The output is the ci- phertext and a secret value Z. Bob applies the agreed-upon key-derivation method to the secret value Z to derive a shared secret key. 4. RSASVE-KEM.Decaps. To decapsulate, Alice (in her role as Party V) performs RSASVE.RECOVER using the ciphertext from Bob, as specified in Sec. 7.2.1.3 of SP 800-56B. The output is the secret value Z. Alice applies the agreed-upon key- derivation method to the secret value Z to derive a shared secret key. Using this KEM requires that all assumptions for the scheme specified in SP 800-56B are met and that all necessary assurances have been obtained. This KEM is IND-CPA-secure if the computational RSA problem is hard for parameter set ParamSets. The computational RSA problem is efficiently solved by a quantum computer so this KEM is considered to be\n\n4Note that RSASVE is NOT a standalone approved scheme. It is a component of the approved KAS1 and KAS2 schemes.\n\nquantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications This section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption A KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for PKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15].", "char_len": 3760, "approx_tokens": 940}
{"chunk_id": "NIST.SP.800-227::c00029", "doc_id": "NIST.SP.800-227", "start_page": 43, "end_page": 45, "text": "the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications This section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption A KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for PKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15].\n\nThe prescription for constructing a KEM-DEM PKE scheme is as follows. Let Π be a KEM, and let Ξ = (Encrypt, Decrypt) be a symmetric-key encryption scheme. One then constructs a PKE called KD-PKE as follows: • KD-PKE.ParamSets = Π.ParamSets • KD-PKE.KeyGen = Π.KeyGen • KD-PKE.Encrypt: given input parameter set p, ek, and message m: 1. Compute (K, cΠ) ← Π.Encaps(p, ek). 2. Compute cΞ ← Ξ.Encrypt(K, m). 3. Output (cΠ, cΞ). • KD-PKE.Decrypt: given input p, dk, and (cΠ, cΞ), 1. Compute K′ ← Π.Decaps(p, dk, cΠ). 2. Output m′ ← Ξ.Decrypt(K′, cΞ). Here, the keys of Ξ are assumed to be the same length as the shared secret keys produced by Π. If not, appropriate key-derivation steps (see Sec. 4.3) can be added to KD-PKE.Encrypt and KD-PKE.Decrypt to transform the shared secret key of Π into a key that is appropriate for use with Ξ. Figure 7 shows the procedure for sending an encrypted message m from Bob to Alice using KD-PKE. In this description, Alice selects the parameter set p.\n\nAlice Bob (ek, dk) ← Π.KeyGen( p) − ek, p − − − − − − −→ (K, cΠ) ← Π.Encaps( p, ek) cΞ ← Ξ.Encrypt(K, m) ←− cΠ, cΞ − − − − − − − K′ ← Π.Decaps( p, dk, cΠ) m ← Ξ.Decrypt(K′, cΞ)\n\nFig. 7. Sending a message using the KEM-DEM paradigm\n\nThis same procedure can also be used to perform key transport by choosing m uniformly at random as the key to be transported. This allows one to perform key transport using any KEM, even one that does not natively perform key transport (e.g., ML-KEM).\n\n5.2.2. Unilateral Authenticated Key Establishment Using a KEM Most applications of key establishment require at least one party (typically, a server) to authenticate their identity. One approach to achieving this is for the server to acquire a certificate of authenticity for their long-term, static KEM encapsulation key. This certificate can then be provided to a client as proof that the key is associated with the server’s identity. An example description of key establishment in this setting is given below and depicted in Fig. 8. The example uses a simplified key confirmation process (see Sec. 4.4).\n\nAlice (server) Bob (client) 1. static: (ek, dk) cert[ek, p, Alice] −cert[ek, p, Alice] − − − − − − − − −→ 2. if cert[ek, p, Alice] invalid, abort. (KB, c) ← Π.Encaps( p, ek) ←− c − − − − − − − − − − 3. KA ← Π.Decaps( p, dk, c) 4. t ← MAC(KA, c) − t − − − − − − − − −→ if MAC.Ver(KB, c,t) rejects, abort. 5. result: KA result: KB\n\nFig. 8. Unilateral authenticated key establishment using a KEM\n\n1. At the outset, Alice has a long-term, static key pair that she generated earlier via (ek, dk) ← Π.KeyGen(p). Here, Π is some KEM, and p is some parameter set of Π. Alice also has a certificate cert[ek, p, Alice] that contains ek and p and associates them both with Alice’s identity. 2. When Bob wants to connect to Alice, he acquires cert[ek, p, Alice] (e.g., from Alice), verifies that the certificate is valid, and extracts ek and p from the certificate. He then performs encapsulation with ek, saves the resulting shared secret key KB, and sends the ciphertext c to Alice. 3. Alice decapsulates c and gets a shared secret key KA. 4. Alice and Bob then perform a simplified key-confirmation step. Alice uses a MAC algorithm to generate a tag t ← MAC(KA, c) for the ciphertext c and sends t to Bob. Bob then runs MAC verification using KB and aborts unless the tag t is accepted.", "char_len": 3957, "approx_tokens": 989}
{"chunk_id": "NIST.SP.800-227::c00030", "doc_id": "NIST.SP.800-227", "start_page": 45, "end_page": 47, "text": ". 2. When Bob wants to connect to Alice, he acquires cert[ek, p, Alice] (e.g., from Alice), verifies that the certificate is valid, and extracts ek and p from the certificate. He then performs encapsulation with ek, saves the resulting shared secret key KB, and sends the ciphertext c to Alice. 3. Alice decapsulates c and gets a shared secret key KA. 4. Alice and Bob then perform a simplified key-confirmation step. Alice uses a MAC algorithm to generate a tag t ← MAC(KA, c) for the ciphertext c and sends t to Bob. Bob then runs MAC verification using KB and aborts unless the tag t is accepted. If the tag is accepted, Bob knows that Alice’s key KA and his key KB are the same (i.e., they share the same key).\n\n5. Alice and Bob can now use their shared secret key to communicate efficiently and securely using symmetric-key cryptography. If the KEM Π is secure, then only a holder of the decapsulation key dk (corresponding to the encapsulation key ek in the certificate) should be able to generate a valid MAC tag in step 4.\n\n5.2.3. Ephemeral Authenticated Key Establishment This section describes an alternative approach to unilaterally authenticated key establishment using a KEM. Compared to the example in Sec. 5.2.2, Alice and Bob will now have the opposite roles in the protocol. Specifically, Bob is now the authenticated party (e.g., a web server), while Alice is the unauthenticated party (e.g., a browser client). Ephemeral KEM key-pair generation will now be performed by the client (i.e., Alice), and Alice will discard the KEM key pair once the connection is established. The server will not use a long-term, static KEM key pair but will need to establish his identity through other means. In this example, identity establishment will be done via a certificate that associates a particular digital signature verification key with Bob’s identity. The following ingredients are required. Let Σ be a digital signature scheme with algorithms Σ.KeyGen, Σ.Sign, and Σ.Ver. As before, KEM key pairs are denoted by (ek, dk). Digital signature key pairs are denoted by (vk, sk), where vk is a public verification key and sk is the corresponding private signing key. The protocol proceeds as follows (see Fig. 9.) 1. At the outset, Bob has previously generated a static digital signature key pair (vkB, skB) and procured a certificate cert[vkB, Bob] that associates the public veri- fication key with his identity. 2. When connecting to Bob, Alice generates an ephemeral KEM key pair (ekA, dkA) and sends the encapsulation key ekA and her chosen parameter set p to Bob, keeping the decapsulation key dkA private. 3. Bob performs encapsulation using ekA, which results in a KEM ciphertext cB and a shared secret key KB. Bob then uses his private signing key skB to sign the transcript of all communications with Alice, including what he will send in this transmission. This transcript includes ekA, p, vkB, cB, and Bob’s certificate cert[vkB, Bob]. He then sends the certificate, signature, and ciphertext to Alice. Finally, he applies a key- derivation function KDF to KB in order to produce two symmetric keys K′ and K′′, destroys KB, and keeps K′ and K′′ private. B B B B 4. Next, Alice performs two checks. First, she checks the validity of Bob’s claimed cer- tificate with the appropriate certification authority. Second, she verifies Bob’s signa- ture on the transcript. If either check fails, Alice aborts. Otherwise, she decapsulates\n\nAlice (client) Bob (server) 1. static: (vkB, skB) cert[vkB, Bob] 2. (ekA, dkA) ← Π.KeyGen( p) − ekA, p − − − − − − − − − −→ 3. (KB, cB) ← Π.Encaps( p, ekA) σ ← Σ.Sign(skB, transcript) (K′ , K′′) ← KDF(KB) B B cert[vkB, Bob], σ, cB ←− − − − − − − − − − − 4. if cert[vkB, Bob] invalid, abort. if Σ.Ver(vkB, σ, transcript) = ⊥, abort. KA ← Π.Decaps( p, dkA, cB)\n\n(K′ , K′′) ← KDF(KA) A A\n\n5. result: K′ , K′′ result: K′ , K′′ A A B B\n\nFig. 9. Using a KEM for key establishment with unilateral authentication", "char_len": 3955, "approx_tokens": 988}
{"chunk_id": "NIST.SP.800-227::c00031", "doc_id": "NIST.SP.800-227", "start_page": 46, "end_page": 48, "text": "na- ture on the transcript. If either check fails, Alice aborts. Otherwise, she decapsulates\n\nAlice (client) Bob (server) 1. static: (vkB, skB) cert[vkB, Bob] 2. (ekA, dkA) ← Π.KeyGen( p) − ekA, p − − − − − − − − − −→ 3. (KB, cB) ← Π.Encaps( p, ekA) σ ← Σ.Sign(skB, transcript) (K′ , K′′) ← KDF(KB) B B cert[vkB, Bob], σ, cB ←− − − − − − − − − − − 4. if cert[vkB, Bob] invalid, abort. if Σ.Ver(vkB, σ, transcript) = ⊥, abort. KA ← Π.Decaps( p, dkA, cB)\n\n(K′ , K′′) ← KDF(KA) A A\n\n5. result: K′ , K′′ result: K′ , K′′ A A B B\n\nFig. 9. Using a KEM for key establishment with unilateral authentication\n\ncB and keeps the resulting shared secret key KA private. She also derives two keys K′ and K′′ via KDF applied to KA and destroys KA. A A 5. Alice and Bob can now use the keys K′ and K′′ for symmetric-key cryptography. For example, they could use K′ for A A ′′ A encryption and KA for authentication.\n\n5.2.4. Static-Ephemeral Unilateral Authenticated Key Establishment Using KEMs This section presents a static-ephemeral key-establishment scheme with unilateral authen- tication, as described in [32]. The scheme combines a shared secret key generated by a static KEM key pair with a shared secret key produced by a freshly generated, ephemeral KEM key pair. Just as in Example 5.2.2, one party possesses a static KEM key pair that is associated with a certificate. In this example, Alice and Bob’s key pairs are generated using the same KEM Π and param- eter set p. In this case, Π and p are determined by Bob’s certificate. Note that Bob may use the same static key pair to perform key establishment with many different parties. To see how different KEMs might be used within one authenticated key-establishment scheme, see Example 5.2.5.\n\nKEMTLS is a protocol with similar elements to this example, though it includes additional features that are not presented here [33]. In particular, KEMTLS utilizes KEM-based authentication and also combines two shared secret keys: one generated by a static KEM key pair and one by an ephemeral KEM key pair. In this example, H denotes a KDF, and Bob is authenticated while Alice is not. Note that the choice of KDF for H in [32] is a cryptographic hash function. There is no key-confirmation step in this scheme, but one may easily incorporate such a step if desired.\n\nAlice (client) Bob (server) 1. static: (ekB, dkB) cert[ekB, p, Bob] cert[ekB, p, Bob] ←− − − − − − − − − − 2. if cert[ekB, p, Bob] invalid, abort. (ek, dk) ← Π.KeyGen( p) (KB, cB) ← Π.Encaps( p, ekB) − ek, p, cB − − − − − − − − − −→ 3. (K, c) ← Π.Encaps( p, ek) K′ ← Π.Decaps( p, dkB, cB) B ←− c − − − − − − − − − − 4. K′ ← Π.Decaps( p, dk, c)\n\n5. result: H(K′, KB) result: H(K, K′ ) B\n\nFig. 10. Static-ephemeral unilateral authenticated key establishment using KEMs\n\n1. At the outset, Bob has a long-term, static key pair that he generated earlier via (ekB, dkB) ← Π.KeyGen(p). Here, Π is some KEM, and p is some parameter set of Π. Bob also has a certificate cert[ekB, p, Bob] that contains ekB and p and associates them both with Bob’s identity. 2. When Alice wants to connect to Bob, she acquires cert[ekB, p, Bob] (e.g., from Bob), verifies that the certificate is valid, and extracts ekB and p from the certificate. She then performs encapsulation with ekB, saves the resulting shared secret key KB, and sends the ciphertext cB to Bob. Alice additionally generates an ephemeral KEM key pair (ek, dk) using the same KEM Π and parameter set p and sends the encapsulation key ek and relevant parameter set p to Bob, keeping the private decapsulation key dk private.", "char_len": 3578, "approx_tokens": 894}
{"chunk_id": "NIST.SP.800-227::c00032", "doc_id": "NIST.SP.800-227", "start_page": 48, "end_page": 50, "text": "p, Bob] that contains ekB and p and associates them both with Bob’s identity. 2. When Alice wants to connect to Bob, she acquires cert[ekB, p, Bob] (e.g., from Bob), verifies that the certificate is valid, and extracts ekB and p from the certificate. She then performs encapsulation with ekB, saves the resulting shared secret key KB, and sends the ciphertext cB to Bob. Alice additionally generates an ephemeral KEM key pair (ek, dk) using the same KEM Π and parameter set p and sends the encapsulation key ek and relevant parameter set p to Bob, keeping the private decapsulation key dk private.\n\n3. Bob uses (p, ek) to perform encapsulation, which results in a KEM ciphertext c and shared secret key K. Bob also performs decapsulation using (p, dkB, cB) to produce another shared secret key K′ . Bob sends ciphertext c to Alice. B 4. Alice uses c, p, and dk to run decapsulation and recover her copy of the ephemeral shared secret key K′. 5. Alice and Bob combine their copies of the shared ephemeral secret key K′ (K) and the shared secret key KB (K′ ) that was computed using Bob’s static key pair. A hash function H is applied to theB result to establish a final shared secret key. It is assumed that if the certificate is valid, then only Bob is capable of performing decapsulation of ciphertexts that were encapsulated using ekB.\n\n5.2.5. Authenticated Key Establishment Using KEMs This section presents a bilaterally authenticated key-establishment scheme using KEMs, as described in [32]. In this example, both Alice and Bob are authenticated using static KEM key pairs associated with certificates. The KEM shared secret keys produced using their static key pairs contribute to the final key and a shared secret key produced using a freshly generated ephemeral KEM key pair. This scheme achieves weak forward secrecy [32, 34]. Alice’s static key pair may correspond to a different KEM than the one associated with Bob’s static key pair as the choices of KEM and parameter set used by Alice and Bob are determined by their certificates. As such, both parties must be able to operate using each other’s KEM encapsulation algorithm. Moreover, the ephemeral KEM key pair may correspond to a third, completely different KEM. To capture this possibility, let (ΠA, pA), (ΠB, pB), and (Π, p) denote the KEM algorithm and parameter set associated with Alice’s static key pair, Bob’s static key pair, and the ephemeral KEM key pair, respectively. This notation allows for the possibility that ΠA = ΠB = Π and pA = pB = p. Additionally, parameter sets are formatted differently for different KEMs (e.g., lattice-based KEMs might include lattice dimension, while code-based KEMs include code length and dimension). Therefore, if two KEMs Πi and Π j are distinct, the corresponding parameter sets are likely also distinct. As with other examples, Alice and Bob will need to negotiate which KEM Π and parameter set p they will use for the ephemeral key pair prior to protocol execution. As in Example 5.2.3, H denotes a KDF. Note that in [32] H is chosen to be a cryptographic hash function. There is no key-confirmation step included in this example, but one could be added. 1. At the outset, Alice and Bob each have a long-term, static key pair. Al- ice has (ekA, dkA), and Bob has (ekB, dkB), which were generated earlier via ΠA.KeyGen(pA) and ΠB.KeyGen(pB), respectively. Alice and Bob also have certifi- cates cert[ekA, pA, Alice] and cert[ekB, pB, Bob], respectively, which contain their cor- responding public keys and associate them to their respective identities.\n\nAlice (client) Bob (server) 1. static: (ekA, dkA) static: (ekB, dkB) cert[ekA, pA, Alice] cert[ekB, pB, Bob]", "char_len": 3678, "approx_tokens": 919}
{"chunk_id": "NIST.SP.800-227::c00033", "doc_id": "NIST.SP.800-227", "start_page": 49, "end_page": 52, "text": "nction. There is no key-confirmation step included in this example, but one could be added. 1. At the outset, Alice and Bob each have a long-term, static key pair. Al- ice has (ekA, dkA), and Bob has (ekB, dkB), which were generated earlier via ΠA.KeyGen(pA) and ΠB.KeyGen(pB), respectively. Alice and Bob also have certifi- cates cert[ekA, pA, Alice] and cert[ekB, pB, Bob], respectively, which contain their cor- responding public keys and associate them to their respective identities.\n\nAlice (client) Bob (server) 1. static: (ekA, dkA) static: (ekB, dkB) cert[ekA, pA, Alice] cert[ekB, pB, Bob]\n\n−cert[ekA, pA, Alice] − − − − − − − − − −→ cert[ekB, pB, Bob] ←− − − − − − − − − − − 2. if cert[ekB, pB, Bob] invalid, abort. if cert[ekA, pA, Alice] invalid, abort. (ek, dk) ← Π.KeyGen( p) (KB, cB) ← ΠB.Encaps( pB, ekB) − ek, cB − − − − − − − − − −→ 3. (K, c) ← Π.Encaps( p, ek) (KA, cA) ← ΠA.Encaps( pA, ekA) K′ ← ΠB.Decaps( pB, dkB, cB) B ←− c, cA − − − − − − − − − − 4. K′ ← Π.Decaps( p, dk, c) K′ ← ΠA.Decaps( pA, dkA, cA) A\n\n5. result: H(K′, K′ , KB) result: H(K, KA, K′ ) A B\n\nFig. 11. Authenticated key establishment using KEMs\n\n2. When Alice wants to connect to Bob, she acquires cert[ekB, pB, Bob] (e.g., from Bob), verifies that the certificate is valid, and extracts ekB, pB from the certificate. Bob also acquires and verifies Alice’s certificate in this step. Alice then performs encapsulation with Bob’s static public key ekB, saves the result- ing shared secret key KB, and sends the ciphertext cB to Bob. Alice additionally gen- erates an ephemeral KEM key pair (ek, dk) and sends the encapsulation key ek and relevant parameter set p to Bob, keeping the private decapsulation key dk private. 3. Bob uses (p, ek) to perform encapsulation, which results in a KEM ciphertext c and shared secret key K. Bob extracts ekA and pA from Alice’s certificate and then per- forms encapsulation with ekA and pA to generate KA and cA. Bob also performs decapsulation using (pB, dkB, cB) to produce another shared se- cret key K′ . Bob sends ciphertexts c and cA to Alice. B 4. Alice uses c, p, and dk to run decapsulation and recover her copy of the ephemeral shared secret key K′. Alice additionally uses cA, pA, and dkA to run decapsulation and recover her copy of the long-term shared secret key K′ . A\n\n5. Alice and Bob combine their copies of the shared ephemeral secret key K′ (K) and static shared secret keys K′ and KB (KA and K′ .) and apply a KDF H to establish a final shared secret key. A B\n\nReferences\n\n[1] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R (2018) Recommendation for Pair-Wise Key-Establishment Schemes Using Discrete Logarithm Cryptography (Depart-ment of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-56Ar3. https://doi.org/10.6028/NIST.SP.800-56Ar3 [2] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R, Simon S (2019) Recommendation for Pair-Wise Key-Establishment Using Integer Factorization Cryptography (Depart-ment of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-56Br2. https://doi.org/10.6028/NIST.SP.800-56Br2 [3] National Institute of Standards and Technology (2024) Module-Lattice-Based Key- Encapsulation Mechanism Standard (Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publications (FIPS) NIST FIPS 203. https://doi.org/10.6028/NIST.FIPS.203 [4] Moody D, Perlner R, Regenscheid A, Robinson A, Cooper D (2024) Transition to Post- Quantum Cryptography Standards (Department of Commerce, Washington, D.C.), NIST Internal Report (IR) NIST IR 8547ipd. https://doi.org/10.6028/NIST.IR.8547.ipd [5] National Institute of Standards and Technology (2019) Security Requirements for Cryptographic Modules (Department of Commerce, Washington, D.C.), Federal In- formation Processing Standards Publications (FIPS) NIST FIPS 140-3,.", "char_len": 3857, "approx_tokens": 964}
{"chunk_id": "NIST.SP.800-227::c00034", "doc_id": "NIST.SP.800-227", "start_page": 52, "end_page": 53, "text": ", D.C.), Federal Information Processing Standards Publications (FIPS) NIST FIPS 203. https://doi.org/10.6028/NIST.FIPS.203 [4] Moody D, Perlner R, Regenscheid A, Robinson A, Cooper D (2024) Transition to Post- Quantum Cryptography Standards (Department of Commerce, Washington, D.C.), NIST Internal Report (IR) NIST IR 8547ipd. https://doi.org/10.6028/NIST.IR.8547.ipd [5] National Institute of Standards and Technology (2019) Security Requirements for Cryptographic Modules (Department of Commerce, Washington, D.C.), Federal In- formation Processing Standards Publications (FIPS) NIST FIPS 140-3,. https://doi.org/ 10.6028/NIST.FIPS.140-3 [6] Barker EB, Kelsey J (2015) Recommendation for Random Number Generation Using Deterministic Random Bit Generators (Department of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-90Ar1. https://doi.org/10.6028/ NIST.SP.800-90Ar1 [7] Sönmez Turan M, Barker E, Kelsey J, McKay K, Baish M, Boyle M (2018) Recom- mendation for the Entropy Sources Used for Random Bit Generation (Department of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-90B. https://doi.org/10.6028/NIST.SP.800-90B [8] Barker EB, Kelsey JM, McKay KA, Roginsky AL, Sönmez Turan M (2025) Recommenda- tion for Random Bit Generator (RBG) Constructions (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-90C. https://doi.org/10.6028/NIST.SP.800-90C [9] Dworkin M (2007) Recommendation for Block Cipher Modes of Operation: Ga- lois/Counter Mode (GCM) and GMAC (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-38D. https://doi.org/ 10.6028/NIST.SP.800-38D [10] Barker E, Branstad D, Smid M (2015) A Profile for U.S. Federal Cryptographic Key Man-agement Systems (CKMS) (National Institute of Standards and Technology, Gaithers-burg, MD), NIST Special Publication (SP) NIST SP 800-152. https:// doi.org/10.6028/NIST.SP.800-152\n\n[11] Shoup V (2001) A Proposal for an ISO Standard for Public Key Encryption, Cryptology ePrint Archive, Paper 2001/112. Available at https://eprint.iacr.org/2001/112. [12] Cramer R, Shoup V (2003) Design and analysis of practical public-key encryption schemes secure against adaptive chosen ciphertext attack. SIAM Journal on Comput- ing 33(1):167–226. https://doi.org/10.1137/S0097539702403773 [13] Herranz J, Hofheinz D, Kiltz E (2006) Some (in)sufficient conditions for secure hybrid encryption, Cryptology ePrint Archive, Paper 2006/265. Available at https://eprint.i acr.org/2006/265. [14] Brainard J, Kaliski B, Turner S, Randall J (2010) Use of the RSA-KEM Key Transport Algorithm in the Cryptographic Message Syntax (CMS), RFC 5990. https://doi.org/ 10.17487/RFC5990. [15] American National Standards Institute (2011) ANSI X9.63-2011, (R2017) - Public Key Cryptography for the Financial Services Industry: Key Agreement and Key Transport Using Elliptic Curve Cryptography (Accredited Standards Committee X9, Annapolis, MD). Available at https://webstore.ansi.org/standards/ascx9/ansix9442007r2017. [16] American National Standards Institute (2007) ANSI X9.44-2007 (R2017), Public Key Cryptography for the Financial Services Industry: Key Establishment Using Integer Factorization Cryptography (Accredited Standards Committee X9, Annapolis, MD). Available at https://webstore.ansi.org/standards/ascx9/ansix9442007r2017. [17] Katz J, Lindell Y (2020) Introduction to Modern Cryptography (Chapman & Hall/CRC, Boca Raton, FL), 3rd Ed. [18] Barker EB, Roginsky A, Davis R (2020) Recommendation for Cryptographic Key Gen- eration (Department of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-133r2. https://doi.org/10.6028/NIST.SP.800-133r2 [19] Barker E (2020) Recommendation for Key Management: Part 1 – General (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-57pt1r5.", "char_len": 3954, "approx_tokens": 988}
{"chunk_id": "NIST.SP.800-227::c00035", "doc_id": "NIST.SP.800-227", "start_page": 53, "end_page": 54, "text": "ble at https://webstore.ansi.org/standards/ascx9/ansix9442007r2017. [17] Katz J, Lindell Y (2020) Introduction to Modern Cryptography (Chapman & Hall/CRC, Boca Raton, FL), 3rd Ed. [18] Barker EB, Roginsky A, Davis R (2020) Recommendation for Cryptographic Key Gen- eration (Department of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-133r2. https://doi.org/10.6028/NIST.SP.800-133r2 [19] Barker E (2020) Recommendation for Key Management: Part 1 – General (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-57pt1r5. https://doi.org/10.6028/NIST.SP.800-57pt1r5 [20] Chen L (2022) Recommendation for Key Derivation Using Pseudorandom Functions (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-108r1-upd1, Includes updates as of February 2, 2024. https://doi.org/10.6028/NIST.SP.800-108r1-upd1 [21] Barker EB, Chen L, Davis R (2020) Recommendation for Key-Derivation Methods in Key-Establishment Schemes (Department of Commerce, Washington, D.C.), NIST Spe- cial Publication (SP) NIST SP 800-56Cr2. https://doi.org/10.6028/NIST.SP.800-56Cr2 [22] Brockhaus H, von Oheimb D, Ounsworth M, Gray J (2025) Internet X.509 Public Key Infrastructure – Certificate Management Protocol (CMP), RFC 9810. https://doi.org/ 10.17487/RFC9810. [23] Driscoll F, Parsons M, Hale B (2024) Terminology for Post-Quantum Traditional Hy- brid Schemes (Internet Engineering Task Force), Internet-Draft draft-ietf-pquip-pqt- hybrid-terminology-05. Work in Progress. Available at https://datatracker.ietf.org/d oc/draft-ietf-pquip-pqt-hybrid-terminology/05/.\n\n[24] Barbosa M, Connolly D, Duarte JD, Kaiser A, Schwabe P, Varner K, Westerbaan B (2024) X-Wing. IACR Communications in Cryptology 1(1). https://doi.org/10.62056/a3qj89n 4e [25] Giacon F, Heuer F, Poettering B (2018) KEM combiners. Public-Key Cryptography – PKC 2018, eds Abdalla M, Dahab R (Springer International Publishing, Cham), pp 190–218. [26] Avanzi R, Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashekvsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2021) CRYSTALS-Kyber Algorithm Specifications and Supporting Documentation (version 3.02). Available at https://pq-crystals.org/kyber/data/kyb er-specification-round3-20210804.pdf. [27] Avanzi R, Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehlé D (2020) CRYSTALS-Kyber Algorithm Specifications and Supporting Documentation, Third-round submission to the NIST’s post-quantum cryptography standardization process. Available at https://csrc.nist.gov/Projects/post-quantum-c ryptography/post-quantum-cryptography-standardization/round-3-submissions. [28] Almeida JB, Olmos SA, Barbosa M, Barthe G, Dupressoir F, Grégoire B, Laporte V, Léchenet JC, Low C, Oliveira T, Pacheco H, Quaresma M, Schwabe P, Strub PY (2024) Formally verifying Kyber Episode V: Machine-checked IND-CCA security and correct- ness of ML-KEM in EasyCrypt, Cryptology ePrint Archive, Paper 2024/843. Available at https://eprint.iacr.org/2024/843. [29] Regev O (2005) On Lattices, Learning with Errors, Random Linear Codes, and Cryp- tography. Proceedings of the Thirty-Seventh Annual ACM Symposium on Theory of Computing STOC ’05 (Association for Computing Machinery, New York, NY, USA), pp 84–93. https://doi.org/10.1145/1060590.1060603. [30] Langlois A, Stehlé D (2015) Worst-case to average-case reductions for module lattices. Designs, Codes and Cryptography 75(3):565–599. https://doi.org/10.1007/ s10623-09938-4. [31] ElGamal T (1985) A public key cryptosystem and a signature scheme based on discrete logarithms. IEEE transactions on information theory 31(4):469–472. https://doi.org/ 10.1109/TIT.1985.1057074 [32] Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehle D (2018) CRYSTALS - Kyber: A CCA-Secure Module-Lattice-Based KEM. 2018 IEEE European Symposium on Security and Privacy (EuroSP), pp 353–367.", "char_len": 3997, "approx_tokens": 999}
{"chunk_id": "NIST.SP.800-227::c00036", "doc_id": "NIST.SP.800-227", "start_page": 54, "end_page": 57, "text": "Stehlé D (2015) Worst-case to average-case reductions for module lattices. Designs, Codes and Cryptography 75(3):565–599. https://doi.org/10.1007/ s10623-09938-4. [31] ElGamal T (1985) A public key cryptosystem and a signature scheme based on discrete logarithms. IEEE transactions on information theory 31(4):469–472. https://doi.org/ 10.1109/TIT.1985.1057074 [32] Bos J, Ducas L, Kiltz E, Lepoint T, Lyubashevsky V, Schanck JM, Schwabe P, Seiler G, Stehle D (2018) CRYSTALS - Kyber: A CCA-Secure Module-Lattice-Based KEM. 2018 IEEE European Symposium on Security and Privacy (EuroSP), pp 353–367. https://doi.org/10.1109/EuroSP.2018.00032 [33] Schwabe P, Stebila D, Wiggers T (2020) Post-quantum TLS without handshake signa- tures. Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communi- cations Security, pp 1461–1480. https://doi.org/10.1145/3372297.3423350 [34] Canetti R, Krawczyk H (2001) Analysis of key-exchange protocols and their use for building secure channels. Advances in Cryptology — EUROCRYPT 2001 (Springer, Berlin, Heidelberg), pp 453–474. https:// doi.org/10.1007/3-540-44987-6_28 [35] Sönmez Turan M, Brandão LTAN (2024) Keyed-Hash Message Authentication Code (HMAC): Specification of HMAC and Recommendations for Message Authentication\n\n(National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Pub- lication (SP) NIST SP 800-224 ipd. https://doi.org/10.6028/NIST.SP.800-224.ipd [36] Dworkin M (2010) Recommendation for Block Cipher Modes of Operation: Three Variants of Ciphertext Stealing for CBC Mode (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) NIST SP 800-38B. https://doi.org/10.6028/NIST.SP.800-38B [37] Kelsey J, Chang SJ, Perlner R (2016) SHA-3 Derived Functions: cSHAKE, KMAC, Tuple- Hash and ParallelHash (Department of Commerce, Washington, D.C.), NIST Special Publication (SP) NIST SP 800-185. https://doi.org/10.6028/NIST.SP.800-185\n\nAppendix A. List of Acronyms\n\nCAVP Cryptographic Algorithm Verification Program CMVP Cryptographic Module Verification Program DRBG Deterministic Random Bit Generator FIPS Federal Information Processing Standards IND-CCA Indistinguishability under Chosen Ciphertext Attack IND-CPA Indistinguishability under Chosen Plaintext Attack ITL Information Technology Laboratory KC Key Confirmation KDF Key-Derivation Function KDM Key-Derivation Method KEM Key-Encapsulation Mechanism MAC Message Authentication Code ML-KEM Module-Lattice-Based Key-Encapsulation Mechanism NIST National Institute of Standards and Technology PKE Public-Key Encryption PoP Proof of Possession RBG Random Bit Generator SP Special Publication TLS Transport Layer Security TTP Trusted Third Party\n\nAppendix B. Glossary\n\nThis section is informative. approved FIPS-approved and/or NIST-recommended. An algorithm or technique that is either 1) specified in a FIPS or NIST recommendation, 2) adopted in a FIPS or NIST recommendation, or 3) specified in a list of NIST-approved security functions. ciphertext With regard to KEMs, a bit string that is produced by the encapsulation algo- rithm and used as an input to the decapsulation algorithm. computationally bounded adversary An adversarial algorithm that is constrained in run- ning time and memory, and is thus unlikely to break a cryptosystem under con- sideration. The nature of the constraints depends on the context, including the desired security strength of the cryptosystem. cryptanalytically relevant quantum computer A device capable of using quantum algo- rithms to break a cryptosystem that is secure against classical (i.e., non-quantum) computers. decapsulation The process of applying the Decaps algorithm of a KEM. This algorithm ac- cepts a KEM ciphertext and the decapsulation key as input and produces a shared secret key as output. decapsulation key A cryptographic key produced by a KEM during key generation and used during decapsulation.", "char_len": 3941, "approx_tokens": 985}
{"chunk_id": "NIST.SP.800-227::c00037", "doc_id": "NIST.SP.800-227", "start_page": 57, "end_page": 58, "text": "ation. The nature of the constraints depends on the context, including the desired security strength of the cryptosystem. cryptanalytically relevant quantum computer A device capable of using quantum algo- rithms to break a cryptosystem that is secure against classical (i.e., non-quantum) computers. decapsulation The process of applying the Decaps algorithm of a KEM. This algorithm ac- cepts a KEM ciphertext and the decapsulation key as input and produces a shared secret key as output. decapsulation key A cryptographic key produced by a KEM during key generation and used during decapsulation. destroy An action applied to a key or other piece of secret data. After a key or piece of secret data is destroyed, no information about its value can be recovered. efficient (cryptographic) algorithm An algorithm whose running time is practical for the relevant security strength. encapsulation The process of applying the Encaps algorithm of a KEM. This algorithm ac- cepts the encapsulation key as input, requires private randomness, and produces a shared secret key and an associated ciphertext as output. encapsulation key A cryptographic key produced by a KEM during key generation and used by the encapsulation algorithm. ephemeral key A cryptographic key that is generated for each execution of a crypto- graphic process (e.g., key establishment) and meets other requirements of the key type (e.g., unique to each message or session). hash function A function on arbitrarily long bit strings in which the length of the output is fixed. At a minimum, the hash function must be one-way and collision-resistant.\n\nidentifier A bit string that is associated with a person, device, or organization. It may be an identifying name or something more abstract (e.g., a string consisting of an IP address). key agreement A (pair-wise) key-establishment procedure in which the resultant secret keying material is a function of information contributed by both participants so that neither party can predetermine the value of the secret keying material inde- pendent of the contributions of the other party. Contrast with key transport. key combiner A function that takes multiple keys or shared secret values as input (possibly along with other information) and produces a single combined key. key confirmation A procedure that provides assurance to one party (i.e., key-confirmation recipient) that another party (i.e., key-confirmation provider) possesses the cor- rect secret keying material and/or shared secret from which that secret keying material is derived. key-confirmation provider The party that provides assurance to the other party (i.e., the recipient) that the two parties have indeed established a shared secret key or other keying material. key-confirmation recipient The party that receives assurance from the other party (i.e., the provider) that the two parties have indeed established a shared secret key or other keying material. key-derivation method A method used to derive keying material from initial shared se- crets and possibly other information. key-derivation key A key used as an input to a key-derivation method to derive additional keying material. key-encapsulation mechanism (KEM) A set of three cryptographic algorithms: KeyGen (key generation), Encaps (encapsulation), and Decaps (decapsulation). These al- gorithms can be used by two parties to securely establish a shared secret key over a public channel. key establishment A procedure that results in secret keying material that is shared among different parties. Key agreement, using a KEM, and key transport are all types of key establishment. keying material A bit string such that any non-overlapping, contiguous segments of the string with required lengths can be used as secret keys, secret initialization vectors, and other secret parameters. key pair A set of two keys with the property that one key can be made public, while the other key must be kept private.", "char_len": 3956, "approx_tokens": 989}
{"chunk_id": "NIST.SP.800-227::c00038", "doc_id": "NIST.SP.800-227", "start_page": 58, "end_page": 60, "text": "used by two parties to securely establish a shared secret key over a public channel. key establishment A procedure that results in secret keying material that is shared among different parties. Key agreement, using a KEM, and key transport are all types of key establishment. keying material A bit string such that any non-overlapping, contiguous segments of the string with required lengths can be used as secret keys, secret initialization vectors, and other secret parameters. key pair A set of two keys with the property that one key can be made public, while the other key must be kept private. In this publication, this could refer to either the (encapsulation key, decapsulation key) key pair of a KEM or the (encryption key, decryption key) key pair of a public-key encryption (PKE) scheme .\n\nkey transport A (pair-wise) key-establishment procedure whereby one party (i.e., the sender) selects a value for the secret keying material and then securely distributes the value to another party (i.e., the receiver). Contrast with key agreement. message authentication code (MAC) A family of symmetric-key cryptographic algorithms that act on input data of arbitrary length to produce an output value of a specified length (i.e., the MAC of the input data). The MAC can be employed to authenticate the origin of the input data and/or provide data integrity protection. message authentication code (MAC) tag Data obtained from the output of a MAC algo- rithm (possibly by truncation) that can be used by an entity to securely verify the integrity and origin of the information used as input to the MAC algorithm. must Indicates a requirement of this recommendation that might not be testable by a CMVP testing lab. negligible Extremely small. Typically quantifies the probability of an undesirable event that might occur during the lifetime of a cryptosystem (including during attacks by computationally bounded adversaries). party An individual (person), organization, device, or process. In this recommendation, there are typically two parties (e.g., Party A and Party B, Alice and Bob) that jointly perform the key-establishment process using a KEM. post-quantum algorithm A cryptographic algorithm that is believed to be secure, even against adversaries who possess a cryptanalytically relevant quantum computer. pseudorandom A process (or data produced by a process) whose outcome is determinis- tic yet also appears effectively random if the internal action of the process is hid- den from observation. For cryptographic purposes, “effectively random” means “computationally indistinguishable from random within the limits of the intended security strength.” public channel A communication channel between two honest parties that can be ob- served and compromised by third parties. quantum-vulnerable algorithm A cryptographic algorithm that is believed to be secure against adversaries who possess only a classical computer but is known to be in- secure against adversaries who possess a cryptanalytically relevant quantum com- puter. security strength A number associated with the amount of work that is required to break a cryptographic algorithm or system. seed A bit string used as input to a pseudorandom process. shall Used to indicate a requirement of this document that will be tested by a CMVP test- ing lab.\n\nshared secret A secret value that has been computed during a key-establishment scheme, is known by all participating parties, and is used as input to a key-derivation method to produce keying material. shared secret key A shared secret that can be used directly as keying material or as a sym- metric key. should Used to indicate a strong recommendation but not a requirement of this docu- ment. Ignoring the recommendation could lead to undesirable results. side-channel attack An attack enabled by the leakage of information from a deployed cryptosystem.", "char_len": 3884, "approx_tokens": 971}
{"chunk_id": "NIST.SP.800-227::c00039", "doc_id": "NIST.SP.800-227", "start_page": 59, "end_page": 62, "text": "t will be tested by a CMVP test- ing lab.\n\nshared secret A secret value that has been computed during a key-establishment scheme, is known by all participating parties, and is used as input to a key-derivation method to produce keying material. shared secret key A shared secret that can be used directly as keying material or as a sym- metric key. should Used to indicate a strong recommendation but not a requirement of this docu- ment. Ignoring the recommendation could lead to undesirable results. side-channel attack An attack enabled by the leakage of information from a deployed cryptosystem. Characteristics that could be exploited in a side-channel attack in- clude timing, power consumption, and electromagnetic and acoustic emissions. static key A key that is intended for use for a relatively long period of time and is typically intended for use in many instances of a cryptographic key-establishment scheme. Contrast with ephemeral key. symmetric-key algorithm A cryptographic algorithm that uses the same secret key for an operation and its complement (e.g., encryption and decryption). Also called a secret-key algorithm. trusted third party An entity other than the owner and verifier that is trusted by the owner, the verifier, or both to provide certain services.\n\nAppendix C. Cryptographic Components\n\nAppendix C.1. Message Authentication Codes (MACs) A MAC algorithm defines a family of cryptographic functions that is parameterized by a symmetric key. It is computationally infeasible to determine the MAC of a newly formed MAC_Data output value without knowledge of the KC_Key value, even if one has seen the MACs corresponding to other MAC_Data values that were computed using that same KC_Key value. The input to a MAC algorithm includes a symmetric key KC_Key and a binary data string MAC_Data that serves as the “message.” That is, a MAC computation is represented as MAC(KC_Key, MAC_Data). In this recommendation, a MAC algorithm is used if key confirmation is performed during key establishment (see Sec. 4.4). When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (i.e., HMAC, AES-CMAC, or KMAC). HMAC is specified in SP 800-224 [35] and requires the use of an approved hash function. AES-CMAC is specified in SP 800-38B [36] for the AES block cipher algorithm specified in FIPS 197. KMAC is specified in SP 800-185 [37]. In addition, AES-GMAC (specified in [9]) is an approved MAC algorithm and may be used. When a MAC tag (MacTag) is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a KC_Key that is determined from a shared secret key. The MAC tag is sent to the other entity participating in the keyestablishment scheme in order to provide assurance that the shared secret key or derived keying material was correctly computed. MacTag computation and verification are described below.\n\nMAC Tag Computation for Key Confirmation. Key confirmation can be performed as one or more additional steps in a KEM scheme. The computation of a MAC tag is represented as follows: MacTag = TMacTagBits[MAC(KC_Key, MAC_Data)]. To compute a MacTag: 1. The agreed-upon MAC algorithm (see Table 1) is used with KC_Key to compute the MAC on MAC_Data, where KC_Key is a symmetric key, and MAC_Data represents the input “message” data. The minimum length of KC_Key is specified in Table 1. KC_Key is obtained from the the shared secret key, as specified in Sec. 4.4.2. The output of the MAC algorithm MacOut put is a bit string whose length in bits is MacOut putBits.\n\nTable 1. Approved MAC algorithms for key confirmation", "char_len": 3647, "approx_tokens": 911}
{"chunk_id": "NIST.SP.800-227::c00040", "doc_id": "NIST.SP.800-227", "start_page": 61, "end_page": 64, "text": "scheme. The computation of a MAC tag is represented as follows: MacTag = TMacTagBits[MAC(KC_Key, MAC_Data)]. To compute a MacTag: 1. The agreed-upon MAC algorithm (see Table 1) is used with KC_Key to compute the MAC on MAC_Data, where KC_Key is a symmetric key, and MAC_Data represents the input “message” data. The minimum length of KC_Key is specified in Table 1. KC_Key is obtained from the the shared secret key, as specified in Sec. 4.4.2. The output of the MAC algorithm MacOut put is a bit string whose length in bits is MacOut putBits.\n\nTable 1. Approved MAC algorithms for key confirmation\n\nMAC Algorithm MacOutputBits Permissible KC_Key Supported Security Lengths (μ bits) Strengths for Key Confirmation (s bits) HMAC_SHA-256 256 HMAC_SHA-512/256 256 HMAC_SHA-384 384 HMAC_SHA-512 512 128 ≤ s ≤ 256 HMAC_SHA3-256 256 s ≤ μ ≤ 512 HMAC_SHA3-384 384 HMAC_SHA3-512 512 KMAC128 ≤ 22040 − 1 s = 128 KMAC256 128 ≤ s ≤ 256 AES-128-CMAC 128 μ = 128 s = 128 AES-192-CMAC 128 μ = 192 128 ≤ s ≤ 192 AES-256-CMAC 128 μ = 256 128 ≤ s ≤ 256 AES-128-GMAC 128 μ = 128 s = 128 AES-192-GMAC 128 μ = 192 128 ≤ s ≤ 192 AES-256-GMAC 128 μ = 256 128 ≤ s ≤ 256\n\n2. The MacOut put bits are input to the truncation function TMacTagBits, which re- turns the leftmost (i.e., initial) bits of MacOut put to be used as the value of MacTag. MacTagBits needs to be less than or equal to MacOut putBits long. When MacTagBits equals MacOut putBits, TMacTagBits acts as the identity function. The minimum value for MacTagBits is 64.\n\nMacTag Verification for Key Confirmation. To verify a received MacTag (i.e., received during key confirmation), a new Mac tag MacTag′ is computed using the values of KC_Key, MacTagBits, and MAC_Data generated by the recipient (as specified in Sec. 4.4.1). MacTag′ is compared with the received MacTag. If their values are equal, then it may be inferred that the same KC_Key, MacTagBits, and MAC_Data values were used in the two MacTag computations.\n\nAppendix C.2. Nonces A nonce is a time-varying value with a negligible chance of repeating. A decapsulator may be required to provide a public nonce that is used for key-confirmation purposes. This circumstance arises when the decapsulator’s public key is static. A nonce may be composed of one or more of the following components, though other components may also be appropriate:\n\n1. A random bit string that is generated anew for each nonce using an approved ran- dom bit generator. A nonce containing a component of this type is called a random nonce. 2. A timestamp of sufficient resolution so that it is different each time it is used. 3. A monotonically increasing sequence number. 4. A combination of a timestamp and a monotonically increasing sequence num- ber such that the sequence number is reset when and only when the timestamp changes. For example, a timestamp may show the date but not the time of day, so a sequence number is appended that will not repeat during a particular day. When a nonce is required for key-confirmation purposes as specified in this recommendation, it should be a random nonce that contains a random bit string output from an approved random bit generator, where both the security strength supported by the instantiation of the random bit generator and the bit length of the random bit string are greater than or equal to the targeted security strength of the key-establishment scheme in which the nonce is used during key confirmation. When feasible, the bit length of the random bit string should be at least twice the targeted security strength. For details concerning the security strength supported by an instantiation of a random bit generator, see the SP 800-90 series of publications [6–8]. As part of the proper implementation of this recommendation, system users and/or agents trusted to act on their behalf should determine whether the components selected for inclusion in any required nonces meet their security requirements.\n\nAppendix D. Changes From Draft SP 800-227", "char_len": 3979, "approx_tokens": 994}
{"chunk_id": "NIST.SP.800-227::c00041", "doc_id": "NIST.SP.800-227", "start_page": 63, "end_page": 64, "text": "me in which the nonce is used during key confirmation. When feasible, the bit length of the random bit string should be at least twice the targeted security strength. For details concerning the security strength supported by an instantiation of a random bit generator, see the SP 800-90 series of publications [6–8]. As part of the proper implementation of this recommendation, system users and/or agents trusted to act on their behalf should determine whether the components selected for inclusion in any required nonces meet their security requirements.\n\nAppendix D. Changes From Draft SP 800-227\n\n1. Section numbers have shifted due to reorganization. 2. Section 4.5 was added to address discussions from the NIST KEM workshop and writ- ten public comments about how the unique functionality of RSA allows for special procedures to achieve proof of possession that does not generally apply to KEMs. 3. To align with existing requirements in SP800-56A and SP800-56B, additional require- ments were added to Sec. 4.1 and 4.2 for ephemeral and static KEM key-pairs, namely: • Additional shall statement in Sec. 4.2: Ephemeral key pairs shall be used in only one execution of key-establishment via a KEM and shall be destroyed as soon as possible after use. • Additional must statement in Sec. 4.2: If an encapsulating party obtains the static encapsulation key of another party, it must have assurance of the other party’s ownership of the key before or during the execution of key- establishment. This assurance can be obtained from a trusted party (e.g., a certificate authority) or a combination of proof of possession and verification of real-world identity. 4. In Sec. 4.6.2, the concatenation of inputs to hash functions was modified to be comma separated. Public comments noted that concatenation may not be appro- priate, depending on the protocol or context. 5. Two examples were added to Sec. 5 (Sec. 5.2.4 and 5.2.5) to illustrate how to use KEMs to achieve authenticated key establishment. Additionally, existing examples were updated. 6. Section 4.3 was updated with guidelines on how to create keys that are smaller than the output KEM key. Public comments noted this as particularly relevant for ML- KEM, which outputs 256-bit keys at all security levels. 7. A public comment noted that a “shall” requirement in Sec. 4.4 was overly restrictive in permitting KEM parameters of one security level to be used alongside lower secu- rity level protocols (e.g., running ML-KEM 768 at 128 bits of security). This has been updated accordingly.", "char_len": 2550, "approx_tokens": 637}
