{"answerable": true, "gold": [{"doc_id": "NIST.IR.8547.ipd", "end_page": 8, "start_page": 8}], "qid": "q001", "question": "what is PQC", "retrieval": {"doc_hit_ranks": [1, 2], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 9, "mode": "hybrid", "rank": 1, "score": 0.031544957774465976, "start_page": 9, "text": "126 ensuring that this transition is as smooth and coordinated as possible, balancing the urgency of 127 adopting PQC with the need to minimize disruption across critical systems.\n\n128 1.2. Audience 129 This document is intended for a broad audience, including federal agencies, technology 130 providers, standards organizations, and Cryptographic Module Validation Program (CMVP) 131 laboratories. These groups play a critical role in preparing for the migration to PQC by 132 developing, implementing, and standardizing the new cryptographic methods necessary to 133 secure information in the era of quantum computing. This document should inform these 134 stakeholder’s efforts and timelines for migrating information technology products, services, and 135 infrastructure to PQC."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 2, "score": 0.031054405392392875, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "end_page": 25, "mode": "hybrid", "rank": 3, "score": 0.02919863597612958, "start_page": 25, "text": "4. Conclusion\n\nThis report summarizes the evaluation criteria for selecting the fourth-round candidate algorithms, their basic designs, and their advantages and disadvantages. NIST greatly appreciates the participation in the NIST PQC Standardization Process. The announcement of the standardization of HQC marks the end of the fourth round, and also marks an end to the standardization process which began with the NIST Call for Proposals in 2016 [22]. We note that not all NIST PQC standardization is concluded, as NIST is also currently evaluating additional digital signatures [75]. NIST will create a draft standard based on HQC and post it for public comment. After the comments are adjudicated, NIST will publish a final version in approximately two years. The standardization of HQC will be the second PQC KEM after ML-KEM. NIST recently published draft SP 800-227, Recommendations for Key-Encapsulation Mechanisms [76], which describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner. NIST plans to host another NIST PQC Standardization Conference in September 2025, with more details to be provided."}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 4, "score": 0.01639344262295082, "start_page": 20, "text": "3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed.\n\nInput checking. The correct and secure operation of cryptographic operations depends crucially on the validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 5, "score": 0.016129032258064516, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 6, "score": 0.015873015873015872, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 7, "score": 0.015625, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 8, "score": 0.015384615384615385, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [1], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p9-p9", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "pages": "p25-p25", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 4}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 10, "start_page": 10}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}, {"doc_id": "NIST.FIPS.205", "end_page": 11, "start_page": 11}], "qid": "q002", "question": "why do we need the PQC standards", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 1, "score": 0.032266458495966696, "start_page": 12, "text": "209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms."}, {"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 9, "mode": "hybrid", "rank": 2, "score": 0.031754032258064516, "start_page": 9, "text": "126 ensuring that this transition is as smooth and coordinated as possible, balancing the urgency of 127 adopting PQC with the need to minimize disruption across critical systems.\n\n128 1.2. Audience 129 This document is intended for a broad audience, including federal agencies, technology 130 providers, standards organizations, and Cryptographic Module Validation Program (CMVP) 131 laboratories. These groups play a critical role in preparing for the migration to PQC by 132 developing, implementing, and standardizing the new cryptographic methods necessary to 133 secure information in the era of quantum computing. This document should inform these 134 stakeholder’s efforts and timelines for migrating information technology products, services, and 135 infrastructure to PQC."}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "end_page": 25, "mode": "hybrid", "rank": 3, "score": 0.0315136476426799, "start_page": 25, "text": "4. Conclusion\n\nThis report summarizes the evaluation criteria for selecting the fourth-round candidate algorithms, their basic designs, and their advantages and disadvantages. NIST greatly appreciates the participation in the NIST PQC Standardization Process. The announcement of the standardization of HQC marks the end of the fourth round, and also marks an end to the standardization process which began with the NIST Call for Proposals in 2016 [22]. We note that not all NIST PQC standardization is concluded, as NIST is also currently evaluating additional digital signatures [75]. NIST will create a draft standard based on HQC and post it for public comment. After the comments are adjudicated, NIST will publish a final version in approximately two years. The standardization of HQC will be the second PQC KEM after ML-KEM. NIST recently published draft SP 800-227, Recommendations for Key-Encapsulation Mechanisms [76], which describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner. NIST plans to host another NIST PQC Standardization Conference in September 2025, with more details to be provided."}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 13, "mode": "hybrid", "rank": 4, "score": 0.030330882352941176, "start_page": 13, "text": "244 These libraries need to incorporate PQC algorithms that are standardized by bodies like NIST. 245 Updating them ensures that developers have access to quantum-resistant cryptographic 246 functions without implementing complex algorithms themselves. This transition involves adding 247 new algorithms, optimizing their implementations for performance, and ensuring those 248 implementations are secure against side-channel attacks.\n\n249 2.2.3. Cryptographic Hardware 250 Cryptographic hardware modules, such as hardware security modules (HSMs) and Trusted 251 Platform Modules (TPMs), provide secure environments for performing cryptographic 252 operations and storing sensitive keys. They are used in various applications, from securing 253 server infrastructure to protecting cryptographic keys on personal devices. 254 Hardware modules must be upgraded or redesigned to support PQC algorithms, which often 255 have larger key sizes and different computational requirements. This includes updating 256 firmware or hardware to handle new algorithms and ensuring that the modules can perform 257 quantum-resistant cryptographic operations efficiently while maintaining the high security 258 standards expected of these devices."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 5, "score": 0.028814262023217248, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures."}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 8, "mode": "hybrid", "rank": 6, "score": 0.02854251012145749, "start_page": 8, "text": "88 1. Introduction 89 Cryptographic algorithms are vital for safeguarding confidential electronic information from 90 unauthorized access. For decades, these algorithms have proved strong enough to defend 91 against attacks using conventional computers that attempt to defeat cryptography. However, 92 future quantum computing may be able to break these algorithms, rendering data and 93 information vulnerable. Countering this future quantum capability requires new cryptographic 94 methods that can protect data from both current conventional computers and the quantum 95 computers of tomorrow. These methods are referred to as post-quantum cryptography (PQC). 96 In response, NIST has released three PQC standards to start the next and significantly large 97 stage of working on the transition to post-quantum cryptography: the Module-Lattice-Based 98 Key-Encapsulation Mechanism [FIPS203], the Module-Lattice-Based Digital Signature Algorithm 99 [FIPS204], and the Stateless Hash-Based Signature Algorithm [FIPS205]. Historically, the journey 100 from algorithm standardization to full integration into information systems can take 10 to 20 101 years. This timeline reflects the complexity of companies building the algorithms into products 102 and services, procuring those products and services, and integrating those products and 103 services into technology infrastructures. 104 Even though the transition to post-quantum cryptography is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 7, "score": 0.015873015873015872, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 8, "mode": "hybrid", "rank": 8, "score": 0.015151515151515152, "start_page": 8, "text": "88 1. Introduction 89 Cryptographic algorithms are vital for safeguarding confidential electronic information from 90 unauthorized access. For decades, these algorithms have proved strong enough to defend 91 against attacks using conventional computers that attempt to defeat cryptography. However, 92 future quantum computing may be able to break these algorithms, rendering data and 93 information vulnerable. Countering this future quantum capability requires new cryptographic 94 methods that can protect data from both current conventional computers and the quantum 95 computers of tomorrow. These methods are referred to as post-quantum cryptography (PQC). 96 In response, NIST has released three PQC standards to start the next and significantly large 97 stage of working on the transition to post-quantum cryptography: the Module-Lattice-Based 98 Key-Encapsulation Mechanism [FIPS203], the Module-Lattice-Based Digital Signature Algorithm 99 [FIPS204], and the Stateless Hash-Based Signature Algorithm [FIPS205]. Historically, the journey 100 from algorithm standardization to full integration into information systems can take 10 to 20 101 years. This timeline reflects the complexity of companies building the algorithms into products 102 and services, procuring those products and services, and integrating those products and 103 services into technology infrastructures. 104 Even though the transition to post-quantum cryptography is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent.\n\n111 1.1. Scope and Purpose 112 Updating cryptographic technology has occurred many times at different scales, such as 113 increasing key sizes or phasing out insecure hash functions and block ciphers. While the 114 transition to PQC is unprecedented in scale, it benefits from a level of awareness and 115 understanding that previous cryptographic changes did not have. NIST recognizes the 116 complexity of migrating the vast array of systems that currently rely on public-key cryptography 117 and acknowledges that this transition will demand substantial effort across diverse applications 118 and infrastructures with specific requirements and constraints. 119 This report serves as the initial step in a broader strategy to manage and guide the transition to 120 post-quantum cryptography. This transition will involve the adoption of new PQC algorithms as 121 well as the careful deprecation, controlled legacy use, and eventual removal of quantum- 122 vulnerable algorithms that are currently widespread in technological infrastructures. Public- 123 private engagement will be crucial on the path toward PQC. Additionally, this report continues 124 NIST’s ongoing dialogue with industry, standards organizations, and relevant agencies to 125 develop a clear roadmap and realistic timeline for transitioning to PQC. NIST is committed to"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p9-p9", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "pages": "p25-p25", "rank": 3}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p13-p13", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 5}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p8-p8", "rank": 6}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 7}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p8-p8", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 10, "start_page": 10}, {"doc_id": "NIST.FIPS.204", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.205", "end_page": 3, "start_page": 3}], "qid": "q003", "question": "What are the PQC standards", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 1, "score": 0.0315136476426799, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8547.ipd::p0018::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 18, "mode": "hybrid", "rank": 2, "score": 0.031024531024531024, "start_page": 18, "text": "417 4. Towards a PQC Standards Transition Timeline 418 NIST’s cryptography standards provide comprehensive guidance on a broad spectrum of 419 cryptographic mechanisms that are essential for securing sensitive information across both 420 federal and nonfederal systems. These standards cover fundamental areas that are crucial for 421 ensuring the confidentiality, integrity, and authenticity of data, such as encryption algorithms, 422 digital signatures, hash functions, key establishment, and random number generation. 423 Additionally, NIST’s standards define key-management practices and offer frameworks for 424 securely generating, storing, distributing, and destroying cryptographic keys. 425 Beyond individual algorithms, NIST standards provide guidance on cryptographic protocols that 426 secure communications, such as the TLS protocol, which protects internet data exchanges. They 427 also specify requirements for cryptographic modules through the CMVP to ensure that 428 implementations meet stringent security standards. NIST has also developed PQC standards to 429 safeguard systems against future quantum attacks. Through collaboration with industry, 430 academia, and other stakeholders, NIST continually updates its cryptographic standards to 431 address evolving security threats and technological advances. 432 National Security Memorandum 10 (NSM-10) establishes the year 2035 as the primary target 433 for completing the migration to PQC across Federal systems [NSM10]: 434 “Any digital system that uses existing public standards for public‐key cryptography, or 435 that is planning to transition to such cryptography, could be vulnerable to an attack by a 436 Cryptographically Relevant Quantum Computer (CRQC). To mitigate this risk, the United 437 States must prioritize the timely and equitable transition of cryptographic systems to 438 quantum-resistant cryptography, with the goal of mitigating as much of the quantum 439 risk as is feasible by 2035.” 440 This date reflects the urgency of transitioning to cryptographic methods that can withstand 441 future quantum threats. However, it is important to recognize that migration timelines may 442 vary based on the specific use case or application. Some systems, particularly those with long- 443 term confidentiality needs or more complex cryptographic infrastructures, may require earlier 444 transitions, while others may adopt PQC at a slower pace due to legacy constraints or lower risk 445 profiles. Flexibility in migration planning is essential to balance the urgency of securing critical 446 systems with the practical challenges that different sectors face during this transition. NIST will 447 work to ensure that these varying timelines are acknowledged and supported while maintaining 448 the overall goal of achieving widespread PQC adoption by 2035."}, {"chunk_id": "NIST.IR.8547.ipd::p0024::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 24, "mode": "hybrid", "rank": 3, "score": 0.030309988518943745, "start_page": 24, "text": "545 techniques until 2035 and generally allow their use, these application-specific standards and 546 guidelines may specify earlier transitions for certain cryptographic algorithms, techniques, and 547 protocols used within these applications. These guidelines will be developed based on the 548 expected impact that a cryptographically relevant quantum computer would have on these 549 applications as well as the level of support for PQC in the relevant standards, products, and 550 services. NIST expects to prioritize the migration to quantum-resistant key-establishment 551 schemes within these updates to protect against “harvest now, decrypt later” attacks, 552 particularly in interactive protocols like TLS and IKE. 553 NIST will also coordinate with standards-developing organizations and industry to ensure that 554 critical security protocols and technologies are updated to support PQC in a timely manner, 555 recognizing that different application areas will have different risks, security needs, and 556 adoption challenges."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 4, "score": 0.028612012987012988, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 5, "score": 0.01639344262295082, "start_page": 12, "text": "209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms."}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 6, "score": 0.016129032258064516, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 7, "score": 0.015151515151515152, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures.\n\n378 3.2.1. Hybrid Key-Establishment Techniques 379 A hybrid key-establishment mode is defined here to be a key establishment scheme that is a 380 combination of two or more components that are themselves cryptographic key-establishment 381 schemes. The hybrid key-establishment scheme becomes a composite of these component 382 schemes. 383 NIST currently allows a generic composite key-establishment technique described in SP 800-56C 384 [SP80056C]. Assume that the value Z is a shared secret that was generated as specified by SP 385 800-56A or 800-56B and that a shared secret T is generated or distributed through other 386 schemes. The value Z’=Z||T may then be treated as a shared secret and any of the key 387 derivation methods given in SP 800-56C may be applied to Z’ to derive secret keying material. 388 NIST intends to update SP 800-56C so that the value Z may be generated as specified by any 389 current and future NIST key-establishment standards. This will include SP 800-56A, SP 800-56B, 390 FIPS 203, and any additional post-quantum key-establishment standards. The desired property 391 of hybrid techniques is that derived keys remain secure if at least one of the component 392 schemes is secure. Security properties can be complex, and for composite key establishment"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0018::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p18-p18", "rank": 2}, {"chunk_id": "NIST.IR.8547.ipd::p0024::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p24-p24", "rank": 3}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 7}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.203", "end_page": 23, "start_page": 22}], "qid": "q004", "question": "What is ML-KEM", "retrieval": {"doc_hit_ranks": [2, 3, 4, 6, 7], "gold_hit_ranks": [4, 6, 7], "hits": [{"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 1, "score": 0.06426011264720942, "start_page": 43, "text": "5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications\nThis section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption\nA KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for\nPKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15]."}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 2, "score": 0.06403688524590165, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 3, "score": 0.06069665184914546, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 4, "score": 0.056288396076298666, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 5, "score": 0.03252247488101534, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.203::p0023::c001", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 6, "score": 0.031024531024531024, "start_page": 23, "text": "The specification of the ML-KEM algorithms in this standard will follow the same pattern. Specifically, this standard will first describe a public-key encryption scheme called K-PKE (in Section 5) and then use the algorithms of K-PKE as subroutines when describing the algorithms of ML-KEM (in Sections 6 and 7). The cryptographic transformation from K-PKE to ML-KEM is crucial for achieving IND-CCA2 security. The scheme K-PKE is not IND-CCA2-secure and shall not be used as a stand-alone scheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability. ML-KEM also comes with a proof of asymptotic theoretical security in a certain heuristic model [4]. Each of the parameter sets of ML-KEM comes with an associated security strength that was estimated based on current cryptanalysis (see Section 8 for details).\n\nParameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329."}, {"chunk_id": "NIST.FIPS.203::p0023::c000", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 7, "score": 0.030309988518943745, "start_page": 23, "text": "The specification of the ML-KEM algorithms in this standard will follow the same pattern. Specifically, this standard will first describe a public-key encryption scheme called K-PKE (in Section 5) and then use the algorithms of K-PKE as subroutines when describing the algorithms of ML-KEM (in Sections 6 and 7). The cryptographic transformation from K-PKE to ML-KEM is crucial for achieving IND-CCA2 security. The scheme K-PKE is not IND-CCA2-secure and shall not be used as a stand-alone scheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability. ML-KEM also comes with a proof of asymptotic theoretical security in a certain heuristic model [4]. Each of the parameter sets of ML-KEM comes with an associated security strength that was estimated based on current cryptanalysis (see Section 8 for details)."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 8, "score": 0.01639344262295082, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.25, "ndcg_at_k": 0.2640681225725909, "recall_at_k": 0.5}, "k8": {"mrr_at_k": 0.25, "ndcg_at_k": 0.48247555939075504, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.25, "ndcg_at_k": 0.48247555939075504, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [4, 6, 7], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0023::c001", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0023::c000", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.204", "end_page": 4, "start_page": 3}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}], "qid": "q005", "question": "explain ML-DSA", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "end_page": 8, "mode": "hybrid", "rank": 1, "score": 0.06186378536922015, "start_page": 8, "text": "5.4 Pre-Hash ML-DSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n 5.4.1 HashML-DSA Signing and Verifying . . . . . . . . . . . . . . . . . . . . . . . . 19\n6 Internal Functions 22\n 6.1 ML-DSA Key Generation (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n 6.2 ML-DSA Signing (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n 6.3 ML-DSA Verifying (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n7 Auxiliary Functions 28\n 7.1 Conversion Between Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33\n 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39\n 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52"}, {"chunk_id": "NIST.FIPS.204::p0007::c002", "doc_id": "NIST.FIPS.204", "end_page": 7, "mode": "hybrid", "rank": 2, "score": 0.05932958454539554, "start_page": 7, "text": "4 Parameter Sets 15\n\n5 External Functions 17\n 5.1 ML-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n 5.2 ML-DSA Signing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n 5.3 ML-DSA Verifying . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\niv"}, {"chunk_id": "NIST.FIPS.204::p0029::c000", "doc_id": "NIST.FIPS.204", "end_page": 29, "mode": "hybrid", "rank": 3, "score": 0.05527095723174155, "start_page": 29, "text": "the platform may require hardware support for hashing to achieve acceptable performance but lack hardware support for SHAKE256 specifically. For some use cases, this may be addressed by signing a digest of the message along with some domain separation information rather than signing the message directly. This version of ML-DSA is known as “pre-hash” ML-DSA or HashML-DSA . In general, the “pure” ML-DSA version is preferred. While key generation for HashML-DSA is the same as for ML-DSA, it is not the same for the signing algorithm HashML-DSA.Sign or the verification algorithm HashML-DSA.Verify. Like ML-DSA, the signing algorithm of HashML-DSA takes the content to be signed, the private key, and a context as input, as well as a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string, though applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a ML-DSA signature or a pre-hash HashML-DSA signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash. 5 While a single key pair may be used for both ML-DSA and HashML-DSA signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or by the application with which the signature is being used. If the default “hedged” variant of is used, the 32-byte random value rnd shall be generated by the cryptographic module that generates the signature (i.e., that runs ML-DSA.Sign_internal). However, all other steps of signing may be performed outside of the cryptographic module that generates the signature. In the case of pre-hashing, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that generates the signature. If the content to be signed is large, hashing of the content is often performed at the application level. For example, in the Cryptographic Message Syntax [29], a digest of the content may be computed, and that digest is signed along with other attributes. If the content is not hashed at the application level, the pre-hash version of ML-DSA signing may be used. In order to maintain the same level of security strength when the content is hashed at the application level or using HashML-DSA , the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180 [8] or FIPS 202 [7]) that provides at least λ bits of classical security strength against both collision and second preimage attacks [7, Table 4].6 The verification of a signature that is created in this way will require the verify function to generate a digest from the message in the same way to be used as input for the verification function."}, {"chunk_id": "NIST.FIPS.204::p0009::c000", "doc_id": "NIST.FIPS.204", "end_page": 9, "mode": "hybrid", "rank": 4, "score": 0.04669647292598113, "start_page": 9, "text": "List of Tables\n\nTable 1 ML-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Table 2 Sizes (in bytes) of keys and signatures of ML-DSA . . . . . . . . . . . . . . . . . . 16 Table 3 While loop and XOF output limits for a 2−256 or less probability of failure . . . . . 52"}, {"chunk_id": "NIST.FIPS.204::p0028::c001", "doc_id": "NIST.FIPS.204", "end_page": 28, "mode": "hybrid", "rank": 5, "score": 0.045979778526721235, "start_page": 28, "text": "5.3 ML-DSA Verifying\nThe verification algorithm ML-DSA.Verify (Algorithm 3) takes a public key, a message, a signature, and a context string as input. The public key, signature, and context string are all encoded as byte strings, while the message is a bit string. ML-DSA.Verify outputs a Boolean value that is true if the signature is valid with respect to the message and the public key and false if the signature is invalid. The verification is accomplished by calling ML-DSA.Verify_internal (Algorithm 8) with the public key, the encoded message, and the signature.\n\nAlgorithm 3 ML-DSA.Verify(pk, M, σ, ctx) Verifies a signature σ for a message M. Input: Public key pk ∈ B32+32k(bitlen (q−1)−d), message M ∈ {0, 1}∗, signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k, context string ctx (a byte string of 255 or fewer bytes). Output: Boolean. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: M′ ← BytesToBits(IntegerToBytes(0, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx) ∥ M 6: return ML-DSA.Verify_internal(pk, M′ , σ)\n\n5.4 Pre-Hash ML-DSA\nFor some cryptographic modules that generate ML-DSA signatures, hashing the message in step 6 of ML-DSA.Sign_internal may result in unacceptable performance if the message M is large. For example,"}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 6, "score": 0.04533450704225352, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "end_page": 19, "mode": "hybrid", "rank": 7, "score": 0.03278688524590164, "start_page": 19, "text": "3. Overview of the ML-DSA Signature Scheme\n\nML-DSA is a digital signature scheme based on CRYSTALS-DILITHIUM [6]. It consists of three main algorithms:\nML-DSA.KeyGen (Algorithm 1), ML-DSA.Sign (Algorithm 2), and ML-DSA.Verify (Algorithm 3). The\nML-DSA scheme uses the Fiat-Shamir With Aborts construction [10, 11] and bears the most resemblance\nto the schemes proposed in [12, 13].\nThis document also defines a closely related but domain-separated signature scheme, HashML-DSA, which differs from ML-DSA in that it includes an additional pre-hashing step before signing. It consists of three main algorithms: ML-DSA.KeyGen (Algorithm 1), which is the same key generation algorithm used for ML-DSA; HashML-DSA.Sign (Algorithm 4); and HashML-DSA.Verify (Algorithm 5).\n\n3.1 Security Properties\nML-DSA is designed to be strongly existentially unforgeable under chosen message attack (SUF-CMA).\nThat is, it is expected that even if an adversary can get the honest party to sign arbitrary messages, the adversary cannot create any additional valid signatures based on the signer’s public key, including on messages for which the signer has already provided a signature.\nBeyond unforgeability, ML-DSA is designed to satisfy additional security properties described in [14]."}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 8, "score": 0.03076923076923077, "start_page": 22, "text": "3.6.1 Randomness Generation Algorithm 1, implementing key generation for ML-DSA, uses an RBG to generate the 256-bit random seed ξ. The seed ξ shall be a fresh (i.e., not previously used) random value generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [19, 20, 21]. Moreover, the RBG used shall have a security strength of at least 192 bits for ML-DSA-65 and 256 bits for ML-DSA-87. For ML-DSA-44, the RBG should have a security strength of at least 192 bits and shall have a security strength of at least 128 bits. If an approved RBG with at least 128 bits of security but less than 192 bits of security is used, then the claimed security strength of ML-DSA-44 is reduced from category 2 to category 1. Additionally, the value rnd is generated using an RBG in the default “hedged” variants of Algorithms 2 and 4 for ML-DSA and HashML-DSA signing, respectively. While this value should ideally be generated by an approved RBG, other methods for generating fresh random values may be used. The primary purpose of rnd is to facilitate countermeasures to side-channel attacks and fault attacks on deterministic signatures, such as [22, 23, 24].3 For this purpose, even a weak RBG may be preferable to the fully deterministic variants of Algorithms 2 and 4.\n\n3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "pages": "p8-p8", "rank": 1}, {"chunk_id": "NIST.FIPS.204::p0007::c002", "doc_id": "NIST.FIPS.204", "pages": "p7-p7", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0029::c000", "doc_id": "NIST.FIPS.204", "pages": "p29-p29", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0009::c000", "doc_id": "NIST.FIPS.204", "pages": "p9-p9", "rank": 4}, {"chunk_id": "NIST.FIPS.204::p0028::c001", "doc_id": "NIST.FIPS.204", "pages": "p28-p28", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "pages": "p19-p19", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.205", "end_page": 52, "start_page": 43}], "qid": "q006", "question": "What are the steps (and inputs/outputs) of SLH-DSA key generation, signing, and verification?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [2, 5, 6, 8], "hits": [{"chunk_id": "NIST.FIPS.205::p0008::c001", "doc_id": "NIST.FIPS.205", "end_page": 8, "mode": "hybrid", "rank": 1, "score": 0.06320163178968044, "start_page": 8, "text": "10 SLH-DSA External Functions 37\n 10.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2.1 Pure SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 38\n 10.2.2 HashSLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 39\n 10.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n11 Parameter Sets 43\n 11.1 SLH-DSA Using SHAKE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n 11.2 SLH-DSA Using SHA2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n 11.2.1 SLH-DSA Using SHA2 for Security Category 1 . . . . . . . . . . . . . . . 45\n 11.2.2 SLH-DSA Using SHA2 for Security Categories 3 and 5 . . . . . . . . . . 46\n\nReferences 47\n\nAppendix A — Differences From the SPHINCS+ Submission 51 A.1 Changes From FIPS 205 Initial Public Draft . . . . . . . . . . . . . . . . . . . . 51\n\nv"}, {"chunk_id": "NIST.FIPS.205::p0044::c001", "doc_id": "NIST.FIPS.205", "end_page": 44, "mode": "hybrid", "rank": 2, "score": 0.057642357642357644, "start_page": 44, "text": "[14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength. The SLH-DSA private key contains two random, secret n-byte values (see Figure 15). SK.seed is used to generate all of the WOTS+ and FORS private key elements. SK.prf is used to generate a randomization value for the randomized hashing of the message in SLH-DSA. The private key also includes a copy of the public key. Both SK.seed and SK.prf shall be generated using an approved random bit generator, where the instantiation of the random bit generator supports at least 8n bits of security strength. Algorithm 18 generates an SLH-DSA key pair. Lines 1 through 3 compute the root of the top layer XMSS tree. Line 4 bundles the three inputs and the computed PK.seed into the private and public keys. SLH-DSA signing has two variants — “hedged” and deterministic (see Section 9.2) — whose keys should only be used for the generation and verification of hedged and deterministic SLH-DSA digital signatures, respectively.\n\nAlgorithm 18 slh_keygen_internal(SK.seed, SK.prf, PK.seed) Generates an SLH-DSA key pair. Input: Secret seed SK.seed, PRF key SK.prf, public seed PK.seed Output: SLH-DSA key pair (SK, PK). 1: ADRS ← toByte(0, 32) ▷ generate the public key for the top-level XMSS tree 2: ADRS.setLayerAddress(d − 1) 3: PK.root ← xmss_node(SK.seed, 0, h′ , PK.seed, ADRS) 4: return ( (SK.seed, SK.prf, PK.seed, PK.root), (PK.seed, PK.root) )\n\n9.2 SLH-DSA Signature Generation An SLH-DSA signature consists of a randomization string, a FORS signature, and a hypertree signature, as shown in Figure 17. Generating an SLH-DSA signature (Algorithm 19) begins by creating an m-byte message digest (lines 2 through 5). A PRF is used to create a message randomizer (line 3), and it is hashed along with the message to create the digest (line 5). Bits are then extracted from the message digest to be signed by the FORS key (line 6), to select an XMSS tree (lines 7 and 9), and to select a WOTS+ key and corresponding FORS key within that XMSS tree (lines 8 and 10). Next, the FORS signature is computed (lines 11 through 14), and the corresponding FORS public key is obtained (line 16). Finally, the FORS public key is signed (line 17).\n\nRandomness R n bytes FORS signature SIGFORS k(1 + a) ⋅ n bytes HT signature SIGHT (h + d ⋅ len) ⋅ n bytes\n\nFigure 17. SLH-DSA signature data format"}, {"chunk_id": "NIST.FIPS.205::p0011::c000", "doc_id": "NIST.FIPS.205", "end_page": 11, "mode": "hybrid", "rank": 3, "score": 0.05427978683656815, "start_page": 11, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard defines a method for digital signature generation that can be used for the protection of binary data (commonly called a message) and for the verification and validation of those digital signatures.1 The security of the stateless hash-based digital signature algorithm (SLH-DSA) relies on the presumed difficulty of finding preimages for hash functions as well as several related\nproperties of the same hash functions. Unlike the algorithms specified in FIPS 186-5 [1], SLH-DSA\nis designed to provide resistance against attacks from a large-scale quantum computer.\nThis standard specifies the mathematical steps that need to be performed for key generation, signature generation, and signature verification. Additional assurances are required for digital signatures to be valid (e.g., the assurance of identity and private key possession). SP 800-89,\nRecommendation for Obtaining Assurances for Digital Signature Applications [3], specifies the\nrequired assurances and the methods for obtaining these assurances."}, {"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "end_page": 18, "mode": "hybrid", "rank": 4, "score": 0.05260192741621398, "start_page": 18, "text": "PK.root\n\nlayer d − 1 = 2\n\nWOTS+ signature\n\nlayer 1\n\nMerkle tree node WOTS+ signature WOTS+ public key\n\nlayer 0 FORS public key\n\nWOTS+ signature\n\nFORS signature Message\n\nFigure 1. An SLH-DSA signature\n\nThe WOTS+ one-time signature scheme is specified in Section 5, and the XMSS multi-time sig- nature scheme is specified in Section 6. Section 7 specifies the generation and verification of hypertree signatures. The FORS few-time signature scheme is specified in Section 8. Finally, Section 9 specifies the SLH-DSA key generation, signature, and verification functions. As the WOTS+, XMSS, hypertree, and FORS schemes described in this standard are not intended for use as stand-alone signature schemes, only the components of the schemes necessary to imple- ment SLH-DSA are described. In particular, these sections do not include functions for key pair generation, and a signature verification function is only specified for hypertree signatures. When used in this standard, WOTS+, XMSS, and FORS signatures are implicitly verified using functions to generate public keys from messages and signatures (see Sections 5.3, 6.3, and 8.4). When verifying an SLH-DSA signature, the randomized hash of the message and the FORS signature are used to compute a candidate FORS public key. The candidate FORS public key and the WOTS+ signature from the layer 0 XMSS key are used to compute a candidate WOTS+ public key, which is then used in conjunction with the corresponding authentication path to compute a candidate XMSS public key. The candidate layer 0 XMSS public key is used along with the layer 1"}, {"chunk_id": "NIST.FIPS.205::p0043::c002", "doc_id": "NIST.FIPS.205", "end_page": 43, "mode": "hybrid", "rank": 5, "score": 0.046943815757279184, "start_page": 43, "text": "SLH-DSA uses h bits of the message digest to select a FORS key: h − h′ bits to select an XMSS tree at the lowest layer and h′ bits to select a WOTS+ key and corresponding FORS key from that tree. k ⋅ a bits of the digest are signed by the selected FORS key. While only h + k ⋅ a bits of the message digest are used, implementation is simplified by extracting the necessary bits from a slightly larger digest. This section describes the functions for SLH-DSA key generation, signature generation, and signature verification. In the functions in this section, where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of SLH-DSA implementations is performed through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to obtain the assurance of private key possession via regeneration, as described in Section 3.1. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 10 provides guidance on the interfaces to be made available to applications.\n\n9.1 SLH-DSA Key Generation\nSLH-DSA public keys contain two elements (see Figure 16). The first is an n-byte public seed PK.seed, which is used in many hash function calls to provide domain separation between different SLH-DSA key pairs. The second value is the hypertree public key (i.e., the root of the top layer XMSS tree). PK.seed shall be generated using an approved random bit generator (see\n\nSK.seed n bytes SK.prf n bytes PK.seed n bytes PK.seed n bytes PK.root n bytes PK.root n bytes\n\nFigure 15. SLH-DSA private key Figure 16. SLH-DSA public key"}, {"chunk_id": "NIST.FIPS.205::p0043::c001", "doc_id": "NIST.FIPS.205", "end_page": 43, "mode": "hybrid", "rank": 6, "score": 0.04209558823529412, "start_page": 43, "text": "m = ⌈h − h′ ⌉ + ⌈h′ ⌉ + ⌈k ⋅ a ⌉\n8 8 8\n\nSLH-DSA uses h bits of the message digest to select a FORS key: h − h′ bits to select an XMSS tree at the lowest layer and h′ bits to select a WOTS+ key and corresponding FORS key from that tree. k ⋅ a bits of the digest are signed by the selected FORS key. While only h + k ⋅ a bits of the message digest are used, implementation is simplified by extracting the necessary bits from a slightly larger digest. This section describes the functions for SLH-DSA key generation, signature generation, and signature verification. In the functions in this section, where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of SLH-DSA implementations is performed through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to obtain the assurance of private key possession via regeneration, as described in Section 3.1. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 10 provides guidance on the interfaces to be made available to applications."}, {"chunk_id": "NIST.FIPS.205::p0008::c000", "doc_id": "NIST.FIPS.205", "end_page": 8, "mode": "hybrid", "rank": 7, "score": 0.0315136476426799, "start_page": 8, "text": "7.1 Hypertree Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . 26\n 7.2 Hypertree Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n8 Forest of Random Subsets (FORS) 29\n 8.1 Generating FORS Secret Values . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n 8.2 Generating a Merkle Hash Tree . . . . . . . . . . . . . . . . . . . . . . . . . 30\n 8.3 Generating a FORS Signature . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n 8.4 Computing a FORS Public Key From a Signature . . . . . . . . . . . . . . . . . 31\n\n9 SLH-DSA Internal Functions 33\n 9.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 9.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n 9.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n10 SLH-DSA External Functions 37\n 10.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2.1 Pure SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 38\n 10.2.2 HashSLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 39\n 10.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 41"}, {"chunk_id": "NIST.FIPS.205::p0044::c000", "doc_id": "NIST.FIPS.205", "end_page": 44, "mode": "hybrid", "rank": 8, "score": 0.03057889822595705, "start_page": 44, "text": "[14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength. The SLH-DSA private key contains two random, secret n-byte values (see Figure 15). SK.seed is used to generate all of the WOTS+ and FORS private key elements. SK.prf is used to generate a randomization value for the randomized hashing of the message in SLH-DSA. The private key also includes a copy of the public key. Both SK.seed and SK.prf shall be generated using an approved random bit generator, where the instantiation of the random bit generator supports at least 8n bits of security strength. Algorithm 18 generates an SLH-DSA key pair. Lines 1 through 3 compute the root of the top layer XMSS tree. Line 4 bundles the three inputs and the computed PK.seed into the private and public keys. SLH-DSA signing has two variants — “hedged” and deterministic (see Section 9.2) — whose keys should only be used for the generation and verification of hedged and deterministic SLH-DSA digital signatures, respectively."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.5, "ndcg_at_k": 0.6309297535714575, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 0.5, "ndcg_at_k": 0.6309297535714575, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 0.5, "ndcg_at_k": 0.6309297535714575, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.5, "ndcg_at_k": 0.6309297535714575, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [2, 5, 6, 8], "top_hit_ids": [{"chunk_id": "NIST.FIPS.205::p0008::c001", "doc_id": "NIST.FIPS.205", "pages": "p8-p8", "rank": 1}, {"chunk_id": "NIST.FIPS.205::p0044::c001", "doc_id": "NIST.FIPS.205", "pages": "p44-p44", "rank": 2}, {"chunk_id": "NIST.FIPS.205::p0011::c000", "doc_id": "NIST.FIPS.205", "pages": "p11-p11", "rank": 3}, {"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "pages": "p18-p18", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0043::c002", "doc_id": "NIST.FIPS.205", "pages": "p43-p43", "rank": 5}, {"chunk_id": "NIST.FIPS.205::p0043::c001", "doc_id": "NIST.FIPS.205", "pages": "p43-p43", "rank": 6}, {"chunk_id": "NIST.FIPS.205::p0008::c000", "doc_id": "NIST.FIPS.205", "pages": "p8-p8", "rank": 7}, {"chunk_id": "NIST.FIPS.205::p0044::c000", "doc_id": "NIST.FIPS.205", "pages": "p44-p44", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 28, "start_page": 28}], "qid": "q007", "question": "give me Algorithm 2 SHAKE128", "retrieval": {"doc_hit_ranks": [1, 3], "gold_hit_ranks": [1], "hits": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 1, "score": 0.045680369617857444, "start_page": 28, "text": "is equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length.\n\nAlgorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results\n\nIn this standard, the incremental API for SHAKE128 will only be invoked through a wrapper XOF,"}, {"chunk_id": "NIST.FIPS.204::p0009::c001", "doc_id": "NIST.FIPS.204", "end_page": 9, "mode": "hybrid", "rank": 2, "score": 0.0401627815821632, "start_page": 9, "text": "Table 1 ML-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Table 2 Sizes (in bytes) of keys and signatures of ML-DSA . . . . . . . . . . . . . . . . . . 16 Table 3 While loop and XOF output limits for a 2−256 or less probability of failure . . . . . 52\n\nList of Algorithms Algorithm 1 ML-DSA.KeyGen() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Algorithm 2 ML-DSA.Sign(sk, M, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 3 ML-DSA.Verify(pk, M, σ, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 4 HashML-DSA.Sign(sk, M, ctx, PH) . . . . . . . . . . . . . . . . . . . . . . 20 Algorithm 5 HashML-DSA.Verify(pk, M, σ, ctx, PH) . . . . . . . . . . . . . . . . . . . . 21 Algorithm 6 ML-DSA.KeyGen_internal(ξ) . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 7 ML-DSA.Sign_internal(sk, M′, rnd) . . . . . . . . . . . . . . . . . . . . . . 25 Algorithm 8 ML-DSA.Verify_internal(pk, M′, σ) . . . . . . . . . . . . . . . . . . . . . . 27 Algorithm 9 IntegerToBits(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 10 BitsToInteger(y, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 11 IntegerToBytes(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 12 BitsToBytes(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 13 BytesToBits(z) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 14 CoeffFromThreeBytes(b0, b1, b2) . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 15 CoeffFromHalfByte(b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 16 SimpleBitPack(w, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 17 BitPack(w, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 18 SimpleBitUnpack(v, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 19 BitUnpack(v, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 20 HintBitPack(h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 21 HintBitUnpack(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 22 pkEncode(ρ, t1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 23 pkDecode(pk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 24 skEncode(ρ, K, tr, s1, s2, t0) . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 25 skDecode(sk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 26 sigEncode(c, z, h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 27 sigDecode(σ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 28 w1Encode(w1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 29 SampleInBall(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Algorithm 30 RejNTTPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 31 RejBoundedPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 32 ExpandA(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 33 ExpandS(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 34 ExpandMask(ρ, μ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 35 Power2Round(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 36 Decompose(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 37 HighBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 38 LowBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41"}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "end_page": 29, "mode": "hybrid", "rank": 3, "score": 0.030330882352941176, "start_page": 29, "text": "which is defined as follows.\n 1. XOF.Init() = SHAKE128.Init().\n 2. XOF.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str).\n 3. XOF.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8 ⋅ l).\nNote that XOF.Squeeze requires the input length to be specified in bytes. This is consistent with the convention that all wrapper functions treat inputs and outputs as byte arrays and measure the lengths of all such arrays in terms of bytes.\n\n4.2 General Algorithms\nThis section specifies a number of algorithms that will be used as subroutines in ML-KEM.\n\n4.2.1 Conversion and Compression Algorithms\nThis section specifies several algorithms for converting between bit arrays, byte arrays, and arrays of integers modulo m. It also specifies a certain operation for compressing integers modulo q, and the corresponding decompression operation.\n\nAlgorithm 3 BitsToBytes(b)\nConverts a bit array (of a length that is a multiple of eight) into an array of bytes.\nInput: bit array b ∈ {0, 1}8⋅l.\nOutput: byte array B ∈ Bl.\n1: B ← (0, ... , 0)\n 2: for (i ← 0; i < 8l; i ++)\n 3: B [⌊i/8⌋] ← B [⌊i/8⌋] + b[i] ⋅ 2i mod 8\n4: end for\n5: return B"}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "end_page": 24, "mode": "hybrid", "rank": 4, "score": 0.029910714285714284, "start_page": 24, "text": "8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it\nshould be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to\nrelate bits, bytes, and words."}, {"chunk_id": "NIST.SP.800-227::p0035::c001", "doc_id": "NIST.SP.800-227", "end_page": 35, "mode": "hybrid", "rank": 5, "score": 0.028629032258064516, "start_page": 35, "text": "For simplicity, the exposition below focuses on a particular case: constructing a single KEM from two component KEMs. Since both the components and the multi-algorithm scheme in this case are of the same type (i.e., KEMs), the result is called a composite KEM. Most keyestablishment schemes of interest can easily be expressed as KEMs (see, e.g., ECDH-KEM in Sec. 5.1.1 and RSA-KEM in Sec. 5.1.2). Moreover, the hybrid PQ/T application typically calls for two component schemes: one post-quantum scheme, and one traditional scheme. The two-algorithm composite KEM described below is easily adapted to other cases, such as combining more than two schemes or combining KEMs with non-KEMs.\n\n4.6.1. Constructing a Composite KEM\nGiven two KEMs Π1 and Π2, one can construct a composite KEM C[Π1, Π2] via the following\nsequence of steps:\n 1. Choose parameter sets. Choose a collection C[Π1, Π2].ParamSets of parameter\n sets. Each parameter set will be a pair p = (p1, p2), where p1 ∈ Π1.ParamSets and\n p2 ∈ Π2.ParamSets.\n 2. Select a key combiner. Choose a key combiner algorithm KeyCombine. The inputs\nto KeyCombine include a pair of shared secret keys (one from Π1 and one from Π2), a pair of ciphertexts, a pair of encapsulation keys, and a parameter set. The output is a single shared secret key. Section 4.6.2 discusses NIST-approved key combiners.\n 3. Construct a composite key-generation algorithm. When a parameter set p =\n (p1, p2) is input, the algorithm C[Π1, Π2].KeyGen will perform:\n 1. (ek1, dk1) ← Π1.KeyGen(p1).\n 2. (ek2, dk2) ← Π2.KeyGen(p2).\n 3. Output composite encapsulation key ek1‖ek2.\n 4. Output composite decapsulation key dk1‖dk2.\n 4. Construct a composite encapsulation algorithm. When a parameter set p =\n (p1, p2) and encapsulation key ek1‖ek2 are input, the algorithm C[Π1, Π2].Encaps\nwill perform:\n 1. (K1, c1) ← Π1.Encaps(p1, ek1).\n 2. (K2, c2) ← Π2.Encaps(p2, ek2).\n 3. Output combined shared secret key\n\nK ← KeyCombine(K1, K2, c1, c2, ek1, ek2, p). (9)\n\n4. Output composite ciphertext c := c1‖c2."}, {"chunk_id": "NIST.SP.800-227::p0036::c000", "doc_id": "NIST.SP.800-227", "end_page": 36, "mode": "hybrid", "rank": 6, "score": 0.02821869488536155, "start_page": 36, "text": "5. Construct a composite decapsulation algorithm. When a parameter set p =\n(p1, p2), decapsulation key dk1‖dk2, and ciphertext c1‖c2 are input, the algorithm\n C[Π1, Π2].Decaps will perform:\n 1. K′ ← Π1.Decaps(p1, dk1, c1).\n 2. K′ ← Π2.Decaps(p2, dk2, c2).\n 3. Output combined shared secret key\n\nK′ ← KeyCombine(K′ , K′ , c1, c2, ek1, ek2, p). (10) 1 2\n\nSince the inputs to KeyCombine include the composite encapsulation key, the decapsulating party must retain a copy of that key or maintain the ability to recreate it after performing key generation.\n\nGeneral multi-algorithm schemes. The above construction can be extended in the obvious way to composite constructions that use more than two component KEMs. Extending to the case of a completely general multi-algorithm key-establishment scheme can be more complex, as the components in such a scheme can vary widely. For example, such schemes could potentially include pre-shared keys or shared secrets established via quantum key distribution. Still, most multi-algorithm schemes will likely include a step in which a series of shared secrets are combined via a key combiner algorithm of a form similar to KeyCombine above. In those cases, an approved key combiner discussed in Sec. 4.6.2 shall be used."}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 7, "score": 0.027149321266968326, "start_page": 30, "text": "Algorithm 4 shows the DER encodings of the OIDs for SHA-256, SHA-512, and SHAKE128. However, it may be used with other hash functions or XOFs.\n\nAlgorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ"}, {"chunk_id": "NIST.FIPS.204::p0023::c003", "doc_id": "NIST.FIPS.204", "end_page": 23, "mode": "hybrid", "rank": 8, "score": 0.025974025974025976, "start_page": 23, "text": "SHAKE256(str, 8l) = SHAKE256(BytesToBits(str), 8l).\n\nIn addition to using a mostly byte-oriented variant of the API defined in FIPS 202 for SHAKE256 and\nSHAKE128, this standard sometimes makes use of the incremental API defined in SP 800-185 [25]. This API\nconsists of three functions for each variant of SHAKE. These functions can be used to absorb a sequence of arbitrary-length strings and squeeze a sequence of arbitrary-length strings. These functions perform buffering to handle any incomplete data blocks while absorbing or squeezing. For example, for SHAKE256:\n\n• ctx ← SHAKE256.Init() Initializes a hash function context.\n\n• ctx ← SHAKE256.Absorb(ctx, str) Injects data to be used in the absorbing phase of SHAKE256 and updates context ctx."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 3], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 1}, {"chunk_id": "NIST.FIPS.204::p0009::c001", "doc_id": "NIST.FIPS.204", "pages": "p9-p9", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "pages": "p29-p29", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "pages": "p24-p24", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0035::c001", "doc_id": "NIST.SP.800-227", "pages": "p35-p35", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0036::c000", "doc_id": "NIST.SP.800-227", "pages": "p36-p36", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0023::c003", "doc_id": "NIST.FIPS.204", "pages": "p23-p23", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 28, "start_page": 28}], "qid": "q008", "question": "What are the steps in Algorithm 2 SHAKE128?", "retrieval": {"doc_hit_ranks": [1, 2, 8], "gold_hit_ranks": [1, 8], "hits": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 1, "score": 0.045680369617857444, "start_page": 28, "text": "is equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length.\n\nAlgorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results\n\nIn this standard, the incremental API for SHAKE128 will only be invoked through a wrapper XOF,"}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "end_page": 29, "mode": "hybrid", "rank": 2, "score": 0.030303030303030304, "start_page": 29, "text": "which is defined as follows.\n 1. XOF.Init() = SHAKE128.Init().\n 2. XOF.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str).\n 3. XOF.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8 ⋅ l).\nNote that XOF.Squeeze requires the input length to be specified in bytes. This is consistent with the convention that all wrapper functions treat inputs and outputs as byte arrays and measure the lengths of all such arrays in terms of bytes.\n\n4.2 General Algorithms\nThis section specifies a number of algorithms that will be used as subroutines in ML-KEM.\n\n4.2.1 Conversion and Compression Algorithms\nThis section specifies several algorithms for converting between bit arrays, byte arrays, and arrays of integers modulo m. It also specifies a certain operation for compressing integers modulo q, and the corresponding decompression operation.\n\nAlgorithm 3 BitsToBytes(b)\nConverts a bit array (of a length that is a multiple of eight) into an array of bytes.\nInput: bit array b ∈ {0, 1}8⋅l.\nOutput: byte array B ∈ Bl.\n1: B ← (0, ... , 0)\n 2: for (i ← 0; i < 8l; i ++)\n 3: B [⌊i/8⌋] ← B [⌊i/8⌋] + b[i] ⋅ 2i mod 8\n4: end for\n5: return B"}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "end_page": 24, "mode": "hybrid", "rank": 3, "score": 0.029513888888888888, "start_page": 24, "text": "8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it\nshould be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to\nrelate bits, bytes, and words."}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 4, "score": 0.027272727272727275, "start_page": 30, "text": "Algorithm 4 shows the DER encodings of the OIDs for SHA-256, SHA-512, and SHAKE128. However, it may be used with other hash functions or XOFs.\n\nAlgorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ"}, {"chunk_id": "NIST.FIPS.205::p0052::c000", "doc_id": "NIST.FIPS.205", "end_page": 52, "mode": "hybrid", "rank": 5, "score": 0.026279628993473032, "start_page": 52, "text": "Algorithm 25 hash_slh_verify(M, SIG, ctx, PH, PK) Verifies a pre-hash SLH-DSA signature. Input: Message M, signature SIG, context string ctx, pre-hash function PH, public key PK. Output: Boolean. 1: if |ctx| > 255 then 2: return false 3: end if 4: switch PH do 5: case SHA-256: 6: OID ← toByte(0x0609608648016503040201, 11) ▷ 2.16.840.1.101.3.4.2.1 7: PHM ← SHA-256(M) 8: case SHA-512: 9: OID ← toByte(0x0609608648016503040203, 11) ▷ 2.16.840.1.101.3.4.2.3 10: PHM ← SHA-512(M) 11: case SHAKE128: 12: OID ← toByte(0x060960864801650304020B, 11) ▷ 2.16.840.1.101.3.4.2.11 13: PHM ← SHAKE128(M, 256) 14: case SHAKE256: 15: OID ← toByte(0x060960864801650304020C, 11) ▷ 2.16.840.1.101.3.4.2.12 16: PHM ← SHAKE256(M, 512) 17: case ... ▷ other approved hash functions or XOFs 18: ... 19: end switch 20: M′ ← toByte(1, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM 21: return slh_verify_internal(M ′ , SIG, PK)"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 6, "score": 0.024934585193166076, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.FIPS.204::p0030::c001", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 7, "score": 0.02402745995423341, "start_page": 30, "text": "Algorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ\n\nAlgorithm 5 presents the signature verification for HashML-DSA . This function constructs M′ in the same way as Algorithm 4 and passes the resulting M′ to Algorithm ML-DSA.Verify_internal for verification. As with the pre-hash signature generation, M′ may be constructed outside of the cryptographic module that performs ML-DSA.Verify_internal. However, in the case of HashML-DSA , the hash or XOF of the content must be computed within a FIPS 140-validated cryptographic module, which may be a different cryptographic module than the one that performs ML-DSA.Verify_internal. As noted in Section 5.4, the identifier associated with the signature should indicate whether ML-DSA or"}, {"chunk_id": "NIST.FIPS.203::p0028::c000", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 8, "score": 0.01639344262295082, "start_page": 28, "text": "where s ∈ B∗.\nThe function G takes one variable-length input and produces two 32-byte outputs. It will be\ndenoted by G ∶ B∗ → B32 × B32. The two outputs of G will be denoted by (a, b) ← G(c), where\na, b ∈ B32, c ∈ B∗, and G(c) = a‖b. The function G shall be instantiated as\n\nG(c) ∶= SHA3-512(c) . (4.5)\n\neXtendable-Output Function (XOF). This standard uses a XOF wrapper defined in terms of the incremental API for SHAKE128 in SP 800-185 [21]. This SHAKE128 API consists of three functions: • ctx ← SHAKE128.Init() Initializes a XOF “context” ctx. • ctx ← SHAKE128.Absorb(ctx, str) Injects data to be used in the “absorbing” phase of SHAKE128 and updates the context accordingly. • (ctx, B) ← SHAKE128.Squeeze(ctx, 8 ⋅ z) Extracts z output bytes produced during the “squeezing” phase of SHAKE128 and updates the context accordingly. While the above functions are constructed using the Keccak-f permutation rather than the XOF SHAKE128 directly, they are defined so that a single SHAKE128 call of the form\n\noutput ← SHAKE128(str1‖ ... ‖strm , 8b1 + ... + 8bl) (4.6)\n\nis equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2, 8], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "pages": "p29-p29", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "pages": "p24-p24", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0052::c000", "doc_id": "NIST.FIPS.205", "pages": "p52-p52", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0030::c001", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0028::c000", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.203", "end_page": 21, "start_page": 21}, {"doc_id": "NIST.FIPS.204", "end_page": 4, "start_page": 3}, {"doc_id": "NIST.FIPS.204", "end_page": 19, "start_page": 19}], "qid": "q009", "question": "What are the difference between ML-KEM and ML-DSA?", "retrieval": {"doc_hit_ranks": [1, 3, 5, 6, 7, 8], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "end_page": 8, "mode": "hybrid", "rank": 1, "score": 0.060447560951593204, "start_page": 8, "text": "5.4 Pre-Hash ML-DSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n 5.4.1 HashML-DSA Signing and Verifying . . . . . . . . . . . . . . . . . . . . . . . . 19\n6 Internal Functions 22\n 6.1 ML-DSA Key Generation (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n 6.2 ML-DSA Signing (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n 6.3 ML-DSA Verifying (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n7 Auxiliary Functions 28\n 7.1 Conversion Between Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33\n 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39\n 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52"}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 2, "score": 0.05789451315398019, "start_page": 43, "text": "5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications\nThis section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption\nA KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for\nPKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15]."}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 3, "score": 0.05726975726975728, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 4, "score": 0.031099324975891997, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 5, "score": 0.030090497737556562, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.204::p0064::c001", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 6, "score": 0.027745885954841176, "start_page": 64, "text": "D.1 Differences Between Version 3.1 and the Round 3 Version of CRYSTALS- DILITHIUM The lengths of the variables ρ′ (private random seed) and μ (message representative) in the signing algorithm were increased from 384 to 512 bits. The increase in the length of μ corrects a security flaw that appeared in the third-round submission, where a collision attack against SHAKE256 with a 384-bit\noutput would make it so that parameters targeting NIST security strength category 5 could only meet\ncategory 4 [32].\nAdditionally, the length of the variable tr (the hash of the public key) was reduced from 384 to 256 bits.\nIn key generation, the variable ς was relabeled as ρ′ and increased in size from 256 bits to 512 bits.\n\nD.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34]."}, {"chunk_id": "NIST.FIPS.204::p0027::c000", "doc_id": "NIST.FIPS.204", "end_page": 27, "mode": "hybrid", "rank": 7, "score": 0.015873015873015872, "start_page": 27, "text": "5. External Functions\n\nThe signing, verifying, and key generation functions can be split into “external” and “internal” components to simplify APIs and Cryptographic Algorithm Validation Program (CAVP) testing. The external components generate randomness and perform various checks before calling their internal counterparts. The internal components are deterministic and can assume that the external components did not encounter error conditions. The distinction between external and internal functions also simplifies the presentation of algorithms for signing and verification by grouping the operations that are shared between ML-DSA.Sign and HashML-DSA.Sign in ML-DSA.Sign_internal and grouping the operations that are shared between ML-DSA.Verify and HashML-DSA.Verify in ML-DSA.Verify_internal.\n\n5.1 ML-DSA Key Generation\nThe key generation algorithm ML-DSA.KeyGen takes no input and outputs a public key and a private key, which are both encoded as byte strings.\nThe algorithm uses an approved RBG to generate a 256-bit (32-byte) random seed ξ that is given as input to ML-DSA.KeyGen_internal (Algorithm 6), which produces the public and private keys."}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 8, "score": 0.015151515151515152, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "pages": "p8-p8", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 4}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0064::c001", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0027::c000", "doc_id": "NIST.FIPS.204", "pages": "p27-p27", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 4, "start_page": 4}, {"doc_id": "NIST.FIPS.203", "end_page": 11, "start_page": 11}], "qid": "q010", "question": "Define ML-KEM encapsulation key and where it’s used.", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 6, 7], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 1, "score": 0.06117215901558128, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 2, "score": 0.05682913147644286, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.FIPS.203::p0022::c000", "doc_id": "NIST.FIPS.203", "end_page": 22, "mode": "hybrid", "rank": 3, "score": 0.04329846248571716, "start_page": 22, "text": "In the typical application, a KEM is used to establish a shared secret key between two parties (here referred to as Alice and Bob) as described in Figure 1. Alice begins by running KeyGen in order to generate a (public) encapsulation key and a (private) decapsulation key. Upon obtaining Alice’s encapsulation key, Bob runs the Encaps algorithm, which produces Bob’s copy K of the shared secret key along with an associated ciphertext. Bob sends the ciphertext to Alice, and Alice completes the process by running the Decaps algorithm using her decapsulation key and the ciphertext. This final step produces Alice’s copy K′ of the shared secret key.\nAfter completing this process, Alice and Bob would like to conclude that their outputs satisfy\nK′ = K and that this value is a secure, random, shared secret key. However, these properties\nonly hold if certain important conditions are satisfied, as discussed in SP 800-227 [1].\n\n3.2 The ML-KEM Scheme\nML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was\ninitially described in [8]. The following is a brief and informal description of the computational\nassumption underlying ML-KEM and how the ML-KEM scheme is constructed."}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "end_page": 21, "mode": "hybrid", "rank": 4, "score": 0.043290043290043295, "start_page": 21, "text": "3. Overview of the ML-KEM Scheme\n\nThis section gives a high-level overview of the ML-KEM scheme.\n\n3.1 Key-Encapsulation Mechanisms\nThe following is a high-level overview of key-encapsulation mechanisms (KEMs). For details, see\n SP 800-227 [1].\nA KEM is a cryptographic scheme that, under certain conditions, can be used to establish a shared secret key between two communicating parties. This shared secret key can then be used for symmetric-key cryptography.\nA KEM consists of three algorithms and a collection of parameter sets. The three algorithms are:\n 1. A probabilistic key generation algorithm denoted by KeyGen\n 2. A probabilistic ”encapsulation” algorithm denoted by Encaps\n 3. A deterministic ”decapsulation” algorithm denoted by Decaps\nThe collection of parameter sets is used to select a trade-off between security and efficiency.\nEach parameter set in the collection is a list of specific (typically numerical) values, one for each parameter required by the three algorithms.\nAlice Bob\n\nKeyGen\n\ndecapsulation key encapsulation key\n\nDecaps ciphertext Encaps\n\nAlice’s copy of the Bob’s copy of the shared secret key shared secret key K′ K\n\nFigure 1. A simple view of key establishment using a KEM"}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 5, "score": 0.031099324975891997, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 6, "score": 0.029910714285714284, "start_page": 44, "text": "This section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation\nThe key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key.\nWhile the encapsulation key can be made public, the decapsulation key shall remain private.\nThe seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a\ndecapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)"}, {"chunk_id": "NIST.FIPS.203::p0010::c001", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 7, "score": 0.02886002886002886, "start_page": 10, "text": "1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government.\n\n1.2 Context Over the past several years, there has been steady progress toward building quantum computers. If large-scale quantum computers are realized, the security of many commonly used public-key cryptosystems will be at risk. This would include key-establishment schemes and digital signature schemes whose security depends on the difficulty of solving the integer factorization and discrete logarithm problems (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantum-resistant public-key cryptographic algorithms. A total of 82 candidate algorithms were submitted to NIST for consideration. After three rounds of evaluation and analysis, NIST selected the first four algorithms for standardization. These algorithms are intended to protect sensitive U.S. Government information well into the foreseeable future, including after the advent of cryptographically-relevant quantum computers. This standard specifies a variant of the selected algorithm CRYSTALS-KYBER, a lattice-based key-encapsulation mechanism (KEM) designed by Peter Schwabe, Roberto Avanzi, Joppe Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John Schanck, Gregor Seiler, Damien Stehlé, and Jintai Ding [4]. Throughout this standard, the KEM specified here will be referred to as ML-KEM, as it is based on the Module Learning With Errors assumption."}, {"chunk_id": "NIST.SP.800-227::p0016::c000", "doc_id": "NIST.SP.800-227", "end_page": 16, "mode": "hybrid", "rank": 8, "score": 0.014925373134328358, "start_page": 16, "text": "party can predetermine it. In key transport (e.g., RSA-OAEP [2]), one party selects the key and then transmits it (in some form) to the other party. Depending on the internal structure of the encapsulation function, a KEM could be viewed as either a key-agreement scheme or a key-transport scheme. For example, the shared secret key in ML-KEM [3] is a function of both the randomness provided by Bob and the (randomly generated) encapsulation key of Alice. Therefore, ML-KEM could be viewed as a key-agreement scheme. However, as the example KEMFROMPKE shows, the encapsulation operation in a KEM might simply consist of Bob generating the shared secret key and then encrypting it, which is key transport. An application can achieve a particular type of key establishment (i.e., key agreement or key transport) using any KEM by taking appropriate additional steps using standard symmetric-key cryptography techniques. That is, given a KEM Π, Alice and Bob can achieve key agreement by both executing Π.KeyGen, sending the encapsulation keys to each other, and completing the steps of key establishment using a KEM. This will result in two separate shared secret keys that can be combined using an appropriate key-derivation method. Conversely, Π can be used to achieve key transport by following the steps in Fig. 7 and replacing m with the shared secret key produced by Π."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2, 7], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0022::c000", "doc_id": "NIST.FIPS.203", "pages": "p22-p22", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "pages": "p21-p21", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0010::c001", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0016::c000", "doc_id": "NIST.SP.800-227", "pages": "p16-p16", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 44, "start_page": 44}], "qid": "q011", "question": "What are the inputs/outputs of ML-KEM KeyGen?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [3, 5], "hits": [{"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 1, "score": 0.060486896615928876, "start_page": 23, "text": "Parameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329.\n\nDecapsulation failures. Provided that all inputs are well-formed and randomness generation is successful, the key establishment procedure of ML-KEM will never explicitly fail, meaning that both ML-KEM.Encaps and ML-KEM.Decaps will each output a 256-bit value. Moreover, if no corruption or interference is present, the two 256-bit values produced by ML-KEM.Encaps and ML-KEM.Decaps will be equal with overwhelming probability (i.e., K′ will equal K in the process described in Figure 1). The event that K′ ≠ K under these conditions is called a decapsulation"}, {"chunk_id": "NIST.FIPS.203::p0048::c000", "doc_id": "NIST.FIPS.203", "end_page": 48, "mode": "hybrid", "rank": 2, "score": 0.05659899801690847, "start_page": 48, "text": "8. Parameter Sets\n\nML-KEM is equipped with three parameter sets, each of the which comprises five individual parameters: k, η1, η2, du, and dv. There are also two constants: n = 256 and q = 3329. The following is a brief and informal description of the roles played by the variable parameters in the algorithms of K-PKE and ML-KEM. See Section 5 for details. • The parameter k determines the dimensions of the matrix A that appears in K-PKE.KeyGen and K-PKE.Encrypt. It also determines the dimensions of vectors s and e in K-PKE.KeyGen and the dimensions of vectors y and e1 in K-PKE.Encrypt. • The parameter η1 is required to specify the distribution for generating the vectors s and e in K-PKE.KeyGen and the vector y in K-PKE.Encrypt. • The parameter η2 is required to specify the distribution for generating the vectors e1 and e2 in K-PKE.Encrypt. • The parameters du and dv serve as parameters and inputs for the functions Compress, Decompress, ByteEncode, and ByteDecode in K-PKE.Encrypt and K-PKE.Decrypt. This standard approves the parameter sets given in Table 2. Each parameter set is associated with a required security strength for randomness generation (see Section 3.3). The sizes of the ML-KEM keys and ciphertexts for each parameter set are summarized in Table 3.\n\nTable 2. Approved parameter sets for ML-KEM"}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 3, "score": 0.047643442622950824, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.FIPS.203::p0056::c000", "doc_id": "NIST.FIPS.203", "end_page": 56, "mode": "hybrid", "rank": 4, "score": 0.04623878536922015, "start_page": 56, "text": "Appendix C — Differences From the CRYSTALS-Kyber Submission\n\nThis appendix lists the differences between CRYSTALS-KYBER (as described in [4]) and the ML-KEM\nscheme (specified in this document) that result in differing input-output behavior of the main algorithms (i.e., KeyGen, Encaps, Decaps). Since a conforming implementation need only match the input-output behavior of these three algorithms (see “Implementations” and Section 3.3 below), the list does not include any of the numerous differences in how the main algorithms actually produce outputs from inputs (e.g., via different computational steps or different subroutines),\nnor any differences in presentation between this standard and [4]."}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 5, "score": 0.0304147465437788, "start_page": 44, "text": "This section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation\nThe key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key.\nWhile the encapsulation key can be made public, the decapsulation key shall remain private.\nThe seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a\ndecapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)"}, {"chunk_id": "NIST.FIPS.203::p0046::c001", "doc_id": "NIST.FIPS.203", "end_page": 46, "mode": "hybrid", "rank": 6, "score": 0.027884615384615386, "start_page": 46, "text": "7.3 ML-KEM Decapsulation\nThe decapsulation algorithm ML-KEM.Decaps of ML-KEM (Algorithm 21) accepts a decapsulation key and an ML-KEM ciphertext as input, does not use any randomness, and outputs a shared secret. This algorithm requires input checking, as specified below.\n\nDecapsulation input check. To check a candidate decapsulation key dk and ciphertext c, perform the following checks:\n 1. (Ciphertext type check) If c is not a byte array of length 32(duk + dv) for the values of du,\ndv, and k specified by the relevant parameter set, then input checking has failed.\n 2. (Decapsulation key type check) If dk is not a byte array of length 768k + 96 for the value of\nk specified by the relevant parameter set, then input checking has failed.\n 3. (Hash check) Perform the computation\n\ntest ← H(dk[384k ∶ 768k + 32])) . (7.2)\n\nIf test ≠ dk[768k + 32 ∶ 768k + 64], then input checking has failed.\nIf all of the above checks pass, then ML-KEM.Decaps can be run with inputs dk ∶= dk and c ∶= c. It\nis important to note that this checking process does not guarantee that dk is a properly produced\noutput of ML-KEM.KeyGen, nor that c is a properly produced output of ML-KEM.Encaps.\nML-KEM.Decaps shall not be run with a decapsulation key or a ciphertext unless both have been checked. However, checking of the decapsulation key need not be performed by the decapsulating party, nor with every execution of ML-KEM.Decaps. Instead, assurance that this\ncheck has been performed can be acquired through other means (see SP 800-227 [1]). Ciphertext\nchecking shall be performed with every execution of ML-KEM.Decaps."}, {"chunk_id": "NIST.FIPS.203::p0037::c001", "doc_id": "NIST.FIPS.203", "end_page": 37, "mode": "hybrid", "rank": 7, "score": 0.025816993464052286, "start_page": 37, "text": "This section describes the component scheme K-PKE. As discussed in Section 3.3, K-PKE is not approved for use in a stand-alone fashion. It serves only as a collection of subroutines for use in the algorithms of the approved scheme ML-KEM, as described in Section 7. K-PKE consists of three algorithms: 1. Key generation (K-PKE.KeyGen) 2. Encryption (K-PKE.Encrypt) 3. Decryption (K-PKE.Decrypt) When K-PKE is instantiated as part of ML-KEM, K-PKE inherits the parameter set selected for ML-KEM. Each parameter set specifies numerical values for each parameter. While n is always 256 and q is always 3329, the values of the remaining parameters k, η1, η2, du, and dv vary among the three parameter sets. Parameters and parameter sets are described in Section 8. The algorithms in this section do not perform any input checking because they are only invoked as subroutines of the main ML-KEM algorithms. The algorithms of ML-KEM themselves do perform input checking as needed. Each of the algorithms of K-PKE is accompanied by a brief, informal description in text. For simplicity, this description is written in terms of vectors and matrices whose entries are elements of Rq . In the actual algorithm, most of the computations occur in the NTT domain in order to improve the efficiency of multiplication. The relevant vectors and matrices will then have entries in Tq . Linear-algebraic arithmetic with such vectors and matrices (e.g., line 18 of K-PKE.KeyGen) is performed as described in Sections 2.4.7 and 4.3.1. The encryption and decryption keys of K-PKE are also stored in the NTT form.\n\n5.1 K-PKE Key Generation The key generation algorithm K-PKE.KeyGen of K-PKE (Algorithm 13) receives a seed as input and outputs an encryption key ekPKE and a decryption key dkPKE. As is typically the case for public-key encryption, the encryption key can be made public, while the decryption key and the randomness must remain private. Indeed, the encryption key of K-PKE will serve as the encapsulation key of ML-KEM (see ML-KEM.KeyGen below) and can thus be made public. Meanwhile, the decryption key and seed of K-PKE.KeyGen must remain private as they can be used to perform decapsulation in ML-KEM. The matrix A generated in steps 3-7 of K-PKE.KeyGen can be stored, as specified in Section 3.3. This allows later operations to use A directly rather than re-expanding it from the public seed ρ.\n\nInformal description. The decryption key of K-PKE.KeyGen is a length-k vector s of elements of Rq (i.e., s ∈ Rk). Roughly speaking, s is a set of secret variables, while the encryption key is a collection of q “noisy” linear equations (A, As + e) in the secret variables s. The rows of the matrix A form the equation coefficients. This matrix is generated pseudorandomly using XOF with only a seed stored in the encryption key. The secret s and the “noise” e are sampled from"}, {"chunk_id": "NIST.FIPS.203::p0033::c001", "doc_id": "NIST.FIPS.203", "end_page": 33, "mode": "hybrid", "rank": 8, "score": 0.014492753623188406, "start_page": 33, "text": "f ×Rq g = NTT−1(f ×Tq g), (4.9)\n\nwhere ×Rq and ×Tq denote multiplication in Rq and Tq , respectively. Moreover, since Tq is a\nproduct of 128 rings that each consist of polynomials of degree at most one, the operation ×Tq\nis much more efficient than the operation ×Rq . For these reasons, the NTT is considered to be\nan integral part of ML-KEM and not merely an optimization.\nAs the rings Rq and Tq have a vector space structure over Zq , the most natural abstract data type to represent elements from either of these rings is Zn. For this reason, the choice of data q structure for the inputs and outputs of NTT and NTT−1 are length-n arrays of integers modulo q. These arrays are understood to represent elements of Tq or Rq , respectively (see Section\n2.4.4). Algorithms 9 and 10 describe an efficient means of computing NTT and NTT−1 in place.\nHowever, to clarify the distinction between the algebraic objects before and after the conversion, the algorithms are written with explicit inputs and outputs. This is consistent with this standard’s convention that all inputs are passed by copy."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [3, 5], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0048::c000", "doc_id": "NIST.FIPS.203", "pages": "p48-p48", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0056::c000", "doc_id": "NIST.FIPS.203", "pages": "p56-p56", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0046::c001", "doc_id": "NIST.FIPS.203", "pages": "p46-p46", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0037::c001", "doc_id": "NIST.FIPS.203", "pages": "p37-p37", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0033::c001", "doc_id": "NIST.FIPS.203", "pages": "p33-p33", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.204", "end_page": 5, "start_page": 5}, {"doc_id": "NIST.FIPS.205", "end_page": 5, "start_page": 5}], "qid": "q012", "question": "How do ML-DSA and SLH-DSA differ in intended use-cases?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "end_page": 18, "mode": "hybrid", "rank": 1, "score": 0.054532886320079695, "start_page": 18, "text": "PK.root\n\nlayer d − 1 = 2\n\nWOTS+ signature\n\nlayer 1\n\nMerkle tree node WOTS+ signature WOTS+ public key\n\nlayer 0 FORS public key\n\nWOTS+ signature\n\nFORS signature Message\n\nFigure 1. An SLH-DSA signature\n\nThe WOTS+ one-time signature scheme is specified in Section 5, and the XMSS multi-time sig- nature scheme is specified in Section 6. Section 7 specifies the generation and verification of hypertree signatures. The FORS few-time signature scheme is specified in Section 8. Finally, Section 9 specifies the SLH-DSA key generation, signature, and verification functions. As the WOTS+, XMSS, hypertree, and FORS schemes described in this standard are not intended for use as stand-alone signature schemes, only the components of the schemes necessary to imple- ment SLH-DSA are described. In particular, these sections do not include functions for key pair generation, and a signature verification function is only specified for hypertree signatures. When used in this standard, WOTS+, XMSS, and FORS signatures are implicitly verified using functions to generate public keys from messages and signatures (see Sections 5.3, 6.3, and 8.4). When verifying an SLH-DSA signature, the randomized hash of the message and the FORS signature are used to compute a candidate FORS public key. The candidate FORS public key and the WOTS+ signature from the layer 0 XMSS key are used to compute a candidate WOTS+ public key, which is then used in conjunction with the corresponding authentication path to compute a candidate XMSS public key. The candidate layer 0 XMSS public key is used along with the layer 1"}, {"chunk_id": "NIST.FIPS.205::p0054::c001", "doc_id": "NIST.FIPS.205", "end_page": 54, "mode": "hybrid", "rank": 2, "score": 0.031544957774465976, "start_page": 54, "text": "Using this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each parameter set is claimed to be at least as secure as a generic block cipher with a prescribed key size. More precisely, it is claimed that the computational resources needed to break SLH-DSA are greater than or equal to the computational resources needed to break the block cipher when these computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models\n are discussed in [26].\n Concretely, the parameter sets with n = 16 are claimed to be in security category 1, the\n parameter sets with n = 24 are claimed to be in security category 3, and the parameter sets with\n n = 32 are claimed to be in security category 5 [10]. For additional discussion of the security\n strength of SLH-DSA, see [10, 27].\n Some applications require a property known as message-bound signatures [28, 29], which\nintuitively requires that it be infeasible for anyone to create a public key and a signature that are valid for two different messages. Signature schemes are not required to have this property under the EUF-CMA security definition used in assigning security categories. In the case of SLH-DSA, the key pair owner could create two messages with the same signature by finding a collision on Hmsg. Due to the length of the output of Hmsg, finding such a collision would be expected to require fewer computational resources than specified for the parameter sets’ claimed security categories in all cases except SLH-DSA-SHA2-128f and SLH-DSA-SHAKE-128f.23 Therefore, applications that require message-bound signatures should either take the expected cost of finding collisions on Hmsg into account when choosing an appropriate parameter set or\n apply a technique (e.g., the BUFF transformation [29]) to obtain the message-bound signatures\nproperty.\n\n11.1 SLH-DSA Using SHAKE\nHmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHAKE-\n128s, SLH-DSA-SHAKE-128f, SLH-DSA-SHAKE-192s, SLH-DSA-SHAKE-192f, SLH-DSA-SHAKE-256s, and SLH-DSA-SHAKE-256f parameter sets:\n Hmsg(R, PK.seed, PK.root, M) = SHAKE256(R ∥ PK.seed ∥ PK.root ∥ M , 8m)\n PRF(PK.seed, SK.seed, ADRS) = SHAKE256(PK.seed ∥ ADRS ∥ SK.seed, 8n)\n PRFmsg(SK.prf, opt_rand, M) = SHAKE256(SK.prf ∥ opt_rand ∥ M , 8n)\n F(PK.seed, ADRS, M1) = SHAKE256(PK.seed ∥ ADRS ∥ M1, 8n)\n H(PK.seed, ADRS, M2) = SHAKE256(PK.seed ∥ ADRS ∥ M2, 8n)\n Tl(PK.seed, ADRS, Ml) = SHAKE256(PK.seed ∥ ADRS ∥ Ml, 8n)\n\n11.2 SLH-DSA Using SHA2\nIn Sections 11.2.1 and 11.2.2, the functions MGF1-SHA-256 and MGF1-SHA-512 are MGF1 from\n Appendix B.2.1 of RFC 8017 [30], where Hash is SHA-256 or SHA-512, respectively. The functions\n\n23Finding a collision would be expected to require computing Hmsg for approximately 2(h+k⋅a)/2 different mes- sages."}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 3, "score": 0.0315136476426799, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.205::p0048::c000", "doc_id": "NIST.FIPS.205", "end_page": 48, "mode": "hybrid", "rank": 4, "score": 0.030798389007344232, "start_page": 48, "text": "a single key pair may be used for both pure and pre-hash signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or the application with which the signature is being used. If the default hedged variant of slh_sign_internal is used, the n-byte random value addrnd shall be generated by the cryptographic module that runs slh_sign_internal. However, M′ in Algorithms 22 and 23 may be constructed outside of the crytographic module. In the case of hash_slh_sign, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that runs slh_sign_internal. In general, the pure version is preferred. However, for some cryptographic modules that generate SLH-DSA signatures, performing lines 3 and 5 of Algorithm 19 may be infeasible if the message M is large. This may, for example, be the result of the module having limited memory to store the message to be signed. Similarly, for some cryptographic modules that verify SLH-DSA signatures, performing line 8 of Algorithm 20 may be infeasible if the message M is large. For some use cases, these issues may be addressed by signing a digest of the content rather than signing the content directly. In many cases where the content to be signed is large, hashing of the content is performed at the application level. For example, in the Cryptographic Message Syntax [23], a digest of the content may be computed, and that digest is signed along with other attributes. In cases in which the content is not hashed at the application level, the pre-hash version of SLH-DSA signing (Section 10.2.2) may be used. To maintain the same level of security strength when the content is hashed at the application level or when using the pre-hash version of SLH-DSA, the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180-4 [8] or FIPS 202 [6]) that provides at least 8n bits of classical security strength against both collision and second preimage attacks [6, Table 4].18 Verification of a signature created in this way will require the verify function to generate a digest from the message in the same way for input to the verification function. Even if it is feasible to compute collisions on the hash functions or XOF used to instantiate Hmsg, PRF, PRFmsg, F, H, and Tl, there is believed to be no adverse effect on the security of SLH-DSA.19 However, if the input to the signing function is a digest of the content, then collisions on the function used to compute the digest can result in forged messages."}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "end_page": 19, "mode": "hybrid", "rank": 5, "score": 0.030117753623188408, "start_page": 19, "text": "Destruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of SLH-DSA shall ensure that any local copies of the inputs and any potentially sensitive intermediate data are destroyed as soon as they are no longer needed.\n\nKey checks. SP 800-89 imposes requirements for the assurance of public-key validity and privatekey possession. In the case of SLH-DSA, where public-key validation is required, implementations shall verify that the public key is 2n bytes in length. When the assurance of private key possession is obtained via regeneration, the owner of the private key shall check that the private key is 4n bytes in length and shall use SK.seed and PK.seed to recompute PK.root and compare the newly generated value with the value in the private key currently held.\n\nFloating-point arithmetic. Implementations of SLH-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. In all pseudocode in this standard in which division is performed (e.g., x/y) and y may not divide x, either ⌊x/y⌋ or ⌈x/y⌉ is used. Both of these can be computed without floating-point arithmetic,\nas ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative\nintegers x and positive integers y."}, {"chunk_id": "NIST.FIPS.204::p0022::c002", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 6, "score": 0.029906956136464335, "start_page": 22, "text": "3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability.\n\n3.6.3 Intermediate Values The data used internally by the key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or the verification of signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of ML-DSA shall ensure that any potentially sensitive intermediate data is destroyed as soon as it is no longer needed. Two particular cases in which implementations may refrain from destroying intermediate data are:\n\n1. The seed ξ generated in step 1 of ML-DSA.KeyGen can be stored for the purpose of later expansion\n\n3In addition, when signing is deterministic, there is leakage through timing side channels of information about the message but not the private key). If the signer does not want to reveal the message being signed, hedged\n signatures should be used (see Section 3.2 in [6])."}, {"chunk_id": "NIST.FIPS.205::p0047::c001", "doc_id": "NIST.FIPS.205", "end_page": 47, "mode": "hybrid", "rank": 7, "score": 0.02946236559139785, "start_page": 47, "text": "Algorithm 21 slh_keygen() Generates an SLH-DSA key pair. Input: (none) Output: SLH-DSA key pair (SK, PK). SK.seed $ n ← 1: − B ▷ set SK.seed, SK.prf, and PK.seed to random n-byte SK.prf $ n ← 2: − B ▷ strings using an approved random bit generator PK.seed $ n ← 3: − B 4: if SK.seed = NULL or SK.prf = NULL or PK.seed = NULL then 5: return ⊥ ▷ return an error indication if random bit generation failed 6: end if 7: return slh_keygen_internal(SK.seed, SK.prf, PK.seed)\n\n10.2 SLH-DSA Signature Generation This section presents two versions of SLH-DSA signature generation: a “pure” version (slh_sign) and a “pre-hash” version (hash_slh_sign). Both versions use slh_sign_internal, but they differ in how the message input to slh_sign_internal is created from the content to be signed. In the pure version, the content is signed by slh_sign_internal along with some domain separation information. In the pre-hash version, a hash of the content is signed by slh_sign_internal along with some domain separation information. Both versions take the content to be signed, the private key, and a context as input. The pre-hash version also takes as input a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string. However, applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a pure signature or a pre-hash signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash.17 While 17In the case of a XOF, this would also include the length of the output from the XOF."}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 22, "text": "3.6.1 Randomness Generation Algorithm 1, implementing key generation for ML-DSA, uses an RBG to generate the 256-bit random seed ξ. The seed ξ shall be a fresh (i.e., not previously used) random value generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [19, 20, 21]. Moreover, the RBG used shall have a security strength of at least 192 bits for ML-DSA-65 and 256 bits for ML-DSA-87. For ML-DSA-44, the RBG should have a security strength of at least 192 bits and shall have a security strength of at least 128 bits. If an approved RBG with at least 128 bits of security but less than 192 bits of security is used, then the claimed security strength of ML-DSA-44 is reduced from category 2 to category 1. Additionally, the value rnd is generated using an RBG in the default “hedged” variants of Algorithms 2 and 4 for ML-DSA and HashML-DSA signing, respectively. While this value should ideally be generated by an approved RBG, other methods for generating fresh random values may be used. The primary purpose of rnd is to facilitate countermeasures to side-channel attacks and fault attacks on deterministic signatures, such as [22, 23, 24].3 For this purpose, even a weak RBG may be preferable to the fully deterministic variants of Algorithms 2 and 4.\n\n3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "pages": "p18-p18", "rank": 1}, {"chunk_id": "NIST.FIPS.205::p0054::c001", "doc_id": "NIST.FIPS.205", "pages": "p54-p54", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 3}, {"chunk_id": "NIST.FIPS.205::p0048::c000", "doc_id": "NIST.FIPS.205", "pages": "p48-p48", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "pages": "p19-p19", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0022::c002", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 6}, {"chunk_id": "NIST.FIPS.205::p0047::c001", "doc_id": "NIST.FIPS.205", "pages": "p47-p47", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 8}]}}
{"answerable": false, "gold": [], "qid": "q013", "question": "What does NIST say about PQC for Wi-Fi 9?", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "hits": [{"chunk_id": "NIST.FIPS.204::p0040::c000", "doc_id": "NIST.FIPS.204", "end_page": 40, "mode": "hybrid", "rank": 1, "score": 0.04421356457417033, "start_page": 40, "text": "Algorithm 15 CoeffFromHalfByte(b)\nLet η ∈ {2, 4}. Generates an element of {−η, −η + 1, ... , η} ∪ {⊥}.\nInput: Integer b ∈ {0, 1, ... , 15}.\nOutput: An integer between −η and η, or ⊥.\n 1: if η = 2 and b < 15 then return 2 − (b mod 5) ▷ rejection sampling from {−2, ... , 2}\n2: else\n 3: if η = 4 and b < 9 then return 4 − b ▷ rejection sampling from {−4, ... , 4}\n4: else return ⊥\n5: end if\n6: end if\n\nAlgorithms 16–19 efficiently translate an element w ∈ R into a byte string and vice versa under the\nassumption that the coefficients of w are in a restricted range. SimpleBitPack assumes that wi ∈ [0, b]\nfor some positive integer b and packs w into a byte string of length 32 ⋅ bitlen b. BitPack allows for the\nmore general restriction wi ∈ [−a, b]. The BitPack algorithm works by merely subtracting w from the\npolynomial ∑255 bXi.\n i=0\n\nAlgorithm 16 SimpleBitPack(w, b) Encodes a polynomial w into a byte string. Input: b ∈ N and w ∈ R such that the coefficients of w are all in [0, b]. Output: A byte string of length 32 ⋅ bitlen b. 1: z ← () ▷ set z to the empty bit string 2: for i from 0 to 255 do 3: endz ← z||IntegerToBits(wi , bitlen b) 4: for 5: return BitsToBytes(z)"}, {"chunk_id": "NIST.FIPS.203::p0052::c000", "doc_id": "NIST.FIPS.203", "end_page": 52, "mode": "hybrid", "rank": 2, "score": 0.029551337359792925, "start_page": 52, "text": "[23] Alagic G, Apon D, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody\nD, Peralta R, Perlner R, Robinson A, Smith-Tone D (2022) Status report on the third round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR)\n 8413. https://doi.org/10.6028/NIST.IR.8413-upd1.\n[24] CRYSTALS-Kyber submission team (2023) “Discussion about Kyber’s tweaked FO transform”,\nPQC-Forum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/W FRDl8DqYQ4.\n[25] CRYSTALS-Kyber submission team (2023) “Kyber decisions, part 2: FO transform”, PQC-\nForum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/C0D3W\n1KoINY/m/99kIvydoAwAJ."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 3, "score": 0.016129032258064516, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 4, "score": 0.015873015873015872, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.FIPS.203::p0005::c000", "doc_id": "NIST.FIPS.203", "end_page": 5, "mode": "hybrid", "rank": 5, "score": 0.015384615384615385, "start_page": 5, "text": "6. Applicability. Federal Information Processing Standards apply to information systems used or operated by federal agencies or by a contractor of an agency or other organization on behalf of an agency. They do not apply to national security systems as defined in 44 U.S.C. 3552. This standard, or other FIPS or NIST Special Publications that specify alternative mechanisms, shall be used wherever the establishment of a shared secret key (or shared secret from which keying material can be generated) is required for federal applications, including the use of such a key with symmetric-key cryptographic algorithms, in accordance with applicable Office of Management and Budget and agency policies. The adoption and use of this standard are available to private and commercial organizations. 7. Implementations. A key-encapsulation mechanism may be implemented in software, firmware, hardware, or any combination thereof. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, different procedures that produce the correct output for every input are permitted. NIST will develop a validation program to test implementations for conformance to the algorithms in this standard. Information about validation programs is available at https: //csrc.nist.gov/projects/cmvp. Example values will be available at https://csrc.nist.gov/proj ects/cryptographic-standards-and-guidelines/example-values. 8. Other Approved Security Functions. Implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government-sensitive information. Approved cryptographic algorithms and techniques include those that are either: (a) Specified in a Federal Information Processing Standards (FIPS) publication, (b) Adopted in a FIPS or NIST recommendation, or (c) Specified in the list of approved security functions in SP 800-140C. 9. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with all federal laws and regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 10. Patents. NIST has entered into two patent license agreements to facilitate the adoption of NIST’s announced selection of the PQC key-encapsulation mechanism CRYSTALS-KYBER. NIST and the licensing parties share a desire, in the public interest, the licensed patents be freely available to be practiced by any implementer of the ML-KEM algorithm as published by NIST. ML-KEM is the name given to the algorithm in this standard derived from CRYSTALS-KYBER. For a summary and extracts from the license, please see https://csrc.nist.gov/csrc/media/P rojects/post-quantum-cryptography/documents/selected-algos-2022/nist-pqc-license-sum mary-and-excerpts.pdf. Implementation of the algorithm specified in the standard may be covered by U.S. and foreign patents of which NIST is not aware."}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 6, "score": 0.015151515151515152, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 7, "score": 0.014925373134328358, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}, {"chunk_id": "NIST.FIPS.205::p0006::c000", "doc_id": "NIST.FIPS.205", "end_page": 6, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 6, "text": "14. Qualifications. The security of a digital signature system depends on the secrecy of the signatory’s private keys. Signatories shall, therefore, guard against the disclosure of their private keys. While it is the intent of this standard to specify general security requirements for generating digital signatures, conformance to this standard does not ensure that a particular implementation is secure. It is the responsibility of an implementer to ensure that any module that implements a digital signature capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The re- sponsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. Since a standard of this nature must be flexible enough to adapt to advancements and innovations in science and technology, this standard will be reviewed every five years in order to assess its adequacy. 15. Waiver Procedure. The Federal Information Security Management Act (FISMA) does not allow for waivers to Federal Information Processing Standards (FIPS) that are made mandatory by the Secretary of Commerce. 16. Where to Obtain Copies of the Standard. This publication is available by accessing https: //csrc.nist.gov/publications. Other computer security publications are available at the same website. 17. How to Cite This Publication. NIST has assigned NIST FIPS 205 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Stateless Hash-Based Dig- ital Signature Standard. (Department of Commerce, Washington, D.C.), Fed- eral Information Processing Standards Publication (FIPS) NIST FIPS 205. https: //doi.org/10.6028/NIST.FIPS.205 18. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-205-comments@nist.gov."}], "metrics": null, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0040::c000", "doc_id": "NIST.FIPS.204", "pages": "p40-p40", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0052::c000", "doc_id": "NIST.FIPS.203", "pages": "p52-p52", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 3}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0005::c000", "doc_id": "NIST.FIPS.203", "pages": "p5-p5", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 7}, {"chunk_id": "NIST.FIPS.205::p0006::c000", "doc_id": "NIST.FIPS.205", "pages": "p6-p6", "rank": 8}]}}
