{"answerable": true, "gold": [{"doc_id": "NIST.IR.8547.ipd", "end_page": 8, "start_page": 8}], "qid": "q001", "question": "what is PQC", "retrieval": {"doc_hit_ranks": [1, 2], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 9, "mode": "hybrid", "rank": 1, "score": 0.031544957774465976, "start_page": 9, "text": "126 ensuring that this transition is as smooth and coordinated as possible, balancing the urgency of 127 adopting PQC with the need to minimize disruption across critical systems.\n\n128 1.2. Audience 129 This document is intended for a broad audience, including federal agencies, technology 130 providers, standards organizations, and Cryptographic Module Validation Program (CMVP) 131 laboratories. These groups play a critical role in preparing for the migration to PQC by 132 developing, implementing, and standardizing the new cryptographic methods necessary to 133 secure information in the era of quantum computing. This document should inform these 134 stakeholder’s efforts and timelines for migrating information technology products, services, and 135 infrastructure to PQC."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 2, "score": 0.031054405392392875, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "end_page": 25, "mode": "hybrid", "rank": 3, "score": 0.02919863597612958, "start_page": 25, "text": "4. Conclusion\n\nThis report summarizes the evaluation criteria for selecting the fourth-round candidate algorithms, their basic designs, and their advantages and disadvantages. NIST greatly appreciates the participation in the NIST PQC Standardization Process. The announcement of the standardization of HQC marks the end of the fourth round, and also marks an end to the standardization process which began with the NIST Call for Proposals in 2016 [22]. We note that not all NIST PQC standardization is concluded, as NIST is also currently evaluating additional digital signatures [75]. NIST will create a draft standard based on HQC and post it for public comment. After the comments are adjudicated, NIST will publish a final version in approximately two years. The standardization of HQC will be the second PQC KEM after ML-KEM. NIST recently published draft SP 800-227, Recommendations for Key-Encapsulation Mechanisms [76], which describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner. NIST plans to host another NIST PQC Standardization Conference in September 2025, with more details to be provided."}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 4, "score": 0.01639344262295082, "start_page": 20, "text": "3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed.\n\nInput checking. The correct and secure operation of cryptographic operations depends crucially on the validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 5, "score": 0.016129032258064516, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 6, "score": 0.015873015873015872, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 7, "score": 0.015625, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 8, "score": 0.015384615384615385, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [1], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p9-p9", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "pages": "p25-p25", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 4}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 10, "start_page": 10}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}, {"doc_id": "NIST.FIPS.205", "end_page": 11, "start_page": 11}], "qid": "q002", "question": "why do we need the PQC standards", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 1, "score": 0.032266458495966696, "start_page": 12, "text": "209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms."}, {"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 9, "mode": "hybrid", "rank": 2, "score": 0.031754032258064516, "start_page": 9, "text": "126 ensuring that this transition is as smooth and coordinated as possible, balancing the urgency of 127 adopting PQC with the need to minimize disruption across critical systems.\n\n128 1.2. Audience 129 This document is intended for a broad audience, including federal agencies, technology 130 providers, standards organizations, and Cryptographic Module Validation Program (CMVP) 131 laboratories. These groups play a critical role in preparing for the migration to PQC by 132 developing, implementing, and standardizing the new cryptographic methods necessary to 133 secure information in the era of quantum computing. This document should inform these 134 stakeholder’s efforts and timelines for migrating information technology products, services, and 135 infrastructure to PQC."}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "end_page": 25, "mode": "hybrid", "rank": 3, "score": 0.0315136476426799, "start_page": 25, "text": "4. Conclusion\n\nThis report summarizes the evaluation criteria for selecting the fourth-round candidate algorithms, their basic designs, and their advantages and disadvantages. NIST greatly appreciates the participation in the NIST PQC Standardization Process. The announcement of the standardization of HQC marks the end of the fourth round, and also marks an end to the standardization process which began with the NIST Call for Proposals in 2016 [22]. We note that not all NIST PQC standardization is concluded, as NIST is also currently evaluating additional digital signatures [75]. NIST will create a draft standard based on HQC and post it for public comment. After the comments are adjudicated, NIST will publish a final version in approximately two years. The standardization of HQC will be the second PQC KEM after ML-KEM. NIST recently published draft SP 800-227, Recommendations for Key-Encapsulation Mechanisms [76], which describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner. NIST plans to host another NIST PQC Standardization Conference in September 2025, with more details to be provided."}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 13, "mode": "hybrid", "rank": 4, "score": 0.030330882352941176, "start_page": 13, "text": "244 These libraries need to incorporate PQC algorithms that are standardized by bodies like NIST. 245 Updating them ensures that developers have access to quantum-resistant cryptographic 246 functions without implementing complex algorithms themselves. This transition involves adding 247 new algorithms, optimizing their implementations for performance, and ensuring those 248 implementations are secure against side-channel attacks.\n\n249 2.2.3. Cryptographic Hardware 250 Cryptographic hardware modules, such as hardware security modules (HSMs) and Trusted 251 Platform Modules (TPMs), provide secure environments for performing cryptographic 252 operations and storing sensitive keys. They are used in various applications, from securing 253 server infrastructure to protecting cryptographic keys on personal devices. 254 Hardware modules must be upgraded or redesigned to support PQC algorithms, which often 255 have larger key sizes and different computational requirements. This includes updating 256 firmware or hardware to handle new algorithms and ensuring that the modules can perform 257 quantum-resistant cryptographic operations efficiently while maintaining the high security 258 standards expected of these devices."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 5, "score": 0.028814262023217248, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures."}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 8, "mode": "hybrid", "rank": 6, "score": 0.02854251012145749, "start_page": 8, "text": "88 1. Introduction 89 Cryptographic algorithms are vital for safeguarding confidential electronic information from 90 unauthorized access. For decades, these algorithms have proved strong enough to defend 91 against attacks using conventional computers that attempt to defeat cryptography. However, 92 future quantum computing may be able to break these algorithms, rendering data and 93 information vulnerable. Countering this future quantum capability requires new cryptographic 94 methods that can protect data from both current conventional computers and the quantum 95 computers of tomorrow. These methods are referred to as post-quantum cryptography (PQC). 96 In response, NIST has released three PQC standards to start the next and significantly large 97 stage of working on the transition to post-quantum cryptography: the Module-Lattice-Based 98 Key-Encapsulation Mechanism [FIPS203], the Module-Lattice-Based Digital Signature Algorithm 99 [FIPS204], and the Stateless Hash-Based Signature Algorithm [FIPS205]. Historically, the journey 100 from algorithm standardization to full integration into information systems can take 10 to 20 101 years. This timeline reflects the complexity of companies building the algorithms into products 102 and services, procuring those products and services, and integrating those products and 103 services into technology infrastructures. 104 Even though the transition to post-quantum cryptography is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 7, "score": 0.015873015873015872, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 8, "mode": "hybrid", "rank": 8, "score": 0.015151515151515152, "start_page": 8, "text": "88 1. Introduction 89 Cryptographic algorithms are vital for safeguarding confidential electronic information from 90 unauthorized access. For decades, these algorithms have proved strong enough to defend 91 against attacks using conventional computers that attempt to defeat cryptography. However, 92 future quantum computing may be able to break these algorithms, rendering data and 93 information vulnerable. Countering this future quantum capability requires new cryptographic 94 methods that can protect data from both current conventional computers and the quantum 95 computers of tomorrow. These methods are referred to as post-quantum cryptography (PQC). 96 In response, NIST has released three PQC standards to start the next and significantly large 97 stage of working on the transition to post-quantum cryptography: the Module-Lattice-Based 98 Key-Encapsulation Mechanism [FIPS203], the Module-Lattice-Based Digital Signature Algorithm 99 [FIPS204], and the Stateless Hash-Based Signature Algorithm [FIPS205]. Historically, the journey 100 from algorithm standardization to full integration into information systems can take 10 to 20 101 years. This timeline reflects the complexity of companies building the algorithms into products 102 and services, procuring those products and services, and integrating those products and 103 services into technology infrastructures. 104 Even though the transition to post-quantum cryptography is starting before a cryptographically 105 relevant quantum computer has been built, there is a pressing threat. Encrypted data remains 106 at risk because of the “harvest now, decrypt later” threat in which adversaries collect encrypted 107 data now with the goal of decrypting it once quantum technology matures. Since sensitive data 108 often retains its value for many years, starting the transition to post-quantum cryptography 109 now is critical to preventing these future breaches. This threat model is one of the main reasons 110 why the transition to post-quantum cryptography is urgent.\n\n111 1.1. Scope and Purpose 112 Updating cryptographic technology has occurred many times at different scales, such as 113 increasing key sizes or phasing out insecure hash functions and block ciphers. While the 114 transition to PQC is unprecedented in scale, it benefits from a level of awareness and 115 understanding that previous cryptographic changes did not have. NIST recognizes the 116 complexity of migrating the vast array of systems that currently rely on public-key cryptography 117 and acknowledges that this transition will demand substantial effort across diverse applications 118 and infrastructures with specific requirements and constraints. 119 This report serves as the initial step in a broader strategy to manage and guide the transition to 120 post-quantum cryptography. This transition will involve the adoption of new PQC algorithms as 121 well as the careful deprecation, controlled legacy use, and eventual removal of quantum- 122 vulnerable algorithms that are currently widespread in technological infrastructures. Public- 123 private engagement will be crucial on the path toward PQC. Additionally, this report continues 124 NIST’s ongoing dialogue with industry, standards organizations, and relevant agencies to 125 develop a clear roadmap and realistic timeline for transitioning to PQC. NIST is committed to"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0009::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p9-p9", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0025::c000", "doc_id": "NIST.IR.8545", "pages": "p25-p25", "rank": 3}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p13-p13", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 5}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p8-p8", "rank": 6}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 7}, {"chunk_id": "NIST.IR.8547.ipd::p0008::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p8-p8", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 10, "start_page": 10}, {"doc_id": "NIST.FIPS.204", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.205", "end_page": 3, "start_page": 3}], "qid": "q003", "question": "What are the PQC standards", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 1, "score": 0.0315136476426799, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8547.ipd::p0018::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 18, "mode": "hybrid", "rank": 2, "score": 0.031024531024531024, "start_page": 18, "text": "417 4. Towards a PQC Standards Transition Timeline 418 NIST’s cryptography standards provide comprehensive guidance on a broad spectrum of 419 cryptographic mechanisms that are essential for securing sensitive information across both 420 federal and nonfederal systems. These standards cover fundamental areas that are crucial for 421 ensuring the confidentiality, integrity, and authenticity of data, such as encryption algorithms, 422 digital signatures, hash functions, key establishment, and random number generation. 423 Additionally, NIST’s standards define key-management practices and offer frameworks for 424 securely generating, storing, distributing, and destroying cryptographic keys. 425 Beyond individual algorithms, NIST standards provide guidance on cryptographic protocols that 426 secure communications, such as the TLS protocol, which protects internet data exchanges. They 427 also specify requirements for cryptographic modules through the CMVP to ensure that 428 implementations meet stringent security standards. NIST has also developed PQC standards to 429 safeguard systems against future quantum attacks. Through collaboration with industry, 430 academia, and other stakeholders, NIST continually updates its cryptographic standards to 431 address evolving security threats and technological advances. 432 National Security Memorandum 10 (NSM-10) establishes the year 2035 as the primary target 433 for completing the migration to PQC across Federal systems [NSM10]: 434 “Any digital system that uses existing public standards for public‐key cryptography, or 435 that is planning to transition to such cryptography, could be vulnerable to an attack by a 436 Cryptographically Relevant Quantum Computer (CRQC). To mitigate this risk, the United 437 States must prioritize the timely and equitable transition of cryptographic systems to 438 quantum-resistant cryptography, with the goal of mitigating as much of the quantum 439 risk as is feasible by 2035.” 440 This date reflects the urgency of transitioning to cryptographic methods that can withstand 441 future quantum threats. However, it is important to recognize that migration timelines may 442 vary based on the specific use case or application. Some systems, particularly those with long- 443 term confidentiality needs or more complex cryptographic infrastructures, may require earlier 444 transitions, while others may adopt PQC at a slower pace due to legacy constraints or lower risk 445 profiles. Flexibility in migration planning is essential to balance the urgency of securing critical 446 systems with the practical challenges that different sectors face during this transition. NIST will 447 work to ensure that these varying timelines are acknowledged and supported while maintaining 448 the overall goal of achieving widespread PQC adoption by 2035."}, {"chunk_id": "NIST.IR.8547.ipd::p0024::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 24, "mode": "hybrid", "rank": 3, "score": 0.030309988518943745, "start_page": 24, "text": "545 techniques until 2035 and generally allow their use, these application-specific standards and 546 guidelines may specify earlier transitions for certain cryptographic algorithms, techniques, and 547 protocols used within these applications. These guidelines will be developed based on the 548 expected impact that a cryptographically relevant quantum computer would have on these 549 applications as well as the level of support for PQC in the relevant standards, products, and 550 services. NIST expects to prioritize the migration to quantum-resistant key-establishment 551 schemes within these updates to protect against “harvest now, decrypt later” attacks, 552 particularly in interactive protocols like TLS and IKE. 553 NIST will also coordinate with standards-developing organizations and industry to ensure that 554 critical security protocols and technologies are updated to support PQC in a timely manner, 555 recognizing that different application areas will have different risks, security needs, and 556 adoption challenges."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 4, "score": 0.028612012987012988, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 5, "score": 0.01639344262295082, "start_page": 12, "text": "209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms."}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 6, "score": 0.016129032258064516, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 7, "score": 0.015151515151515152, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures.\n\n378 3.2.1. Hybrid Key-Establishment Techniques 379 A hybrid key-establishment mode is defined here to be a key establishment scheme that is a 380 combination of two or more components that are themselves cryptographic key-establishment 381 schemes. The hybrid key-establishment scheme becomes a composite of these component 382 schemes. 383 NIST currently allows a generic composite key-establishment technique described in SP 800-56C 384 [SP80056C]. Assume that the value Z is a shared secret that was generated as specified by SP 385 800-56A or 800-56B and that a shared secret T is generated or distributed through other 386 schemes. The value Z’=Z||T may then be treated as a shared secret and any of the key 387 derivation methods given in SP 800-56C may be applied to Z’ to derive secret keying material. 388 NIST intends to update SP 800-56C so that the value Z may be generated as specified by any 389 current and future NIST key-establishment standards. This will include SP 800-56A, SP 800-56B, 390 FIPS 203, and any additional post-quantum key-establishment standards. The desired property 391 of hybrid techniques is that derived keys remain secure if at least one of the component 392 schemes is secure. Security properties can be complex, and for composite key establishment"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0018::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p18-p18", "rank": 2}, {"chunk_id": "NIST.IR.8547.ipd::p0024::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p24-p24", "rank": 3}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 7}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.203", "end_page": 23, "start_page": 22}], "qid": "q004", "question": "What is ML-KEM", "retrieval": {"doc_hit_ranks": [2, 3, 4, 6, 7], "gold_hit_ranks": [4, 6, 7], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 1, "score": 0.06426011264720942, "start_page": 43, "text": "5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications\nThis section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption\nA KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for\nPKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15]."}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 2, "score": 0.06403688524590165, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 3, "score": 0.06069665184914546, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 4, "score": 0.056288396076298666, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 5, "score": 0.03252247488101534, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.203::p0023::c001", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 6, "score": 0.031024531024531024, "start_page": 23, "text": "The specification of the ML-KEM algorithms in this standard will follow the same pattern. Specifically, this standard will first describe a public-key encryption scheme called K-PKE (in Section 5) and then use the algorithms of K-PKE as subroutines when describing the algorithms of ML-KEM (in Sections 6 and 7). The cryptographic transformation from K-PKE to ML-KEM is crucial for achieving IND-CCA2 security. The scheme K-PKE is not IND-CCA2-secure and shall not be used as a stand-alone scheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability. ML-KEM also comes with a proof of asymptotic theoretical security in a certain heuristic model [4]. Each of the parameter sets of ML-KEM comes with an associated security strength that was estimated based on current cryptanalysis (see Section 8 for details).\n\nParameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329."}, {"chunk_id": "NIST.FIPS.203::p0023::c000", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 7, "score": 0.030309988518943745, "start_page": 23, "text": "The specification of the ML-KEM algorithms in this standard will follow the same pattern. Specifically, this standard will first describe a public-key encryption scheme called K-PKE (in Section 5) and then use the algorithms of K-PKE as subroutines when describing the algorithms of ML-KEM (in Sections 6 and 7). The cryptographic transformation from K-PKE to ML-KEM is crucial for achieving IND-CCA2 security. The scheme K-PKE is not IND-CCA2-secure and shall not be used as a stand-alone scheme (see Section 3.3). A notable feature of ML-KEM is the use of the number-theoretic transform (NTT). The NTT converts a polynomial f ∈ Rq to an alternative representation as a vector f of linear polynomials. Working with NTT representations enables significantly faster multiplication of polynomials. Other operations (e.g., addition, rounding, and sampling) can be done in either representation. ML-KEM satisfies the essential KEM property of correctness. This means that in the absence of corruption or interference, the process in Figure 1 will result in K′ = K with overwhelming probability. ML-KEM also comes with a proof of asymptotic theoretical security in a certain heuristic model [4]. Each of the parameter sets of ML-KEM comes with an associated security strength that was estimated based on current cryptanalysis (see Section 8 for details)."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 8, "score": 0.01639344262295082, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.25, "ndcg_at_k": 0.2640681225725909, "recall_at_k": 0.5}, "k8": {"mrr_at_k": 0.25, "ndcg_at_k": 0.48247555939075504, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.25, "ndcg_at_k": 0.48247555939075504, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [4, 6, 7], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0023::c001", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0023::c000", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.204", "end_page": 4, "start_page": 3}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}], "qid": "q005", "question": "explain ML-DSA", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "end_page": 8, "mode": "hybrid", "rank": 1, "score": 0.06186378536922015, "start_page": 8, "text": "5.4 Pre-Hash ML-DSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n 5.4.1 HashML-DSA Signing and Verifying . . . . . . . . . . . . . . . . . . . . . . . . 19\n6 Internal Functions 22\n 6.1 ML-DSA Key Generation (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n 6.2 ML-DSA Signing (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n 6.3 ML-DSA Verifying (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n7 Auxiliary Functions 28\n 7.1 Conversion Between Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33\n 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39\n 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52"}, {"chunk_id": "NIST.FIPS.204::p0007::c002", "doc_id": "NIST.FIPS.204", "end_page": 7, "mode": "hybrid", "rank": 2, "score": 0.05932958454539554, "start_page": 7, "text": "4 Parameter Sets 15\n\n5 External Functions 17\n 5.1 ML-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n 5.2 ML-DSA Signing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n 5.3 ML-DSA Verifying . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\niv"}, {"chunk_id": "NIST.FIPS.204::p0029::c000", "doc_id": "NIST.FIPS.204", "end_page": 29, "mode": "hybrid", "rank": 3, "score": 0.05527095723174155, "start_page": 29, "text": "the platform may require hardware support for hashing to achieve acceptable performance but lack hardware support for SHAKE256 specifically. For some use cases, this may be addressed by signing a digest of the message along with some domain separation information rather than signing the message directly. This version of ML-DSA is known as “pre-hash” ML-DSA or HashML-DSA . In general, the “pure” ML-DSA version is preferred. While key generation for HashML-DSA is the same as for ML-DSA, it is not the same for the signing algorithm HashML-DSA.Sign or the verification algorithm HashML-DSA.Verify. Like ML-DSA, the signing algorithm of HashML-DSA takes the content to be signed, the private key, and a context as input, as well as a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string, though applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a ML-DSA signature or a pre-hash HashML-DSA signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash. 5 While a single key pair may be used for both ML-DSA and HashML-DSA signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or by the application with which the signature is being used. If the default “hedged” variant of is used, the 32-byte random value rnd shall be generated by the cryptographic module that generates the signature (i.e., that runs ML-DSA.Sign_internal). However, all other steps of signing may be performed outside of the cryptographic module that generates the signature. In the case of pre-hashing, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that generates the signature. If the content to be signed is large, hashing of the content is often performed at the application level. For example, in the Cryptographic Message Syntax [29], a digest of the content may be computed, and that digest is signed along with other attributes. If the content is not hashed at the application level, the pre-hash version of ML-DSA signing may be used. In order to maintain the same level of security strength when the content is hashed at the application level or using HashML-DSA , the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180 [8] or FIPS 202 [7]) that provides at least λ bits of classical security strength against both collision and second preimage attacks [7, Table 4].6 The verification of a signature that is created in this way will require the verify function to generate a digest from the message in the same way to be used as input for the verification function."}, {"chunk_id": "NIST.FIPS.204::p0009::c000", "doc_id": "NIST.FIPS.204", "end_page": 9, "mode": "hybrid", "rank": 4, "score": 0.04669647292598113, "start_page": 9, "text": "List of Tables\n\nTable 1 ML-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Table 2 Sizes (in bytes) of keys and signatures of ML-DSA . . . . . . . . . . . . . . . . . . 16 Table 3 While loop and XOF output limits for a 2−256 or less probability of failure . . . . . 52"}, {"chunk_id": "NIST.FIPS.204::p0028::c001", "doc_id": "NIST.FIPS.204", "end_page": 28, "mode": "hybrid", "rank": 5, "score": 0.045979778526721235, "start_page": 28, "text": "5.3 ML-DSA Verifying\nThe verification algorithm ML-DSA.Verify (Algorithm 3) takes a public key, a message, a signature, and a context string as input. The public key, signature, and context string are all encoded as byte strings, while the message is a bit string. ML-DSA.Verify outputs a Boolean value that is true if the signature is valid with respect to the message and the public key and false if the signature is invalid. The verification is accomplished by calling ML-DSA.Verify_internal (Algorithm 8) with the public key, the encoded message, and the signature.\n\nAlgorithm 3 ML-DSA.Verify(pk, M, σ, ctx) Verifies a signature σ for a message M. Input: Public key pk ∈ B32+32k(bitlen (q−1)−d), message M ∈ {0, 1}∗, signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k, context string ctx (a byte string of 255 or fewer bytes). Output: Boolean. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: M′ ← BytesToBits(IntegerToBytes(0, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx) ∥ M 6: return ML-DSA.Verify_internal(pk, M′ , σ)\n\n5.4 Pre-Hash ML-DSA\nFor some cryptographic modules that generate ML-DSA signatures, hashing the message in step 6 of ML-DSA.Sign_internal may result in unacceptable performance if the message M is large. For example,"}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 6, "score": 0.04533450704225352, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "end_page": 19, "mode": "hybrid", "rank": 7, "score": 0.03278688524590164, "start_page": 19, "text": "3. Overview of the ML-DSA Signature Scheme\n\nML-DSA is a digital signature scheme based on CRYSTALS-DILITHIUM [6]. It consists of three main algorithms:\nML-DSA.KeyGen (Algorithm 1), ML-DSA.Sign (Algorithm 2), and ML-DSA.Verify (Algorithm 3). The\nML-DSA scheme uses the Fiat-Shamir With Aborts construction [10, 11] and bears the most resemblance\nto the schemes proposed in [12, 13].\nThis document also defines a closely related but domain-separated signature scheme, HashML-DSA, which differs from ML-DSA in that it includes an additional pre-hashing step before signing. It consists of three main algorithms: ML-DSA.KeyGen (Algorithm 1), which is the same key generation algorithm used for ML-DSA; HashML-DSA.Sign (Algorithm 4); and HashML-DSA.Verify (Algorithm 5).\n\n3.1 Security Properties\nML-DSA is designed to be strongly existentially unforgeable under chosen message attack (SUF-CMA).\nThat is, it is expected that even if an adversary can get the honest party to sign arbitrary messages, the adversary cannot create any additional valid signatures based on the signer’s public key, including on messages for which the signer has already provided a signature.\nBeyond unforgeability, ML-DSA is designed to satisfy additional security properties described in [14]."}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 8, "score": 0.03076923076923077, "start_page": 22, "text": "3.6.1 Randomness Generation Algorithm 1, implementing key generation for ML-DSA, uses an RBG to generate the 256-bit random seed ξ. The seed ξ shall be a fresh (i.e., not previously used) random value generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [19, 20, 21]. Moreover, the RBG used shall have a security strength of at least 192 bits for ML-DSA-65 and 256 bits for ML-DSA-87. For ML-DSA-44, the RBG should have a security strength of at least 192 bits and shall have a security strength of at least 128 bits. If an approved RBG with at least 128 bits of security but less than 192 bits of security is used, then the claimed security strength of ML-DSA-44 is reduced from category 2 to category 1. Additionally, the value rnd is generated using an RBG in the default “hedged” variants of Algorithms 2 and 4 for ML-DSA and HashML-DSA signing, respectively. While this value should ideally be generated by an approved RBG, other methods for generating fresh random values may be used. The primary purpose of rnd is to facilitate countermeasures to side-channel attacks and fault attacks on deterministic signatures, such as [22, 23, 24].3 For this purpose, even a weak RBG may be preferable to the fully deterministic variants of Algorithms 2 and 4.\n\n3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "pages": "p8-p8", "rank": 1}, {"chunk_id": "NIST.FIPS.204::p0007::c002", "doc_id": "NIST.FIPS.204", "pages": "p7-p7", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0029::c000", "doc_id": "NIST.FIPS.204", "pages": "p29-p29", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0009::c000", "doc_id": "NIST.FIPS.204", "pages": "p9-p9", "rank": 4}, {"chunk_id": "NIST.FIPS.204::p0028::c001", "doc_id": "NIST.FIPS.204", "pages": "p28-p28", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "pages": "p19-p19", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.205", "end_page": 52, "start_page": 43}], "qid": "q006", "question": "What are the steps (and inputs/outputs) of SLH-DSA key generation, signing, and verification?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [1, 3, 4, 6], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.205::p0044::c001", "doc_id": "NIST.FIPS.205", "end_page": 44, "mode": "hybrid", "rank": 1, "score": 0.057642357642357644, "start_page": 44, "text": "[14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength. The SLH-DSA private key contains two random, secret n-byte values (see Figure 15). SK.seed is used to generate all of the WOTS+ and FORS private key elements. SK.prf is used to generate a randomization value for the randomized hashing of the message in SLH-DSA. The private key also includes a copy of the public key. Both SK.seed and SK.prf shall be generated using an approved random bit generator, where the instantiation of the random bit generator supports at least 8n bits of security strength. Algorithm 18 generates an SLH-DSA key pair. Lines 1 through 3 compute the root of the top layer XMSS tree. Line 4 bundles the three inputs and the computed PK.seed into the private and public keys. SLH-DSA signing has two variants — “hedged” and deterministic (see Section 9.2) — whose keys should only be used for the generation and verification of hedged and deterministic SLH-DSA digital signatures, respectively.\n\nAlgorithm 18 slh_keygen_internal(SK.seed, SK.prf, PK.seed) Generates an SLH-DSA key pair. Input: Secret seed SK.seed, PRF key SK.prf, public seed PK.seed Output: SLH-DSA key pair (SK, PK). 1: ADRS ← toByte(0, 32) ▷ generate the public key for the top-level XMSS tree 2: ADRS.setLayerAddress(d − 1) 3: PK.root ← xmss_node(SK.seed, 0, h′ , PK.seed, ADRS) 4: return ( (SK.seed, SK.prf, PK.seed, PK.root), (PK.seed, PK.root) )\n\n9.2 SLH-DSA Signature Generation An SLH-DSA signature consists of a randomization string, a FORS signature, and a hypertree signature, as shown in Figure 17. Generating an SLH-DSA signature (Algorithm 19) begins by creating an m-byte message digest (lines 2 through 5). A PRF is used to create a message randomizer (line 3), and it is hashed along with the message to create the digest (line 5). Bits are then extracted from the message digest to be signed by the FORS key (line 6), to select an XMSS tree (lines 7 and 9), and to select a WOTS+ key and corresponding FORS key within that XMSS tree (lines 8 and 10). Next, the FORS signature is computed (lines 11 through 14), and the corresponding FORS public key is obtained (line 16). Finally, the FORS public key is signed (line 17).\n\nRandomness R n bytes FORS signature SIGFORS k(1 + a) ⋅ n bytes HT signature SIGHT (h + d ⋅ len) ⋅ n bytes\n\nFigure 17. SLH-DSA signature data format"}, {"chunk_id": "NIST.FIPS.205::p0011::c000", "doc_id": "NIST.FIPS.205", "end_page": 11, "mode": "hybrid", "rank": 2, "score": 0.05427978683656815, "start_page": 11, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard defines a method for digital signature generation that can be used for the protection of binary data (commonly called a message) and for the verification and validation of those digital signatures.1 The security of the stateless hash-based digital signature algorithm (SLH-DSA) relies on the presumed difficulty of finding preimages for hash functions as well as several related\nproperties of the same hash functions. Unlike the algorithms specified in FIPS 186-5 [1], SLH-DSA\nis designed to provide resistance against attacks from a large-scale quantum computer.\nThis standard specifies the mathematical steps that need to be performed for key generation, signature generation, and signature verification. Additional assurances are required for digital signatures to be valid (e.g., the assurance of identity and private key possession). SP 800-89,\nRecommendation for Obtaining Assurances for Digital Signature Applications [3], specifies the\nrequired assurances and the methods for obtaining these assurances."}, {"chunk_id": "NIST.FIPS.205::p0043::c002", "doc_id": "NIST.FIPS.205", "end_page": 43, "mode": "hybrid", "rank": 3, "score": 0.046943815757279184, "start_page": 43, "text": "SLH-DSA uses h bits of the message digest to select a FORS key: h − h′ bits to select an XMSS tree at the lowest layer and h′ bits to select a WOTS+ key and corresponding FORS key from that tree. k ⋅ a bits of the digest are signed by the selected FORS key. While only h + k ⋅ a bits of the message digest are used, implementation is simplified by extracting the necessary bits from a slightly larger digest. This section describes the functions for SLH-DSA key generation, signature generation, and signature verification. In the functions in this section, where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of SLH-DSA implementations is performed through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to obtain the assurance of private key possession via regeneration, as described in Section 3.1. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 10 provides guidance on the interfaces to be made available to applications.\n\n9.1 SLH-DSA Key Generation\nSLH-DSA public keys contain two elements (see Figure 16). The first is an n-byte public seed PK.seed, which is used in many hash function calls to provide domain separation between different SLH-DSA key pairs. The second value is the hypertree public key (i.e., the root of the top layer XMSS tree). PK.seed shall be generated using an approved random bit generator (see\n\nSK.seed n bytes SK.prf n bytes PK.seed n bytes PK.seed n bytes PK.root n bytes PK.root n bytes\n\nFigure 15. SLH-DSA private key Figure 16. SLH-DSA public key"}, {"chunk_id": "NIST.FIPS.205::p0043::c001", "doc_id": "NIST.FIPS.205", "end_page": 43, "mode": "hybrid", "rank": 4, "score": 0.04209558823529412, "start_page": 43, "text": "m = ⌈h − h′ ⌉ + ⌈h′ ⌉ + ⌈k ⋅ a ⌉\n8 8 8\n\nSLH-DSA uses h bits of the message digest to select a FORS key: h − h′ bits to select an XMSS tree at the lowest layer and h′ bits to select a WOTS+ key and corresponding FORS key from that tree. k ⋅ a bits of the digest are signed by the selected FORS key. While only h + k ⋅ a bits of the message digest are used, implementation is simplified by extracting the necessary bits from a slightly larger digest. This section describes the functions for SLH-DSA key generation, signature generation, and signature verification. In the functions in this section, where randomness is required, the random values are provided as inputs to the functions. The interfaces specified in this section will be used when testing of SLH-DSA implementations is performed through the Cryptographic Algorithm Validation Program (CAVP). The key generation function in this section may also be used to obtain the assurance of private key possession via regeneration, as described in Section 3.1. Other than for testing purposes, the interfaces for key generation and signature generation specified in this section should not be made available to applications, as any random values required for key generation and signature generation shall be generated by the cryptographic module. Section 10 provides guidance on the interfaces to be made available to applications."}, {"chunk_id": "NIST.FIPS.205::p0008::c000", "doc_id": "NIST.FIPS.205", "end_page": 8, "mode": "hybrid", "rank": 5, "score": 0.0315136476426799, "start_page": 8, "text": "7.1 Hypertree Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . 26\n 7.2 Hypertree Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n8 Forest of Random Subsets (FORS) 29\n 8.1 Generating FORS Secret Values . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n 8.2 Generating a Merkle Hash Tree . . . . . . . . . . . . . . . . . . . . . . . . . 30\n 8.3 Generating a FORS Signature . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n 8.4 Computing a FORS Public Key From a Signature . . . . . . . . . . . . . . . . . 31\n\n9 SLH-DSA Internal Functions 33\n 9.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 9.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n 9.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n10 SLH-DSA External Functions 37\n 10.1 SLH-DSA Key Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2 SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n 10.2.1 Pure SLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 38\n 10.2.2 HashSLH-DSA Signature Generation . . . . . . . . . . . . . . . . . . . 39\n 10.3 SLH-DSA Signature Verification . . . . . . . . . . . . . . . . . . . . . . . . . . 41"}, {"chunk_id": "NIST.FIPS.205::p0044::c000", "doc_id": "NIST.FIPS.205", "end_page": 44, "mode": "hybrid", "rank": 6, "score": 0.03057889822595705, "start_page": 44, "text": "[14, 15, 16]), where the instantiation of the random bit generator supports at least 8n bits of security strength. The SLH-DSA private key contains two random, secret n-byte values (see Figure 15). SK.seed is used to generate all of the WOTS+ and FORS private key elements. SK.prf is used to generate a randomization value for the randomized hashing of the message in SLH-DSA. The private key also includes a copy of the public key. Both SK.seed and SK.prf shall be generated using an approved random bit generator, where the instantiation of the random bit generator supports at least 8n bits of security strength. Algorithm 18 generates an SLH-DSA key pair. Lines 1 through 3 compute the root of the top layer XMSS tree. Line 4 bundles the three inputs and the computed PK.seed into the private and public keys. SLH-DSA signing has two variants — “hedged” and deterministic (see Section 9.2) — whose keys should only be used for the generation and verification of hedged and deterministic SLH-DSA digital signatures, respectively."}, {"chunk_id": "NIST.FIPS.205::p0019::c001", "doc_id": "NIST.FIPS.205", "end_page": 19, "mode": "hybrid", "rank": 7, "score": 0.01639344262295082, "start_page": 19, "text": "Randomness generation. SLH-DSA key generation (Algorithm 21) requires the generation of three random n-byte values: PK.seed, SK.seed, and SK.prf, where n is 16, 24, or 32, depending on the parameter set. For each invocation of key generation, each of these values shall be a fresh (i.e., not previously used) random value generated using an approved random bit generator\n(RBG), as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [14, 15, 16]. Moreover, the RBG\nused shall have a security strength of at least 8n bits. See Table 2 for the value of n for each parameter set.\n\nDestruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of SLH-DSA shall ensure that any local copies of the inputs and any potentially sensitive intermediate data are destroyed as soon as they are no longer needed."}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "end_page": 19, "mode": "hybrid", "rank": 8, "score": 0.016129032258064516, "start_page": 19, "text": "Destruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of SLH-DSA shall ensure that any local copies of the inputs and any potentially sensitive intermediate data are destroyed as soon as they are no longer needed.\n\nKey checks. SP 800-89 imposes requirements for the assurance of public-key validity and privatekey possession. In the case of SLH-DSA, where public-key validation is required, implementations shall verify that the public key is 2n bytes in length. When the assurance of private key possession is obtained via regeneration, the owner of the private key shall check that the private key is 4n bytes in length and shall use SK.seed and PK.seed to recompute PK.root and compare the newly generated value with the value in the private key currently held.\n\nFloating-point arithmetic. Implementations of SLH-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. In all pseudocode in this standard in which division is performed (e.g., x/y) and y may not divide x, either ⌊x/y⌋ or ⌈x/y⌉ is used. Both of these can be computed without floating-point arithmetic,\nas ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative\nintegers x and positive integers y."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 3, 4, 6], "top_hit_ids": [{"chunk_id": "NIST.FIPS.205::p0044::c001", "doc_id": "NIST.FIPS.205", "pages": "p44-p44", "rank": 1}, {"chunk_id": "NIST.FIPS.205::p0011::c000", "doc_id": "NIST.FIPS.205", "pages": "p11-p11", "rank": 2}, {"chunk_id": "NIST.FIPS.205::p0043::c002", "doc_id": "NIST.FIPS.205", "pages": "p43-p43", "rank": 3}, {"chunk_id": "NIST.FIPS.205::p0043::c001", "doc_id": "NIST.FIPS.205", "pages": "p43-p43", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0008::c000", "doc_id": "NIST.FIPS.205", "pages": "p8-p8", "rank": 5}, {"chunk_id": "NIST.FIPS.205::p0044::c000", "doc_id": "NIST.FIPS.205", "pages": "p44-p44", "rank": 6}, {"chunk_id": "NIST.FIPS.205::p0019::c001", "doc_id": "NIST.FIPS.205", "pages": "p19-p19", "rank": 7}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "pages": "p19-p19", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 28, "start_page": 28}], "qid": "q007", "question": "give me Algorithm 2 SHAKE128", "retrieval": {"doc_hit_ranks": [1, 3], "gold_hit_ranks": [1], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 1, "score": 0.045680369617857444, "start_page": 28, "text": "is equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length.\n\nAlgorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results\n\nIn this standard, the incremental API for SHAKE128 will only be invoked through a wrapper XOF,"}, {"chunk_id": "NIST.FIPS.204::p0009::c001", "doc_id": "NIST.FIPS.204", "end_page": 9, "mode": "hybrid", "rank": 2, "score": 0.0401627815821632, "start_page": 9, "text": "Table 1 ML-DSA parameter sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Table 2 Sizes (in bytes) of keys and signatures of ML-DSA . . . . . . . . . . . . . . . . . . 16 Table 3 While loop and XOF output limits for a 2−256 or less probability of failure . . . . . 52\n\nList of Algorithms Algorithm 1 ML-DSA.KeyGen() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Algorithm 2 ML-DSA.Sign(sk, M, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 3 ML-DSA.Verify(pk, M, σ, ctx) . . . . . . . . . . . . . . . . . . . . . . . . . 18 Algorithm 4 HashML-DSA.Sign(sk, M, ctx, PH) . . . . . . . . . . . . . . . . . . . . . . 20 Algorithm 5 HashML-DSA.Verify(pk, M, σ, ctx, PH) . . . . . . . . . . . . . . . . . . . . 21 Algorithm 6 ML-DSA.KeyGen_internal(ξ) . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Algorithm 7 ML-DSA.Sign_internal(sk, M′, rnd) . . . . . . . . . . . . . . . . . . . . . . 25 Algorithm 8 ML-DSA.Verify_internal(pk, M′, σ) . . . . . . . . . . . . . . . . . . . . . . 27 Algorithm 9 IntegerToBits(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 10 BitsToInteger(y, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 11 IntegerToBytes(x, α) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Algorithm 12 BitsToBytes(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 13 BytesToBits(z) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 14 CoeffFromThreeBytes(b0, b1, b2) . . . . . . . . . . . . . . . . . . . . . . . . 29 Algorithm 15 CoeffFromHalfByte(b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 16 SimpleBitPack(w, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 17 BitPack(w, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Algorithm 18 SimpleBitUnpack(v, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 19 BitUnpack(v, a, b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Algorithm 20 HintBitPack(h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 21 HintBitUnpack(y) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Algorithm 22 pkEncode(ρ, t1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 23 pkDecode(pk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Algorithm 24 skEncode(ρ, K, tr, s1, s2, t0) . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 25 skDecode(sk) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Algorithm 26 sigEncode(c, z, h) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 27 sigDecode(σ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 28 w1Encode(w1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Algorithm 29 SampleInBall(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Algorithm 30 RejNTTPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 31 RejBoundedPoly(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Algorithm 32 ExpandA(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 33 ExpandS(ρ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 34 ExpandMask(ρ, μ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Algorithm 35 Power2Round(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 36 Decompose(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 37 HighBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Algorithm 38 LowBits(r) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41"}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "end_page": 29, "mode": "hybrid", "rank": 3, "score": 0.030330882352941176, "start_page": 29, "text": "which is defined as follows.\n 1. XOF.Init() = SHAKE128.Init().\n 2. XOF.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str).\n 3. XOF.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8 ⋅ l).\nNote that XOF.Squeeze requires the input length to be specified in bytes. This is consistent with the convention that all wrapper functions treat inputs and outputs as byte arrays and measure the lengths of all such arrays in terms of bytes.\n\n4.2 General Algorithms\nThis section specifies a number of algorithms that will be used as subroutines in ML-KEM.\n\n4.2.1 Conversion and Compression Algorithms\nThis section specifies several algorithms for converting between bit arrays, byte arrays, and arrays of integers modulo m. It also specifies a certain operation for compressing integers modulo q, and the corresponding decompression operation.\n\nAlgorithm 3 BitsToBytes(b)\nConverts a bit array (of a length that is a multiple of eight) into an array of bytes.\nInput: bit array b ∈ {0, 1}8⋅l.\nOutput: byte array B ∈ Bl.\n1: B ← (0, ... , 0)\n 2: for (i ← 0; i < 8l; i ++)\n 3: B [⌊i/8⌋] ← B [⌊i/8⌋] + b[i] ⋅ 2i mod 8\n4: end for\n5: return B"}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "end_page": 24, "mode": "hybrid", "rank": 4, "score": 0.029910714285714284, "start_page": 24, "text": "8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it\nshould be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to\nrelate bits, bytes, and words."}, {"chunk_id": "NIST.SP.800-227::p0035::c001", "doc_id": "NIST.SP.800-227", "end_page": 35, "mode": "hybrid", "rank": 5, "score": 0.028629032258064516, "start_page": 35, "text": "For simplicity, the exposition below focuses on a particular case: constructing a single KEM from two component KEMs. Since both the components and the multi-algorithm scheme in this case are of the same type (i.e., KEMs), the result is called a composite KEM. Most keyestablishment schemes of interest can easily be expressed as KEMs (see, e.g., ECDH-KEM in Sec. 5.1.1 and RSA-KEM in Sec. 5.1.2). Moreover, the hybrid PQ/T application typically calls for two component schemes: one post-quantum scheme, and one traditional scheme. The two-algorithm composite KEM described below is easily adapted to other cases, such as combining more than two schemes or combining KEMs with non-KEMs.\n\n4.6.1. Constructing a Composite KEM\nGiven two KEMs Π1 and Π2, one can construct a composite KEM C[Π1, Π2] via the following\nsequence of steps:\n 1. Choose parameter sets. Choose a collection C[Π1, Π2].ParamSets of parameter\n sets. Each parameter set will be a pair p = (p1, p2), where p1 ∈ Π1.ParamSets and\n p2 ∈ Π2.ParamSets.\n 2. Select a key combiner. Choose a key combiner algorithm KeyCombine. The inputs\nto KeyCombine include a pair of shared secret keys (one from Π1 and one from Π2), a pair of ciphertexts, a pair of encapsulation keys, and a parameter set. The output is a single shared secret key. Section 4.6.2 discusses NIST-approved key combiners.\n 3. Construct a composite key-generation algorithm. When a parameter set p =\n (p1, p2) is input, the algorithm C[Π1, Π2].KeyGen will perform:\n 1. (ek1, dk1) ← Π1.KeyGen(p1).\n 2. (ek2, dk2) ← Π2.KeyGen(p2).\n 3. Output composite encapsulation key ek1‖ek2.\n 4. Output composite decapsulation key dk1‖dk2.\n 4. Construct a composite encapsulation algorithm. When a parameter set p =\n (p1, p2) and encapsulation key ek1‖ek2 are input, the algorithm C[Π1, Π2].Encaps\nwill perform:\n 1. (K1, c1) ← Π1.Encaps(p1, ek1).\n 2. (K2, c2) ← Π2.Encaps(p2, ek2).\n 3. Output combined shared secret key\n\nK ← KeyCombine(K1, K2, c1, c2, ek1, ek2, p). (9)\n\n4. Output composite ciphertext c := c1‖c2."}, {"chunk_id": "NIST.SP.800-227::p0036::c000", "doc_id": "NIST.SP.800-227", "end_page": 36, "mode": "hybrid", "rank": 6, "score": 0.02821869488536155, "start_page": 36, "text": "5. Construct a composite decapsulation algorithm. When a parameter set p =\n(p1, p2), decapsulation key dk1‖dk2, and ciphertext c1‖c2 are input, the algorithm\n C[Π1, Π2].Decaps will perform:\n 1. K′ ← Π1.Decaps(p1, dk1, c1).\n 2. K′ ← Π2.Decaps(p2, dk2, c2).\n 3. Output combined shared secret key\n\nK′ ← KeyCombine(K′ , K′ , c1, c2, ek1, ek2, p). (10) 1 2\n\nSince the inputs to KeyCombine include the composite encapsulation key, the decapsulating party must retain a copy of that key or maintain the ability to recreate it after performing key generation.\n\nGeneral multi-algorithm schemes. The above construction can be extended in the obvious way to composite constructions that use more than two component KEMs. Extending to the case of a completely general multi-algorithm key-establishment scheme can be more complex, as the components in such a scheme can vary widely. For example, such schemes could potentially include pre-shared keys or shared secrets established via quantum key distribution. Still, most multi-algorithm schemes will likely include a step in which a series of shared secrets are combined via a key combiner algorithm of a form similar to KeyCombine above. In those cases, an approved key combiner discussed in Sec. 4.6.2 shall be used."}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 7, "score": 0.027149321266968326, "start_page": 30, "text": "Algorithm 4 shows the DER encodings of the OIDs for SHA-256, SHA-512, and SHAKE128. However, it may be used with other hash functions or XOFs.\n\nAlgorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ"}, {"chunk_id": "NIST.FIPS.204::p0023::c003", "doc_id": "NIST.FIPS.204", "end_page": 23, "mode": "hybrid", "rank": 8, "score": 0.025974025974025976, "start_page": 23, "text": "SHAKE256(str, 8l) = SHAKE256(BytesToBits(str), 8l).\n\nIn addition to using a mostly byte-oriented variant of the API defined in FIPS 202 for SHAKE256 and\nSHAKE128, this standard sometimes makes use of the incremental API defined in SP 800-185 [25]. This API\nconsists of three functions for each variant of SHAKE. These functions can be used to absorb a sequence of arbitrary-length strings and squeeze a sequence of arbitrary-length strings. These functions perform buffering to handle any incomplete data blocks while absorbing or squeezing. For example, for SHAKE256:\n\n• ctx ← SHAKE256.Init() Initializes a hash function context.\n\n• ctx ← SHAKE256.Absorb(ctx, str) Injects data to be used in the absorbing phase of SHAKE256 and updates context ctx."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 3], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 1}, {"chunk_id": "NIST.FIPS.204::p0009::c001", "doc_id": "NIST.FIPS.204", "pages": "p9-p9", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "pages": "p29-p29", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "pages": "p24-p24", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0035::c001", "doc_id": "NIST.SP.800-227", "pages": "p35-p35", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0036::c000", "doc_id": "NIST.SP.800-227", "pages": "p36-p36", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0023::c003", "doc_id": "NIST.FIPS.204", "pages": "p23-p23", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 28, "start_page": 28}], "qid": "q008", "question": "What are the steps in Algorithm 2 SHAKE128?", "retrieval": {"doc_hit_ranks": [1, 2, 8], "gold_hit_ranks": [1, 8], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 1, "score": 0.045680369617857444, "start_page": 28, "text": "is equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length.\n\nAlgorithm 2 SHAKE128example(str1, ... , strm , b1, ... , bl) Performs a sequence of absorbing operations followed by a sequence of squeezing operations. Input: byte arrays str1, ... , strm . Input: positive integers b1, ... , bl. l b . Output: a byte array of length ∑j=1 j 1: ctx ← SHAKE128.Init() ▷ initialize context 2: for (i ← 1; i ≤ m; i ++) 3: endctx ← SHAKE128.Absorb(ctx, stri ) ▷ absorb byte array stri 4: for 5: for (j ← 1; j ≤ l; j ++) 6: end(ctx, outj) ← SHAKE128.Squeeze(ctx, 8 ⋅ bj) ▷ squeeze bj-many bytes 7: for 8: output ← out1‖ ... ‖outl ▷ return the concatenation of all the results\n\nIn this standard, the incremental API for SHAKE128 will only be invoked through a wrapper XOF,"}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "end_page": 29, "mode": "hybrid", "rank": 2, "score": 0.030303030303030304, "start_page": 29, "text": "which is defined as follows.\n 1. XOF.Init() = SHAKE128.Init().\n 2. XOF.Absorb(ctx, str) = SHAKE128.Absorb(ctx, str).\n 3. XOF.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8 ⋅ l).\nNote that XOF.Squeeze requires the input length to be specified in bytes. This is consistent with the convention that all wrapper functions treat inputs and outputs as byte arrays and measure the lengths of all such arrays in terms of bytes.\n\n4.2 General Algorithms\nThis section specifies a number of algorithms that will be used as subroutines in ML-KEM.\n\n4.2.1 Conversion and Compression Algorithms\nThis section specifies several algorithms for converting between bit arrays, byte arrays, and arrays of integers modulo m. It also specifies a certain operation for compressing integers modulo q, and the corresponding decompression operation.\n\nAlgorithm 3 BitsToBytes(b)\nConverts a bit array (of a length that is a multiple of eight) into an array of bytes.\nInput: bit array b ∈ {0, 1}8⋅l.\nOutput: byte array B ∈ Bl.\n1: B ← (0, ... , 0)\n 2: for (i ← 0; i < 8l; i ++)\n 3: B [⌊i/8⌋] ← B [⌊i/8⌋] + b[i] ⋅ 2i mod 8\n4: end for\n5: return B"}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "end_page": 24, "mode": "hybrid", "rank": 3, "score": 0.029513888888888888, "start_page": 24, "text": "8. G.Squeeze(ctx, l) = SHAKE128.Squeeze(ctx, 8l)\n\nIn addition to SHAKE128 and SHAKE256, HashML-DSA.Sign and HashML-DSA.Verify may call other approved hash functions for pre-hashing. The pseudocode in this standard also treats these functions as returning a byte string as output while supporting either a bit string or a byte string as input. Here, it\nshould be noted that the hash functions defined in [8] use different rules (i.e., big-endian ordering) to\nrelate bits, bytes, and words."}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 4, "score": 0.027272727272727275, "start_page": 30, "text": "Algorithm 4 shows the DER encodings of the OIDs for SHA-256, SHA-512, and SHAKE128. However, it may be used with other hash functions or XOFs.\n\nAlgorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ"}, {"chunk_id": "NIST.FIPS.205::p0052::c000", "doc_id": "NIST.FIPS.205", "end_page": 52, "mode": "hybrid", "rank": 5, "score": 0.026279628993473032, "start_page": 52, "text": "Algorithm 25 hash_slh_verify(M, SIG, ctx, PH, PK) Verifies a pre-hash SLH-DSA signature. Input: Message M, signature SIG, context string ctx, pre-hash function PH, public key PK. Output: Boolean. 1: if |ctx| > 255 then 2: return false 3: end if 4: switch PH do 5: case SHA-256: 6: OID ← toByte(0x0609608648016503040201, 11) ▷ 2.16.840.1.101.3.4.2.1 7: PHM ← SHA-256(M) 8: case SHA-512: 9: OID ← toByte(0x0609608648016503040203, 11) ▷ 2.16.840.1.101.3.4.2.3 10: PHM ← SHA-512(M) 11: case SHAKE128: 12: OID ← toByte(0x060960864801650304020B, 11) ▷ 2.16.840.1.101.3.4.2.11 13: PHM ← SHAKE128(M, 256) 14: case SHAKE256: 15: OID ← toByte(0x060960864801650304020C, 11) ▷ 2.16.840.1.101.3.4.2.12 16: PHM ← SHAKE256(M, 512) 17: case ... ▷ other approved hash functions or XOFs 18: ... 19: end switch 20: M′ ← toByte(1, 1) ∥ toByte(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM 21: return slh_verify_internal(M ′ , SIG, PK)"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 6, "score": 0.024934585193166076, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.FIPS.204::p0030::c001", "doc_id": "NIST.FIPS.204", "end_page": 30, "mode": "hybrid", "rank": 7, "score": 0.02402745995423341, "start_page": 30, "text": "Algorithm 4 HashML-DSA.Sign(sk, M , ctx, PH) Generate a “pre-hash” ML-DSA signature. Input: Private key sk ∈ B32+32+64+32⋅((l+k)⋅bitlen (2η)+dk), message M ∈ {0, 1}∗, context string ctx (a byte string of 255 or fewer bytes), pre-hash function PH. Output: ML-DSA signature σ ∈ Bλ/4+l⋅32⋅(1+bitlen (γ1−1))+ω+k. 1: if |ctx| > 255 then 2: return ⊥ ▷ return an error indication if the context string is too long 3: end if 4: 5: rnd ← B32 ▷ for the optional deterministic variant, substitute rnd ← {0}32 6: if rnd = NULL then 7: return ⊥ ▷ return an error indication if random bit generation failed 8: end if 9: 10: switch PH do 11: case SHA-256: 12: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01 ▷ 2.16.840.1.101.3.4.2.1 13: PHM ← SHA256(M) 14: case SHA-512: 15: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03 ▷ 2.16.840.1.101.3.4.2.3 16: PHM ← SHA512(M) 17: case SHAKE128: 18: OID ← 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x0B ▷ 2.16.840.1.101.3.4.2.11 19: PHM ← SHAKE128(M, 256) 20: case ... 21: ... 22: end switch 23: M′ ← BytesToBits(IntegerToBytes(1, 1) ∥ IntegerToBytes(|ctx|, 1) ∥ ctx ∥ OID ∥ PHM) σ ← ML-DSA Sign internal ′ 24: . _ (sk, M , rnd) 25: return σ\n\nAlgorithm 5 presents the signature verification for HashML-DSA . This function constructs M′ in the same way as Algorithm 4 and passes the resulting M′ to Algorithm ML-DSA.Verify_internal for verification. As with the pre-hash signature generation, M′ may be constructed outside of the cryptographic module that performs ML-DSA.Verify_internal. However, in the case of HashML-DSA , the hash or XOF of the content must be computed within a FIPS 140-validated cryptographic module, which may be a different cryptographic module than the one that performs ML-DSA.Verify_internal. As noted in Section 5.4, the identifier associated with the signature should indicate whether ML-DSA or"}, {"chunk_id": "NIST.FIPS.203::p0028::c000", "doc_id": "NIST.FIPS.203", "end_page": 28, "mode": "hybrid", "rank": 8, "score": 0.01639344262295082, "start_page": 28, "text": "where s ∈ B∗.\nThe function G takes one variable-length input and produces two 32-byte outputs. It will be\ndenoted by G ∶ B∗ → B32 × B32. The two outputs of G will be denoted by (a, b) ← G(c), where\na, b ∈ B32, c ∈ B∗, and G(c) = a‖b. The function G shall be instantiated as\n\nG(c) ∶= SHA3-512(c) . (4.5)\n\neXtendable-Output Function (XOF). This standard uses a XOF wrapper defined in terms of the incremental API for SHAKE128 in SP 800-185 [21]. This SHAKE128 API consists of three functions: • ctx ← SHAKE128.Init() Initializes a XOF “context” ctx. • ctx ← SHAKE128.Absorb(ctx, str) Injects data to be used in the “absorbing” phase of SHAKE128 and updates the context accordingly. • (ctx, B) ← SHAKE128.Squeeze(ctx, 8 ⋅ z) Extracts z output bytes produced during the “squeezing” phase of SHAKE128 and updates the context accordingly. While the above functions are constructed using the Keccak-f permutation rather than the XOF SHAKE128 directly, they are defined so that a single SHAKE128 call of the form\n\noutput ← SHAKE128(str1‖ ... ‖strm , 8b1 + ... + 8bl) (4.6)\n\nis equivalent to performing Algorithm 2. This equivalence holds whether or not |stri | and bj are\nmultiples of the SHAKE128 block length."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2, 8], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0028::c001", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0029::c000", "doc_id": "NIST.FIPS.203", "pages": "p29-p29", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0024::c001", "doc_id": "NIST.FIPS.204", "pages": "p24-p24", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0030::c000", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0052::c000", "doc_id": "NIST.FIPS.205", "pages": "p52-p52", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0030::c001", "doc_id": "NIST.FIPS.204", "pages": "p30-p30", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0028::c000", "doc_id": "NIST.FIPS.203", "pages": "p28-p28", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 3, "start_page": 3}, {"doc_id": "NIST.FIPS.203", "end_page": 21, "start_page": 21}, {"doc_id": "NIST.FIPS.204", "end_page": 4, "start_page": 3}, {"doc_id": "NIST.FIPS.204", "end_page": 19, "start_page": 19}], "qid": "q009", "question": "What are the difference between ML-KEM and ML-DSA?", "retrieval": {"doc_hit_ranks": [1, 3, 5, 6, 7, 8], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "end_page": 8, "mode": "hybrid", "rank": 1, "score": 0.060447560951593204, "start_page": 8, "text": "5.4 Pre-Hash ML-DSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n 5.4.1 HashML-DSA Signing and Verifying . . . . . . . . . . . . . . . . . . . . . . . . 19\n6 Internal Functions 22\n 6.1 ML-DSA Key Generation (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n 6.2 ML-DSA Signing (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n 6.3 ML-DSA Verifying (Internal) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n7 Auxiliary Functions 28\n 7.1 Conversion Between Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n 7.2 Encodings of ML-DSA Keys and Signatures . . . . . . . . . . . . . . . . . . . . . . . . 33\n 7.3 Pseudorandom Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n 7.4 High-Order and Low-Order Bits and Hints . . . . . . . . . . . . . . . . . . . . . . . . 39\n 7.5 NTT and NTT−1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n 7.6 Arithmetic Under NTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\nReferences 47\n\nAppendix A — Montgomery Multiplication 50\n\nAppendix B — Zetas Array 51\n\nAppendix C — Loop Bounds 52"}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 2, "score": 0.05789451315398019, "start_page": 43, "text": "5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications\nThis section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption\nA KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for\nPKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15]."}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 3, "score": 0.05726975726975728, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 4, "score": 0.031099324975891997, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 5, "score": 0.030090497737556562, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.204::p0064::c001", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 6, "score": 0.027745885954841176, "start_page": 64, "text": "D.1 Differences Between Version 3.1 and the Round 3 Version of CRYSTALS- DILITHIUM The lengths of the variables ρ′ (private random seed) and μ (message representative) in the signing algorithm were increased from 384 to 512 bits. The increase in the length of μ corrects a security flaw that appeared in the third-round submission, where a collision attack against SHAKE256 with a 384-bit\noutput would make it so that parameters targeting NIST security strength category 5 could only meet\ncategory 4 [32].\nAdditionally, the length of the variable tr (the hash of the public key) was reduced from 384 to 256 bits.\nIn key generation, the variable ς was relabeled as ρ′ and increased in size from 256 bits to 512 bits.\n\nD.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34]."}, {"chunk_id": "NIST.FIPS.204::p0027::c000", "doc_id": "NIST.FIPS.204", "end_page": 27, "mode": "hybrid", "rank": 7, "score": 0.015873015873015872, "start_page": 27, "text": "5. External Functions\n\nThe signing, verifying, and key generation functions can be split into “external” and “internal” components to simplify APIs and Cryptographic Algorithm Validation Program (CAVP) testing. The external components generate randomness and perform various checks before calling their internal counterparts. The internal components are deterministic and can assume that the external components did not encounter error conditions. The distinction between external and internal functions also simplifies the presentation of algorithms for signing and verification by grouping the operations that are shared between ML-DSA.Sign and HashML-DSA.Sign in ML-DSA.Sign_internal and grouping the operations that are shared between ML-DSA.Verify and HashML-DSA.Verify in ML-DSA.Verify_internal.\n\n5.1 ML-DSA Key Generation\nThe key generation algorithm ML-DSA.KeyGen takes no input and outputs a public key and a private key, which are both encoded as byte strings.\nThe algorithm uses an approved RBG to generate a 256-bit (32-byte) random seed ξ that is given as input to ML-DSA.KeyGen_internal (Algorithm 6), which produces the public and private keys."}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 8, "score": 0.015151515151515152, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0008::c000", "doc_id": "NIST.FIPS.204", "pages": "p8-p8", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 4}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0064::c001", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 6}, {"chunk_id": "NIST.FIPS.204::p0027::c000", "doc_id": "NIST.FIPS.204", "pages": "p27-p27", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 4, "start_page": 4}, {"doc_id": "NIST.FIPS.203", "end_page": 11, "start_page": 11}], "qid": "q010", "question": "Define ML-KEM encapsulation key and where it’s used.", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 6, 7], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 1, "score": 0.06117215901558128, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 2, "score": 0.05682913147644286, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.FIPS.203::p0022::c000", "doc_id": "NIST.FIPS.203", "end_page": 22, "mode": "hybrid", "rank": 3, "score": 0.04329846248571716, "start_page": 22, "text": "In the typical application, a KEM is used to establish a shared secret key between two parties (here referred to as Alice and Bob) as described in Figure 1. Alice begins by running KeyGen in order to generate a (public) encapsulation key and a (private) decapsulation key. Upon obtaining Alice’s encapsulation key, Bob runs the Encaps algorithm, which produces Bob’s copy K of the shared secret key along with an associated ciphertext. Bob sends the ciphertext to Alice, and Alice completes the process by running the Decaps algorithm using her decapsulation key and the ciphertext. This final step produces Alice’s copy K′ of the shared secret key.\nAfter completing this process, Alice and Bob would like to conclude that their outputs satisfy\nK′ = K and that this value is a secure, random, shared secret key. However, these properties\nonly hold if certain important conditions are satisfied, as discussed in SP 800-227 [1].\n\n3.2 The ML-KEM Scheme\nML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was\ninitially described in [8]. The following is a brief and informal description of the computational\nassumption underlying ML-KEM and how the ML-KEM scheme is constructed."}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "end_page": 21, "mode": "hybrid", "rank": 4, "score": 0.043290043290043295, "start_page": 21, "text": "3. Overview of the ML-KEM Scheme\n\nThis section gives a high-level overview of the ML-KEM scheme.\n\n3.1 Key-Encapsulation Mechanisms\nThe following is a high-level overview of key-encapsulation mechanisms (KEMs). For details, see\n SP 800-227 [1].\nA KEM is a cryptographic scheme that, under certain conditions, can be used to establish a shared secret key between two communicating parties. This shared secret key can then be used for symmetric-key cryptography.\nA KEM consists of three algorithms and a collection of parameter sets. The three algorithms are:\n 1. A probabilistic key generation algorithm denoted by KeyGen\n 2. A probabilistic ”encapsulation” algorithm denoted by Encaps\n 3. A deterministic ”decapsulation” algorithm denoted by Decaps\nThe collection of parameter sets is used to select a trade-off between security and efficiency.\nEach parameter set in the collection is a list of specific (typically numerical) values, one for each parameter required by the three algorithms.\nAlice Bob\n\nKeyGen\n\ndecapsulation key encapsulation key\n\nDecaps ciphertext Encaps\n\nAlice’s copy of the Bob’s copy of the shared secret key shared secret key K′ K\n\nFigure 1. A simple view of key establishment using a KEM"}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 5, "score": 0.031099324975891997, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 6, "score": 0.029910714285714284, "start_page": 44, "text": "This section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation\nThe key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key.\nWhile the encapsulation key can be made public, the decapsulation key shall remain private.\nThe seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a\ndecapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)"}, {"chunk_id": "NIST.FIPS.203::p0010::c001", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 7, "score": 0.02886002886002886, "start_page": 10, "text": "1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government.\n\n1.2 Context Over the past several years, there has been steady progress toward building quantum computers. If large-scale quantum computers are realized, the security of many commonly used public-key cryptosystems will be at risk. This would include key-establishment schemes and digital signature schemes whose security depends on the difficulty of solving the integer factorization and discrete logarithm problems (both over finite fields and elliptic curves). As a result, in 2016, NIST initiated a public Post-Quantum Cryptography (PQC) Standardization process to select quantum-resistant public-key cryptographic algorithms. A total of 82 candidate algorithms were submitted to NIST for consideration. After three rounds of evaluation and analysis, NIST selected the first four algorithms for standardization. These algorithms are intended to protect sensitive U.S. Government information well into the foreseeable future, including after the advent of cryptographically-relevant quantum computers. This standard specifies a variant of the selected algorithm CRYSTALS-KYBER, a lattice-based key-encapsulation mechanism (KEM) designed by Peter Schwabe, Roberto Avanzi, Joppe Bos, Léo Ducas, Eike Kiltz, Tancrède Lepoint, Vadim Lyubashevsky, John Schanck, Gregor Seiler, Damien Stehlé, and Jintai Ding [4]. Throughout this standard, the KEM specified here will be referred to as ML-KEM, as it is based on the Module Learning With Errors assumption."}, {"chunk_id": "NIST.SP.800-227::p0016::c000", "doc_id": "NIST.SP.800-227", "end_page": 16, "mode": "hybrid", "rank": 8, "score": 0.014925373134328358, "start_page": 16, "text": "party can predetermine it. In key transport (e.g., RSA-OAEP [2]), one party selects the key and then transmits it (in some form) to the other party. Depending on the internal structure of the encapsulation function, a KEM could be viewed as either a key-agreement scheme or a key-transport scheme. For example, the shared secret key in ML-KEM [3] is a function of both the randomness provided by Bob and the (randomly generated) encapsulation key of Alice. Therefore, ML-KEM could be viewed as a key-agreement scheme. However, as the example KEMFROMPKE shows, the encapsulation operation in a KEM might simply consist of Bob generating the shared secret key and then encrypting it, which is key transport. An application can achieve a particular type of key establishment (i.e., key agreement or key transport) using any KEM by taking appropriate additional steps using standard symmetric-key cryptography techniques. That is, given a KEM Π, Alice and Bob can achieve key agreement by both executing Π.KeyGen, sending the encapsulation keys to each other, and completing the steps of key establishment using a KEM. This will result in two separate shared secret keys that can be combined using an appropriate key-derivation method. Conversely, Π can be used to achieve key transport by following the steps in Fig. 7 and replacing m with the shared secret key produced by Π."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2, 7], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0022::c000", "doc_id": "NIST.FIPS.203", "pages": "p22-p22", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "pages": "p21-p21", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0010::c001", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0016::c000", "doc_id": "NIST.SP.800-227", "pages": "p16-p16", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 44, "start_page": 44}], "qid": "q011", "question": "What are the inputs/outputs of ML-KEM KeyGen?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [3, 5], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 1, "score": 0.060486896615928876, "start_page": 23, "text": "Parameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329.\n\nDecapsulation failures. Provided that all inputs are well-formed and randomness generation is successful, the key establishment procedure of ML-KEM will never explicitly fail, meaning that both ML-KEM.Encaps and ML-KEM.Decaps will each output a 256-bit value. Moreover, if no corruption or interference is present, the two 256-bit values produced by ML-KEM.Encaps and ML-KEM.Decaps will be equal with overwhelming probability (i.e., K′ will equal K in the process described in Figure 1). The event that K′ ≠ K under these conditions is called a decapsulation"}, {"chunk_id": "NIST.FIPS.203::p0048::c000", "doc_id": "NIST.FIPS.203", "end_page": 48, "mode": "hybrid", "rank": 2, "score": 0.05659899801690847, "start_page": 48, "text": "8. Parameter Sets\n\nML-KEM is equipped with three parameter sets, each of the which comprises five individual parameters: k, η1, η2, du, and dv. There are also two constants: n = 256 and q = 3329. The following is a brief and informal description of the roles played by the variable parameters in the algorithms of K-PKE and ML-KEM. See Section 5 for details. • The parameter k determines the dimensions of the matrix A that appears in K-PKE.KeyGen and K-PKE.Encrypt. It also determines the dimensions of vectors s and e in K-PKE.KeyGen and the dimensions of vectors y and e1 in K-PKE.Encrypt. • The parameter η1 is required to specify the distribution for generating the vectors s and e in K-PKE.KeyGen and the vector y in K-PKE.Encrypt. • The parameter η2 is required to specify the distribution for generating the vectors e1 and e2 in K-PKE.Encrypt. • The parameters du and dv serve as parameters and inputs for the functions Compress, Decompress, ByteEncode, and ByteDecode in K-PKE.Encrypt and K-PKE.Decrypt. This standard approves the parameter sets given in Table 2. Each parameter set is associated with a required security strength for randomness generation (see Section 3.3). The sizes of the ML-KEM keys and ciphertexts for each parameter set are summarized in Table 3.\n\nTable 2. Approved parameter sets for ML-KEM"}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 3, "score": 0.047643442622950824, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.FIPS.203::p0056::c000", "doc_id": "NIST.FIPS.203", "end_page": 56, "mode": "hybrid", "rank": 4, "score": 0.04623878536922015, "start_page": 56, "text": "Appendix C — Differences From the CRYSTALS-Kyber Submission\n\nThis appendix lists the differences between CRYSTALS-KYBER (as described in [4]) and the ML-KEM\nscheme (specified in this document) that result in differing input-output behavior of the main algorithms (i.e., KeyGen, Encaps, Decaps). Since a conforming implementation need only match the input-output behavior of these three algorithms (see “Implementations” and Section 3.3 below), the list does not include any of the numerous differences in how the main algorithms actually produce outputs from inputs (e.g., via different computational steps or different subroutines),\nnor any differences in presentation between this standard and [4]."}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 5, "score": 0.0304147465437788, "start_page": 44, "text": "This section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation\nThe key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key.\nWhile the encapsulation key can be made public, the decapsulation key shall remain private.\nThe seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a\ndecapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)"}, {"chunk_id": "NIST.FIPS.203::p0046::c001", "doc_id": "NIST.FIPS.203", "end_page": 46, "mode": "hybrid", "rank": 6, "score": 0.027884615384615386, "start_page": 46, "text": "7.3 ML-KEM Decapsulation\nThe decapsulation algorithm ML-KEM.Decaps of ML-KEM (Algorithm 21) accepts a decapsulation key and an ML-KEM ciphertext as input, does not use any randomness, and outputs a shared secret. This algorithm requires input checking, as specified below.\n\nDecapsulation input check. To check a candidate decapsulation key dk and ciphertext c, perform the following checks:\n 1. (Ciphertext type check) If c is not a byte array of length 32(duk + dv) for the values of du,\ndv, and k specified by the relevant parameter set, then input checking has failed.\n 2. (Decapsulation key type check) If dk is not a byte array of length 768k + 96 for the value of\nk specified by the relevant parameter set, then input checking has failed.\n 3. (Hash check) Perform the computation\n\ntest ← H(dk[384k ∶ 768k + 32])) . (7.2)\n\nIf test ≠ dk[768k + 32 ∶ 768k + 64], then input checking has failed.\nIf all of the above checks pass, then ML-KEM.Decaps can be run with inputs dk ∶= dk and c ∶= c. It\nis important to note that this checking process does not guarantee that dk is a properly produced\noutput of ML-KEM.KeyGen, nor that c is a properly produced output of ML-KEM.Encaps.\nML-KEM.Decaps shall not be run with a decapsulation key or a ciphertext unless both have been checked. However, checking of the decapsulation key need not be performed by the decapsulating party, nor with every execution of ML-KEM.Decaps. Instead, assurance that this\ncheck has been performed can be acquired through other means (see SP 800-227 [1]). Ciphertext\nchecking shall be performed with every execution of ML-KEM.Decaps."}, {"chunk_id": "NIST.FIPS.203::p0037::c001", "doc_id": "NIST.FIPS.203", "end_page": 37, "mode": "hybrid", "rank": 7, "score": 0.025816993464052286, "start_page": 37, "text": "This section describes the component scheme K-PKE. As discussed in Section 3.3, K-PKE is not approved for use in a stand-alone fashion. It serves only as a collection of subroutines for use in the algorithms of the approved scheme ML-KEM, as described in Section 7. K-PKE consists of three algorithms: 1. Key generation (K-PKE.KeyGen) 2. Encryption (K-PKE.Encrypt) 3. Decryption (K-PKE.Decrypt) When K-PKE is instantiated as part of ML-KEM, K-PKE inherits the parameter set selected for ML-KEM. Each parameter set specifies numerical values for each parameter. While n is always 256 and q is always 3329, the values of the remaining parameters k, η1, η2, du, and dv vary among the three parameter sets. Parameters and parameter sets are described in Section 8. The algorithms in this section do not perform any input checking because they are only invoked as subroutines of the main ML-KEM algorithms. The algorithms of ML-KEM themselves do perform input checking as needed. Each of the algorithms of K-PKE is accompanied by a brief, informal description in text. For simplicity, this description is written in terms of vectors and matrices whose entries are elements of Rq . In the actual algorithm, most of the computations occur in the NTT domain in order to improve the efficiency of multiplication. The relevant vectors and matrices will then have entries in Tq . Linear-algebraic arithmetic with such vectors and matrices (e.g., line 18 of K-PKE.KeyGen) is performed as described in Sections 2.4.7 and 4.3.1. The encryption and decryption keys of K-PKE are also stored in the NTT form.\n\n5.1 K-PKE Key Generation The key generation algorithm K-PKE.KeyGen of K-PKE (Algorithm 13) receives a seed as input and outputs an encryption key ekPKE and a decryption key dkPKE. As is typically the case for public-key encryption, the encryption key can be made public, while the decryption key and the randomness must remain private. Indeed, the encryption key of K-PKE will serve as the encapsulation key of ML-KEM (see ML-KEM.KeyGen below) and can thus be made public. Meanwhile, the decryption key and seed of K-PKE.KeyGen must remain private as they can be used to perform decapsulation in ML-KEM. The matrix A generated in steps 3-7 of K-PKE.KeyGen can be stored, as specified in Section 3.3. This allows later operations to use A directly rather than re-expanding it from the public seed ρ.\n\nInformal description. The decryption key of K-PKE.KeyGen is a length-k vector s of elements of Rq (i.e., s ∈ Rk). Roughly speaking, s is a set of secret variables, while the encryption key is a collection of q “noisy” linear equations (A, As + e) in the secret variables s. The rows of the matrix A form the equation coefficients. This matrix is generated pseudorandomly using XOF with only a seed stored in the encryption key. The secret s and the “noise” e are sampled from"}, {"chunk_id": "NIST.FIPS.203::p0033::c001", "doc_id": "NIST.FIPS.203", "end_page": 33, "mode": "hybrid", "rank": 8, "score": 0.014492753623188406, "start_page": 33, "text": "f ×Rq g = NTT−1(f ×Tq g), (4.9)\n\nwhere ×Rq and ×Tq denote multiplication in Rq and Tq , respectively. Moreover, since Tq is a\nproduct of 128 rings that each consist of polynomials of degree at most one, the operation ×Tq\nis much more efficient than the operation ×Rq . For these reasons, the NTT is considered to be\nan integral part of ML-KEM and not merely an optimization.\nAs the rings Rq and Tq have a vector space structure over Zq , the most natural abstract data type to represent elements from either of these rings is Zn. For this reason, the choice of data q structure for the inputs and outputs of NTT and NTT−1 are length-n arrays of integers modulo q. These arrays are understood to represent elements of Tq or Rq , respectively (see Section\n2.4.4). Algorithms 9 and 10 describe an efficient means of computing NTT and NTT−1 in place.\nHowever, to clarify the distinction between the algebraic objects before and after the conversion, the algorithms are written with explicit inputs and outputs. This is consistent with this standard’s convention that all inputs are passed by copy."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.3333333333333333, "ndcg_at_k": 0.5, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [3, 5], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0048::c000", "doc_id": "NIST.FIPS.203", "pages": "p48-p48", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0056::c000", "doc_id": "NIST.FIPS.203", "pages": "p56-p56", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0046::c001", "doc_id": "NIST.FIPS.203", "pages": "p46-p46", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0037::c001", "doc_id": "NIST.FIPS.203", "pages": "p37-p37", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0033::c001", "doc_id": "NIST.FIPS.203", "pages": "p33-p33", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.204", "end_page": 5, "start_page": 5}, {"doc_id": "NIST.FIPS.205", "end_page": 5, "start_page": 5}], "qid": "q012", "question": "How do ML-DSA and SLH-DSA differ in intended use-cases?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "end_page": 18, "mode": "hybrid", "rank": 1, "score": 0.054532886320079695, "start_page": 18, "text": "PK.root\n\nlayer d − 1 = 2\n\nWOTS+ signature\n\nlayer 1\n\nMerkle tree node WOTS+ signature WOTS+ public key\n\nlayer 0 FORS public key\n\nWOTS+ signature\n\nFORS signature Message\n\nFigure 1. An SLH-DSA signature\n\nThe WOTS+ one-time signature scheme is specified in Section 5, and the XMSS multi-time sig- nature scheme is specified in Section 6. Section 7 specifies the generation and verification of hypertree signatures. The FORS few-time signature scheme is specified in Section 8. Finally, Section 9 specifies the SLH-DSA key generation, signature, and verification functions. As the WOTS+, XMSS, hypertree, and FORS schemes described in this standard are not intended for use as stand-alone signature schemes, only the components of the schemes necessary to imple- ment SLH-DSA are described. In particular, these sections do not include functions for key pair generation, and a signature verification function is only specified for hypertree signatures. When used in this standard, WOTS+, XMSS, and FORS signatures are implicitly verified using functions to generate public keys from messages and signatures (see Sections 5.3, 6.3, and 8.4). When verifying an SLH-DSA signature, the randomized hash of the message and the FORS signature are used to compute a candidate FORS public key. The candidate FORS public key and the WOTS+ signature from the layer 0 XMSS key are used to compute a candidate WOTS+ public key, which is then used in conjunction with the corresponding authentication path to compute a candidate XMSS public key. The candidate layer 0 XMSS public key is used along with the layer 1"}, {"chunk_id": "NIST.FIPS.205::p0054::c001", "doc_id": "NIST.FIPS.205", "end_page": 54, "mode": "hybrid", "rank": 2, "score": 0.031544957774465976, "start_page": 54, "text": "Using this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each parameter set is claimed to be at least as secure as a generic block cipher with a prescribed key size. More precisely, it is claimed that the computational resources needed to break SLH-DSA are greater than or equal to the computational resources needed to break the block cipher when these computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models\n are discussed in [26].\n Concretely, the parameter sets with n = 16 are claimed to be in security category 1, the\n parameter sets with n = 24 are claimed to be in security category 3, and the parameter sets with\n n = 32 are claimed to be in security category 5 [10]. For additional discussion of the security\n strength of SLH-DSA, see [10, 27].\n Some applications require a property known as message-bound signatures [28, 29], which\nintuitively requires that it be infeasible for anyone to create a public key and a signature that are valid for two different messages. Signature schemes are not required to have this property under the EUF-CMA security definition used in assigning security categories. In the case of SLH-DSA, the key pair owner could create two messages with the same signature by finding a collision on Hmsg. Due to the length of the output of Hmsg, finding such a collision would be expected to require fewer computational resources than specified for the parameter sets’ claimed security categories in all cases except SLH-DSA-SHA2-128f and SLH-DSA-SHAKE-128f.23 Therefore, applications that require message-bound signatures should either take the expected cost of finding collisions on Hmsg into account when choosing an appropriate parameter set or\n apply a technique (e.g., the BUFF transformation [29]) to obtain the message-bound signatures\nproperty.\n\n11.1 SLH-DSA Using SHAKE\nHmsg, PRF, PRFmsg, F, H, and Tl shall be instantiated as follows for the SLH-DSA-SHAKE-\n128s, SLH-DSA-SHAKE-128f, SLH-DSA-SHAKE-192s, SLH-DSA-SHAKE-192f, SLH-DSA-SHAKE-256s, and SLH-DSA-SHAKE-256f parameter sets:\n Hmsg(R, PK.seed, PK.root, M) = SHAKE256(R ∥ PK.seed ∥ PK.root ∥ M , 8m)\n PRF(PK.seed, SK.seed, ADRS) = SHAKE256(PK.seed ∥ ADRS ∥ SK.seed, 8n)\n PRFmsg(SK.prf, opt_rand, M) = SHAKE256(SK.prf ∥ opt_rand ∥ M , 8n)\n F(PK.seed, ADRS, M1) = SHAKE256(PK.seed ∥ ADRS ∥ M1, 8n)\n H(PK.seed, ADRS, M2) = SHAKE256(PK.seed ∥ ADRS ∥ M2, 8n)\n Tl(PK.seed, ADRS, Ml) = SHAKE256(PK.seed ∥ ADRS ∥ Ml, 8n)\n\n11.2 SLH-DSA Using SHA2\nIn Sections 11.2.1 and 11.2.2, the functions MGF1-SHA-256 and MGF1-SHA-512 are MGF1 from\n Appendix B.2.1 of RFC 8017 [30], where Hash is SHA-256 or SHA-512, respectively. The functions\n\n23Finding a collision would be expected to require computing Hmsg for approximately 2(h+k⋅a)/2 different mes- sages."}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "end_page": 64, "mode": "hybrid", "rank": 3, "score": 0.0315136476426799, "start_page": 64, "text": "D.2 Differences Between Version 3.1 of CRYSTALS-DILITHIUM and FIPS 204 Initial Public Draft\nIn order to ensure the properties noted in [14], ML-DSA increases the length of tr to 512 bits and increases\nthe length of c to 384 and 512 bits for the parameter sets ML-DSA-65 and ML-DSA-87, respectively. In draft ML-DSA, only the first 256 bits of c are used in the generation of c.\nIn Version 3.1 of the CRYSTALS-DILITHIUM submission, the default version of the signing algorithm is deterministic with ρ′ being generated pseudorandomly from the signer’s private key and the message, and an optional version of the signing algorithm has ρ′ sampled instead as a 512-bit random string. In ML-DSA, ρ′ is generated by a “hedged” procedure in which ρ′ is pseudorandomly derived from the signer’s private key, the message, and a 256-bit string rnd, which should be generated by an Approved RBG by default. The ML-DSA standard also allows for an optional deterministic version in which rnd is a 256-bit constant string.\nThe draft ML-DSA standard also included pseudocode that unintentionally omitted a check for malformed\ninput while unpacking the hint [33]. Failure to perform this check results in a signature scheme that is not\nstrongly existentially unforgeable [34].\n\nD.3 Changes From FIPS 204 Initial Public Draft In the final version of the ML-DSA standard, the omitted malformed input check was restored to the hint unpacking algorithm (Algorithm 21). Additionally, in the final version of ML-DSA, all of the bits of c are used in the generation of c (Algorithm 29), and ExpandMask (Algorithm 34) is modified to take output bits from the beginning of the output of H. Based on comments that were submitted on the draft version, more details were provided for the pre-hash version HashML-DSA in Section 5.4. These modifications include domain separation for the cases in which the message is signed directly and cases in which a digest of the message is signed. The changes were made by explicitly defining external functions for both versions of the signing and verification functions"}, {"chunk_id": "NIST.FIPS.205::p0048::c000", "doc_id": "NIST.FIPS.205", "end_page": 48, "mode": "hybrid", "rank": 4, "score": 0.030798389007344232, "start_page": 48, "text": "a single key pair may be used for both pure and pre-hash signatures, it is recommended that each key pair only be used for one version or the other. If a non-empty context string is to be used, this should either be indicated by the signature’s identifier or the application with which the signature is being used. If the default hedged variant of slh_sign_internal is used, the n-byte random value addrnd shall be generated by the cryptographic module that runs slh_sign_internal. However, M′ in Algorithms 22 and 23 may be constructed outside of the crytographic module. In the case of hash_slh_sign, the hash or XOF of the content to be signed must be computed within a FIPS 140-validated cryptographic module, but it may be a different cryptographic module than the one that runs slh_sign_internal. In general, the pure version is preferred. However, for some cryptographic modules that generate SLH-DSA signatures, performing lines 3 and 5 of Algorithm 19 may be infeasible if the message M is large. This may, for example, be the result of the module having limited memory to store the message to be signed. Similarly, for some cryptographic modules that verify SLH-DSA signatures, performing line 8 of Algorithm 20 may be infeasible if the message M is large. For some use cases, these issues may be addressed by signing a digest of the content rather than signing the content directly. In many cases where the content to be signed is large, hashing of the content is performed at the application level. For example, in the Cryptographic Message Syntax [23], a digest of the content may be computed, and that digest is signed along with other attributes. In cases in which the content is not hashed at the application level, the pre-hash version of SLH-DSA signing (Section 10.2.2) may be used. To maintain the same level of security strength when the content is hashed at the application level or when using the pre-hash version of SLH-DSA, the digest that is signed needs to be generated using an approved hash function or XOF (e.g., from FIPS 180-4 [8] or FIPS 202 [6]) that provides at least 8n bits of classical security strength against both collision and second preimage attacks [6, Table 4].18 Verification of a signature created in this way will require the verify function to generate a digest from the message in the same way for input to the verification function. Even if it is feasible to compute collisions on the hash functions or XOF used to instantiate Hmsg, PRF, PRFmsg, F, H, and Tl, there is believed to be no adverse effect on the security of SLH-DSA.19 However, if the input to the signing function is a digest of the content, then collisions on the function used to compute the digest can result in forged messages."}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "end_page": 19, "mode": "hybrid", "rank": 5, "score": 0.030117753623188408, "start_page": 19, "text": "Destruction of sensitive data. Data used internally by key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of SLH-DSA shall ensure that any local copies of the inputs and any potentially sensitive intermediate data are destroyed as soon as they are no longer needed.\n\nKey checks. SP 800-89 imposes requirements for the assurance of public-key validity and privatekey possession. In the case of SLH-DSA, where public-key validation is required, implementations shall verify that the public key is 2n bytes in length. When the assurance of private key possession is obtained via regeneration, the owner of the private key shall check that the private key is 4n bytes in length and shall use SK.seed and PK.seed to recompute PK.root and compare the newly generated value with the value in the private key currently held.\n\nFloating-point arithmetic. Implementations of SLH-DSA shall not use floating-point arithmetic, as rounding errors in floating point operations may lead to incorrect results in some cases. In all pseudocode in this standard in which division is performed (e.g., x/y) and y may not divide x, either ⌊x/y⌋ or ⌈x/y⌉ is used. Both of these can be computed without floating-point arithmetic,\nas ordinary integer division x/y computes ⌊x/y⌋, and ⌈x/y⌉ = ⌊(x + y − 1)/y⌋ for non-negative\nintegers x and positive integers y."}, {"chunk_id": "NIST.FIPS.204::p0022::c002", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 6, "score": 0.029906956136464335, "start_page": 22, "text": "3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability.\n\n3.6.3 Intermediate Values The data used internally by the key generation and signing algorithms in intermediate computation steps could be used by an adversary to gain information about the private key and thereby compromise security. The data used internally by verification algorithms is similarly sensitive for some applications, including the verification of signatures that are used as bearer tokens (i.e., authentication secrets) or the verification of signatures on plaintext messages that are intended to be confidential. Intermediate values of the verification algorithm may reveal information about its inputs (i.e., the message, signature, and public key), and in some applications, security or privacy requires one or more of these inputs to be confidential. Therefore, implementations of ML-DSA shall ensure that any potentially sensitive intermediate data is destroyed as soon as it is no longer needed. Two particular cases in which implementations may refrain from destroying intermediate data are:\n\n1. The seed ξ generated in step 1 of ML-DSA.KeyGen can be stored for the purpose of later expansion\n\n3In addition, when signing is deterministic, there is leakage through timing side channels of information about the message but not the private key). If the signer does not want to reveal the message being signed, hedged\n signatures should be used (see Section 3.2 in [6])."}, {"chunk_id": "NIST.FIPS.205::p0047::c001", "doc_id": "NIST.FIPS.205", "end_page": 47, "mode": "hybrid", "rank": 7, "score": 0.02946236559139785, "start_page": 47, "text": "Algorithm 21 slh_keygen() Generates an SLH-DSA key pair. Input: (none) Output: SLH-DSA key pair (SK, PK). SK.seed $ n ← 1: − B ▷ set SK.seed, SK.prf, and PK.seed to random n-byte SK.prf $ n ← 2: − B ▷ strings using an approved random bit generator PK.seed $ n ← 3: − B 4: if SK.seed = NULL or SK.prf = NULL or PK.seed = NULL then 5: return ⊥ ▷ return an error indication if random bit generation failed 6: end if 7: return slh_keygen_internal(SK.seed, SK.prf, PK.seed)\n\n10.2 SLH-DSA Signature Generation This section presents two versions of SLH-DSA signature generation: a “pure” version (slh_sign) and a “pre-hash” version (hash_slh_sign). Both versions use slh_sign_internal, but they differ in how the message input to slh_sign_internal is created from the content to be signed. In the pure version, the content is signed by slh_sign_internal along with some domain separation information. In the pre-hash version, a hash of the content is signed by slh_sign_internal along with some domain separation information. Both versions take the content to be signed, the private key, and a context as input. The pre-hash version also takes as input a hash function or XOF that is to be used to pre-hash the content to be signed. The context string has a maximum length of 255 bytes. By default, the context is the empty string. However, applications may specify the use of a non-empty context string. The identifier for a signature (e.g., the object identifier [OID]) should indicate whether the signature is a pure signature or a pre-hash signature. In the case of pre-hash signatures, the identifier should also indicate the hash function or XOF used to compute the pre-hash.17 While 17In the case of a XOF, this would also include the length of the output from the XOF."}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "end_page": 22, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 22, "text": "3.6.1 Randomness Generation Algorithm 1, implementing key generation for ML-DSA, uses an RBG to generate the 256-bit random seed ξ. The seed ξ shall be a fresh (i.e., not previously used) random value generated using an approved RBG, as prescribed in SP 800-90A, SP 800-90B, and SP 800-90C [19, 20, 21]. Moreover, the RBG used shall have a security strength of at least 192 bits for ML-DSA-65 and 256 bits for ML-DSA-87. For ML-DSA-44, the RBG should have a security strength of at least 192 bits and shall have a security strength of at least 128 bits. If an approved RBG with at least 128 bits of security but less than 192 bits of security is used, then the claimed security strength of ML-DSA-44 is reduced from category 2 to category 1. Additionally, the value rnd is generated using an RBG in the default “hedged” variants of Algorithms 2 and 4 for ML-DSA and HashML-DSA signing, respectively. While this value should ideally be generated by an approved RBG, other methods for generating fresh random values may be used. The primary purpose of rnd is to facilitate countermeasures to side-channel attacks and fault attacks on deterministic signatures, such as [22, 23, 24].3 For this purpose, even a weak RBG may be preferable to the fully deterministic variants of Algorithms 2 and 4.\n\n3.6.2 Public-Key and Signature Length Checks\nAlgorithm 3, implementing verification for ML-DSA, and Algorithm 5, implementing verification for HashML- DSA, specify the length of the signature σ and the public key pk in terms of the parameters described in Table 1. If an implementation of ML-DSA can accept inputs for σ or pk of any other length, it shall return false whenever the lengths of either of these inputs differ from their lengths specified in this standard.\nFailing to check the length of pk or σ may interfere with the security properties that ML-DSA is designed to have, like strong unforgeability."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.205::p0018::c000", "doc_id": "NIST.FIPS.205", "pages": "p18-p18", "rank": 1}, {"chunk_id": "NIST.FIPS.205::p0054::c001", "doc_id": "NIST.FIPS.205", "pages": "p54-p54", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0064::c002", "doc_id": "NIST.FIPS.204", "pages": "p64-p64", "rank": 3}, {"chunk_id": "NIST.FIPS.205::p0048::c000", "doc_id": "NIST.FIPS.205", "pages": "p48-p48", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0019::c002", "doc_id": "NIST.FIPS.205", "pages": "p19-p19", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0022::c002", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 6}, {"chunk_id": "NIST.FIPS.205::p0047::c001", "doc_id": "NIST.FIPS.205", "pages": "p47-p47", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0022::c001", "doc_id": "NIST.FIPS.204", "pages": "p22-p22", "rank": 8}]}}
{"answerable": false, "gold": [], "qid": "q013", "question": "What does NIST say about PQC for Wi-Fi 9?", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "has_gold_in_primary_k": null, "hits": [{"chunk_id": "NIST.FIPS.204::p0040::c000", "doc_id": "NIST.FIPS.204", "end_page": 40, "mode": "hybrid", "rank": 1, "score": 0.04421356457417033, "start_page": 40, "text": "Algorithm 15 CoeffFromHalfByte(b)\nLet η ∈ {2, 4}. Generates an element of {−η, −η + 1, ... , η} ∪ {⊥}.\nInput: Integer b ∈ {0, 1, ... , 15}.\nOutput: An integer between −η and η, or ⊥.\n 1: if η = 2 and b < 15 then return 2 − (b mod 5) ▷ rejection sampling from {−2, ... , 2}\n2: else\n 3: if η = 4 and b < 9 then return 4 − b ▷ rejection sampling from {−4, ... , 4}\n4: else return ⊥\n5: end if\n6: end if\n\nAlgorithms 16–19 efficiently translate an element w ∈ R into a byte string and vice versa under the\nassumption that the coefficients of w are in a restricted range. SimpleBitPack assumes that wi ∈ [0, b]\nfor some positive integer b and packs w into a byte string of length 32 ⋅ bitlen b. BitPack allows for the\nmore general restriction wi ∈ [−a, b]. The BitPack algorithm works by merely subtracting w from the\npolynomial ∑255 bXi.\n i=0\n\nAlgorithm 16 SimpleBitPack(w, b) Encodes a polynomial w into a byte string. Input: b ∈ N and w ∈ R such that the coefficients of w are all in [0, b]. Output: A byte string of length 32 ⋅ bitlen b. 1: z ← () ▷ set z to the empty bit string 2: for i from 0 to 255 do 3: endz ← z||IntegerToBits(wi , bitlen b) 4: for 5: return BitsToBytes(z)"}, {"chunk_id": "NIST.FIPS.203::p0052::c000", "doc_id": "NIST.FIPS.203", "end_page": 52, "mode": "hybrid", "rank": 2, "score": 0.029551337359792925, "start_page": 52, "text": "[23] Alagic G, Apon D, Cooper D, Dang Q, Dang T, Kelsey J, Lichtinger J, Liu YK, Miller C, Moody\nD, Peralta R, Perlner R, Robinson A, Smith-Tone D (2022) Status report on the third round of the NIST post-quantum cryptography standardization process (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR)\n 8413. https://doi.org/10.6028/NIST.IR.8413-upd1.\n[24] CRYSTALS-Kyber submission team (2023) “Discussion about Kyber’s tweaked FO transform”,\nPQC-Forum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/W FRDl8DqYQ4.\n[25] CRYSTALS-Kyber submission team (2023) “Kyber decisions, part 2: FO transform”, PQC-\nForum Post. Available at https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/C0D3W\n1KoINY/m/99kIvydoAwAJ."}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 3, "score": 0.016129032258064516, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 4, "score": 0.015873015873015872, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.FIPS.203::p0005::c000", "doc_id": "NIST.FIPS.203", "end_page": 5, "mode": "hybrid", "rank": 5, "score": 0.015384615384615385, "start_page": 5, "text": "6. Applicability. Federal Information Processing Standards apply to information systems used or operated by federal agencies or by a contractor of an agency or other organization on behalf of an agency. They do not apply to national security systems as defined in 44 U.S.C. 3552. This standard, or other FIPS or NIST Special Publications that specify alternative mechanisms, shall be used wherever the establishment of a shared secret key (or shared secret from which keying material can be generated) is required for federal applications, including the use of such a key with symmetric-key cryptographic algorithms, in accordance with applicable Office of Management and Budget and agency policies. The adoption and use of this standard are available to private and commercial organizations. 7. Implementations. A key-encapsulation mechanism may be implemented in software, firmware, hardware, or any combination thereof. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, different procedures that produce the correct output for every input are permitted. NIST will develop a validation program to test implementations for conformance to the algorithms in this standard. Information about validation programs is available at https: //csrc.nist.gov/projects/cmvp. Example values will be available at https://csrc.nist.gov/proj ects/cryptographic-standards-and-guidelines/example-values. 8. Other Approved Security Functions. Implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government-sensitive information. Approved cryptographic algorithms and techniques include those that are either: (a) Specified in a Federal Information Processing Standards (FIPS) publication, (b) Adopted in a FIPS or NIST recommendation, or (c) Specified in the list of approved security functions in SP 800-140C. 9. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with all federal laws and regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 10. Patents. NIST has entered into two patent license agreements to facilitate the adoption of NIST’s announced selection of the PQC key-encapsulation mechanism CRYSTALS-KYBER. NIST and the licensing parties share a desire, in the public interest, the licensed patents be freely available to be practiced by any implementer of the ML-KEM algorithm as published by NIST. ML-KEM is the name given to the algorithm in this standard derived from CRYSTALS-KYBER. For a summary and extracts from the license, please see https://csrc.nist.gov/csrc/media/P rojects/post-quantum-cryptography/documents/selected-algos-2022/nist-pqc-license-sum mary-and-excerpts.pdf. Implementation of the algorithm specified in the standard may be covered by U.S. and foreign patents of which NIST is not aware."}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 6, "score": 0.015151515151515152, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 7, "score": 0.014925373134328358, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}, {"chunk_id": "NIST.FIPS.205::p0006::c000", "doc_id": "NIST.FIPS.205", "end_page": 6, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 6, "text": "14. Qualifications. The security of a digital signature system depends on the secrecy of the signatory’s private keys. Signatories shall, therefore, guard against the disclosure of their private keys. While it is the intent of this standard to specify general security requirements for generating digital signatures, conformance to this standard does not ensure that a particular implementation is secure. It is the responsibility of an implementer to ensure that any module that implements a digital signature capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The re- sponsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. Since a standard of this nature must be flexible enough to adapt to advancements and innovations in science and technology, this standard will be reviewed every five years in order to assess its adequacy. 15. Waiver Procedure. The Federal Information Security Management Act (FISMA) does not allow for waivers to Federal Information Processing Standards (FIPS) that are made mandatory by the Secretary of Commerce. 16. Where to Obtain Copies of the Standard. This publication is available by accessing https: //csrc.nist.gov/publications. Other computer security publications are available at the same website. 17. How to Cite This Publication. NIST has assigned NIST FIPS 205 as the publication identifier for this FIPS, per the NIST Technical Series Publication Identifier Syntax. NIST recommends that it be cited as follows: National Institute of Standards and Technology (2024) Stateless Hash-Based Dig- ital Signature Standard. (Department of Commerce, Washington, D.C.), Fed- eral Information Processing Standards Publication (FIPS) NIST FIPS 205. https: //doi.org/10.6028/NIST.FIPS.205 18. Inquiries and Comments. Inquiries and comments about this FIPS may be submitted to fips-205-comments@nist.gov."}], "metrics": null, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0040::c000", "doc_id": "NIST.FIPS.204", "pages": "p40-p40", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0052::c000", "doc_id": "NIST.FIPS.203", "pages": "p52-p52", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 3}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0005::c000", "doc_id": "NIST.FIPS.203", "pages": "p5-p5", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 7}, {"chunk_id": "NIST.FIPS.205::p0006::c000", "doc_id": "NIST.FIPS.205", "pages": "p6-p6", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 10, "start_page": 10}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}, {"doc_id": "NIST.FIPS.204", "end_page": 11, "start_page": 11}], "qid": "q014", "question": "What underlying mathematical hardness assumptions form the security basis for ML-KEM, ML-DSA, and SLH-DSA?", "retrieval": {"doc_hit_ranks": [1, 3, 4, 6, 7], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.FIPS.204::p0025::c001", "doc_id": "NIST.FIPS.204", "end_page": 25, "mode": "hybrid", "rank": 1, "score": 0.04086721054344931, "start_page": 25, "text": "γ γ1 - coefficient range of y [see §6.2] 217 219 219\n 2 - low-order rounding range [see §6.2] (q − 1)/88 (q − 1)/32 (q − 1)/32\n (k, l) - dimensions of A [see §6.1] (4,4) (6,5) (8,7)\n η - private key range [see §6.1] 2 4 2\n β = τ ⋅ η [see §6.2] 78 196 120\n ω - max # of 1’s in the hint h [see §6.2] 80 55 75\n Challenge entropy log (256) + τ [see §6.2] 192 225 257\nRepetitions (see 2 τ explanation below) 4.25 5.1 3.85\nClaimed security strength Category 2 Category 3 Category 5\n\nThree ML-DSA parameter sets are included in Table 1. Each parameter set assigns values for all of the parameters used in the ML-DSA algorithms for key generation, signing, and verification. For informational purposes, some parameters used in the analysis of these algorithms are also included in the table. In particular, “repetitions” refers to the expected number of repetitions of the main loop in the signing\nalgorithm from eq. 5 in [5]. The names of the parameter sets are of the form “ML-DSA-kl,” where (k, l)\nare the dimensions of the matrix A.\nThese parameter sets were designed to meet certain security strength categories defined by NIST in its\noriginal Call for Proposals [26]. These security strength categories are explained further in SP 800-57, Part\n1 [9].\nUsing this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each ML-DSA parameter set is claimed to be at least as secure as a generic block cipher with a prescribed key size or a generic hash function with a prescribed output length. More precisely, it is claimed that the computational resources needed to break ML-DSA are greater than or equal to the computational resources needed to break the block cipher or hash function when these computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly\nstudied models are discussed in [27].\nConcretely, the parameter set ML-DSA-44 is claimed to be in security strength category 2, ML-DSA-65 is\nclaimed to be in category 3, and ML-DSA-87 is claimed to be in category 5 [6]. For additional discussion of\nthe security strength of MLWE-based cryptosystems, see [28].\nThe sizes of keys and signatures that correspond to each parameter set are given in Table 2. Certain optimizations are possible when storing ML-DSA public and private keys. If additional space is available, one can precompute and store A to speed up signing and verifying. Alternatively, if one wants to reduce"}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "end_page": 8, "mode": "hybrid", "rank": 2, "score": 0.03278688524590164, "start_page": 8, "text": "1. Introduction\n\nThe National Institute of Standards and Technology (NIST) initiated the Post-Quantum Cryptography (PQC) Standardization Process in December 2016 to select quantum-resistant public-key cryptographic algorithms for standardization in response to the substantial development and advancement of quantum computing. After three rounds of evaluation and analysis, NIST announced the selection of the first algorithms to be standardized [2]. The key encapsulation mechanism (KEM) selected for standardization was CRYSTALS-Kyber (ML-KEM [3]). The digital signatures selected were CRYSTALS-Dilithium (ML-DSA [4]), Falcon (FN-DSA), and SPHINCS+ (SLH-DSA [5]). For a detailed explanation of NIST’s choices, as well as a summary of the third round, see NIST IR 8413 [2]. In addition to those initial selections, NIST advanced four KEM candidates to the fourth round for continued evaluation: BIKE [6], Classic McEliece [7], HQC [8], and SIKE [9]. These algorithms were all based on different security assumptions than ML-KEM. NIST indicated that it would select one or two of the algorithms for standardization at the conclusion of the fourth round. The fourth round began in July 2022 and involved a thorough analysis of the theoretical and empirical evidence used to justify the security of the candidates. During this time, the submitters of SIKE acknowledged its insecurity and recommended against its further use. The submission teams of the unbroken fourth-round candidates were invited to present updates for their candidate algorithms at the Fifth NIST PQC Standardization Conference in Rockville, Maryland, on April 10-12, 2024. The submitters participated in a joint panel to discuss the candidates’ merits, and several researchers presented work that was relevant to the PQC standardization process. Throughout the fourth round, NIST received valuable feedback from the cryptographic community. Based on this feedback and internal reviews of the fourth-round candidates, NIST announced the selection of HQC in March 2025 for standardization. Table 1 shows a timeline of major events with respect to the NIST PQC Standardization Process to date."}, {"chunk_id": "NIST.FIPS.204::p0019::c001", "doc_id": "NIST.FIPS.204", "end_page": 19, "mode": "hybrid", "rank": 3, "score": 0.031746031746031744, "start_page": 19, "text": "3.1 Security Properties\nML-DSA is designed to be strongly existentially unforgeable under chosen message attack (SUF-CMA).\nThat is, it is expected that even if an adversary can get the honest party to sign arbitrary messages, the adversary cannot create any additional valid signatures based on the signer’s public key, including on messages for which the signer has already provided a signature.\nBeyond unforgeability, ML-DSA is designed to satisfy additional security properties described in [14].\n\n3.2 Computational Assumptions\nSecurity for lattice-based digital signature schemes is typically related to the Learning With Errors (LWE)\nproblem and the short integer solution (SIS) problem. The LWE problem [15] is to recover a vector s ∈ Zn\ngiven a set of random “noisy” linear equations2 satisfied by . The SIS problem is to find a non-zero q\ns solution\nt ∈ Zn for a given linear system over Zq of the form At = 0 such that ‖t‖ is small. For appropriate\nq ∞ choices of parameters, these problems are intractable for the best known techniques, including Gaussian elimination.\nWhen the module Zn in LWE and SIS is replaced by a module over a ring larger than Zq (e.g., Rq), the resulting problems q\n are called Module Learning With Errors (MLWE) [4] and Module Short Integer Solution\n(MSIS). The security of ML-DSA is based on the MLWE problem over Rq and a nonstandard variant of\nMSIS called SelfTargetMSIS [16].\n\n3.3 ML-DSA Construction\nML-DSA is a Schnorr-like signature with several optimizations. The Schnorr signature scheme applies the Fiat-Shamir heuristic to an interactive protocol between a verifier who knows g (the generator of a group in\n which discrete logs are believed to be difficult) and the value y = gx and a prover who knows g and x. The\ninteractive protocol, where the prover demonstrates knowledge of x to the verifier, consists of three steps:"}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "end_page": 19, "mode": "hybrid", "rank": 4, "score": 0.031054405392392875, "start_page": 19, "text": "3. Overview of the ML-DSA Signature Scheme\n\nML-DSA is a digital signature scheme based on CRYSTALS-DILITHIUM [6]. It consists of three main algorithms:\nML-DSA.KeyGen (Algorithm 1), ML-DSA.Sign (Algorithm 2), and ML-DSA.Verify (Algorithm 3). The\nML-DSA scheme uses the Fiat-Shamir With Aborts construction [10, 11] and bears the most resemblance\nto the schemes proposed in [12, 13].\nThis document also defines a closely related but domain-separated signature scheme, HashML-DSA, which differs from ML-DSA in that it includes an additional pre-hashing step before signing. It consists of three main algorithms: ML-DSA.KeyGen (Algorithm 1), which is the same key generation algorithm used for ML-DSA; HashML-DSA.Sign (Algorithm 4); and HashML-DSA.Verify (Algorithm 5).\n\n3.1 Security Properties\nML-DSA is designed to be strongly existentially unforgeable under chosen message attack (SUF-CMA).\nThat is, it is expected that even if an adversary can get the honest party to sign arbitrary messages, the adversary cannot create any additional valid signatures based on the signer’s public key, including on messages for which the signer has already provided a signature.\nBeyond unforgeability, ML-DSA is designed to satisfy additional security properties described in [14]."}, {"chunk_id": "NIST.FIPS.205::p0047::c000", "doc_id": "NIST.FIPS.205", "end_page": 47, "mode": "hybrid", "rank": 5, "score": 0.02664576802507837, "start_page": 47, "text": "10. SLH-DSA External Functions\n\nThis section provides guidance on the key generation, signature generation, and signature verification functions that should be provided for use by applications. The functions in this section use the functions in Section 9 to implement the underlying SLH-DSA scheme.\n\n10.1 SLH-DSA Key Generation\nAlgorithm 21 generates an SLH-DSA key pair. Lines 1 through 3 generate the random values for the private and public keys, and line 7 calls slh_keygen_internal to compute PK.root and return the private and public key. PK.seed, SK.seed, and SK.prf shall be generated using an\napproved random bit generator (see [14, 15, 16]), where the instantiation of the random bit\ngenerator supports at least 8n bits of security strength.\n\nAlgorithm 21 slh_keygen() Generates an SLH-DSA key pair. Input: (none) Output: SLH-DSA key pair (SK, PK). SK.seed $ n ← 1: − B ▷ set SK.seed, SK.prf, and PK.seed to random n-byte SK.prf $ n ← 2: − B ▷ strings using an approved random bit generator PK.seed $ n ← 3: − B 4: if SK.seed = NULL or SK.prf = NULL or PK.seed = NULL then 5: return ⊥ ▷ return an error indication if random bit generation failed 6: end if 7: return slh_keygen_internal(SK.seed, SK.prf, PK.seed)"}, {"chunk_id": "NIST.FIPS.204::p0007::c001", "doc_id": "NIST.FIPS.204", "end_page": 7, "mode": "hybrid", "rank": 6, "score": 0.016129032258064516, "start_page": 7, "text": "2 Glossary of Terms, Acronyms, and Symbols 2\n 2.1 Terms and Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n 2.2 Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n 2.3 Mathematical Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n 2.4 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n 2.4.1 Rings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n 2.4.2 Vectors and Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n 2.5 NTT Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n\n3 Overview of the ML-DSA Signature Scheme 9\n 3.1 Security Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n 3.2 Computational Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n 3.3 ML-DSA Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n 3.4 Hedged and Deterministic Signing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n 3.5 Use of Digital Signatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n 3.6 Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n 3.6.1 Randomness Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n 3.6.2 Public-Key and Signature Length Checks . . . . . . . . . . . . . . . . . . . . . 12\n 3.6.3 Intermediate Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n 3.6.4 No Floating-Point Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n 3.7 Use of Symmetric Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n4 Parameter Sets 15"}, {"chunk_id": "NIST.FIPS.203::p0022::c001", "doc_id": "NIST.FIPS.203", "end_page": 22, "mode": "hybrid", "rank": 7, "score": 0.015625, "start_page": 22, "text": "3.2 The ML-KEM Scheme\nML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was\ninitially described in [8]. The following is a brief and informal description of the computational\nassumption underlying ML-KEM and how the ML-KEM scheme is constructed.\n\nThe computational assumption. The security of ML-KEM is based on the presumed hardness of the so-called Module Learning with Errors (MLWE) problem [9], which is a generalization of the Learning With Errors (LWE) problem introduced by Regev in 2005 [10]. The hardness of the MLWE problem is itself based on the presumed hardness of certain computational problems in module lattices [9]. This motivates the name of the scheme ML-KEM. In the LWE problem, the input is a set of random “noisy” linear equations in some secret variables x ∈ Zn, and the task is to recover x. The noise in the equations is such that standard algorithms q (e.g., Gaussian elimination) are intractable. The LWE problem naturally lends itself to cryptographic applications. For example, if x is interpreted as a secret key, then one can encrypt a one-bit plaintext value by sampling either an approximately correct linear equation (if the plaintext is zero) or a far-from-correct linear equation (if the plaintext is one). Plausibly, only a party in possession of x can distinguish these two cases. Encryption can then be delegated to another party by publishing a large collection of noisy linear equations, which can be combined appropriately by the encrypting party. The result is an asymmetric encryption scheme. The MLWE problem is similar to the LWE problem. An important difference is that, in MLWE, Zn q is replaced by a certain module Rk, which is constructed by taking the k-fold Cartesian product of a certain polynomial ring Rq . Inqparticular, the secret in the MLWE problem is an element x of the module Rk. The ring R is discussed in detail in Section 4.3. q q"}, {"chunk_id": "NIST.IR.8545::p0017::c001", "doc_id": "NIST.IR.8545", "end_page": 17, "mode": "hybrid", "rank": 8, "score": 0.015384615384615385, "start_page": 17, "text": "3.1. HQC\nHQC (Hamming Quasi-Cyclic) is a KEM based on quasi-cyclic codes, where no trapdoor is\nhidden in the code [27]. It was designed to leverage the structural advantages of quasicyclic codes while maintaining a more direct security reduction to the problem of decoding a random linear code. Unlike the other code-based candidates, the only coding-theory\nhardness assumptions required by HQC’s security proof are parameterizations of the decisional Quasi-Cyclic Syndrome Decoding (QCSD) assumption. BIKE additionally assumes\nthe hardness of Quasi-Cyclic Codeword Finding (QCCF), and Classic McEliece requires assumptions concerning binary Goppa codes [27, 28].\n\nDesign. HQC is similar in structure to Learning with Errors (LWE)-based cryptosystems, like\nRegev [29], LPR (Lyubashevsky, Peikert, Regev) [30], and ML-KEM [14]. The IND-CPA-secure\npublic-key encryption (PKE) can be described as follows.\nLet R = F2[x]/(xn − 1) for n prime such that xn − 1 has only two irreducible factors modulo\n2. The secret key is a randomly sampled pair (x, y) ∈ R2, and the public key is the pair\n(h, s = x + h · y), where h is randomly sampled from R. Because the secret key is generated\nindependently of the underlying quasi-cyclic code, there is no hidden structure in the HQC public parity-check matrix. This enables the security reduction to be independent of the\ndecoding algorithm used for decryption [27]. In addition to h, the public key includes a\npublic generator matrix G ∈ Fk×n for a concatenated Reed-Muller Reed-Solomon (RMRS)\ncode. The structure of this 2 code is assumed to be visible to all parties.\nTo encrypt a message m ∈ Fk, the sender randomly samples three polynomials e, r1, r2 ∈ R\nof appropriate low weights 2 and responds with the ciphertext\n\nc = (u, v) := (r1 + h · r2, mG + s · r2 + e). (1)\n\nTo decrypt, the receiver uses the decoding algorithm for an RMRS code to decode (v − u · y)."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.FIPS.204::p0025::c001", "doc_id": "NIST.FIPS.204", "pages": "p25-p25", "rank": 1}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "pages": "p8-p8", "rank": 2}, {"chunk_id": "NIST.FIPS.204::p0019::c001", "doc_id": "NIST.FIPS.204", "pages": "p19-p19", "rank": 3}, {"chunk_id": "NIST.FIPS.204::p0019::c000", "doc_id": "NIST.FIPS.204", "pages": "p19-p19", "rank": 4}, {"chunk_id": "NIST.FIPS.205::p0047::c000", "doc_id": "NIST.FIPS.205", "pages": "p47-p47", "rank": 5}, {"chunk_id": "NIST.FIPS.204::p0007::c001", "doc_id": "NIST.FIPS.204", "pages": "p7-p7", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0022::c001", "doc_id": "NIST.FIPS.203", "pages": "p22-p22", "rank": 7}, {"chunk_id": "NIST.IR.8545::p0017::c001", "doc_id": "NIST.IR.8545", "pages": "p17-p17", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 48, "start_page": 48}], "qid": "q015", "question": "What are the exact sizes in bytes for the encapsulation key and ciphertext when using the ML-KEM-768 parameter set?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7], "gold_hit_ranks": [1], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.203::p0048::c001", "doc_id": "NIST.FIPS.203", "end_page": 48, "mode": "hybrid", "rank": 1, "score": 0.06530936012691697, "start_page": 48, "text": "Table 2. Approved parameter sets for ML-KEM\n\nn q k η1 η2 du dv required RBG strength (bits) ML-KEM-512 256 3329 2 3 2 10 4 128 ML-KEM-768 256 3329 3 2 2 10 4 192 ML-KEM-1024 256 3329 4 2 2 11 5 256\n\nTable 3. Sizes (in bytes) of keys and ciphertexts of ML-KEM\n\nencapsulation key decapsulation key ciphertext shared secret key ML-KEM-512 800 1632 768 32 ML-KEM-768 1184 2400 1088 32 ML-KEM-1024 1568 3168 1568 32\n\nA parameter set name can also be said to denote a (parameter-free) KEM. Specifically, ML-KEM-x can be used to denote the parameter-free KEM that results from instantiating the scheme ML-KEM with the parameter set ML-KEM-x.\nThe three parameter sets included in Table 2 were designed to meet certain security strength\ncategories defined by NIST in its original Call for Proposals [4, 22]. These security strength\ncategories are explained further in SP 800-57, Part 1 [7].\nUsing this approach, security strength is not described by a single number, such as “128 bits of security.” Instead, each ML-KEM parameter set is claimed to be at least as secure as a generic"}, {"chunk_id": "NIST.FIPS.203::p0049::c001", "doc_id": "NIST.FIPS.203", "end_page": 49, "mode": "hybrid", "rank": 2, "score": 0.06088206778744369, "start_page": 49, "text": "block cipher with a prescribed key size or a generic hash function with a prescribed output length. More precisely, it is claimed that the computational resources needed to break ML-KEM are greater than or equal to the computational resources needed to break the block cipher or hash function when those computational resources are estimated using any realistic model of computation. Different models of computation can be more or less realistic and, accordingly, lead to more or less accurate estimates of security strength. Some commonly studied models\nare discussed in [23].\nConcretely, ML-KEM-512 is claimed to be in security category 1, ML-KEM-768 is claimed to be in security category 3, and ML-KEM-1024 is claimed to be in security category 5. For additional\ndiscussion of the security strength of MLWE-based cryptosystems, see [4].\n\nSelecting an appropriate parameter set. When initially establishing cryptographic protections for data, the strongest possible parameter set should be used. This has a number of advantages, including reducing the likelihood of costly transitions to higher-security parameter sets in the future. At the same time, it should be noted that some parameter sets might have adverse performance effects for the relevant application (e.g., the algorithm may be unacceptably slow, or objects such as keys or ciphertexts may be unacceptably large). NIST recommends using ML-KEM-768 as the default parameter set, as it provides a large security margin at a reasonable performance cost. In cases where this is impractical or even higher security is required, other parameter sets may be used."}, {"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "end_page": 23, "mode": "hybrid", "rank": 3, "score": 0.05768348446097807, "start_page": 23, "text": "Parameter sets and algorithms. Recall that a KEM consists of algorithms KeyGen, Encaps, and Decaps, along with a collection of parameter sets. In the case of ML-KEM, the three aforementioned algorithms are: 1. ML-KEM.KeyGen (Algorithm 19) 2. ML-KEM.Encaps (Algorithm 20) 3. ML-KEM.Decaps (Algorithm 21) These algorithms are described and discussed in detail in Section 7. ML-KEM comes equipped with three parameter sets: • ML-KEM-512 (security category 1) • ML-KEM-768 (security category 3) • ML-KEM-1024 (security category 5) These parameter sets are described and discussed in detail in Section 8. The security categories 1-5 are defined in SP 800-57, Part 1 [7]. Each parameter set assigns a particular numerical value to five integer variables: k, η1, η2, du, and dv. The values of these variables in each parameter set are given in Table 2 of Section 8. In addition to these five variable parameters, there are also two constants: n = 256 and q = 3329.\n\nDecapsulation failures. Provided that all inputs are well-formed and randomness generation is successful, the key establishment procedure of ML-KEM will never explicitly fail, meaning that both ML-KEM.Encaps and ML-KEM.Decaps will each output a 256-bit value. Moreover, if no corruption or interference is present, the two 256-bit values produced by ML-KEM.Encaps and ML-KEM.Decaps will be equal with overwhelming probability (i.e., K′ will equal K in the process described in Figure 1). The event that K′ ≠ K under these conditions is called a decapsulation"}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 4, "score": 0.046649531024531024, "start_page": 44, "text": "7. The ML-KEM Key-Encapsulation Mechanism\n\nThis section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs."}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "end_page": 44, "mode": "hybrid", "rank": 5, "score": 0.04583053878828527, "start_page": 44, "text": "This section describes the three main algorithms of the ML-KEM scheme:\n 1. Key generation (ML-KEM.KeyGen)\n 2. Encapsulation (ML-KEM.Encaps)\n 3. Decapsulation (ML-KEM.Decaps)\nTo instantiate ML-KEM, one must select a parameter set. Each parameter set is associated with a particular trade-off between security and performance. The three possible parameter sets are called ML-KEM-512, ML-KEM-768, and ML-KEM-1024 and are described in detail in Table 2 of Section 8. Each parameter set assigns specific numerical values to the individual parameters n, q, k, η1, η2, du, and dv. While n is always 256 and q is always 3329, the remaining parameters vary among the three parameter sets. Implementers shall ensure that the three algorithms of ML-KEM listed above are only invoked with a valid parameter set, and that this parameter set is selected appropriately for the desired application. Moreover, implementers shall ensure that the parameter set used in any particular invocation of ML-KEM.Encaps or ML-KEM.Decaps matches the parameter set associated to the provided inputs.\n\n7.1 ML-KEM Key Generation\nThe key generation algorithm ML-KEM.KeyGen for ML-KEM (Algorithm 19) accepts no input, generates randomness internally, and produces an encapsulation key and a decapsulation key.\nWhile the encapsulation key can be made public, the decapsulation key shall remain private.\nThe seed (d, z) generated in steps 1 and 2 of ML-KEM.KeyGen can be stored for later expansion using ML-KEM.KeyGen_internal (see Section 3.3). As the seed can be used to compute the decapsulation key, it is sensitive data and shall be treated with the same safeguards as a\ndecapsulation key (see SP 800-227 [1]).\n\nAlgorithm 19 ML-KEM.KeyGen() Generates an encapsulation key and a corresponding decapsulation key. Output: encapsulation key ek ∈ B384k+32 . Output: decapsulation key dk ∈ B768k+96 . d $ B32 ▷ d is 32 random bytes (see Section 3.3) ← 1: − z $ B32 ▷ z is 32 random bytes (see Section 3.3) ← 2: − 3: if d == NULL or z == NULL then 4: return ⊥ ▷ return an error indication if random bit generation failed 5: end if 6: (ek, dk) ← ML-KEM.KeyGen_internal(d, z) ▷ run internal key generation algorithm 7: return (ek, dk)"}, {"chunk_id": "NIST.FIPS.203::p0024::c001", "doc_id": "NIST.FIPS.203", "end_page": 24, "mode": "hybrid", "rank": 6, "score": 0.042671259089169536, "start_page": 24, "text": "Parameter set Decapsulation failure rate ML-KEM-512 2−138.8 ML-KEM-768 2−164.8 ML-KEM-1024 2−174.8\n\nTerminology for keys. A KEM involves three different types of keys: encapsulation keys, decapsulation keys, and shared secret keys. ML-KEM is built on top of the component public-key encryption scheme K-PKE, which has two additional key types: encryption keys and decryption keys. In the literature, encapsulation keys and encryption keys are sometimes referred to as “public keys,” while decapsulation keys and decryption keys are sometimes referred to as “pri- vate keys.” In order to reduce confusion, this standard will not use the terms “public key” or “private key.” Instead, keys will be referred to only using the more specific terms, i.e., one of “encapsulation key”, “decapsulation key”, “encryption key”, “decryption key”, and “shared secret key”.\n\n3.3 Requirements for ML-KEM Implementations This section describes several requirements for cryptographic modules that implement ML-KEM. Implementation requirements specific to particular algorithms will be described in later sections. Additional requirements, including requirements for using ML-KEM in specific applications, are given in SP 800-227 [1]. While conforming implementations must adhere to all of these requirements, adherence does not guarantee that the result will be secure (see Point 13 in the announcement)."}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 7, "score": 0.030536130536130537, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 8, "score": 0.02919863597612958, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0048::c001", "doc_id": "NIST.FIPS.203", "pages": "p48-p48", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0049::c001", "doc_id": "NIST.FIPS.203", "pages": "p49-p49", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0023::c002", "doc_id": "NIST.FIPS.203", "pages": "p23-p23", "rank": 3}, {"chunk_id": "NIST.FIPS.203::p0044::c000", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0044::c001", "doc_id": "NIST.FIPS.203", "pages": "p44-p44", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0024::c001", "doc_id": "NIST.FIPS.203", "pages": "p24-p24", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.IR.8547.ipd", "end_page": 20, "start_page": 20}], "qid": "q016", "question": "According to NIST transition guidelines, when will the use of legacy ECDSA and RSA digital signatures with a 112-bit security strength be officially disallowed?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [1], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0020::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 20, "mode": "hybrid", "rank": 1, "score": 0.04918032786885246, "start_page": 20, "text": "485 4.1.1. Digital Signatures 486 Table 2 lists currently approved quantum-vulnerable digital signature algorithm standards. 488 Table 2: Quantum-vulnerable digital signature algorithms\n\nDigital Signature Parameters Transition Algorithm Family\n\nECDSA 112 bits of security strength Deprecated after 2030\n [FIPS186] Disallowed after 2035\n ≥ 128 bits of security strength Disallowed after 2035\n EdDSA ≥ 128 bits of security strength Disallowed after 2035\n [FIPS186]\n\nRSA 112 bits of security strength Deprecated after 2030\n [FIPS186] Disallowed after 2035\n ≥ 128 bits of security strength Disallowed after 2035\n\n491 NIST’s long-term cryptographic algorithm transition plans are outlined in SP 800-57pt1 (Part 1) 492 [SP80057]. These guidelines had projected that NIST would disallow public-key schemes that 493 provide 112 bits of security on January 1, 2031. However, based on the need to migrate to 494 quantum-resistant algorithms during this timeframe, NIST intends to instead deprecate classical 495 digital signatures at the 112-bit security level. Organizations may continue using these 496 algorithms and parameter sets as they migrate to the post-quantum signatures identified in 497 Table 3.\n\n499 Table 3. Post-quantum digital signature algorithms\n\nDigital Signature Parameter Sets Security Security Algorithm Family Strength Category ML-DSA ML-DSA-44 128 bits 2 [FIPS204] ML-DSA-65 192 bits 3"}, {"chunk_id": "NIST.IR.8547.ipd::p0022::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 22, "mode": "hybrid", "rank": 2, "score": 0.04738666351569577, "start_page": 22, "text": "505 Similar to the transition for digital signature algorithms, NIST intends to instead deprecate 506 rather than fully disallow classical key-establishment schemes at the 112-bit security level. 507 Organizations may continue using these algorithms and parameter sets as they migrate to ML- 508 KEM or other approved quantum-resistant techniques. However, in order to mitigate the risk of 509 “harvest now, decrypt later” attacks on network communications, application-specific 510 guidance, as described in Sec. 4.2, may require or recommend migration to quantum-resistant 511 key establishment schemes before the classical schemes are generally disallowed. 512 Table 5 lists current quantum-resistant key establishment schemes. At this time, ML-KEM is the 513 only approved post-quantum key-establishment scheme based on public key cryptography. 514 Additional algorithms are still being considered as part of the fourth round of the NIST PQC 515 Standardization process. NIST expects to select one or more alternatives to ML-KEM in the 516 future. 517 Table 5: Post-quantum key-establishment schemes\n\nKey Establishment Scheme Parameter Sets Security Strength Security Category ML-KEM ML-KEM-512 128 bits 1\n [FIPS203] ML-DSA-768 192 bits 3\n\nML-DSA-1024 256 bits 5"}, {"chunk_id": "NIST.IR.8547.ipd::p0019::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 19, "mode": "hybrid", "rank": 3, "score": 0.04715356328259554, "start_page": 19, "text": "455 The terms “acceptable,” “deprecated, “disallowed,” and “legacy use” are used throughout SP 456 800-131A to indicate the approval status of an algorithm: 457 • Acceptable means that the algorithm and key length/ strength in a FIPS or SP are 458 approved for use in accordance with any associated guidance. 459 • Deprecated means that the algorithm and key length/strength may be used, but there is 460 some security risk. The data owner must examine this risk potential and decide whether 461 to continue to use a deprecated algorithm or key length. 462 • Disallowed means that the algorithm, key length/strength, parameter set, or scheme is 463 no longer allowed for the stated purpose. 464 • Legacy use means that the algorithm, scheme, or parameter set may only be used to 465 process already protected information (e.g., to decrypt ciphertext data or to verify a 466 digital signature). 468 Transition schedules are primarily driven by the level of cryptographic protection that a given 469 algorithm and associated parameter set can provide, which is described as a rough measure 470 known as security strength. Historically, the security strength that an algorithm could provide 471 was defined in terms of the amount of work (i.e., the number of operations) that is required to 472 break the algorithm (i.e., an algorithm has s bits of security strength if breaking the algorithm 473 requires 2s operations of some kind, where s = 112, 128, 192, or 256). However, there are 474 significant uncertainties in estimating the security strengths of post-quantum cryptosystems 475 given the difficulty of accurately predicting the performance characteristics of future quantum 476 computers, such as their cost, speed, and memory size. 477 While NIST guidelines continue to use bit-length security strengths to describe the level of 478 protection offered by an algorithm and parameter set against attacks by classical computers, 479 post-quantum security is described using a collection of broad security categories. Each 480 category is defined by a comparatively easy-to-analyze reference primitive, whose security 481 serves as a floor for a wide variety of metrics that are deemed potentially relevant to practical 482 security. NIST based its classification on the range of security strengths offered by the existing 483 standards in symmetric cryptography. Table 1 provides a summary of these security categories. 484 Table 1: Post-Quantum Security Categories Security Attack Type Example Category 1 Key search on a block cipher with a 128-bit key AES-128 2 Collision search on a 256-bit hash function SHA-256 3 Key search on a block cipher with a 192-bit key AES-192 4 Collision search on a 384-bit hash function SHA3-384 5 Key search on a block cipher with a 256-bit key AES-256"}, {"chunk_id": "NIST.IR.8547.ipd::p0022::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 22, "mode": "hybrid", "rank": 4, "score": 0.04457454507857733, "start_page": 22, "text": "ML-DSA-1024 256 bits 5\n\n519 4.1.3. Symmetric Cryptography 520 NIST’s existing standards in symmetric cryptography — including hash functions, XOFs, block 521 ciphers, KDFs, and DRBGs — are significantly less vulnerable to known quantum attacks than 522 the public-key cryptography standards in SP 800-56A, SP 800-56B, and FIPS 186. In particular, all 523 NIST-approved symmetric primitives that provide at least 128 bits of classical security are 524 believed to meet the requirements of at least Category 1 security within the system of five 525 security strength categories for evaluating parameter sets in the NIST PQC standardization 526 process (see Table 1). NIST has a few symmetric cryptography standards at the 112-bit security 527 level, which will be disallowed in 2030. Applications should move away from these when 528 transitioning to post-quantum cryptography. 529 Table 6: Block ciphers\n\nBlock Cipher Parameter Sets Security Security Strength Category\n\nAES AES-128 128 bits 1\n [FIPS197] AES-192 192 bits 3\n\nAES-256 256 bits 5"}, {"chunk_id": "NIST.IR.8547.ipd::p0021::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 21, "mode": "hybrid", "rank": 5, "score": 0.03149801587301587, "start_page": 21, "text": "Digital Signature Parameter Sets Security Security\nAlgorithm Family Strength Category\n SLH-DSA SLH-DSA-SHA2-128[s/f] 128 bits 1\n [FIPS205] SLH-DSA-SHAKE-128[s/f]\n SLH-DSA-SHA2-192[s/f] 192 bits 3\n SLH-DSA-SHAKE-192[s/f]\n SLH-DSA-SHA2-256[s/f] 256 bits 5\n SLH-DSA-SHAKE-256[s/f]\nLMS, HSS With SHA-256/192 192 bits 3\n [SP800208] With SHAKE256/192\nWith SHA-256 256 bits 5\nWith SHAKE256\nXMSS, XMSSMT With SHA-256/192 192 bits 3\n [SP800208] With SHAKE256/192\nWith SHA-256 256 bits 5\nWith SHAKE256\n\n501 4.1.2. Key Establishment 502 Table 4 lists currently approved quantum-vulnerable key-establishment. 503 Table 4: Quantum-vulnerable key-establishment schemes\n\nKey Establishment Parameters Transition Scheme\n\nFinite Field 112 bits of security strength Deprecated after 2030 DH and MQV Disallowed after 2035\n [SP80056A] ≥ 128 bits of security strength Disallowed after 2035\n\nElliptic Curve 112 bits of security strength Deprecated after 2030 DH and MQC Disallowed after 2035\n [SP80056A] ≥ 128 bits of security strength Disallowed after 2035\n\nRSA 112 bits of security strength Deprecated after 2030\n [SP80056B] Disallowed after 2035\n ≥ 128 bits of security strength Disallowed after 2035"}, {"chunk_id": "NIST.IR.8547.ipd::p0010::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 10, "mode": "hybrid", "rank": 6, "score": 0.03055037313432836, "start_page": 10, "text": "137 2.1. Cryptographic Standards 138 Federal Information Processing Standards (FIPS) and the NIST Special Publication (SP) 800-series 139 specify a broad set of cryptographic primitives, algorithms, and schemes, including many public- 140 key cryptosystems that will be deprecated and ultimately disallowed as part of the transition to 141 post-quantum cryptography. This section identifies quantum-vulnerable algorithms in NIST’s 142 existing cryptographic standards as well as the post-quantum algorithm standards that have 143 been recently published. Section 4.1 provides the transition plan for the quantum-vulnerable 144 algorithms in these standards.\n\n145 2.1.1. Digital Signature Algorithms 146 Digital signature algorithms are used to provide identity authentication, integrity 147 authentication, source authentication, and support for non-repudiation. Digital signature 148 algorithms are used in conjunction with hash functions or eXtendable-Output Functions (XOFs) 149 to sign messages of arbitrary length. 150 NIST-approved digital signature algorithms were historically specified in FIPS 186 [FIPS186]. The 151 current revision of FIPS 186 specifies the Elliptic Curve Digital Signature Algorithm (ECDSA) and 152 adopts the RSA algorithm specified in RFC 8017 and PKCS 1 (version 1.5 and higher) and the 153 Edwards-Curve Digital Signature Algorithm (EdDSA) specified in RFC 8032. The related SP 800- 154 186 [SP800186] specifies the elliptic curves to be used with ECDSA and the elliptic curve 155 cryptography (ECC) based key establishment schemes in SP 800-56A [SP80056A]. These 156 algorithms are vulnerable to Shor’s Algorithm on a cryptographically relevant quantum 157 computer. 158 FIPS 204 and 205 each specify quantum-resistant digital signature schemes. FIPS 204 specifies 159 the Module-Lattice-Based Digital Signature Algorithm (ML-DSA) [FIPS204], which is derived 160 from the CRYSTALS-Dilithium submission. FIPS 205 specifies the Stateless Hash-Based Digital 161 Signature Algorithm (SLH-DSA), which is derived from the SPHINCS+ submission [FIPS205]. 162 SP 800-208, Recommendation for Stateful Hash-Based Signature Schemes, specifies two stateful 163 hash-based signature (HBS) schemes — the Leighton-Micali Signature (LMS) system and the 164 eXtended Merkle Signature Scheme (XMSS) — along with their multi-tree variants, the 165 Hierarchical Signature System (HSS) and multi-tree XMSS (XMSSMT) [SP800208]. These schemes 166 are also resistant to attacks by quantum computers. In stateful hash-based signature (HBS) 167 schemes, the HBS private key consists of a large set of one-time signature (OTS) private keys. 168 The security of these schemes relies on the signer to ensure that no individual OTS key is ever 169 used to sign more than one message. Due to this need to maintain state, HBS schemes are not 170 intended for general use. 171 In the future, NIST intends to develop a FIPS that specifies a digital signature algorithm derived 172 from FALCON as an additional alternative to these standards. In addition, NIST is evaluating 173 other proposed digital signature algorithms for possible standardization through the Additional"}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 7, "score": 0.02664576802507837, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures."}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 16, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 16, "text": "353 Such hybrid solutions are often utilized as a hedge against a cryptographic or implementation 354 flaw in one of the underlying component algorithms. It may also provide a path for 355 accommodating the use of PQC if sector-specific requirements still require legacy quantum- 356 vulnerable algorithms. However, hybrid solutions add complexity to implementations and 357 architectures, which can increase security risks and costs during the transition to PQC. When 358 used, hybrid solutions are typically expected to be temporary measures that lead to a second 359 transition to cryptographic tools that use only PQC algorithms. 360 These trade-offs will vary based on the hybrid techniques used, the applications involved, and 361 the vendor and user communities that will develop and deploy them. Implementers and 362 standards organizations that specify cryptographic protocols and technologies need to carefully 363 consider the security, costs, and complexity of hybrid solutions in their environments. 364 Industry and standards organizations are considering a variety of techniques for hybrid 365 solutions with key-establishment schemes and digital signatures. NIST intends to accommodate 366 the use of hybrid techniques in its cryptographic standards to facilitate the transition to PQC 367 where their use is desired. 368 Whether hybrid solutions are used or not, quantum-vulnerable and quantum-resistant 369 cryptographic algorithms will be fielded and used alongside each other in many applications 370 and systems during the transition to PQC to facilitate interoperability. For example, many 371 network security protocols support the use of multiple sets of cryptographic algorithms and 372 allow two communicating parties to negotiate which algorithms to use in each session. 373 Similarly, during the transition to PQC, public key infrastructures using quantum-vulnerable 374 digital signature algorithms are expected to be deployed and used alongside those using 375 quantum-resistant algorithms. Such approaches are not considered hybrid solutions if each 376 session only uses a single cryptographic algorithm for key establishment and/or digital 377 signatures.\n\n378 3.2.1. Hybrid Key-Establishment Techniques 379 A hybrid key-establishment mode is defined here to be a key establishment scheme that is a 380 combination of two or more components that are themselves cryptographic key-establishment 381 schemes. The hybrid key-establishment scheme becomes a composite of these component 382 schemes. 383 NIST currently allows a generic composite key-establishment technique described in SP 800-56C 384 [SP80056C]. Assume that the value Z is a shared secret that was generated as specified by SP 385 800-56A or 800-56B and that a shared secret T is generated or distributed through other 386 schemes. The value Z’=Z||T may then be treated as a shared secret and any of the key 387 derivation methods given in SP 800-56C may be applied to Z’ to derive secret keying material. 388 NIST intends to update SP 800-56C so that the value Z may be generated as specified by any 389 current and future NIST key-establishment standards. This will include SP 800-56A, SP 800-56B, 390 FIPS 203, and any additional post-quantum key-establishment standards. The desired property 391 of hybrid techniques is that derived keys remain secure if at least one of the component 392 schemes is secure. Security properties can be complex, and for composite key establishment"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 3, 5], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0020::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p20-p20", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0022::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p22-p22", "rank": 2}, {"chunk_id": "NIST.IR.8547.ipd::p0019::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p19-p19", "rank": 3}, {"chunk_id": "NIST.IR.8547.ipd::p0022::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p22-p22", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0021::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p21-p21", "rank": 5}, {"chunk_id": "NIST.IR.8547.ipd::p0010::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p10-p10", "rank": 6}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 7}, {"chunk_id": "NIST.IR.8547.ipd::p0016::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p16-p16", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.IR.8545", "end_page": 16, "start_page": 16}, {"doc_id": "NIST.IR.8545", "end_page": 19, "start_page": 18}], "qid": "q017", "question": "Why did NIST choose to select HQC over BIKE for standardization as a general-purpose KEM at the end of the fourth round?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 8], "gold_hit_ranks": [2], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.IR.8545::p0010::c000", "doc_id": "NIST.IR.8545", "end_page": 10, "mode": "hybrid", "rank": 1, "score": 0.05553163211057948, "start_page": 10, "text": "1.1. Purpose and Organization of This Document This report summarizes the fourth round of the NIST PQC Standardization Process. Section 2 enumerates the candidates that were included in the fourth round. It also describes the evaluation criteria and selection process used to ultimately select HQC for standardization. Section 3 summarizes each of the fourth-round candidates, including a brief description of the algorithm and its characteristics with regard to security, performance, and implementation. This section also presents the rationale for standardizing some candidate algorithms and not others. Section 4 concludes and describes the next steps in the standardization process."}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "end_page": 16, "mode": "hybrid", "rank": 2, "score": 0.048915917503966164, "start_page": 16, "text": "In IR 8413 [2], NIST requested feedback on specific use cases for which Classic McEliece would be a good solution. Responses noted that Classic McEliece may provide better performance than BIKE or HQC for applications in which a public key can be transferred once and then used for several encapsulations (e.g., file encryption and virtual private networks [VPNs]) due to its small ciphertext size and fast encapsulation and decapsulation. There was also some interest in Classic McEliece based on the perception that it is a conservative choice. However, the interest expressed in Classic McEliece was limited, and having more standards to implement adds complexity to protocols and PQC migration. Classic McEliece is currently under consideration for standardization by the International Organization for Standardization (ISO). Concurrent standardization of Classic McEliece by NIST and ISO risks the creation of incompatible standards. After the ISO standardization process has been completed, NIST may consider developing a standard for Classic McEliece based on the ISO standard. However, Classic McEliece is no longer under consideration for standardization as part of the current NIST PQC Standardization Process. At the end of the third round, NIST indicated its intent to standardize at most one of BIKE or HQC for use as a general-purpose KEM [2]. As specified in the Call for Proposals [22], submitted KEMs were evaluated based on how well they appear to provide IND-CCA2 security, particularly for KEMs intended for general use. While NIST has confidence in the indistinguishability under chosen-plaintext attack (IND-CPA) security of BIKE and HQC, both schemes require a sufficiently low decryption failure rate (DFR) in order to be IND-CCA2- secure. There is evidence that HQC has a sufficiently low DFR and recent work indicates that with minor modifications, BIKE achieves the same [26]. However, NIST does not consider the DFR analysis for BIKE to be as mature as that for HQC. Additionally, HQC is not believed to require additional modifications to achieve the desired security properties. Given the critical need for strong IND-CCA2 security in a general-purpose KEM, HQC was selected for standardization. In summary, NIST has only selected HQC for standardization. The algorithms that were not selected are not under consideration for standardization by NIST as part of the current NIST PQC Standardization Process."}, {"chunk_id": "NIST.IR.8545::p0012::c000", "doc_id": "NIST.IR.8545", "end_page": 12, "mode": "hybrid", "rank": 3, "score": 0.0471386476426799, "start_page": 12, "text": "assumptions and aims to reduce the risk that a single cryptanalytic breakthrough will leave no viable standard for key establishment. In pursuit of that goal, NIST selected fourthround candidates whose security was based on computational assumptions that differ significantly from that of ML-KEM. Specifically, the candidates consisted of the isogeny-based KEM SIKE and the code-based KEMs BIKE, HQC, and Classic McEliece. See Table 2. NIST’s key-establishment standards are currently utilized in a wide variety of applications. The specific properties required for a key-establishment scheme to provide security in a given application can vary. However, in terms of formal security definitions, a single notion suffices for key-establishment schemes that are intended for general use: semantic security with respect to adaptive chosen ciphertext attacks (equivalently, IND-CCA2 security). ML-KEM is believed to satisfy IND-CCA2 security and is expected to serve as a general-purpose scheme in any application that calls for NIST-approved post-quantum keyestablishment. The formal security statuses of the fourth-round KEM candidates vary significantly. SIKE, the sole isogeny-based candidate, was broken and thus does not satisfy IND-CCA2 security [17]. The code-based candidates BIKE, HQC, and Classic McEliece are believed to satisfy IND-CCA2 security. However, NIST’s level of confidence in the IND-CCA2 security of these schemes is not equal. Notably, NIST has a higher level of confidence in the IND-CCA2 security of HQC than BIKE (see Sec. 3 for further details). Submitters to the fourth round were encouraged but not required to provide proofs of IND- CCA2 security (from clearly stated computational assumptions) in relevant models. NIST defined five security categories to compare the security strengths provided by the submissions. Submitters were asked to provide a classification of the security of the parameter sets of their schemes following the definitions provided in [16]. NIST also listed other desirable security properties, such as resistance to side-channel and multi-key attacks and resistance to misuse. Submissions were encouraged to note any additional desirable security properties that they provided. Finally, NIST required submission packages to summarize known cryptanalytic attacks on the scheme and complexity estimates for those attacks."}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "end_page": 8, "mode": "hybrid", "rank": 4, "score": 0.031054405392392875, "start_page": 8, "text": "1. Introduction\n\nThe National Institute of Standards and Technology (NIST) initiated the Post-Quantum Cryptography (PQC) Standardization Process in December 2016 to select quantum-resistant public-key cryptographic algorithms for standardization in response to the substantial development and advancement of quantum computing. After three rounds of evaluation and analysis, NIST announced the selection of the first algorithms to be standardized [2]. The key encapsulation mechanism (KEM) selected for standardization was CRYSTALS-Kyber (ML-KEM [3]). The digital signatures selected were CRYSTALS-Dilithium (ML-DSA [4]), Falcon (FN-DSA), and SPHINCS+ (SLH-DSA [5]). For a detailed explanation of NIST’s choices, as well as a summary of the third round, see NIST IR 8413 [2]. In addition to those initial selections, NIST advanced four KEM candidates to the fourth round for continued evaluation: BIKE [6], Classic McEliece [7], HQC [8], and SIKE [9]. These algorithms were all based on different security assumptions than ML-KEM. NIST indicated that it would select one or two of the algorithms for standardization at the conclusion of the fourth round. The fourth round began in July 2022 and involved a thorough analysis of the theoretical and empirical evidence used to justify the security of the candidates. During this time, the submitters of SIKE acknowledged its insecurity and recommended against its further use. The submission teams of the unbroken fourth-round candidates were invited to present updates for their candidate algorithms at the Fifth NIST PQC Standardization Conference in Rockville, Maryland, on April 10-12, 2024. The submitters participated in a joint panel to discuss the candidates’ merits, and several researchers presented work that was relevant to the PQC standardization process. Throughout the fourth round, NIST received valuable feedback from the cryptographic community. Based on this feedback and internal reviews of the fourth-round candidates, NIST announced the selection of HQC in March 2025 for standardization. Table 1 shows a timeline of major events with respect to the NIST PQC Standardization Process to date."}, {"chunk_id": "NIST.IR.8545::p0015::c001", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 5, "score": 0.03057889822595705, "start_page": 15, "text": "when network conditions are sufficiently bad, BIKE outperforms HQC. Packet delay seems to affect both HQC and BIKE equally. These results align with a prior expectation about the performances of BIKE and HQC based on their differences in speeds and sizes. When the size differences between HQC and BIKE do not affect the protocol execution time, the protocol runs faster with HQC. When the differences affect the protocol execution time noticeably, BIKE is more attractive than HQC. For TLS, BIKE would likely be more attractive than HQC over the web. The cited studies do not provide data for Classic McEliece, which is likely not a desirable choice for TLS 1.3 and QUIC due to its generally large encapsulation keys.\n\n2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1"}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 6, "score": 0.02736726874657909, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 7, "score": 0.026736111111111113, "start_page": 43, "text": "5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement.\n\n5.2. Examples of KEM Applications\nThis section provides a high-level overview of several example applications of KEMs.\n\n5.2.1. KEM-DEM Public-Key Encryption\nA KEM can be combined with a symmetric-key encryption scheme to yield very efficient public-key encryption. This is sometimes referred to as the KEM-DEM paradigm for\nPKE [17]. Examples include El Gamal encryption [31] and the Elliptic Curve Integrated Encryption Scheme (ECIES) standardized in ANSI X9.63 [15]."}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 8, "score": 0.015384615384615385, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.5, "ndcg_at_k": 0.38685280723454163, "recall_at_k": 0.5}, "k5": {"mrr_at_k": 0.5, "ndcg_at_k": 0.38685280723454163, "recall_at_k": 0.5}, "k8": {"mrr_at_k": 0.5, "ndcg_at_k": 0.38685280723454163, "recall_at_k": 0.5}}, "primary": {"mrr_at_k": 0.5, "ndcg_at_k": 0.38685280723454163, "recall_at_k": 0.5}, "primary_k": 8}, "near_page_hit_ranks": [2, 5, 8], "top_hit_ids": [{"chunk_id": "NIST.IR.8545::p0010::c000", "doc_id": "NIST.IR.8545", "pages": "p10-p10", "rank": 1}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "pages": "p16-p16", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0012::c000", "doc_id": "NIST.IR.8545", "pages": "p12-p12", "rank": 3}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "pages": "p8-p8", "rank": 4}, {"chunk_id": "NIST.IR.8545::p0015::c001", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0043::c001", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 7}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.SP.800-227", "end_page": 29, "start_page": 29}], "qid": "q018", "question": "Under NIST recommendations for key-encapsulation mechanisms, what specific components must be concatenated to create the MAC_Data string during key confirmation?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [1, 6], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.SP.800-227::p0029::c001", "doc_id": "NIST.SP.800-227", "end_page": 29, "mode": "hybrid", "rank": 1, "score": 0.06557377049180328, "start_page": 29, "text": "4.4.1. Creating the MAC Data During key confirmation, the KC provider creates a message with a MAC tag that is computed on MAC_Data that contains context-specific information. The MAC_Data is formatted as follows: MAC_Data = KC_Step_Label ‖ IDP ‖ IDR ‖ EphP ‖ EphR ‖ ExtraP ‖ ExtraR • KC_Step_Label is a six-byte character string that indicates that the MAC_Data is used for key confirmation, whether the MAC_Data is used for the first or second key-confirmation message, and the party serving as the KC provider, either the en- capsulator (E) or decapsulator (D). The four valid options are ”KC_1_E”, ”KC_2_E”, ”KC_1_D”, or ”KC_2_D”. As an example, ”KC_1_D” indicates that the decapsu- lator (D) is the KC provider and sends the first KC message. ”KC_2_E” could then be used by the encapsulator (E) to provide bilateral key confirmation. • IDP and IDR are the identifiers used to label the KC provider and recipient, respec- tively. • EphP and EphR are ephemeral data provided by the KC provider and recipient, re- spectively. The encapsulator’s ephemeral data is the ciphertext. The decapsulator’s ephemeral data is the encapsulation key ek if ek is ephemeral. Otherwise, the de- capsulator’s ephemeral data shall be a nonce with a bit length that is at least equal to the targeted security strength of the KEM key-establishment process (see Appendix C.2). When a nonce is used during key confirmation, it needs to be provided to the en- capsulator to construct MAC_Data for MAC tag generation or verification. • ExtraP and ExtraR are optional additional data provided by the KC provider and re- cipient, respectively. This could include additional identifiers, values computed dur- ing the key-establishment process but not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details.\n\n4.4.2. Obtaining the Key-Confirmation Key\nIn order to create and validate the MAC tag for the created MAC_Data, the parties create a dedicated key-confirmation key (KC_Key). This can be either a portion of the KEM"}, {"chunk_id": "NIST.SP.800-227::p0061::c001", "doc_id": "NIST.SP.800-227", "end_page": 61, "mode": "hybrid", "rank": 2, "score": 0.06130536130536131, "start_page": 61, "text": "Appendix C.1. Message Authentication Codes (MACs) A MAC algorithm defines a family of cryptographic functions that is parameterized by a symmetric key. It is computationally infeasible to determine the MAC of a newly formed MAC_Data output value without knowledge of the KC_Key value, even if one has seen the MACs corresponding to other MAC_Data values that were computed using that same KC_Key value. The input to a MAC algorithm includes a symmetric key KC_Key and a binary data string MAC_Data that serves as the “message.” That is, a MAC computation is represented as MAC(KC_Key, MAC_Data). In this recommendation, a MAC algorithm is used if key confirmation is performed during key establishment (see Sec. 4.4). When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (i.e., HMAC, AES-CMAC, or KMAC). HMAC is specified in SP 800-224 [35] and requires the use of an approved hash function. AES-CMAC is specified in SP 800-38B [36] for the AES block cipher algorithm specified in FIPS 197. KMAC is specified in SP 800-185 [37]. In addition, AES-GMAC (specified in [9]) is an approved MAC algorithm and may be used. When a MAC tag (MacTag) is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a KC_Key that is determined from a shared secret key. The MAC tag is sent to the other entity participating in the keyestablishment scheme in order to provide assurance that the shared secret key or derived keying material was correctly computed. MacTag computation and verification are described below.\n\nMAC Tag Computation for Key Confirmation. Key confirmation can be performed as one or more additional steps in a KEM scheme. The computation of a MAC tag is represented as follows: MacTag = TMacTagBits[MAC(KC_Key, MAC_Data)]. To compute a MacTag: 1. The agreed-upon MAC algorithm (see Table 1) is used with KC_Key to compute the MAC on MAC_Data, where KC_Key is a symmetric key, and MAC_Data represents the input “message” data. The minimum length of KC_Key is specified in Table 1. KC_Key is obtained from the the shared secret key, as specified in Sec. 4.4.2. The output of the MAC algorithm MacOut put is a bit string whose length in bits is MacOut putBits."}, {"chunk_id": "NIST.SP.800-227::p0062::c001", "doc_id": "NIST.SP.800-227", "end_page": 62, "mode": "hybrid", "rank": 3, "score": 0.059768111790170615, "start_page": 62, "text": "2. The MacOut put bits are input to the truncation function TMacTagBits, which re-\nturns the leftmost (i.e., initial) bits of MacOut put to be used as the value of MacTag. MacTagBits needs to be less than or equal to MacOut putBits long. When MacTagBits equals MacOut putBits, TMacTagBits acts as the identity function. The minimum value for MacTagBits is 64.\n\nMacTag Verification for Key Confirmation. To verify a received MacTag (i.e., received during key confirmation), a new Mac tag MacTag′ is computed using the values of KC_Key, MacTagBits, and MAC_Data generated by the recipient (as specified in Sec. 4.4.1). MacTag′ is compared with the received MacTag. If their values are equal, then it may be inferred that the same KC_Key, MacTagBits, and MAC_Data values were used in the two MacTag computations.\n\nAppendix C.2. Nonces A nonce is a time-varying value with a negligible chance of repeating. A decapsulator may be required to provide a public nonce that is used for key-confirmation purposes. This circumstance arises when the decapsulator’s public key is static. A nonce may be composed of one or more of the following components, though other components may also be appropriate:"}, {"chunk_id": "NIST.SP.800-227::p0032::c000", "doc_id": "NIST.SP.800-227", "end_page": 32, "mode": "hybrid", "rank": 4, "score": 0.059708143773113044, "start_page": 32, "text": "This example only provides unilateral key confirmation. If Bob also wanted assurance, another round of key confirmation can be performed by swapping roles. During this additional round, Alice generates new MAC_Data using KC_2_D as the label and indicating herself as the KC provider (see Sec. 4.4.1), generates a tag on new MAC_Data, and sends the new tag to Bob for verification."}, {"chunk_id": "NIST.SP.800-227::p0028::c000", "doc_id": "NIST.SP.800-227", "end_page": 28, "mode": "hybrid", "rank": 5, "score": 0.05639169266292946, "start_page": 28, "text": "an input to the KDM in place of the shared secret. A key derivation step is included in the example protocol in Sec. 5.2.3.\n\n4.4. Key Confirmation Key confirmation (KC) refers to the actions taken to provide assurance to one party (i.e., the key-confirmation recipient) that another party (i.e., the key-confirmation provider) possesses matching keying material. In the case of KEMs, this confirmation is done for keying material that was produced by encapsulation and/or decapsulation. Key confirmation should be used during KEM usage, as it may enhance the security properties of the overall key-establishment process. Confirming successful establishment of the shared secret key can also address potential errors in transmission or decapsulation. Key confirmation can also act as a proof of possession (see Sec. 4.5). While this section includes a description of an explicit process, key confirmation can be accomplished in a variety of other ways. For example, successful use of the shared secret key for authenticated encryption can act as key confirmation. Key confirmation is typically achieved by exchanging a value that can only be calculated correctly with very high probability if the key establishment was successful. Some common protocols perform key confirmation in a manner that is integrated into the steps of the protocol. For example, bilateral key confirmation is provided during a TLS handshake protocol by the generation and verification of a message authentication code (MAC) over all previous messages in the handshake using a symmetric MAC key that was established during the handshake. In some circumstances, it may be appropriate to perform key confirmation by including dedicated key-confirmation steps in a key-establishment scheme. An acceptable method for providing key confirmation during a key-establishment scheme involves the KC provider calculating a MAC tag on MAC_Data and sending the MAC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods."}, {"chunk_id": "NIST.SP.800-227::p0029::c000", "doc_id": "NIST.SP.800-227", "end_page": 29, "mode": "hybrid", "rank": 6, "score": 0.03225806451612903, "start_page": 29, "text": "will then obtain the KC key from their copy of the shared secret key produced by the KEM and use it to verify the MAC tag.\n\n4.4.1. Creating the MAC Data During key confirmation, the KC provider creates a message with a MAC tag that is computed on MAC_Data that contains context-specific information. The MAC_Data is formatted as follows: MAC_Data = KC_Step_Label ‖ IDP ‖ IDR ‖ EphP ‖ EphR ‖ ExtraP ‖ ExtraR • KC_Step_Label is a six-byte character string that indicates that the MAC_Data is used for key confirmation, whether the MAC_Data is used for the first or second key-confirmation message, and the party serving as the KC provider, either the en- capsulator (E) or decapsulator (D). The four valid options are ”KC_1_E”, ”KC_2_E”, ”KC_1_D”, or ”KC_2_D”. As an example, ”KC_1_D” indicates that the decapsu- lator (D) is the KC provider and sends the first KC message. ”KC_2_E” could then be used by the encapsulator (E) to provide bilateral key confirmation. • IDP and IDR are the identifiers used to label the KC provider and recipient, respec- tively. • EphP and EphR are ephemeral data provided by the KC provider and recipient, re- spectively. The encapsulator’s ephemeral data is the ciphertext. The decapsulator’s ephemeral data is the encapsulation key ek if ek is ephemeral. Otherwise, the de- capsulator’s ephemeral data shall be a nonce with a bit length that is at least equal to the targeted security strength of the KEM key-establishment process (see Appendix C.2). When a nonce is used during key confirmation, it needs to be provided to the en- capsulator to construct MAC_Data for MAC tag generation or verification. • ExtraP and ExtraR are optional additional data provided by the KC provider and re- cipient, respectively. This could include additional identifiers, values computed dur- ing the key-establishment process but not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details."}, {"chunk_id": "NIST.SP.800-227::p0061::c000", "doc_id": "NIST.SP.800-227", "end_page": 61, "mode": "hybrid", "rank": 7, "score": 0.030776515151515152, "start_page": 61, "text": "Appendix C. Cryptographic Components\n\nAppendix C.1. Message Authentication Codes (MACs) A MAC algorithm defines a family of cryptographic functions that is parameterized by a symmetric key. It is computationally infeasible to determine the MAC of a newly formed MAC_Data output value without knowledge of the KC_Key value, even if one has seen the MACs corresponding to other MAC_Data values that were computed using that same KC_Key value. The input to a MAC algorithm includes a symmetric key KC_Key and a binary data string MAC_Data that serves as the “message.” That is, a MAC computation is represented as MAC(KC_Key, MAC_Data). In this recommendation, a MAC algorithm is used if key confirmation is performed during key establishment (see Sec. 4.4). When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (i.e., HMAC, AES-CMAC, or KMAC). HMAC is specified in SP 800-224 [35] and requires the use of an approved hash function. AES-CMAC is specified in SP 800-38B [36] for the AES block cipher algorithm specified in FIPS 197. KMAC is specified in SP 800-185 [37]. In addition, AES-GMAC (specified in [9]) is an approved MAC algorithm and may be used. When a MAC tag (MacTag) is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a KC_Key that is determined from a shared secret key. The MAC tag is sent to the other entity participating in the keyestablishment scheme in order to provide assurance that the shared secret key or derived keying material was correctly computed. MacTag computation and verification are described below."}, {"chunk_id": "NIST.SP.800-227::p0028::c001", "doc_id": "NIST.SP.800-227", "end_page": 28, "mode": "hybrid", "rank": 8, "score": 0.03057889822595705, "start_page": 28, "text": "4.4. Key Confirmation Key confirmation (KC) refers to the actions taken to provide assurance to one party (i.e., the key-confirmation recipient) that another party (i.e., the key-confirmation provider) possesses matching keying material. In the case of KEMs, this confirmation is done for keying material that was produced by encapsulation and/or decapsulation. Key confirmation should be used during KEM usage, as it may enhance the security properties of the overall key-establishment process. Confirming successful establishment of the shared secret key can also address potential errors in transmission or decapsulation. Key confirmation can also act as a proof of possession (see Sec. 4.5). While this section includes a description of an explicit process, key confirmation can be accomplished in a variety of other ways. For example, successful use of the shared secret key for authenticated encryption can act as key confirmation. Key confirmation is typically achieved by exchanging a value that can only be calculated correctly with very high probability if the key establishment was successful. Some common protocols perform key confirmation in a manner that is integrated into the steps of the protocol. For example, bilateral key confirmation is provided during a TLS handshake protocol by the generation and verification of a message authentication code (MAC) over all previous messages in the handshake using a symmetric MAC key that was established during the handshake. In some circumstances, it may be appropriate to perform key confirmation by including dedicated key-confirmation steps in a key-establishment scheme. An acceptable method for providing key confirmation during a key-establishment scheme involves the KC provider calculating a MAC tag on MAC_Data and sending the MAC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods.\n\nKey-confirmation key. The key-confirmation steps specified in this recommendation can be incorporated into any scheme using a KEM to establish a shared secret key. To perform key confirmation, a dedicated KC key will be determined from the shared secret key produced by the KEM. The KC provider will use the KC key with an approved MAC algorithm to create a MAC tag on certain data and provide the tag to the KC recipient. The KC recipient"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 5, 6, 8], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0029::c001", "doc_id": "NIST.SP.800-227", "pages": "p29-p29", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0061::c001", "doc_id": "NIST.SP.800-227", "pages": "p61-p61", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0062::c001", "doc_id": "NIST.SP.800-227", "pages": "p62-p62", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0032::c000", "doc_id": "NIST.SP.800-227", "pages": "p32-p32", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0028::c000", "doc_id": "NIST.SP.800-227", "pages": "p28-p28", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0029::c000", "doc_id": "NIST.SP.800-227", "pages": "p29-p29", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0061::c000", "doc_id": "NIST.SP.800-227", "pages": "p61-p61", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0028::c001", "doc_id": "NIST.SP.800-227", "pages": "p28-p28", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.SP.800-227", "end_page": 11, "start_page": 11}], "qid": "q019", "question": "Which specific message authentication code (MAC) algorithms are approved for use during the key confirmation process of a KEM?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [8], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.SP.800-227::p0028::c001", "doc_id": "NIST.SP.800-227", "end_page": 28, "mode": "hybrid", "rank": 1, "score": 0.032018442622950824, "start_page": 28, "text": "4.4. Key Confirmation Key confirmation (KC) refers to the actions taken to provide assurance to one party (i.e., the key-confirmation recipient) that another party (i.e., the key-confirmation provider) possesses matching keying material. In the case of KEMs, this confirmation is done for keying material that was produced by encapsulation and/or decapsulation. Key confirmation should be used during KEM usage, as it may enhance the security properties of the overall key-establishment process. Confirming successful establishment of the shared secret key can also address potential errors in transmission or decapsulation. Key confirmation can also act as a proof of possession (see Sec. 4.5). While this section includes a description of an explicit process, key confirmation can be accomplished in a variety of other ways. For example, successful use of the shared secret key for authenticated encryption can act as key confirmation. Key confirmation is typically achieved by exchanging a value that can only be calculated correctly with very high probability if the key establishment was successful. Some common protocols perform key confirmation in a manner that is integrated into the steps of the protocol. For example, bilateral key confirmation is provided during a TLS handshake protocol by the generation and verification of a message authentication code (MAC) over all previous messages in the handshake using a symmetric MAC key that was established during the handshake. In some circumstances, it may be appropriate to perform key confirmation by including dedicated key-confirmation steps in a key-establishment scheme. An acceptable method for providing key confirmation during a key-establishment scheme involves the KC provider calculating a MAC tag on MAC_Data and sending the MAC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods.\n\nKey-confirmation key. The key-confirmation steps specified in this recommendation can be incorporated into any scheme using a KEM to establish a shared secret key. To perform key confirmation, a dedicated KC key will be determined from the shared secret key produced by the KEM. The KC provider will use the KC key with an approved MAC algorithm to create a MAC tag on certain data and provide the tag to the KC recipient. The KC recipient"}, {"chunk_id": "NIST.SP.800-227::p0061::c001", "doc_id": "NIST.SP.800-227", "end_page": 61, "mode": "hybrid", "rank": 2, "score": 0.03177805800756621, "start_page": 61, "text": "Appendix C.1. Message Authentication Codes (MACs) A MAC algorithm defines a family of cryptographic functions that is parameterized by a symmetric key. It is computationally infeasible to determine the MAC of a newly formed MAC_Data output value without knowledge of the KC_Key value, even if one has seen the MACs corresponding to other MAC_Data values that were computed using that same KC_Key value. The input to a MAC algorithm includes a symmetric key KC_Key and a binary data string MAC_Data that serves as the “message.” That is, a MAC computation is represented as MAC(KC_Key, MAC_Data). In this recommendation, a MAC algorithm is used if key confirmation is performed during key establishment (see Sec. 4.4). When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (i.e., HMAC, AES-CMAC, or KMAC). HMAC is specified in SP 800-224 [35] and requires the use of an approved hash function. AES-CMAC is specified in SP 800-38B [36] for the AES block cipher algorithm specified in FIPS 197. KMAC is specified in SP 800-185 [37]. In addition, AES-GMAC (specified in [9]) is an approved MAC algorithm and may be used. When a MAC tag (MacTag) is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a KC_Key that is determined from a shared secret key. The MAC tag is sent to the other entity participating in the keyestablishment scheme in order to provide assurance that the shared secret key or derived keying material was correctly computed. MacTag computation and verification are described below.\n\nMAC Tag Computation for Key Confirmation. Key confirmation can be performed as one or more additional steps in a KEM scheme. The computation of a MAC tag is represented as follows: MacTag = TMacTagBits[MAC(KC_Key, MAC_Data)]. To compute a MacTag: 1. The agreed-upon MAC algorithm (see Table 1) is used with KC_Key to compute the MAC on MAC_Data, where KC_Key is a symmetric key, and MAC_Data represents the input “message” data. The minimum length of KC_Key is specified in Table 1. KC_Key is obtained from the the shared secret key, as specified in Sec. 4.4.2. The output of the MAC algorithm MacOut put is a bit string whose length in bits is MacOut putBits."}, {"chunk_id": "NIST.SP.800-227::p0029::c000", "doc_id": "NIST.SP.800-227", "end_page": 29, "mode": "hybrid", "rank": 3, "score": 0.03128054740957967, "start_page": 29, "text": "will then obtain the KC key from their copy of the shared secret key produced by the KEM and use it to verify the MAC tag.\n\n4.4.1. Creating the MAC Data During key confirmation, the KC provider creates a message with a MAC tag that is computed on MAC_Data that contains context-specific information. The MAC_Data is formatted as follows: MAC_Data = KC_Step_Label ‖ IDP ‖ IDR ‖ EphP ‖ EphR ‖ ExtraP ‖ ExtraR • KC_Step_Label is a six-byte character string that indicates that the MAC_Data is used for key confirmation, whether the MAC_Data is used for the first or second key-confirmation message, and the party serving as the KC provider, either the en- capsulator (E) or decapsulator (D). The four valid options are ”KC_1_E”, ”KC_2_E”, ”KC_1_D”, or ”KC_2_D”. As an example, ”KC_1_D” indicates that the decapsu- lator (D) is the KC provider and sends the first KC message. ”KC_2_E” could then be used by the encapsulator (E) to provide bilateral key confirmation. • IDP and IDR are the identifiers used to label the KC provider and recipient, respec- tively. • EphP and EphR are ephemeral data provided by the KC provider and recipient, re- spectively. The encapsulator’s ephemeral data is the ciphertext. The decapsulator’s ephemeral data is the encapsulation key ek if ek is ephemeral. Otherwise, the de- capsulator’s ephemeral data shall be a nonce with a bit length that is at least equal to the targeted security strength of the KEM key-establishment process (see Appendix C.2). When a nonce is used during key confirmation, it needs to be provided to the en- capsulator to construct MAC_Data for MAC tag generation or verification. • ExtraP and ExtraR are optional additional data provided by the KC provider and re- cipient, respectively. This could include additional identifiers, values computed dur- ing the key-establishment process but not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details."}, {"chunk_id": "NIST.SP.800-227::p0010::c000", "doc_id": "NIST.SP.800-227", "end_page": 10, "mode": "hybrid", "rank": 4, "score": 0.028991596638655463, "start_page": 10, "text": "approved, this SP describes KEMs both generally and with respect to what is approved. Specific requirements will be clearly noted with “shall” and “must” statements.\n\n1.3. Requirements Conforming implementations of approved KEMs are required to satisfy all of the requirements below. Requirements that are testable by a Cryptographic Module Validation Program (CMVP) validation lab are enumerated with the prefix “RS,” and requirements that are not testable by a validation lab are enumerated with the prefix “RM.” Each requirement is directly quoted from the corresponding referenced section. Requirements RS6, RS7, RS8, RS10, and RS11 pertain to key confirmation (Sec. 4.4), which is recommended but not required. The following requirements are testable by a CMVP validation lab (i.e., shall statements): RS1 (Section 3.1) KEM implementations shall comply with a specific NIST FIPS or SP that specifies the algorithms of the relevant KEM. For example, a conforming implemen- tation of ML-KEM shall comply with FIPS 203 [3]. 1 RS2 (Section 3.1) KEM implementations shall follow the guidelines given in FIPS 140-3 [5] and associated implementation guidance. RS3 (Section 3.1) KEM implementations shall use approved components with security strengths that meet or exceed the required strength for each KEM parameter set. RS4 (Section 3.1) Random bits shall be generated using approved techniques, as de- scribed in the latest revisions of SP 800-90A, SP 800-90B, and SP 800-90C [6–8]. RS5 (Section 3.2) Except for random seeds and data that can be easily computed from public information, all intermediate values used in any given KEM algorithm (i.e., KeyGen, Encaps, and Decaps) shall be destroyed before the algorithm terminates. RS6 (Section 4.2) If an application uses an ephemeral key pair, the key pair shall be used for only one execution of key-establishment via a KEM and shall be destroyed as soon as possible after its use. RS7 (Section 4.4.1) When a nonce is used by the decapsulator during key confirmation (as specified herein), a nonce with a bit length that is (at least) equal to the targeted security strength of the KEM key-establishment process shall be used (see Appendix C.2). RS8 (Section 4.4.1) For key confirmation, the MAC algorithm and key-confirmation key used shall have security strengths that are equal to or greater than the desired se- curity strength of the application. 1The CMVP will perform random input-output tests in an attempt to ascertain whether this requirement is satisfied. Ensuring full functional equivalence to the specification via testing is not possible (see the “must” requirement RM1)."}, {"chunk_id": "NIST.SP.800-227::p0028::c000", "doc_id": "NIST.SP.800-227", "end_page": 28, "mode": "hybrid", "rank": 5, "score": 0.015873015873015872, "start_page": 28, "text": "an input to the KDM in place of the shared secret. A key derivation step is included in the example protocol in Sec. 5.2.3.\n\n4.4. Key Confirmation Key confirmation (KC) refers to the actions taken to provide assurance to one party (i.e., the key-confirmation recipient) that another party (i.e., the key-confirmation provider) possesses matching keying material. In the case of KEMs, this confirmation is done for keying material that was produced by encapsulation and/or decapsulation. Key confirmation should be used during KEM usage, as it may enhance the security properties of the overall key-establishment process. Confirming successful establishment of the shared secret key can also address potential errors in transmission or decapsulation. Key confirmation can also act as a proof of possession (see Sec. 4.5). While this section includes a description of an explicit process, key confirmation can be accomplished in a variety of other ways. For example, successful use of the shared secret key for authenticated encryption can act as key confirmation. Key confirmation is typically achieved by exchanging a value that can only be calculated correctly with very high probability if the key establishment was successful. Some common protocols perform key confirmation in a manner that is integrated into the steps of the protocol. For example, bilateral key confirmation is provided during a TLS handshake protocol by the generation and verification of a message authentication code (MAC) over all previous messages in the handshake using a symmetric MAC key that was established during the handshake. In some circumstances, it may be appropriate to perform key confirmation by including dedicated key-confirmation steps in a key-establishment scheme. An acceptable method for providing key confirmation during a key-establishment scheme involves the KC provider calculating a MAC tag on MAC_Data and sending the MAC tag to the KC recipient for confirmation of the provider’s correct calculation of the shared secret key. Unilateral key confirmation is provided when only one of the parties serves as the key-confirmation provider. If mutual key confirmation is desired (i.e., bilateral key confirmation), then the parties swap roles for the second KC process, and the new provider (i.e., the previous recipient) sends a MAC value on a different data string (i.e., different MAC_Data) to the new recipient (i.e., the previous provider). This recommendation makes no statement as to the adequacy of other methods."}, {"chunk_id": "NIST.SP.800-227::p0029::c001", "doc_id": "NIST.SP.800-227", "end_page": 29, "mode": "hybrid", "rank": 6, "score": 0.015625, "start_page": 29, "text": "4.4.1. Creating the MAC Data During key confirmation, the KC provider creates a message with a MAC tag that is computed on MAC_Data that contains context-specific information. The MAC_Data is formatted as follows: MAC_Data = KC_Step_Label ‖ IDP ‖ IDR ‖ EphP ‖ EphR ‖ ExtraP ‖ ExtraR • KC_Step_Label is a six-byte character string that indicates that the MAC_Data is used for key confirmation, whether the MAC_Data is used for the first or second key-confirmation message, and the party serving as the KC provider, either the en- capsulator (E) or decapsulator (D). The four valid options are ”KC_1_E”, ”KC_2_E”, ”KC_1_D”, or ”KC_2_D”. As an example, ”KC_1_D” indicates that the decapsu- lator (D) is the KC provider and sends the first KC message. ”KC_2_E” could then be used by the encapsulator (E) to provide bilateral key confirmation. • IDP and IDR are the identifiers used to label the KC provider and recipient, respec- tively. • EphP and EphR are ephemeral data provided by the KC provider and recipient, re- spectively. The encapsulator’s ephemeral data is the ciphertext. The decapsulator’s ephemeral data is the encapsulation key ek if ek is ephemeral. Otherwise, the de- capsulator’s ephemeral data shall be a nonce with a bit length that is at least equal to the targeted security strength of the KEM key-establishment process (see Appendix C.2). When a nonce is used during key confirmation, it needs to be provided to the en- capsulator to construct MAC_Data for MAC tag generation or verification. • ExtraP and ExtraR are optional additional data provided by the KC provider and re- cipient, respectively. This could include additional identifiers, values computed dur- ing the key-establishment process but not transmitted, or any other information that the party wants to include. This information can be known ahead of time by both parties or transmitted during key confirmation. The MAC algorithm and KC_Key used shall have security strengths equal to or greater than the desired security strength of the application. See Appendix C.1 for permitted MAC algorithms and further details.\n\n4.4.2. Obtaining the Key-Confirmation Key\nIn order to create and validate the MAC tag for the created MAC_Data, the parties create a dedicated key-confirmation key (KC_Key). This can be either a portion of the KEM"}, {"chunk_id": "NIST.SP.800-227::p0061::c000", "doc_id": "NIST.SP.800-227", "end_page": 61, "mode": "hybrid", "rank": 7, "score": 0.015151515151515152, "start_page": 61, "text": "Appendix C. Cryptographic Components\n\nAppendix C.1. Message Authentication Codes (MACs) A MAC algorithm defines a family of cryptographic functions that is parameterized by a symmetric key. It is computationally infeasible to determine the MAC of a newly formed MAC_Data output value without knowledge of the KC_Key value, even if one has seen the MACs corresponding to other MAC_Data values that were computed using that same KC_Key value. The input to a MAC algorithm includes a symmetric key KC_Key and a binary data string MAC_Data that serves as the “message.” That is, a MAC computation is represented as MAC(KC_Key, MAC_Data). In this recommendation, a MAC algorithm is used if key confirmation is performed during key establishment (see Sec. 4.4). When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (i.e., HMAC, AES-CMAC, or KMAC). HMAC is specified in SP 800-224 [35] and requires the use of an approved hash function. AES-CMAC is specified in SP 800-38B [36] for the AES block cipher algorithm specified in FIPS 197. KMAC is specified in SP 800-185 [37]. In addition, AES-GMAC (specified in [9]) is an approved MAC algorithm and may be used. When a MAC tag (MacTag) is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a KC_Key that is determined from a shared secret key. The MAC tag is sent to the other entity participating in the keyestablishment scheme in order to provide assurance that the shared secret key or derived keying material was correctly computed. MacTag computation and verification are described below."}, {"chunk_id": "NIST.SP.800-227::p0011::c000", "doc_id": "NIST.SP.800-227", "end_page": 11, "mode": "hybrid", "rank": 8, "score": 0.014925373134328358, "start_page": 11, "text": "RS9 (Section 4.4.2) The key-confirmation key shall only be used for key confirmation and destroyed after use. RS10 (Appendix C.1) When key confirmation requires the use of a MAC algorithm, it shall be an approved MAC algorithm (e.g., HMAC, AES-CMAC, KMAC). In addition, AES- GMAC (specified in [9]) is an approved MAC algorithm and may be used. RS11 (Appendix C.1) When a MAC tag is used for key confirmation, an entity shall compute the MAC tag on received or derived data using a MAC algorithm with a MacKey that is determined from a shared secret key. The following requirements are not testable by a CMVP validation lab (i.e., must state- ments): RM1 (Section 3.1). Implementations must correctly implement the mathematical func- tionality of the target KEM. 2 RM2 (Section 4.2) In applications of KEMs, a parameter set with an application-appropriate security strength must be selected (see [10, Section 2.2]). RM3 (Section 4.2) If an encapsulating party obtains the static encapsulation key of another party, it must have assurance of the other party’s ownership of the key before or during the execution of key-establishment. RM4 (Section 4.2) The devices used to execute KEM algorithms and store any sensitive data (e.g., decapsulation keys) must be appropriately secured. RM5 (Section 4.2) The key-establishment process that takes place over the channel used by Alice and Bob must satisfy an application-appropriate notion of integrity."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.125, "ndcg_at_k": 0.31546487678572877, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.125, "ndcg_at_k": 0.31546487678572877, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [4, 8], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0028::c001", "doc_id": "NIST.SP.800-227", "pages": "p28-p28", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0061::c001", "doc_id": "NIST.SP.800-227", "pages": "p61-p61", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0029::c000", "doc_id": "NIST.SP.800-227", "pages": "p29-p29", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0010::c000", "doc_id": "NIST.SP.800-227", "pages": "p10-p10", "rank": 4}, {"chunk_id": "NIST.SP.800-227::p0028::c000", "doc_id": "NIST.SP.800-227", "pages": "p28-p28", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0029::c001", "doc_id": "NIST.SP.800-227", "pages": "p29-p29", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0061::c000", "doc_id": "NIST.SP.800-227", "pages": "p61-p61", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0011::c000", "doc_id": "NIST.SP.800-227", "pages": "p11-p11", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.SP.800-227", "end_page": 36, "start_page": 35}], "qid": "q020", "question": "What are the required steps to construct a composite key-encapsulation mechanism (KEM) from two existing component KEMs?", "retrieval": {"doc_hit_ranks": [1, 4, 8], "gold_hit_ranks": [], "has_gold_in_primary_k": false, "hits": [{"chunk_id": "NIST.SP.800-227::p0005::c000", "doc_id": "NIST.SP.800-227", "end_page": 5, "mode": "hybrid", "rank": 1, "score": 0.0635386119257087, "start_page": 5, "text": "September 2025\n\nAbstract\n\nA key-encapsulation mechanism (KEM) is a set of algorithms that can be used by two parties under certain conditions to securely establish a shared secret key over a public channel. A shared secret key that is established using a KEM can then be used with symmetric-key cryptographic algorithms to perform essential tasks in secure communications, such as encryption and authentication. This document describes the basic definitions, properties, and applications of KEMs. It also provides recommendations for implementing and using KEMs in a secure manner.\n\nKeywords\n\ncryptography; encryption; key-encapsulation mechanism; key establishment; public-key cryptography.\n\nReports on Computer Systems Technology"}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "end_page": 3, "mode": "hybrid", "rank": 2, "score": 0.060193045797553996, "start_page": 3, "text": "Abstract A key-encapsulation mechanism (KEM) is a set of algorithms that, under certain conditions, can be used by two parties to establish a shared secret key over a public channel. A shared secret key that is securely established using a KEM can then be used with symmetric-key cryptographic algorithms to perform basic tasks in secure communications, such as encryption and authentication. This standard specifies a key-encapsulation mechanism called ML-KEM. The security of ML-KEM is related to the computational difficulty of the Module Learning with Errors problem. At present, ML-KEM is believed to be secure, even against adversaries who possess a quantum computer. This standard specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, these are ML-KEM-512, ML-KEM-768, and ML-KEM-1024.\n\nKeywords: computer security; cryptography; encryption; Federal Information Processing Standards; key-encapsulation mechanism; lattice-based cryptography; post-quantum; public-key cryptography."}, {"chunk_id": "NIST.FIPS.203::p0025::c000", "doc_id": "NIST.FIPS.203", "end_page": 25, "mode": "hybrid", "rank": 3, "score": 0.05728961707751967, "start_page": 25, "text": "Controlled access to internal functions. The key-encapsulation mechanism ML-KEM makes use of internal, “derandomized” functions ML-KEM.KeyGen_internal, ML-KEM.Encaps_internal, and ML-KEM.Decaps_internal, specified in Section 6. The interfaces for these functions should not be made available to applications other than for testing purposes. In particular, the sampling of random values required for key generation (as specified in ML-KEM.KeyGen) and encapsulation (as specified in ML-KEM.Encaps) shall be performed by the cryptographic module.\n\nEquivalent implementations. For every algorithm that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, the specified algorithm may be replaced with a different procedure that produces the correct output for every input (where “input” includes the specified input as well as all parameter values and all randomness)."}, {"chunk_id": "NIST.SP.800-227::p0007::c001", "doc_id": "NIST.SP.800-227", "end_page": 7, "mode": "hybrid", "rank": 4, "score": 0.05388999400082094, "start_page": 7, "text": "1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.1. Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.2. Scope and Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.3. Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n2. Overview of Key-Encapsulation Mechanisms . . . . . . . . . . . . . . . . . . . . . 4\n 2.1. Overview and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n 2.2. Basic Definitions and Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n 2.3. Theoretical Security of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3. Requirements for Secure KEM Implementations . . . . . . . . . . . . . . . . . . . 11\n 3.1. Compliance With NIST Standards and Validation . . . . . . . . . . . . . . . . 11\n 3.2. Managing Cryptographic Data . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n 3.3. Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4. Using KEMs Securely in Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n 4.1. How to Establish a Key With a KEM . . . . . . . . . . . . . . . . . . . . . . . 15\n 4.2. Conditions for Using KEMs Securely . . . . . . . . . . . . . . . . . . . . . . . 17\n 4.3. Post Processing of the Shared Secret Key . . . . . . . . . . . . . . . . . . . . 19\n 4.4. Key Confirmation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n 4.4.1. Creating the MAC Data . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n 4.4.2. Obtaining the Key-Confirmation Key . . . . . . . . . . . . . . . . . . 21\n 4.4.3. Key-Confirmation Example . . . . . . . . . . . . . . . . . . . . . . . . 22\n 4.5. Proof of Possession for KEM Keys . . . . . . . . . . . . . . . . . . . . . . . . 24\n 4.6. Multi-Algorithm KEMs and PQ/T Hybrids . . . . . . . . . . . . . . . . . . . . 26\n 4.6.1. Constructing a Composite KEM . . . . . . . . . . . . . . . . . . . . . 27\n 4.6.2. Approved Key Combiners . . . . . . . . . . . . . . . . . . . . . . . . 28\n 4.6.3. Security Considerations for Composite Schemes . . . . . . . . . . . 31\n5. Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1. Examples of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1.1. A KEM From Diffie-Hellman . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1.2. A KEM From RSA Secret-Value Encapsulation . . . . . . . . . . . . . 34\n 5.1.3. ML-KEM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\niii"}, {"chunk_id": "NIST.FIPS.203::p0004::c000", "doc_id": "NIST.FIPS.203", "end_page": 4, "mode": "hybrid", "rank": 5, "score": 0.05358859681148838, "start_page": 4, "text": "Announcing the Module-Lattice-Based Key-Encapsulation Mechanism Standard\n\nFederal Information Processing Standards (FIPS) publications are developed by the National Institute of Standards and Technology (NIST) under 15 U.S.C. 278g-3 and issued by the Secretary of Commerce under 40 U.S.C. 11331. 1. Name of Standard. Module-Lattice-Based Key-Encapsulation Mechanism Standard (FIPS 203). 2. Category of Standard. Computer Security. Subcategory. Cryptography. 3. Explanation. A cryptographic key (or simply “key”) is represented in a computer as a string of bits. A shared secret key is a cryptographic key that is computed jointly by two parties (e.g., Alice and Bob) using a set of algorithms. Under certain conditions, these algorithms ensure that both parties will produce the same key and that this key is secret from adversaries. Such a shared secret key can then be used with symmetric-key cryptographic algorithms (specified in other NIST standards) to perform tasks such as encryption and authentication of digital information. This standard specifies a set of algorithms for establishing a shared secret key. While there are many methods for establishing a shared secret key, the particular method described in this standard is a key-encapsulation mechanism (KEM). In a KEM, the computation of the shared secret key begins with Alice generating a decapsu- lation key and an encapsulation key. Alice keeps the decapsulation key private and makes the encapsulation key available to Bob. Bob then uses Alice’s encapsulation key to generate one copy of a shared secret key along with an associated ciphertext. Bob then sends the ciphertext to Alice. Finally, Alice uses the ciphertext from Bob along with Alice’s private decapsulation key to compute another copy of the shared secret key. The security of the particular KEM specified in this standard is related to the computational difficulty of solving certain systems of noisy linear equations, specifically the Module Learn- ing With Errors (MLWE) problem. At present, it is believed that this particular method of establishing a shared secret key is secure, even against adversaries who possess a quantum computer. In the future, additional KEMs may be specified and approved in FIPS publications or in NIST Special Publications. 4. Approving Authority. Secretary of Commerce. 5. Maintenance Agency. Department of Commerce, National Institute of Standards and Tech- nology, Information Technology Laboratory (ITL)."}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "end_page": 21, "mode": "hybrid", "rank": 6, "score": 0.04163851351351351, "start_page": 21, "text": "3. Overview of the ML-KEM Scheme\n\nThis section gives a high-level overview of the ML-KEM scheme.\n\n3.1 Key-Encapsulation Mechanisms\nThe following is a high-level overview of key-encapsulation mechanisms (KEMs). For details, see\n SP 800-227 [1].\nA KEM is a cryptographic scheme that, under certain conditions, can be used to establish a shared secret key between two communicating parties. This shared secret key can then be used for symmetric-key cryptography.\nA KEM consists of three algorithms and a collection of parameter sets. The three algorithms are:\n 1. A probabilistic key generation algorithm denoted by KeyGen\n 2. A probabilistic ”encapsulation” algorithm denoted by Encaps\n 3. A deterministic ”decapsulation” algorithm denoted by Decaps\nThe collection of parameter sets is used to select a trade-off between security and efficiency.\nEach parameter set in the collection is a list of specific (typically numerical) values, one for each parameter required by the three algorithms.\nAlice Bob\n\nKeyGen\n\ndecapsulation key encapsulation key\n\nDecaps ciphertext Encaps\n\nAlice’s copy of the Bob’s copy of the shared secret key shared secret key K′ K\n\nFigure 1. A simple view of key establishment using a KEM"}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "end_page": 10, "mode": "hybrid", "rank": 7, "score": 0.040062914599608444, "start_page": 10, "text": "1. Introduction\n\n1.1 Purpose and Scope\nThis standard specifies the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). A key-encapsulation mechanism (KEM) is a set of algorithms that can be used to establish a shared secret key between two parties communicating over a public channel. A KEM is a particular type of key establishment scheme. Other NIST-approved key establishment schemes are specified in NIST Special Publication (SP) 800-56A, Recommendation for Pair-Wise Key-Establishment\nSchemes Using Discrete Logarithm-Based Cryptography [2], and SP 800-56B, Recommendation\nfor Pair-Wise Key Establishment Schemes Using Integer Factorization Cryptography [3].\nThe key establishment schemes specified in SP 800-56A and SP 800-56B are vulnerable to attacks that use sufficiently-capable quantum computers. ML-KEM is an approved alternative that is presently believed to be secure, even against adversaries in possession of a large-scale fault-tolerant quantum computer. ML-KEM is derived from the round-three version of the\nCRYSTALS-KYBER KEM [4], a submission in the NIST Post-Quantum Cryptography Standardization\nproject. For the differences between ML-KEM and CRYSTALS-KYBER, see Appendix C.\nThis standard specifies the algorithms and parameter sets of the ML-KEM scheme. It aims to provide sufficient information to implement ML-KEM in a manner that can pass validation (see https://csrc.nist.gov/projects/cryptographic- module- validation- program). For general definitions and properties of KEMs, including requirements for the secure use of KEMs\nin applications, see SP 800-227 [1].\nThis standard specifies three parameter sets for ML-KEM that offer different trade-offs in security strength versus performance. All three parameter sets of ML-KEM are approved to protect sensitive, non-classified communication systems of the U.S. Federal Government."}, {"chunk_id": "NIST.SP.800-227::p0007::c000", "doc_id": "NIST.SP.800-227", "end_page": 7, "mode": "hybrid", "rank": 8, "score": 0.026687875574407917, "start_page": 7, "text": "Table of Contents\n\n1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.1. Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.2. Scope and Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n 1.3. Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n2. Overview of Key-Encapsulation Mechanisms . . . . . . . . . . . . . . . . . . . . . 4\n 2.1. Overview and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n 2.2. Basic Definitions and Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n 2.3. Theoretical Security of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3. Requirements for Secure KEM Implementations . . . . . . . . . . . . . . . . . . . 11\n 3.1. Compliance With NIST Standards and Validation . . . . . . . . . . . . . . . . 11\n 3.2. Managing Cryptographic Data . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n 3.3. Additional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4. Using KEMs Securely in Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n 4.1. How to Establish a Key With a KEM . . . . . . . . . . . . . . . . . . . . . . . 15\n 4.2. Conditions for Using KEMs Securely . . . . . . . . . . . . . . . . . . . . . . . 17\n 4.3. Post Processing of the Shared Secret Key . . . . . . . . . . . . . . . . . . . . 19\n 4.4. Key Confirmation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n 4.4.1. Creating the MAC Data . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n 4.4.2. Obtaining the Key-Confirmation Key . . . . . . . . . . . . . . . . . . 21\n 4.4.3. Key-Confirmation Example . . . . . . . . . . . . . . . . . . . . . . . . 22\n 4.5. Proof of Possession for KEM Keys . . . . . . . . . . . . . . . . . . . . . . . . 24\n 4.6. Multi-Algorithm KEMs and PQ/T Hybrids . . . . . . . . . . . . . . . . . . . . 26\n 4.6.1. Constructing a Composite KEM . . . . . . . . . . . . . . . . . . . . . 27\n 4.6.2. Approved Key Combiners . . . . . . . . . . . . . . . . . . . . . . . . 28\n 4.6.3. Security Considerations for Composite Schemes . . . . . . . . . . . 31\n5. Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1. Examples of KEMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1.1. A KEM From Diffie-Hellman . . . . . . . . . . . . . . . . . . . . . . . 33\n 5.1.2. A KEM From RSA Secret-Value Encapsulation . . . . . . . . . . . . . 34\n 5.1.3. ML-KEM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}}, "primary": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "primary_k": 8}, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0005::c000", "doc_id": "NIST.SP.800-227", "pages": "p5-p5", "rank": 1}, {"chunk_id": "NIST.FIPS.203::p0003::c000", "doc_id": "NIST.FIPS.203", "pages": "p3-p3", "rank": 2}, {"chunk_id": "NIST.FIPS.203::p0025::c000", "doc_id": "NIST.FIPS.203", "pages": "p25-p25", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0007::c001", "doc_id": "NIST.SP.800-227", "pages": "p7-p7", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0004::c000", "doc_id": "NIST.FIPS.203", "pages": "p4-p4", "rank": 5}, {"chunk_id": "NIST.FIPS.203::p0021::c000", "doc_id": "NIST.FIPS.203", "pages": "p21-p21", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0010::c000", "doc_id": "NIST.FIPS.203", "pages": "p10-p10", "rank": 7}, {"chunk_id": "NIST.SP.800-227::p0007::c000", "doc_id": "NIST.SP.800-227", "pages": "p7-p7", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.IR.8545", "end_page": 16, "start_page": 16}, {"doc_id": "NIST.IR.8545", "end_page": 23, "start_page": 23}], "qid": "q021", "question": "Why did NIST decide not to select Classic McEliece for standardization during the fourth round, despite maintaining confidence in its security?", "retrieval": {"doc_hit_ranks": [1, 2, 3, 4, 5, 6, 7, 8], "gold_hit_ranks": [1, 2], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.IR.8545::p0023::c000", "doc_id": "NIST.IR.8545", "end_page": 23, "mode": "hybrid", "rank": 1, "score": 0.032018442622950824, "start_page": 23, "text": "Additionally, during the third round, Classic McEliece was proposed to be added to the ISO/International Electrotechnical Commission (IEC) standard ISO/IEC 18033-2. This concurrent standardization effort remains active and ongoing.\n\nOverall assessment. NIST remains confident in the security of Classic McEliece,5 although recent progress in cryptanalysis somewhat undermines the case for treating it as an especially conservative choice. Its large public-key size makes Classic McEliece an unattractive choice for most common applications, but it offers an excellent performance profile for applications that are sensitive to ciphertext size, where public keys are rarely transmitted. NIST does not find the case for standardizing Classic McEliece compelling, due to skepticism that it will see widespread use. In the event that Classic McEliece does become widely used through other standards, and that NIST remains confident in its security while also determining that there is sufficient need, NIST may develop a NIST standard based on the widely used version."}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "end_page": 16, "mode": "hybrid", "rank": 2, "score": 0.03200204813108039, "start_page": 16, "text": "In IR 8413 [2], NIST requested feedback on specific use cases for which Classic McEliece would be a good solution. Responses noted that Classic McEliece may provide better performance than BIKE or HQC for applications in which a public key can be transferred once and then used for several encapsulations (e.g., file encryption and virtual private networks [VPNs]) due to its small ciphertext size and fast encapsulation and decapsulation. There was also some interest in Classic McEliece based on the perception that it is a conservative choice. However, the interest expressed in Classic McEliece was limited, and having more standards to implement adds complexity to protocols and PQC migration. Classic McEliece is currently under consideration for standardization by the International Organization for Standardization (ISO). Concurrent standardization of Classic McEliece by NIST and ISO risks the creation of incompatible standards. After the ISO standardization process has been completed, NIST may consider developing a standard for Classic McEliece based on the ISO standard. However, Classic McEliece is no longer under consideration for standardization as part of the current NIST PQC Standardization Process. At the end of the third round, NIST indicated its intent to standardize at most one of BIKE or HQC for use as a general-purpose KEM [2]. As specified in the Call for Proposals [22], submitted KEMs were evaluated based on how well they appear to provide IND-CCA2 security, particularly for KEMs intended for general use. While NIST has confidence in the indistinguishability under chosen-plaintext attack (IND-CPA) security of BIKE and HQC, both schemes require a sufficiently low decryption failure rate (DFR) in order to be IND-CCA2- secure. There is evidence that HQC has a sufficiently low DFR and recent work indicates that with minor modifications, BIKE achieves the same [26]. However, NIST does not consider the DFR analysis for BIKE to be as mature as that for HQC. Additionally, HQC is not believed to require additional modifications to achieve the desired security properties. Given the critical need for strong IND-CCA2 security in a general-purpose KEM, HQC was selected for standardization. In summary, NIST has only selected HQC for standardization. The algorithms that were not selected are not under consideration for standardization by NIST as part of the current NIST PQC Standardization Process."}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "end_page": 8, "mode": "hybrid", "rank": 3, "score": 0.03131881575727918, "start_page": 8, "text": "1. Introduction\n\nThe National Institute of Standards and Technology (NIST) initiated the Post-Quantum Cryptography (PQC) Standardization Process in December 2016 to select quantum-resistant public-key cryptographic algorithms for standardization in response to the substantial development and advancement of quantum computing. After three rounds of evaluation and analysis, NIST announced the selection of the first algorithms to be standardized [2]. The key encapsulation mechanism (KEM) selected for standardization was CRYSTALS-Kyber (ML-KEM [3]). The digital signatures selected were CRYSTALS-Dilithium (ML-DSA [4]), Falcon (FN-DSA), and SPHINCS+ (SLH-DSA [5]). For a detailed explanation of NIST’s choices, as well as a summary of the third round, see NIST IR 8413 [2]. In addition to those initial selections, NIST advanced four KEM candidates to the fourth round for continued evaluation: BIKE [6], Classic McEliece [7], HQC [8], and SIKE [9]. These algorithms were all based on different security assumptions than ML-KEM. NIST indicated that it would select one or two of the algorithms for standardization at the conclusion of the fourth round. The fourth round began in July 2022 and involved a thorough analysis of the theoretical and empirical evidence used to justify the security of the candidates. During this time, the submitters of SIKE acknowledged its insecurity and recommended against its further use. The submission teams of the unbroken fourth-round candidates were invited to present updates for their candidate algorithms at the Fifth NIST PQC Standardization Conference in Rockville, Maryland, on April 10-12, 2024. The submitters participated in a joint panel to discuss the candidates’ merits, and several researchers presented work that was relevant to the PQC standardization process. Throughout the fourth round, NIST received valuable feedback from the cryptographic community. Based on this feedback and internal reviews of the fourth-round candidates, NIST announced the selection of HQC in March 2025 for standardization. Table 1 shows a timeline of major events with respect to the NIST PQC Standardization Process to date."}, {"chunk_id": "NIST.IR.8545::p0011::c000", "doc_id": "NIST.IR.8545", "end_page": 11, "mode": "hybrid", "rank": 4, "score": 0.031024531024531024, "start_page": 11, "text": "2. Evaluation Criteria and Selection Process\n\n2.1. Acceptance of the Fourth-Round Candidates\nNIST selected four candidate algorithms for the fourth round, all of which were KEMs. Classic McEliece was a third-round finalist, and the other three algorithms were alternates [13].\nThe set of finalists included the algorithms that NIST considered to be the most promising to fit the majority of use cases and be ready for standardization soon after the third round.\nThe alternate candidates were regarded as potential candidates for future standardization, most likely after another round of evaluation.\nThe submission teams were allowed to make minor modifications and resubmit their packages, which had to meet the same requirements as the original submissions. The complete\nupdated specifications were posted on NIST’s PQC website [15] for public review on October 27, 2022. Most of the changes focused on fixing minor issues that were identified\nduring the third round and clarifying or simplifying the submission specification. One modification of note that occurred during the fourth round is BIKE’s decoder. The thresholds for the decoder were altered to reduce the risk of decryption failure. No major redesigns or changes were allowed.\n\nTable 2. Fourth-round KEM candidates organized by category, with the candidate selected for standardization bolded and in blue"}, {"chunk_id": "NIST.IR.8545::p0021::c001", "doc_id": "NIST.IR.8545", "end_page": 21, "mode": "hybrid", "rank": 5, "score": 0.03076923076923077, "start_page": 21, "text": "Overall assessment. NIST found that BIKE is a KEM that would complement ML-KEM well with respect to having a different underlying security problem and balanced performance characteristics. BIKE also offers smaller keys and ciphertexts than HQC. NIST reviewed several DFR analyses of BIKE, including recent results indicating that an approximate 9% increase in block size leads to a sufficiently low DFR for security level 1 parameters. Despite these promising results, NIST found the security analysis of HQC to be more mature and stable than that of BIKE. As such, NIST has not selected BIKE for standardization.\n\n3.3. Classic McEliece\nDesign. Classic McEliece is a code-based KEM that uses binary Goppa codes in the Niederreiter variant of the McEliece cryptosystem combined with standard techniques to achieve IND-CCA2 security. Due to the use of Goppa codes, the KEM has perfect correctness.4 It is a merger of the second-round submissions Classic McEliece and NTS-KEM. The original\nMcEliece cryptosystem was published in [43] and was also based on binary Goppa codes."}, {"chunk_id": "NIST.IR.8545::p0012::c000", "doc_id": "NIST.IR.8545", "end_page": 12, "mode": "hybrid", "rank": 6, "score": 0.030330882352941176, "start_page": 12, "text": "assumptions and aims to reduce the risk that a single cryptanalytic breakthrough will leave no viable standard for key establishment. In pursuit of that goal, NIST selected fourthround candidates whose security was based on computational assumptions that differ significantly from that of ML-KEM. Specifically, the candidates consisted of the isogeny-based KEM SIKE and the code-based KEMs BIKE, HQC, and Classic McEliece. See Table 2. NIST’s key-establishment standards are currently utilized in a wide variety of applications. The specific properties required for a key-establishment scheme to provide security in a given application can vary. However, in terms of formal security definitions, a single notion suffices for key-establishment schemes that are intended for general use: semantic security with respect to adaptive chosen ciphertext attacks (equivalently, IND-CCA2 security). ML-KEM is believed to satisfy IND-CCA2 security and is expected to serve as a general-purpose scheme in any application that calls for NIST-approved post-quantum keyestablishment. The formal security statuses of the fourth-round KEM candidates vary significantly. SIKE, the sole isogeny-based candidate, was broken and thus does not satisfy IND-CCA2 security [17]. The code-based candidates BIKE, HQC, and Classic McEliece are believed to satisfy IND-CCA2 security. However, NIST’s level of confidence in the IND-CCA2 security of these schemes is not equal. Notably, NIST has a higher level of confidence in the IND-CCA2 security of HQC than BIKE (see Sec. 3 for further details). Submitters to the fourth round were encouraged but not required to provide proofs of IND- CCA2 security (from clearly stated computational assumptions) in relevant models. NIST defined five security categories to compare the security strengths provided by the submissions. Submitters were asked to provide a classification of the security of the parameter sets of their schemes following the definitions provided in [16]. NIST also listed other desirable security properties, such as resistance to side-channel and multi-key attacks and resistance to misuse. Submissions were encouraged to note any additional desirable security properties that they provided. Finally, NIST required submission packages to summarize known cryptanalytic attacks on the scheme and complexity estimates for those attacks."}, {"chunk_id": "NIST.IR.8545::p0017::c000", "doc_id": "NIST.IR.8545", "end_page": 17, "mode": "hybrid", "rank": 7, "score": 0.029827662395050816, "start_page": 17, "text": "3. Summary of the Fourth-Round Candidates\n\nThis section describes each of the fourth-round candidates, including their advantages and disadvantages and why a scheme was selected for standardization or not.\nSection 3 of IR 8413[2] introduces some computational and security concepts and history\nthat might be referenced throughout the subsequent subsections. The provided information reduced redundancy, as some of the candidates’ security analyses have properties in common. The information was not intended to be an exhaustive security or literature review.\n\n3.1. HQC\nHQC (Hamming Quasi-Cyclic) is a KEM based on quasi-cyclic codes, where no trapdoor is\nhidden in the code [27]. It was designed to leverage the structural advantages of quasicyclic codes while maintaining a more direct security reduction to the problem of decoding a random linear code. Unlike the other code-based candidates, the only coding-theory\nhardness assumptions required by HQC’s security proof are parameterizations of the decisional Quasi-Cyclic Syndrome Decoding (QCSD) assumption. BIKE additionally assumes\nthe hardness of Quasi-Cyclic Codeword Finding (QCCF), and Classic McEliece requires assumptions concerning binary Goppa codes [27, 28]."}, {"chunk_id": "NIST.IR.8545::p0010::c000", "doc_id": "NIST.IR.8545", "end_page": 10, "mode": "hybrid", "rank": 8, "score": 0.029631255487269532, "start_page": 10, "text": "1.1. Purpose and Organization of This Document This report summarizes the fourth round of the NIST PQC Standardization Process. Section 2 enumerates the candidates that were included in the fourth round. It also describes the evaluation criteria and selection process used to ultimately select HQC for standardization. Section 3 summarizes each of the fourth-round candidates, including a brief description of the algorithm and its characteristics with regard to security, performance, and implementation. This section also presents the rationale for standardizing some candidate algorithms and not others. Section 4 concludes and describes the next steps in the standardization process."}], "metrics": {"at_k": {"k1": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 0.5}, "k3": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k5": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "k8": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 1.0, "ndcg_at_k": 1.0, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [1, 2, 7], "top_hit_ids": [{"chunk_id": "NIST.IR.8545::p0023::c000", "doc_id": "NIST.IR.8545", "pages": "p23-p23", "rank": 1}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "pages": "p16-p16", "rank": 2}, {"chunk_id": "NIST.IR.8545::p0008::c000", "doc_id": "NIST.IR.8545", "pages": "p8-p8", "rank": 3}, {"chunk_id": "NIST.IR.8545::p0011::c000", "doc_id": "NIST.IR.8545", "pages": "p11-p11", "rank": 4}, {"chunk_id": "NIST.IR.8545::p0021::c001", "doc_id": "NIST.IR.8545", "pages": "p21-p21", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0012::c000", "doc_id": "NIST.IR.8545", "pages": "p12-p12", "rank": 6}, {"chunk_id": "NIST.IR.8545::p0017::c000", "doc_id": "NIST.IR.8545", "pages": "p17-p17", "rank": 7}, {"chunk_id": "NIST.IR.8545::p0010::c000", "doc_id": "NIST.IR.8545", "pages": "p10-p10", "rank": 8}]}}
{"answerable": false, "gold": [], "qid": "q022", "question": "What does ABDJSDFS mean?", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "has_gold_in_primary_k": null, "hits": [{"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 1, "score": 0.01639344262295082, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 2, "score": 0.016129032258064516, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 3, "score": 0.015873015873015872, "start_page": 20, "text": "3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed.\n\nInput checking. The correct and secure operation of cryptographic operations depends crucially on the validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:"}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 4, "score": 0.015625, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "end_page": 15, "mode": "hybrid", "rank": 5, "score": 0.015384615384615385, "start_page": 15, "text": "2.2.3. Algorithm and Implementation Characteristics The Call for Proposals [22] also requested various desirable algorithm and implementation characteristics for consideration, particularly flexibility, simplicity, and ease of adoption. An important characteristic of candidates is their potential performance impact on existing widely used protocols (e.g., TLS, IPSec, and SSH) and certificates. The third round included real-world experiments to identify potential performance problems with the algorithms. These experiments continued into the fourth round with a greater focus on HQC and BIKE (see Sec. 2.2.2). NIST believes it is important to select cryptographic standards that will be capable of protecting sensitive government information as well as being widely adopted for use in industry. In selecting a cryptographic algorithm for standardization, an evaluation factor is whether a patent might hinder the adoption of a cryptographic standard. All submission teams were required to submit statements regarding knowledge of patents involving their algorithms and implementations, which are available on the NIST PQC fourth round submissions website [23]. The submitters of HQC indicated two patents that could potentially be relevant to an implementation of HQC. However, the patent owner committed and agreed to grant to any interested party on a worldwide basis a non-exclusive license for the purpose of implementing the standard without compensation and under reasonable terms and conditions that are demonstrably free of any unfair discrimination.1\n\n2.3. Selection of the Candidates for Standardization\nIn relative order of importance, NIST considered the security, cost and performance, and algorithm and implementation characteristics of the candidates in selecting what to standardize. Early in the fourth round, published cryptanalytic results demonstrated that SIKE\nwas insecure [17, 24, 25], resulting in its removal from consideration [9].\n\n1See the Statement by Patent Owner included with the HQC submission at https://csrc.nist.gov/csrc/media\n/Projects/post-quantum-cryptography/documents/round-4/final-ip-statements/HQC-Statements-Round\n4.pdf"}, {"chunk_id": "NIST.IR.8545::p0023::c000", "doc_id": "NIST.IR.8545", "end_page": 23, "mode": "hybrid", "rank": 6, "score": 0.015151515151515152, "start_page": 23, "text": "Additionally, during the third round, Classic McEliece was proposed to be added to the ISO/International Electrotechnical Commission (IEC) standard ISO/IEC 18033-2. This concurrent standardization effort remains active and ongoing.\n\nOverall assessment. NIST remains confident in the security of Classic McEliece,5 although recent progress in cryptanalysis somewhat undermines the case for treating it as an especially conservative choice. Its large public-key size makes Classic McEliece an unattractive choice for most common applications, but it offers an excellent performance profile for applications that are sensitive to ciphertext size, where public keys are rarely transmitted. NIST does not find the case for standardizing Classic McEliece compelling, due to skepticism that it will see widespread use. In the event that Classic McEliece does become widely used through other standards, and that NIST remains confident in its security while also determining that there is sufficient need, NIST may develop a NIST standard based on the widely used version."}, {"chunk_id": "NIST.SP.800-227::p0003::c000", "doc_id": "NIST.SP.800-227", "end_page": 3, "mode": "hybrid", "rank": 7, "score": 0.014925373134328358, "start_page": 3, "text": "Certain commercial equipment, instruments, software, or materials, commercial or non-commercial, are identified in this paper in order to specify the experimental procedure adequately. Such identification does not imply recommendation or endorsement of any product or service by NIST, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose. There may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST. Organizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at https://csrc.nist.gov/publications."}, {"chunk_id": "NIST.IR.8545::p0003::c000", "doc_id": "NIST.IR.8545", "end_page": 3, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 3, "text": "Certain equipment, instruments, software, or materials, commercial or non-commercial, are identified in this paper in order to specify the experimental procedure adequately. Such identification does not imply recommendation or endorsement of any product or service by NIST, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose. There may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST. Organizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at https://csrc.nist.gov/publications.\n\nNIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax"}], "metrics": null, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 4}, {"chunk_id": "NIST.IR.8545::p0015::c002", "doc_id": "NIST.IR.8545", "pages": "p15-p15", "rank": 5}, {"chunk_id": "NIST.IR.8545::p0023::c000", "doc_id": "NIST.IR.8545", "pages": "p23-p23", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0003::c000", "doc_id": "NIST.SP.800-227", "pages": "p3-p3", "rank": 7}, {"chunk_id": "NIST.IR.8545::p0003::c000", "doc_id": "NIST.IR.8545", "pages": "p3-p3", "rank": 8}]}}
{"answerable": true, "gold": [{"doc_id": "NIST.FIPS.203", "end_page": 13, "start_page": 13}], "qid": "q023", "question": "What does MLWE mean?", "retrieval": {"doc_hit_ranks": [1, 5, 8], "gold_hit_ranks": [8], "has_gold_in_primary_k": true, "hits": [{"chunk_id": "NIST.FIPS.203::p0022::c002", "doc_id": "NIST.FIPS.203", "end_page": 22, "mode": "hybrid", "rank": 1, "score": 0.032266458495966696, "start_page": 22, "text": "The computational assumption. The security of ML-KEM is based on the presumed hardness of the so-called Module Learning with Errors (MLWE) problem [9], which is a generalization of the Learning With Errors (LWE) problem introduced by Regev in 2005 [10]. The hardness of the MLWE problem is itself based on the presumed hardness of certain computational problems in module lattices [9]. This motivates the name of the scheme ML-KEM. In the LWE problem, the input is a set of random “noisy” linear equations in some secret variables x ∈ Zn, and the task is to recover x. The noise in the equations is such that standard algorithms q (e.g., Gaussian elimination) are intractable. The LWE problem naturally lends itself to cryptographic applications. For example, if x is interpreted as a secret key, then one can encrypt a one-bit plaintext value by sampling either an approximately correct linear equation (if the plaintext is zero) or a far-from-correct linear equation (if the plaintext is one). Plausibly, only a party in possession of x can distinguish these two cases. Encryption can then be delegated to another party by publishing a large collection of noisy linear equations, which can be combined appropriately by the encrypting party. The result is an asymmetric encryption scheme. The MLWE problem is similar to the LWE problem. An important difference is that, in MLWE, Zn q is replaced by a certain module Rk, which is constructed by taking the k-fold Cartesian product of a certain polynomial ring Rq . Inqparticular, the secret in the MLWE problem is an element x of the module Rk. The ring R is discussed in detail in Section 4.3. q q\n\nThe ML-KEM construction. At a high level, the construction of the scheme ML-KEM proceeds in two steps. First, the ideas discussed previously are used to construct a public-key encryption (PKE) scheme from the MLWE problem. Second, this PKE scheme is converted into a key-encapsulation\nmechanism using the so-called Fujisaki-Okamoto (FO) transform [11, 12]. Due to certain properties of the FO transform, the resulting KEM provides security in a significantly more general\nattack model than the PKE scheme. As a result, ML-KEM is believed to satisfy so-called IND-CCA2\nsecurity [1, 4, 13, 14]."}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "end_page": 43, "mode": "hybrid", "rank": 2, "score": 0.02690100430416069, "start_page": 43, "text": "quantum-vulnerable, as mentioned in Section 2.2. This KEM is not claimed to be IND-CCAsecure. In similar ways, KEMs could be constructed from RSA-OAEP-basic, as specified in Sec. 9.2.3 of SP 800-56B.\n\n5.1.3. ML-KEM ML-KEM is a high-performance, general-purpose, lattice-based key-encapsulation mechanism. It is a NIST-approved KEM and was standardized in FIPS 203 [3]. ML-KEM is based on CRYSTALS-Kyber [26], which was a candidate in the NIST PQC standardization process. It is believed to satisfy IND-CCA security (Definition 4), even against adversaries in possession of a cryptanalytically relevant quantum computer [17, 27, 28]. The asymptotic, theoretical security of ML-KEM is based on the presumed hardness of the Module Learning with Errors (MLWE) problem [29, 30]. FIPS 203 directly describes ML-KEM as a KEM in a manner that closely matches the notation of this document. Specifically, the components of ML-KEM are described in FIPS 203 as follows [3]: • ML-KEM.ParamSets. There are three parameter sets described in Sec. 8 of FIPS 203: ML-KEM-512, ML-KEM-768, and ML-KEM-1024. • ML-KEM.KeyGen. The key-generation algorithm of ML-KEM is specified as Algorithm 19 in Sec. 7.1 of FIPS 203. • ML-KEM.Encaps. The encapsulation algorithm of ML-KEM is specified as Algorithm 20 in Sec. 7.2 of FIPS 203. • ML-KEM.Decaps. The decapsulation algorithm of ML-KEM is specified as Algorithm 21 in Sec. 7.3 of FIPS 203. This document treats parameter sets as an explicit input for the KEM algorithms KeyGen, Encaps, and Decaps. By contrast, the algorithms of ML-KEM described in FIPS 203 expect the chosen parameter set to be stored in a set of global variables that are accessible to each of the algorithms of ML-KEM. This is only a difference in presentation and does not imply any particular implementation requirement."}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "end_page": 39, "mode": "hybrid", "rank": 3, "score": 0.01639344262295082, "start_page": 39, "text": "K ← KDF(K1, K2) (16)\n\nthat only uses the two shared secret keys K1 (of Π1) and K2 (of Π2) does not preserve IND-CCA security, regardless of the properties of the KDF. So, for example, the scheme Π2 could be so broken that C[Π1, Π2] is not IND-CCA, even if Π1 is IND-CCA and regardless of what KDF is used. Therefore, NIST encourages the use of key combiners that generically preserve IND-CCA security, in the sense that the combined scheme is IND-CCA, provided at least one of the ingredient KEMs is IND-CCA. One example of such a key combiner is as in (15). Let H denote a hash function from the SHA-3 family, which is approved for use in one-step key derivation in SP 800-56C [21]. Define the key combiner KeyCombineCCA as follows (recalling the notation in Sec. 4.6): H • Inputs from Π1: ek1, c1, K1 • Inputs from Π2: ek2, c2, K2 • Output: H(K1, K2, c1, c2, ek1, ek2, domain_sep) The domain separator domain_sep should be used to uniquely identify the composite scheme in use (e.g., Π1, Π2, order of composition, choice of parameter set, key combiner, KDF). As shown in [25], KeyCombineCCA preserves IND-CCA security if H is modeled as a random oracle. Note that [25] does H not incorporate encapsulation keys into the combiner, as this is not needed to achieve the IND-CCA-preserving property. However, including en-"}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 4, "score": 0.016129032258064516, "start_page": 20, "text": "Testing and validation. Mistakes in implementations can easily lead to security vulnerabilities or a loss of usability. Therefore, it is crucial that implementations are validated for conformance to NIST cryptographic standards and FIPS 140 by the Cryptographic Algorithm Validation Program (CAVP) and CMVP. Validation testing checks whether a given implementation correctly computes the desired output for only a small number of (often randomly sampled) inputs. This means that validation testing does not guarantee correct functioning on all inputs, which is often impossible to ensure. Nonetheless, implementations must correctly implement the mathematical functionality of the target KEM. As validation only tests input-output behavior, implementations need not follow the exact stepby-step algorithmic specifications in the NIST standard that specifies the relevant KEM. Any implementation that produces the correct output for every input will pass validation. Requiring equivalence only at the level of input-output functionality (e.g., rather than in terms of step-by-step behavior) is desirable, as different implementations can then be optimized for different goals. For example, some implementations will focus on maximizing efficiency, while other implementations will employ numerous side-channel and leakage protection techniques.\n\n3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed."}, {"chunk_id": "NIST.FIPS.203::p0022::c001", "doc_id": "NIST.FIPS.203", "end_page": 22, "mode": "hybrid", "rank": 5, "score": 0.015625, "start_page": 22, "text": "3.2 The ML-KEM Scheme\nML-KEM is a key-encapsulation mechanism based on CRYSTALS-KYBER [4], a scheme that was\ninitially described in [8]. The following is a brief and informal description of the computational\nassumption underlying ML-KEM and how the ML-KEM scheme is constructed.\n\nThe computational assumption. The security of ML-KEM is based on the presumed hardness of the so-called Module Learning with Errors (MLWE) problem [9], which is a generalization of the Learning With Errors (LWE) problem introduced by Regev in 2005 [10]. The hardness of the MLWE problem is itself based on the presumed hardness of certain computational problems in module lattices [9]. This motivates the name of the scheme ML-KEM. In the LWE problem, the input is a set of random “noisy” linear equations in some secret variables x ∈ Zn, and the task is to recover x. The noise in the equations is such that standard algorithms q (e.g., Gaussian elimination) are intractable. The LWE problem naturally lends itself to cryptographic applications. For example, if x is interpreted as a secret key, then one can encrypt a one-bit plaintext value by sampling either an approximately correct linear equation (if the plaintext is zero) or a far-from-correct linear equation (if the plaintext is one). Plausibly, only a party in possession of x can distinguish these two cases. Encryption can then be delegated to another party by publishing a large collection of noisy linear equations, which can be combined appropriately by the encrypting party. The result is an asymmetric encryption scheme. The MLWE problem is similar to the LWE problem. An important difference is that, in MLWE, Zn q is replaced by a certain module Rk, which is constructed by taking the k-fold Cartesian product of a certain polynomial ring Rq . Inqparticular, the secret in the MLWE problem is an element x of the module Rk. The ring R is discussed in detail in Section 4.3. q q"}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "end_page": 20, "mode": "hybrid", "rank": 6, "score": 0.015384615384615385, "start_page": 20, "text": "3.2. Managing Cryptographic Data KEM implementations need to manage all cryptographic data appropriately, including data used during the execution of KEM algorithms (i.e., intermediate values) and data at rest (e.g., decapsulation key). As a cryptographic module has no control over data that exists outside of the module (e.g., while in transit from one module to another), such data is not discussed here. However, a cryptographic module can exert control over what data it outputs to the outside world (e.g., by ensuring correct implementations of all functions). It can also exert control over what data it accepts from the outside world (e.g., by performing appropriate input-checking and importing). In general, cryptographic data needs to be destroyed as soon as it is no longer needed. Some examples include destroying intermediate computation values at the end of an algorithm, destroying the randomness generated by RBGs after encapsulation, and destroying keys after all relevant communication sessions are completed.\n\nInput checking. The correct and secure operation of cryptographic operations depends crucially on the validity of the provided inputs. Even relatively benign faults, such as accepting an input that is too long or too short, can have serious security consequences. KEM implementations need to perform input checking in an appropriate manner for all KEM algorithms (i.e., KeyGen, Encaps, and Decaps). The exact form of the required input checking is described in the FIPS or SP that specifies the relevant KEM. Sometimes, an input will not need to be checked. Instead, the implementer can acquire assurance that the input was validly generated or has already been checked, as in the following cases:"}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "end_page": 9, "mode": "hybrid", "rank": 7, "score": 0.015151515151515152, "start_page": 9, "text": "1.1. Background\nA key-establishment scheme is a set of algorithms that can be used to securely establish a shared secret key between two or more parties. Such a shared secret key can then be used to perform tasks that are suitable for symmetric-key cryptography, such as efficient confidential communication.\nMany widely deployed key-establishment schemes — including those specified in NIST Special Publication (SP) 800-56A [1] and SP 800-56B [2] — are vulnerable to cryptographic attacks that make use of a large-scale, cryptanalytically relevant quantum computer. In 2016,\nNIST initiated a process to select and standardize a set of post-quantum key-establishment schemes (i.e., key-establishment schemes that would not be vulnerable to attacks even by cryptanalytically-relevant quantum computers). In response, NIST received feedback from the cryptographic community that the post-quantum key-establishment schemes best suited for standardization and widespread deployment are key-encapsulation mechanisms (KEMs). The first KEM standard that resulted from this NIST Post-Quantum Cryptography (PQC) standardization process was ML-KEM, which is specified in Federal Information\nProcessing Standards (FIPS) publication 203 [3].\nAt the time of the standardization of ML-KEM, NIST had not provided extensive guidelines on the basic definitions, properties, and applications of KEMs. This recommendation is meant to provide these guidelines, supplement the current and future standardization of KEMs, and provide recommendations for implementing and using KEMs in a secure manner.\n\n1.2. Scope and Purpose\nThis recommendation provides guidelines on the basic definitions, properties, and applications of KEMs; supplements the current and future standardization of KEMs; and makes some requirements and recommendations for implementing and using KEMs in FIPS 140- validated cryptographic modules. This recommendation also provides guidelines for vendors who wish to securely combine keying material produced via approved post-quantum methods with keying material produced via other (potentially quantum-vulnerable) methods.\nThis recommendation does not discuss how or when to migrate from quantum-vulnerable\nkey-establishment procedures to post-quantum KEMs (see [4]), nor does it provide a specification for any particular KEM. Such specifications will be provided in a FIPS or an SP, such\nas the specification of ML-KEM in FIPS 203 [3].\nThis recommendation includes explanatory and educational material to aid in the general understanding of KEMs. While SPs typically only include material that pertains to what is"}, {"chunk_id": "NIST.FIPS.203::p0013::c001", "doc_id": "NIST.FIPS.203", "end_page": 13, "mode": "hybrid", "rank": 8, "score": 0.014925373134328358, "start_page": 13, "text": "public-key A set of three cryptographic algorithms (KeyGen, Encrypt, and Decrypt) encryption scheme that can be used by two parties to send secret data over a public channel. (PKE) Also known as an asymmetric encryption scheme. shared secret A secret value that has been computed during a key-establishment scheme, is known by both participants, and is used as input to a key- derivation method to produce keying material. shared secret key A shared secret that can be used directly as a cryptographic key in symmetric-key cryptography. It does not require additional key deriva- tion. The shared secret key must be kept private and must be destroyed when no longer needed. security category A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST (see [7]). security strength A number associated with the amount of work (i.e., the number of op- erations) that is required to break a cryptographic algorithm or system. shall Used to indicate a requirement of this standard. should Used to indicate a strong recommendation but not a requirement of this standard. Ignoring the recommendation could lead to undesirable results.\n\n2.2 Acronyms AES Advanced Encryption Standard CBD Centered Binomial Distribution FIPS Federal Information Processing Standard KEM Key-Encapsulation Mechanism LWE Learning with Errors MLWE Module Learning with Errors NIST National Institute of Standards and Technology NISTIR NIST Interagency or Internal Report NTT Number-Theoretic Transform PKE Public-Key Encryption PQC Post-Quantum Cryptography PRF Pseudorandom Function RBG Random Bit Generator SHA Secure Hash Algorithm"}], "metrics": {"at_k": {"k1": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k3": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k5": {"mrr_at_k": 0.0, "ndcg_at_k": 0.0, "recall_at_k": 0.0}, "k8": {"mrr_at_k": 0.125, "ndcg_at_k": 0.31546487678572877, "recall_at_k": 1.0}}, "primary": {"mrr_at_k": 0.125, "ndcg_at_k": 0.31546487678572877, "recall_at_k": 1.0}, "primary_k": 8}, "near_page_hit_ranks": [8], "top_hit_ids": [{"chunk_id": "NIST.FIPS.203::p0022::c002", "doc_id": "NIST.FIPS.203", "pages": "p22-p22", "rank": 1}, {"chunk_id": "NIST.SP.800-227::p0043::c000", "doc_id": "NIST.SP.800-227", "pages": "p43-p43", "rank": 2}, {"chunk_id": "NIST.SP.800-227::p0039::c001", "doc_id": "NIST.SP.800-227", "pages": "p39-p39", "rank": 3}, {"chunk_id": "NIST.SP.800-227::p0020::c001", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 4}, {"chunk_id": "NIST.FIPS.203::p0022::c001", "doc_id": "NIST.FIPS.203", "pages": "p22-p22", "rank": 5}, {"chunk_id": "NIST.SP.800-227::p0020::c002", "doc_id": "NIST.SP.800-227", "pages": "p20-p20", "rank": 6}, {"chunk_id": "NIST.SP.800-227::p0009::c001", "doc_id": "NIST.SP.800-227", "pages": "p9-p9", "rank": 7}, {"chunk_id": "NIST.FIPS.203::p0013::c001", "doc_id": "NIST.FIPS.203", "pages": "p13-p13", "rank": 8}]}}
{"answerable": false, "gold": [], "qid": "q024", "question": "What hardware does PQC standard require?", "retrieval": {"doc_hit_ranks": [], "gold_hit_ranks": [], "has_gold_in_primary_k": null, "hits": [{"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 13, "mode": "hybrid", "rank": 1, "score": 0.03252247488101534, "start_page": 13, "text": "244 These libraries need to incorporate PQC algorithms that are standardized by bodies like NIST. 245 Updating them ensures that developers have access to quantum-resistant cryptographic 246 functions without implementing complex algorithms themselves. This transition involves adding 247 new algorithms, optimizing their implementations for performance, and ensuring those 248 implementations are secure against side-channel attacks.\n\n249 2.2.3. Cryptographic Hardware 250 Cryptographic hardware modules, such as hardware security modules (HSMs) and Trusted 251 Platform Modules (TPMs), provide secure environments for performing cryptographic 252 operations and storing sensitive keys. They are used in various applications, from securing 253 server infrastructure to protecting cryptographic keys on personal devices. 254 Hardware modules must be upgraded or redesigned to support PQC algorithms, which often 255 have larger key sizes and different computational requirements. This includes updating 256 firmware or hardware to handle new algorithms and ensuring that the modules can perform 257 quantum-resistant cryptographic operations efficiently while maintaining the high security 258 standards expected of these devices."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 2, "score": 0.031054405392392875, "start_page": 12, "text": "215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms.\n\n226 2.2.1. Network Protocol and Security Technology Standards 227 Network protocols and security technology standards define the rules for data exchange over 228 networks and ensure secure and reliable communication. Examples include Transport Layer 229 Security (TLS), Secure Shell (SSH), Internet Protocol Security (IPsec), and Cryptographic Message 230 Syntax (CMS). 231 These protocols and security technologies often rely on classical cryptographic algorithms that 232 are vulnerable to quantum attacks. Updating them to incorporate PQC algorithms is essential to 233 maintaining data confidentiality and integrity. This involves revising protocol specifications to 234 support new key exchange mechanisms and authentication methods that are quantum- 235 resistant. In some cases, this will involve simply assigning an identifier for the new algorithm. In 236 other cases, more significant changes will be required to accommodate the larger sizes of the 237 PQC algorithms or as a result of the new algorithms having different interfaces."}, {"chunk_id": "NIST.IR.8547.ipd::p0015::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 15, "mode": "hybrid", "rank": 3, "score": 0.029437229437229435, "start_page": 15, "text": "317 systems may continue to use quantum-vulnerable algorithms until quantum computers that are 318 capable of breaking current, quantum-vulnerable algorithms become available, at which point 319 authentication using these algorithms will need to be disabled. 320 Supporting quantum-resistant algorithms for authentication will require upgrades to both the 321 system performing and accepting the authentication, as well as to any supporting 322 infrastructure, such as a PKI. It may also require obtaining hardware cryptographic tokens that 323 support the quantum-resistant algorithms."}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "end_page": 16, "mode": "hybrid", "rank": 4, "score": 0.028612012987012988, "start_page": 16, "text": "In IR 8413 [2], NIST requested feedback on specific use cases for which Classic McEliece would be a good solution. Responses noted that Classic McEliece may provide better performance than BIKE or HQC for applications in which a public key can be transferred once and then used for several encapsulations (e.g., file encryption and virtual private networks [VPNs]) due to its small ciphertext size and fast encapsulation and decapsulation. There was also some interest in Classic McEliece based on the perception that it is a conservative choice. However, the interest expressed in Classic McEliece was limited, and having more standards to implement adds complexity to protocols and PQC migration. Classic McEliece is currently under consideration for standardization by the International Organization for Standardization (ISO). Concurrent standardization of Classic McEliece by NIST and ISO risks the creation of incompatible standards. After the ISO standardization process has been completed, NIST may consider developing a standard for Classic McEliece based on the ISO standard. However, Classic McEliece is no longer under consideration for standardization as part of the current NIST PQC Standardization Process. At the end of the third round, NIST indicated its intent to standardize at most one of BIKE or HQC for use as a general-purpose KEM [2]. As specified in the Call for Proposals [22], submitted KEMs were evaluated based on how well they appear to provide IND-CCA2 security, particularly for KEMs intended for general use. While NIST has confidence in the indistinguishability under chosen-plaintext attack (IND-CPA) security of BIKE and HQC, both schemes require a sufficiently low decryption failure rate (DFR) in order to be IND-CCA2- secure. There is evidence that HQC has a sufficiently low DFR and recent work indicates that with minor modifications, BIKE achieves the same [26]. However, NIST does not consider the DFR analysis for BIKE to be as mature as that for HQC. Additionally, HQC is not believed to require additional modifications to achieve the desired security properties. Given the critical need for strong IND-CCA2 security in a general-purpose KEM, HQC was selected for standardization. In summary, NIST has only selected HQC for standardization. The algorithms that were not selected are not under consideration for standardization by NIST as part of the current NIST PQC Standardization Process."}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "end_page": 12, "mode": "hybrid", "rank": 5, "score": 0.01639344262295082, "start_page": 12, "text": "209 • Key derivation 210 • Key wrapping 211 • Random bit generation 212 As discussed in Sec. 4.1.3, the existing algorithm standards for symmetric cryptography are less 213 vulnerable to attacks by quantum computers. NIST does not expect to need to transition away 214 from these standards as part of the PQC migration.\n\n215 2.2. Cryptographic Technologies and Components 216 Once PQC algorithms have been standardized, applications will need to be modified to make 217 use of them. Many applications include components that are based on standardized protocols 218 and security technologies that will need to be revised to support the use of the PQC algorithms. 219 In addition, applications are built on top of software cryptographic libraries that either provide 220 the implementations of the cryptographic algorithms or provide an interface to hardware 221 cryptographic modules. Any software cryptographic libraries and hardware cryptographic 222 modules used by an application will also need to be revised to support the PQC algorithms. 223 Applications may also rely upon infrastructure components, such as public key infrastructures 224 (PKI), that would need to be updated to support the PQC algorithms before the applications 225 themselves can migrate to using the PQC algorithms."}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c001", "doc_id": "NIST.IR.8547.ipd", "end_page": 13, "mode": "hybrid", "rank": 6, "score": 0.015873015873015872, "start_page": 13, "text": "249 2.2.3. Cryptographic Hardware 250 Cryptographic hardware modules, such as hardware security modules (HSMs) and Trusted 251 Platform Modules (TPMs), provide secure environments for performing cryptographic 252 operations and storing sensitive keys. They are used in various applications, from securing 253 server infrastructure to protecting cryptographic keys on personal devices. 254 Hardware modules must be upgraded or redesigned to support PQC algorithms, which often 255 have larger key sizes and different computational requirements. This includes updating 256 firmware or hardware to handle new algorithms and ensuring that the modules can perform 257 quantum-resistant cryptographic operations efficiently while maintaining the high security 258 standards expected of these devices.\n\n259 2.2.4. PKI and Other Infrastructure Components 260 Public key infrastructure (PKI) systems manage digital certificates and public-private key pairs to 261 enable secure communication and authentication across networks. Other infrastructure 262 components include certification authorities (CAs), registration authorities, key management 263 systems, and directory services. 264 PKI components must be updated to issue, distribute, and manage certificates that use PQC 265 algorithms and to sign certificates and revocation status information using PQC algorithms. This 266 includes supporting new cryptographic algorithms in certificate issuance processes and 267 modifying validation and revocation mechanisms. Ensuring backward compatibility and 268 interoperability during the transition period is crucial to maintaining trust and security across 269 the network."}, {"chunk_id": "NIST.FIPS.203::p0013::c001", "doc_id": "NIST.FIPS.203", "end_page": 13, "mode": "hybrid", "rank": 7, "score": 0.015384615384615385, "start_page": 13, "text": "public-key A set of three cryptographic algorithms (KeyGen, Encrypt, and Decrypt) encryption scheme that can be used by two parties to send secret data over a public channel. (PKE) Also known as an asymmetric encryption scheme. shared secret A secret value that has been computed during a key-establishment scheme, is known by both participants, and is used as input to a key- derivation method to produce keying material. shared secret key A shared secret that can be used directly as a cryptographic key in symmetric-key cryptography. It does not require additional key deriva- tion. The shared secret key must be kept private and must be destroyed when no longer needed. security category A number associated with the security strength of a post-quantum cryptographic algorithm, as specified by NIST (see [7]). security strength A number associated with the amount of work (i.e., the number of op- erations) that is required to break a cryptographic algorithm or system. shall Used to indicate a requirement of this standard. should Used to indicate a strong recommendation but not a requirement of this standard. Ignoring the recommendation could lead to undesirable results.\n\n2.2 Acronyms AES Advanced Encryption Standard CBD Centered Binomial Distribution FIPS Federal Information Processing Standard KEM Key-Encapsulation Mechanism LWE Learning with Errors MLWE Module Learning with Errors NIST National Institute of Standards and Technology NISTIR NIST Interagency or Internal Report NTT Number-Theoretic Transform PKE Public-Key Encryption PQC Post-Quantum Cryptography PRF Pseudorandom Function RBG Random Bit Generator SHA Secure Hash Algorithm"}, {"chunk_id": "NIST.FIPS.204::p0005::c000", "doc_id": "NIST.FIPS.204", "end_page": 5, "mode": "hybrid", "rank": 8, "score": 0.014705882352941176, "start_page": 5, "text": "7. Applications. A digital signature algorithm allows an entity to authenticate the integrity of signed data and the identity of the signatory. The recipient of a signed message can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation since the signatory cannot easily repudiate the signature at a later time. A digital signature algorithm is intended for use in electronic mail, electronic funds transfer, electronic data interchange, software distribution, data storage, and other applications that require data integrity assurance and data origin authentication. 8. Implementations. A digital signature algorithm may be implemented in software, firmware, hardware, or any combination thereof. NIST will develop a validation program to test implementations for conformance to the algorithm in this standard. For every computational procedure that is specified in this standard, a conforming implementation may replace the given set of steps with any mathematically equivalent set of steps. In other words, different procedures that produce the correct output for every input are permitted. Information about validation programs is available at https://csrc.nist.gov/projects/cmvp. Examples for digital signature algorithms are available at https://csrc.nist.gov/projects/cryptographic-standards -and-guidelines/example-values. Agencies are advised that digital signature key pairs shall not be used for other purposes. 9. Other Approved Security Functions. Digital signature implementations that comply with this standard shall employ cryptographic algorithms that have been approved for protecting Federal Government- sensitive information. Approved cryptographic algorithms and techniques include those that are either: a. Specified in a Federal Information Processing Standards (FIPS) publication, b. Adopted in a FIPS or NIST recommendation, or c. Specified in the list of approved security functions in SP 800-140C. 10. Export Control. Certain cryptographic devices and technical data regarding them are subject to federal export controls. Exports of cryptographic modules that implement this standard and technical data regarding them must comply with these federal regulations and be licensed by the Bureau of Industry and Security of the U.S. Department of Commerce. Information about export regulations is available at https://www.bis.doc.gov. 11. Patents. The algorithm in this standard may be covered by U.S. or foreign patents. 12. Implementation Schedule. This standard becomes effective immediately upon final publication. 13. Specifications. Federal Information Processing Standards (FIPS) 204, Module-Lattice-Based Digital Signature Standard (affixed). 14. Qualifications. The security of a digital signature system depends on maintaining the secrecy of the signatory’s private keys. Signatories shall, therefore, guard against the disclosure of their private keys. While it is the intent of this standard to specify general security requirements for generating digital signatures, conformance to this standard does not ensure that a particular implementation is secure. It is the responsibility of an implementer to ensure that any module that implements a digital signature capability is designed and built in a secure manner. Similarly, the use of a product containing an implementation that conforms to this standard does not guarantee the security of the overall system in which the product is used. The responsible authority in each agency or department shall ensure that an overall implementation provides an acceptable level of security. ii"}], "metrics": null, "near_page_hit_ranks": [], "top_hit_ids": [{"chunk_id": "NIST.IR.8547.ipd::p0013::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p13-p13", "rank": 1}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 2}, {"chunk_id": "NIST.IR.8547.ipd::p0015::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p15-p15", "rank": 3}, {"chunk_id": "NIST.IR.8545::p0016::c000", "doc_id": "NIST.IR.8545", "pages": "p16-p16", "rank": 4}, {"chunk_id": "NIST.IR.8547.ipd::p0012::c000", "doc_id": "NIST.IR.8547.ipd", "pages": "p12-p12", "rank": 5}, {"chunk_id": "NIST.IR.8547.ipd::p0013::c001", "doc_id": "NIST.IR.8547.ipd", "pages": "p13-p13", "rank": 6}, {"chunk_id": "NIST.FIPS.203::p0013::c001", "doc_id": "NIST.FIPS.203", "pages": "p13-p13", "rank": 7}, {"chunk_id": "NIST.FIPS.204::p0005::c000", "doc_id": "NIST.FIPS.204", "pages": "p5-p5", "rank": 8}]}}
